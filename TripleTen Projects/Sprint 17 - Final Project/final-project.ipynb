{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Part 1: Project Workplan"]},{"cell_type":"markdown","metadata":{},"source":["**The aim of our project is to predict churn rates* for our customer, Interconnect.**\n","- From our results/final report, the company will be better prepared when it comes to forecasting which clients are in a higher likelihood of disconneting their services (which more than likely is to a competitor with more enticing perks).\n","\n","\n","- Interconnect will then plan on offering a larger scope of benefits to those clients in danger of turning over. This may also prove particularly useful in its market share battle against its competitors as the telecomm industry sprints to expand their perks each year as new cell phones come out (a constant cycle).\n","\n","-----\n","\n","`Step 1 - Initialization`\n","- Import all required and prospective libraries that will be leveraged in future stages of the project.\n","\n","\n","- Download the data and briefly inspect each DataFrame structure.\n","\n","`Step 2 - Preprocessing & EDA`\n","- Determine the necessary process to clean and massage the data.\n","\n","\n","- Create short, concise summaries on each DataFrame along with visualizations (plots) for thought organization and guidance.\n","\n","\n","- Perform EDA, including but not limited to: dtype and naming revisions, class balancing, value scaling, feature engineering, encoding and merging.\n"," - Fill in any gaps due to changes made to the DataFrame(s).\n","\n","\n","- Deploy time series tools/analysis to get a sense of trends and seasonality to paint a more complete picture.\n","\n","`Step 3 - Model Selection, Training and Fine-Tuning`\n","- Select various models based on the goal, binary classification. Compare initial scoring performance across the model selections, incorporate a dummy model benchmark.\n","\n","\n","- Fine-tune models using hyperparameters and gridsearches. Include gradient boosting techniques. \n","\n","`Step 4 - Model Evaluation`\n","- Decide on the optimal model based on cross comparisons and boosting techniques. Perform model evaluation based on a new set of data (test dataset) and document results. \n","\n","\n","- If statisfactory, record why the model was selected, its results (along with speed and accuracy insights) and what needs to be done in order to monitor/manage the model in a go-forward basis.\n","\n","`Step 5 - Comprehensive Report`\n","- Create an extensive report on the process/steps taken, the results and the overall recommendations.\n"," - Illustrate findings/results incorporating 'quick hits' or 'highlights' so the customer has a better handle on the report and can easily share internally.\n","\n","\n","\n","\n","--------\n","\n","**The churn rate measures a company's loss in subscribers for a given period of time. The cost of acquiring new customers is much higher than it is to retain current customers.*"]},{"cell_type":"markdown","metadata":{},"source":["-----------"]},{"cell_type":"markdown","metadata":{},"source":["# Part 2: Solution Code"]},{"cell_type":"markdown","metadata":{},"source":["# Initialization"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-12-01T00:01:09.452543Z","iopub.status.busy":"2023-12-01T00:01:09.451781Z","iopub.status.idle":"2023-12-01T00:01:09.464746Z","shell.execute_reply":"2023-12-01T00:01:09.463770Z","shell.execute_reply.started":"2023-12-01T00:01:09.452511Z"},"trusted":true},"outputs":[],"source":["def warn(*args, **kwargs): # attempt at removing warnings\n","    pass\n","import warnings\n","warnings.warn = warn\n","\n","warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n","warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n","warnings.filterwarnings(\"ignore\", category=FutureWarning) \n","warnings.filterwarnings(\"ignore\", category=UserWarning) \n","\n","from warnings import simplefilter\n","simplefilter(action='ignore', category=FutureWarning)"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-12-01T00:01:09.466923Z","iopub.status.busy":"2023-12-01T00:01:09.466547Z","iopub.status.idle":"2023-12-01T00:01:16.067426Z","shell.execute_reply":"2023-12-01T00:01:16.066500Z","shell.execute_reply.started":"2023-12-01T00:01:09.466895Z"},"trusted":true},"outputs":[{"data":{"text/html":["        <script type=\"text/javascript\">\n","        window.PlotlyConfig = {MathJaxConfig: 'local'};\n","        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n","        if (typeof require !== 'undefined') {\n","        require.undef(\"plotly\");\n","        requirejs.config({\n","            paths: {\n","                'plotly': ['https://cdn.plot.ly/plotly-2.27.0.min']\n","            }\n","        });\n","        require(['plotly'], function(Plotly) {\n","            window._Plotly = Plotly;\n","        });\n","        }\n","        </script>\n","        "]},"metadata":{},"output_type":"display_data"}],"source":["# common libraries\n","import pandas as pd\n","import numpy as np\n","from functools import reduce\n","from numpy import unique\n","\n","# other libraries\n","# from scipy.stats import randint as \n","\n","# viz libraries\n","import plotly.express as px\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","px.defaults.template = \"plotly_white\"\n","import plotly.graph_objects as go\n","from plotly.subplots import make_subplots\n","# import plotly.figure_factory as ff\n","from plotly.offline import init_notebook_mode, iplot, plot\n","init_notebook_mode(connected=True)\n","# import pygwalker as pyg # leveraging once DFs are merged\n","\n","# sklearn\n","from sklearn.metrics import roc_auc_score, f1_score\n","from sklearn.metrics import confusion_matrix, classification_report, precision_recall_curve, accuracy_score, ConfusionMatrixDisplay, auc, roc_curve\n","from sklearn.linear_model import LogisticRegression, RidgeClassifier\n","from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n","from sklearn.model_selection import train_test_split, RandomizedSearchCV, TimeSeriesSplit, cross_val_score\n","from sklearn.utils import shuffle, resample\n","from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.dummy import DummyClassifier\n","from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n","from sklearn.pipeline import Pipeline\n","from sklearn.model_selection import KFold, StratifiedKFold, RepeatedStratifiedKFold\n","from sklearn.calibration import calibration_curve, CalibrationDisplay\n","from sklearn.neighbors import KNeighborsClassifier\n","\n","# gradient boosting\n","import lightgbm as lgb\n","import xgboost as xgb\n","\n","# other\n","import os\n","os.environ['OPENBLAS_NUM_THREADS'] = '1'"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-12-01T00:01:16.069338Z","iopub.status.busy":"2023-12-01T00:01:16.069046Z","iopub.status.idle":"2023-12-01T00:01:16.166613Z","shell.execute_reply":"2023-12-01T00:01:16.165661Z","shell.execute_reply.started":"2023-12-01T00:01:16.069312Z"},"trusted":true},"outputs":[],"source":["try:\n","    contract_data = pd.read_csv('/kaggle/input/final-provider/contract.csv') # index_col=[0], parse_dates=[0]\n","    personal_data = pd.read_csv('/kaggle/input/final-provider/personal.csv') \n","    internet_data = pd.read_csv('/kaggle/input/final-provider/internet.csv') \n","    phone_data = pd.read_csv('/kaggle/input/final-provider/phone.csv') \n","except:\n","    contract_data = pd.read_csv('/Users/dani/Data Science/TripleTen Projects/Project Data/Final Project/contract.csv') # index_col=[0], parse_dates=[0]\n","    personal_data = pd.read_csv('/Users/dani/Data Science/TripleTen Projects/Project Data/Final Project/personal.csv') \n","    internet_data = pd.read_csv('/Users/dani/Data Science/TripleTen Projects/Project Data/Final Project/internet.csv') \n","    phone_data = pd.read_csv('/Users/dani/Data Science/TripleTen Projects/Project Data/Final Project/phone.csv') "]},{"cell_type":"markdown","metadata":{},"source":["-----------"]},{"cell_type":"markdown","metadata":{},"source":["# Exploratory Data Analysis"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-12-01T00:01:16.168419Z","iopub.status.busy":"2023-12-01T00:01:16.168112Z","iopub.status.idle":"2023-12-01T00:01:16.172765Z","shell.execute_reply":"2023-12-01T00:01:16.171720Z","shell.execute_reply.started":"2023-12-01T00:01:16.168393Z"},"trusted":true},"outputs":[],"source":["encoder = LabelEncoder() "]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-12-01T00:01:16.176302Z","iopub.status.busy":"2023-12-01T00:01:16.175779Z","iopub.status.idle":"2023-12-01T00:01:16.188455Z","shell.execute_reply":"2023-12-01T00:01:16.187339Z","shell.execute_reply.started":"2023-12-01T00:01:16.176263Z"},"trusted":true},"outputs":[],"source":["# to bypass limitations and encode multiple columns\n","class MultiColumnLabelEncoder:\n","    def __init__(self,columns = None):\n","        self.columns = columns # column names to encode\n","\n","    def fit(self,X,y=None):\n","        return self \n","\n","    def transform(self,X):\n","        '''\n","        Transforms columns of X specified in self.columns using\n","        LabelEncoder(). If no columns specified, transforms all\n","        columns in X.\n","        '''\n","        output = X.copy()\n","        if self.columns is not None:\n","            for col in self.columns:\n","                output[col] = LabelEncoder().fit_transform(output[col])\n","        else:\n","            for colname,col in output.iteritems():\n","                output[colname] = LabelEncoder().fit_transform(col)\n","        return output\n","\n","    def fit_transform(self,X,y=None):\n","        return self.fit(X,y).transform(X)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# function to classify features\n","def classify_features(df):\n","    categorical_features = []\n","    non_categorical_features = []\n","    discrete_features = []\n","    continuous_features = []\n","\n","    for column in df.columns:\n","        if df[column].dtype in ['object', 'bool', 'category']: \n","            if df[column].nunique() < 15:\n","                categorical_features.append(column)\n","            else: \n","                non_categorical_features.append(column)\n","        elif df[column].dtype in ['int64', 'float64']:\n","            if df[column].nunique() < 10:\n","                discrete_features.append(column)\n","            else: \n","                continuous_features.append(column)\n","    return categorical_features, non_categorical_features, discrete_features, continuous_features"]},{"cell_type":"markdown","metadata":{},"source":["-----------"]},{"cell_type":"markdown","metadata":{},"source":["# Contract data"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-12-01T00:01:16.190169Z","iopub.status.busy":"2023-12-01T00:01:16.189761Z","iopub.status.idle":"2023-12-01T00:01:16.228222Z","shell.execute_reply":"2023-12-01T00:01:16.227238Z","shell.execute_reply.started":"2023-12-01T00:01:16.190139Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 7043 entries, 0 to 7042\n","Data columns (total 8 columns):\n"," #   Column            Non-Null Count  Dtype  \n","---  ------            --------------  -----  \n"," 0   customerID        7043 non-null   object \n"," 1   BeginDate         7043 non-null   object \n"," 2   EndDate           7043 non-null   object \n"," 3   Type              7043 non-null   object \n"," 4   PaperlessBilling  7043 non-null   object \n"," 5   PaymentMethod     7043 non-null   object \n"," 6   MonthlyCharges    7043 non-null   float64\n"," 7   TotalCharges      7043 non-null   object \n","dtypes: float64(1), object(7)\n","memory usage: 440.3+ KB\n"]}],"source":["contract_data.info()"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Categorical Features: ['EndDate', 'Type', 'PaperlessBilling', 'PaymentMethod']\n","Non-Categorical Features: ['customerID', 'BeginDate', 'TotalCharges']\n","Discrete Features: []\n","Continuous Features: ['MonthlyCharges']\n"]}],"source":["categorical, non_categorical, discrete, continuous = classify_features(contract_data)\n","\n","print(\"Categorical Features:\", categorical)\n","print(\"Non-Categorical Features:\", non_categorical)\n","print(\"Discrete Features:\", discrete)\n","print(\"Continuous Features:\", continuous)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-12-01T00:01:16.229899Z","iopub.status.busy":"2023-12-01T00:01:16.229534Z","iopub.status.idle":"2023-12-01T00:01:16.249827Z","shell.execute_reply":"2023-12-01T00:01:16.248847Z","shell.execute_reply.started":"2023-12-01T00:01:16.229869Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>MonthlyCharges</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>7043.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>64.761692</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>30.090047</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>18.250000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>35.500000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>70.350000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>89.850000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>118.750000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       MonthlyCharges\n","count     7043.000000\n","mean        64.761692\n","std         30.090047\n","min         18.250000\n","25%         35.500000\n","50%         70.350000\n","75%         89.850000\n","max        118.750000"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["contract_data.describe()"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-12-01T00:01:16.251631Z","iopub.status.busy":"2023-12-01T00:01:16.251230Z","iopub.status.idle":"2023-12-01T00:01:16.266840Z","shell.execute_reply":"2023-12-01T00:01:16.265843Z","shell.execute_reply.started":"2023-12-01T00:01:16.251595Z"},"trusted":true},"outputs":[{"data":{"text/plain":["customerID          0\n","BeginDate           0\n","EndDate             0\n","Type                0\n","PaperlessBilling    0\n","PaymentMethod       0\n","MonthlyCharges      0\n","TotalCharges        0\n","dtype: int64"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["contract_data.isna().sum()"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-12-01T00:01:16.268495Z","iopub.status.busy":"2023-12-01T00:01:16.268149Z","iopub.status.idle":"2023-12-01T00:01:16.288021Z","shell.execute_reply":"2023-12-01T00:01:16.286925Z","shell.execute_reply.started":"2023-12-01T00:01:16.268467Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>customerID</th>\n","      <th>BeginDate</th>\n","      <th>EndDate</th>\n","      <th>Type</th>\n","      <th>PaperlessBilling</th>\n","      <th>PaymentMethod</th>\n","      <th>MonthlyCharges</th>\n","      <th>TotalCharges</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>7590-VHVEG</td>\n","      <td>2020-01-01</td>\n","      <td>No</td>\n","      <td>Month-to-month</td>\n","      <td>Yes</td>\n","      <td>Electronic check</td>\n","      <td>29.85</td>\n","      <td>29.85</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5575-GNVDE</td>\n","      <td>2017-04-01</td>\n","      <td>No</td>\n","      <td>One year</td>\n","      <td>No</td>\n","      <td>Mailed check</td>\n","      <td>56.95</td>\n","      <td>1889.5</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3668-QPYBK</td>\n","      <td>2019-10-01</td>\n","      <td>2019-12-01 00:00:00</td>\n","      <td>Month-to-month</td>\n","      <td>Yes</td>\n","      <td>Mailed check</td>\n","      <td>53.85</td>\n","      <td>108.15</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>7795-CFOCW</td>\n","      <td>2016-05-01</td>\n","      <td>No</td>\n","      <td>One year</td>\n","      <td>No</td>\n","      <td>Bank transfer (automatic)</td>\n","      <td>42.30</td>\n","      <td>1840.75</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>9237-HQITU</td>\n","      <td>2019-09-01</td>\n","      <td>2019-11-01 00:00:00</td>\n","      <td>Month-to-month</td>\n","      <td>Yes</td>\n","      <td>Electronic check</td>\n","      <td>70.70</td>\n","      <td>151.65</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7038</th>\n","      <td>6840-RESVB</td>\n","      <td>2018-02-01</td>\n","      <td>No</td>\n","      <td>One year</td>\n","      <td>Yes</td>\n","      <td>Mailed check</td>\n","      <td>84.80</td>\n","      <td>1990.5</td>\n","    </tr>\n","    <tr>\n","      <th>7039</th>\n","      <td>2234-XADUH</td>\n","      <td>2014-02-01</td>\n","      <td>No</td>\n","      <td>One year</td>\n","      <td>Yes</td>\n","      <td>Credit card (automatic)</td>\n","      <td>103.20</td>\n","      <td>7362.9</td>\n","    </tr>\n","    <tr>\n","      <th>7040</th>\n","      <td>4801-JZAZL</td>\n","      <td>2019-03-01</td>\n","      <td>No</td>\n","      <td>Month-to-month</td>\n","      <td>Yes</td>\n","      <td>Electronic check</td>\n","      <td>29.60</td>\n","      <td>346.45</td>\n","    </tr>\n","    <tr>\n","      <th>7041</th>\n","      <td>8361-LTMKD</td>\n","      <td>2019-07-01</td>\n","      <td>2019-11-01 00:00:00</td>\n","      <td>Month-to-month</td>\n","      <td>Yes</td>\n","      <td>Mailed check</td>\n","      <td>74.40</td>\n","      <td>306.6</td>\n","    </tr>\n","    <tr>\n","      <th>7042</th>\n","      <td>3186-AJIEK</td>\n","      <td>2014-08-01</td>\n","      <td>No</td>\n","      <td>Two year</td>\n","      <td>Yes</td>\n","      <td>Bank transfer (automatic)</td>\n","      <td>105.65</td>\n","      <td>6844.5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7043 rows × 8 columns</p>\n","</div>"],"text/plain":["      customerID   BeginDate              EndDate            Type  \\\n","0     7590-VHVEG  2020-01-01                   No  Month-to-month   \n","1     5575-GNVDE  2017-04-01                   No        One year   \n","2     3668-QPYBK  2019-10-01  2019-12-01 00:00:00  Month-to-month   \n","3     7795-CFOCW  2016-05-01                   No        One year   \n","4     9237-HQITU  2019-09-01  2019-11-01 00:00:00  Month-to-month   \n","...          ...         ...                  ...             ...   \n","7038  6840-RESVB  2018-02-01                   No        One year   \n","7039  2234-XADUH  2014-02-01                   No        One year   \n","7040  4801-JZAZL  2019-03-01                   No  Month-to-month   \n","7041  8361-LTMKD  2019-07-01  2019-11-01 00:00:00  Month-to-month   \n","7042  3186-AJIEK  2014-08-01                   No        Two year   \n","\n","     PaperlessBilling              PaymentMethod  MonthlyCharges TotalCharges  \n","0                 Yes           Electronic check           29.85        29.85  \n","1                  No               Mailed check           56.95       1889.5  \n","2                 Yes               Mailed check           53.85       108.15  \n","3                  No  Bank transfer (automatic)           42.30      1840.75  \n","4                 Yes           Electronic check           70.70       151.65  \n","...               ...                        ...             ...          ...  \n","7038              Yes               Mailed check           84.80       1990.5  \n","7039              Yes    Credit card (automatic)          103.20       7362.9  \n","7040              Yes           Electronic check           29.60       346.45  \n","7041              Yes               Mailed check           74.40        306.6  \n","7042              Yes  Bank transfer (automatic)          105.65       6844.5  \n","\n","[7043 rows x 8 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["display(contract_data)"]},{"cell_type":"markdown","metadata":{},"source":["`Preprocessing`"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-12-01T00:01:16.290000Z","iopub.status.busy":"2023-12-01T00:01:16.289422Z","iopub.status.idle":"2023-12-01T00:01:16.458983Z","shell.execute_reply":"2023-12-01T00:01:16.457771Z","shell.execute_reply.started":"2023-12-01T00:01:16.289959Z"},"trusted":true},"outputs":[{"data":{"text/plain":["[' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","Index: 7032 entries, 0 to 7042\n","Data columns (total 8 columns):\n"," #   Column             Non-Null Count  Dtype         \n","---  ------             --------------  -----         \n"," 0   customer_id        7032 non-null   object        \n"," 1   begin_date         7032 non-null   datetime64[ns]\n"," 2   end_date           7032 non-null   object        \n"," 3   contract_type      7032 non-null   object        \n"," 4   paperless_billing  7032 non-null   object        \n"," 5   payment_method     7032 non-null   object        \n"," 6   monthly_charges    7032 non-null   float64       \n"," 7   total_charges      7032 non-null   float64       \n","dtypes: datetime64[ns](1), float64(2), object(5)\n","memory usage: 494.4+ KB\n"]}],"source":["contract_df = contract_data.copy()\n","# column renaming\n","contract_df = contract_df.rename(columns={\"customerID\": \"customer_id\", \"BeginDate\": \"begin_date\", \"EndDate\": \"end_date\", \"Type\": \"contract_type\",\n","                           \"PaperlessBilling\": \"paperless_billing\", \"PaymentMethod\": \"payment_method\", \"MonthlyCharges\": \"monthly_charges\",\n","                           \"TotalCharges\": \"total_charges\"})\n","\n","# datatype conversions\n","contract_df['begin_date'] = pd.to_datetime(contract_df['begin_date'])\n","\n","\n","# display(contract_df.iloc[488]) # first error callout, turns out there are 11 rows without a 'total_charges' value\n","# display(contract_df['total_charges'].isnull().sum()) \n","problem_cells = [ ]\n","\n","for value in contract_df['total_charges']:\n","    try:\n","        pd.to_numeric(value)\n","    except:\n","        problem_cells.append(value)\n","        \n","display(problem_cells)\n","display()\n","\n","contract_df['total_charges'].replace(\" \", np.nan, inplace=True) # replacing empty strings so we can drop the rows\n","contract_df['total_charges'] = pd.to_numeric(contract_df['total_charges']) # conversion to match 'monthly_charges'\n","contract_df = contract_df.dropna(subset=['total_charges']) # 11 rows should not make that big of a dent given it's a tiny percentage of total\n","\n","contract_df.info()"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-12-01T00:01:16.462269Z","iopub.status.busy":"2023-12-01T00:01:16.461895Z","iopub.status.idle":"2023-12-01T00:01:16.492390Z","shell.execute_reply":"2023-12-01T00:01:16.491408Z","shell.execute_reply.started":"2023-12-01T00:01:16.462237Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>customer_id</th>\n","      <th>begin_date</th>\n","      <th>contract_type</th>\n","      <th>paperless_billing</th>\n","      <th>payment_method</th>\n","      <th>monthly_charges</th>\n","      <th>total_charges</th>\n","      <th>churn_target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>7590-VHVEG</td>\n","      <td>2020-01-01</td>\n","      <td>Month-to-month</td>\n","      <td>Yes</td>\n","      <td>Electronic check</td>\n","      <td>29.85</td>\n","      <td>29.85</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5575-GNVDE</td>\n","      <td>2017-04-01</td>\n","      <td>One year</td>\n","      <td>No</td>\n","      <td>Mailed check</td>\n","      <td>56.95</td>\n","      <td>1889.50</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3668-QPYBK</td>\n","      <td>2019-10-01</td>\n","      <td>Month-to-month</td>\n","      <td>Yes</td>\n","      <td>Mailed check</td>\n","      <td>53.85</td>\n","      <td>108.15</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>7795-CFOCW</td>\n","      <td>2016-05-01</td>\n","      <td>One year</td>\n","      <td>No</td>\n","      <td>Bank transfer (automatic)</td>\n","      <td>42.30</td>\n","      <td>1840.75</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>9237-HQITU</td>\n","      <td>2019-09-01</td>\n","      <td>Month-to-month</td>\n","      <td>Yes</td>\n","      <td>Electronic check</td>\n","      <td>70.70</td>\n","      <td>151.65</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7038</th>\n","      <td>6840-RESVB</td>\n","      <td>2018-02-01</td>\n","      <td>One year</td>\n","      <td>Yes</td>\n","      <td>Mailed check</td>\n","      <td>84.80</td>\n","      <td>1990.50</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7039</th>\n","      <td>2234-XADUH</td>\n","      <td>2014-02-01</td>\n","      <td>One year</td>\n","      <td>Yes</td>\n","      <td>Credit card (automatic)</td>\n","      <td>103.20</td>\n","      <td>7362.90</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7040</th>\n","      <td>4801-JZAZL</td>\n","      <td>2019-03-01</td>\n","      <td>Month-to-month</td>\n","      <td>Yes</td>\n","      <td>Electronic check</td>\n","      <td>29.60</td>\n","      <td>346.45</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7041</th>\n","      <td>8361-LTMKD</td>\n","      <td>2019-07-01</td>\n","      <td>Month-to-month</td>\n","      <td>Yes</td>\n","      <td>Mailed check</td>\n","      <td>74.40</td>\n","      <td>306.60</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7042</th>\n","      <td>3186-AJIEK</td>\n","      <td>2014-08-01</td>\n","      <td>Two year</td>\n","      <td>Yes</td>\n","      <td>Bank transfer (automatic)</td>\n","      <td>105.65</td>\n","      <td>6844.50</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7032 rows × 8 columns</p>\n","</div>"],"text/plain":["     customer_id begin_date   contract_type paperless_billing  \\\n","0     7590-VHVEG 2020-01-01  Month-to-month               Yes   \n","1     5575-GNVDE 2017-04-01        One year                No   \n","2     3668-QPYBK 2019-10-01  Month-to-month               Yes   \n","3     7795-CFOCW 2016-05-01        One year                No   \n","4     9237-HQITU 2019-09-01  Month-to-month               Yes   \n","...          ...        ...             ...               ...   \n","7038  6840-RESVB 2018-02-01        One year               Yes   \n","7039  2234-XADUH 2014-02-01        One year               Yes   \n","7040  4801-JZAZL 2019-03-01  Month-to-month               Yes   \n","7041  8361-LTMKD 2019-07-01  Month-to-month               Yes   \n","7042  3186-AJIEK 2014-08-01        Two year               Yes   \n","\n","                 payment_method  monthly_charges  total_charges  churn_target  \n","0              Electronic check            29.85          29.85             1  \n","1                  Mailed check            56.95        1889.50             1  \n","2                  Mailed check            53.85         108.15             0  \n","3     Bank transfer (automatic)            42.30        1840.75             1  \n","4              Electronic check            70.70         151.65             0  \n","...                         ...              ...            ...           ...  \n","7038               Mailed check            84.80        1990.50             1  \n","7039    Credit card (automatic)           103.20        7362.90             1  \n","7040           Electronic check            29.60         346.45             1  \n","7041               Mailed check            74.40         306.60             0  \n","7042  Bank transfer (automatic)           105.65        6844.50             1  \n","\n","[7032 rows x 8 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["# target handling\n","contract_df.query('end_date == \" \"') # no empty cells in target column\n","\n","contract_df['churn_target'] = np.where(contract_df['end_date'] == 'No', 1, 0) # 1 = no churn, 0 = churn\n","contract_df = contract_df.drop(['end_date'], axis=1)\n","\n","display(contract_df)"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-12-01T00:01:54.691356Z","iopub.status.busy":"2023-12-01T00:01:54.690923Z","iopub.status.idle":"2023-12-01T00:01:56.224365Z","shell.execute_reply":"2023-12-01T00:01:56.223272Z","shell.execute_reply.started":"2023-12-01T00:01:54.691321Z"},"trusted":true},"outputs":[{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"alignmentgroup":"True","hovertemplate":"variable=0<br>payment_method=%{x}<br>value=%{y}<extra></extra>","legendgroup":"0","marker":{"color":"#636efa","pattern":{"shape":""}},"name":"0","offsetgroup":"0","orientation":"v","showlegend":true,"textposition":"auto","texttemplate":"%{y}","type":"bar","x":["Bank transfer (automatic)","Credit card (automatic)","Electronic check","Mailed check"],"xaxis":"x","y":[589,580,1850,893],"yaxis":"y"}],"layout":{"autosize":false,"barmode":"relative","legend":{"title":{"text":"variable"},"tracegroupgap":0},"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"title":{"text":"Customer Payment Method"},"xaxis":{"anchor":"y","domain":[0,1],"title":{"text":"payment_method"}},"yaxis":{"anchor":"x","domain":[0,1],"title":{"text":"value"}}}},"text/html":["<div>                            <div id=\"dc6384f2-e46b-4e53-bb12-41bda06b94e2\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"dc6384f2-e46b-4e53-bb12-41bda06b94e2\")) {                    Plotly.newPlot(                        \"dc6384f2-e46b-4e53-bb12-41bda06b94e2\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=0\\u003cbr\\u003epayment_method=%{x}\\u003cbr\\u003evalue=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"0\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"0\",\"offsetgroup\":\"0\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"texttemplate\":\"%{y}\",\"x\":[\"Bank transfer (automatic)\",\"Credit card (automatic)\",\"Electronic check\",\"Mailed check\"],\"xaxis\":\"x\",\"y\":[589,580,1850,893],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"payment_method\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"value\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Customer Payment Method\"},\"barmode\":\"relative\",\"showlegend\":false,\"autosize\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('dc6384f2-e46b-4e53-bb12-41bda06b94e2');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"alignmentgroup":"True","hovertemplate":"variable=0<br>contract_type=%{x}<br>value=%{y}<extra></extra>","legendgroup":"0","marker":{"color":"#636efa","pattern":{"shape":""}},"name":"0","offsetgroup":"0","orientation":"v","showlegend":true,"textposition":"auto","texttemplate":"%{y}","type":"bar","x":["Month-to-month","One year","Two year"],"xaxis":"x","y":[1850,398,580],"yaxis":"y"}],"layout":{"autosize":false,"barmode":"relative","legend":{"title":{"text":"variable"},"tracegroupgap":0},"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"title":{"text":"Customer Contract Type"},"xaxis":{"anchor":"y","domain":[0,1],"title":{"text":"contract_type"}},"yaxis":{"anchor":"x","domain":[0,1],"title":{"text":"value"}}}},"text/html":["<div>                            <div id=\"4f1e3a5c-fe00-4bd9-932a-f6a2ce00fca6\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"4f1e3a5c-fe00-4bd9-932a-f6a2ce00fca6\")) {                    Plotly.newPlot(                        \"4f1e3a5c-fe00-4bd9-932a-f6a2ce00fca6\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=0\\u003cbr\\u003econtract_type=%{x}\\u003cbr\\u003evalue=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"0\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"0\",\"offsetgroup\":\"0\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"texttemplate\":\"%{y}\",\"x\":[\"Month-to-month\",\"One year\",\"Two year\"],\"xaxis\":\"x\",\"y\":[1850,398,580],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"contract_type\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"value\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Customer Contract Type\"},\"barmode\":\"relative\",\"showlegend\":false,\"autosize\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('4f1e3a5c-fe00-4bd9-932a-f6a2ce00fca6');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"}],"source":["payment_grp = contract_df.groupby(['contract_type','payment_method']).size().reset_index().groupby('payment_method')[[0]].max()\n","# display(payment_grp)\n","fig = px.bar(payment_grp,title=\"Customer Payment Method\",text_auto = True)\n","fig.update_layout(showlegend=False,autosize=False)\n","fig.show()\n","\n","contract_type_grp = contract_df.groupby(['contract_type','payment_method']).size().reset_index().groupby('contract_type')[[0]].max()\n","# display(contract_type_grp)\n","fig = px.bar(contract_type_grp,title=\"Customer Contract Type\",text_auto = True)\n","fig.update_layout(showlegend=False,autosize=False)\n","fig.show()"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 1300x600 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["crosstab = pd.crosstab(contract_df['payment_method'], contract_df['contract_type'])\n","fig, ax = plt.subplots(figsize=(13, 6))\n","g = sns.heatmap(crosstab, cbar=False, cmap=\"BuGn\", linewidths=0.3, annot=True, fmt='d', ax=ax)\n","\n","g.set_ylabel('Payment Method')\n","g.set_xlabel('Type')\n","\n","ax.text(x=0.5, y=1.1, s='Contract Data', fontsize=16, weight='bold', ha='center', va='bottom', transform=ax.transAxes)\n","ax.text(x=0.5, y=1.05, s='Heatmap Analysis', fontsize=8, alpha=0.75, ha='center', va='bottom', transform=ax.transAxes)\n","\n","plt.yticks(rotation=0)\n","plt.xticks(rotation=0)\n","plt.show()"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-12-01T00:02:36.916012Z","iopub.status.busy":"2023-12-01T00:02:36.915540Z","iopub.status.idle":"2023-12-01T00:02:36.942607Z","shell.execute_reply":"2023-12-01T00:02:36.941607Z","shell.execute_reply.started":"2023-12-01T00:02:36.915974Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>customer_id</th>\n","      <th>begin_date</th>\n","      <th>contract_type</th>\n","      <th>paperless_billing</th>\n","      <th>payment_method</th>\n","      <th>monthly_charges</th>\n","      <th>total_charges</th>\n","      <th>churn_target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>7590-VHVEG</td>\n","      <td>2020-01-01</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>29.85</td>\n","      <td>29.85</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5575-GNVDE</td>\n","      <td>2017-04-01</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>56.95</td>\n","      <td>1889.50</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3668-QPYBK</td>\n","      <td>2019-10-01</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>53.85</td>\n","      <td>108.15</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>7795-CFOCW</td>\n","      <td>2016-05-01</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>42.30</td>\n","      <td>1840.75</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>9237-HQITU</td>\n","      <td>2019-09-01</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>70.70</td>\n","      <td>151.65</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7038</th>\n","      <td>6840-RESVB</td>\n","      <td>2018-02-01</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>84.80</td>\n","      <td>1990.50</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7039</th>\n","      <td>2234-XADUH</td>\n","      <td>2014-02-01</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>103.20</td>\n","      <td>7362.90</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7040</th>\n","      <td>4801-JZAZL</td>\n","      <td>2019-03-01</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>29.60</td>\n","      <td>346.45</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7041</th>\n","      <td>8361-LTMKD</td>\n","      <td>2019-07-01</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>74.40</td>\n","      <td>306.60</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7042</th>\n","      <td>3186-AJIEK</td>\n","      <td>2014-08-01</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>105.65</td>\n","      <td>6844.50</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7032 rows × 8 columns</p>\n","</div>"],"text/plain":["     customer_id begin_date  contract_type  paperless_billing  payment_method  \\\n","0     7590-VHVEG 2020-01-01              0                  1               2   \n","1     5575-GNVDE 2017-04-01              1                  0               3   \n","2     3668-QPYBK 2019-10-01              0                  1               3   \n","3     7795-CFOCW 2016-05-01              1                  0               0   \n","4     9237-HQITU 2019-09-01              0                  1               2   \n","...          ...        ...            ...                ...             ...   \n","7038  6840-RESVB 2018-02-01              1                  1               3   \n","7039  2234-XADUH 2014-02-01              1                  1               1   \n","7040  4801-JZAZL 2019-03-01              0                  1               2   \n","7041  8361-LTMKD 2019-07-01              0                  1               3   \n","7042  3186-AJIEK 2014-08-01              2                  1               0   \n","\n","      monthly_charges  total_charges  churn_target  \n","0               29.85          29.85             1  \n","1               56.95        1889.50             1  \n","2               53.85         108.15             0  \n","3               42.30        1840.75             1  \n","4               70.70         151.65             0  \n","...               ...            ...           ...  \n","7038            84.80        1990.50             1  \n","7039           103.20        7362.90             1  \n","7040            29.60         346.45             1  \n","7041            74.40         306.60             0  \n","7042           105.65        6844.50             1  \n","\n","[7032 rows x 8 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["# label encoding\n","contract_df = MultiColumnLabelEncoder(columns = ['contract_type','paperless_billing', 'payment_method']).fit_transform(contract_df)\n","\n","display(contract_df)"]},{"cell_type":"markdown","metadata":{},"source":["`Summary`\n","\n","Peaking into our contract data, we see issues with column naming, and column datatypes. We attempt amend those two to start and find that one of the features has empty strings in it's value range (through an iterative examination). \n","\n","Once we find the specific culprits, we replace with NaN values so we can then drop the rows themselves. Thse are small in numbers compared to the entire DF and so are more comfortable with the removal and do not expect much, if any, impact down the line. "]},{"cell_type":"markdown","metadata":{},"source":["-----------"]},{"cell_type":"markdown","metadata":{},"source":["# Personal data"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-12-01T00:02:39.542076Z","iopub.status.busy":"2023-12-01T00:02:39.541696Z","iopub.status.idle":"2023-12-01T00:02:39.554628Z","shell.execute_reply":"2023-12-01T00:02:39.553612Z","shell.execute_reply.started":"2023-12-01T00:02:39.542045Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 7043 entries, 0 to 7042\n","Data columns (total 5 columns):\n"," #   Column         Non-Null Count  Dtype \n","---  ------         --------------  ----- \n"," 0   customerID     7043 non-null   object\n"," 1   gender         7043 non-null   object\n"," 2   SeniorCitizen  7043 non-null   int64 \n"," 3   Partner        7043 non-null   object\n"," 4   Dependents     7043 non-null   object\n","dtypes: int64(1), object(4)\n","memory usage: 275.2+ KB\n"]}],"source":["personal_data.info()"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Categorical Features: ['gender', 'Partner', 'Dependents']\n","Non-Categorical Features: ['customerID']\n","Discrete Features: ['SeniorCitizen']\n","Continuous Features: []\n"]}],"source":["categorical, non_categorical, discrete, continuous = classify_features(personal_data)\n","\n","print(\"Categorical Features:\", categorical)\n","print(\"Non-Categorical Features:\", non_categorical)\n","print(\"Discrete Features:\", discrete)\n","print(\"Continuous Features:\", continuous)"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["gender\n","Male      3555\n","Female    3488\n","Name: count, dtype: int64\n","\n"]},{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"alignmentgroup":"True","hovertemplate":"variable=count<br>gender=%{x}<br>Count (#)=%{y}<extra></extra>","legendgroup":"count","marker":{"color":"darkgreen","pattern":{"shape":""}},"name":"count","offsetgroup":"count","orientation":"v","showlegend":true,"textposition":"auto","texttemplate":"%{y}","type":"bar","x":["Male","Female"],"xaxis":"x","y":[3555,3488],"yaxis":"y"}],"layout":{"autosize":false,"barmode":"relative","legend":{"title":{"text":"variable"},"tracegroupgap":0},"margin":{"t":60},"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"xaxis":{"anchor":"y","domain":[0,1],"title":{"text":"gender"}},"yaxis":{"anchor":"x","domain":[0,1],"title":{"text":"Count (#)"}}}},"text/html":["<div>                            <div id=\"e3b933cf-d776-4912-b24e-f4b83ccf955c\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"e3b933cf-d776-4912-b24e-f4b83ccf955c\")) {                    Plotly.newPlot(                        \"e3b933cf-d776-4912-b24e-f4b83ccf955c\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=count\\u003cbr\\u003egender=%{x}\\u003cbr\\u003eCount (#)=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"count\",\"marker\":{\"color\":\"darkgreen\",\"pattern\":{\"shape\":\"\"}},\"name\":\"count\",\"offsetgroup\":\"count\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"texttemplate\":\"%{y}\",\"x\":[\"Male\",\"Female\"],\"xaxis\":\"x\",\"y\":[3555,3488],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"gender\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Count (#)\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\",\"showlegend\":false,\"autosize\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('e3b933cf-d776-4912-b24e-f4b83ccf955c');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"alignmentgroup":"True","hovertemplate":"variable=count<br>gender=%{x}<br>Count (#)=%{y}<extra></extra>","legendgroup":"count","marker":{"color":"darkgreen","pattern":{"shape":""}},"name":"count","offsetgroup":"count","orientation":"v","showlegend":true,"textposition":"auto","texttemplate":"%{y}","type":"bar","x":["Male","Female"],"xaxis":"x","y":[3555,3488],"yaxis":"y"}],"layout":{"autosize":false,"barmode":"relative","legend":{"title":{"text":"variable"},"tracegroupgap":0},"margin":{"t":60},"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"xaxis":{"anchor":"y","domain":[0,1],"title":{"text":"gender"}},"yaxis":{"anchor":"x","domain":[0,1],"title":{"text":"Count (#)"}}}},"text/html":["<div>                            <div id=\"69b096f2-be81-472f-a00f-02bab7bb0859\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"69b096f2-be81-472f-a00f-02bab7bb0859\")) {                    Plotly.newPlot(                        \"69b096f2-be81-472f-a00f-02bab7bb0859\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=count\\u003cbr\\u003egender=%{x}\\u003cbr\\u003eCount (#)=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"count\",\"marker\":{\"color\":\"darkgreen\",\"pattern\":{\"shape\":\"\"}},\"name\":\"count\",\"offsetgroup\":\"count\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"texttemplate\":\"%{y}\",\"x\":[\"Male\",\"Female\"],\"xaxis\":\"x\",\"y\":[3555,3488],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"gender\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Count (#)\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\",\"showlegend\":false,\"autosize\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('69b096f2-be81-472f-a00f-02bab7bb0859');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Partner\n","No     3641\n","Yes    3402\n","Name: count, dtype: int64\n","\n"]},{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"alignmentgroup":"True","hovertemplate":"variable=count<br>Partner=%{x}<br>Count (#)=%{y}<extra></extra>","legendgroup":"count","marker":{"color":"darkgreen","pattern":{"shape":""}},"name":"count","offsetgroup":"count","orientation":"v","showlegend":true,"textposition":"auto","texttemplate":"%{y}","type":"bar","x":["No","Yes"],"xaxis":"x","y":[3641,3402],"yaxis":"y"}],"layout":{"autosize":false,"barmode":"relative","legend":{"title":{"text":"variable"},"tracegroupgap":0},"margin":{"t":60},"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"xaxis":{"anchor":"y","domain":[0,1],"title":{"text":"Partner"}},"yaxis":{"anchor":"x","domain":[0,1],"title":{"text":"Count (#)"}}}},"text/html":["<div>                            <div id=\"fa7497d1-f290-4bc1-a9a4-ac20682d7607\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"fa7497d1-f290-4bc1-a9a4-ac20682d7607\")) {                    Plotly.newPlot(                        \"fa7497d1-f290-4bc1-a9a4-ac20682d7607\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=count\\u003cbr\\u003ePartner=%{x}\\u003cbr\\u003eCount (#)=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"count\",\"marker\":{\"color\":\"darkgreen\",\"pattern\":{\"shape\":\"\"}},\"name\":\"count\",\"offsetgroup\":\"count\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"texttemplate\":\"%{y}\",\"x\":[\"No\",\"Yes\"],\"xaxis\":\"x\",\"y\":[3641,3402],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Partner\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Count (#)\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\",\"showlegend\":false,\"autosize\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('fa7497d1-f290-4bc1-a9a4-ac20682d7607');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"alignmentgroup":"True","hovertemplate":"variable=count<br>Partner=%{x}<br>Count (#)=%{y}<extra></extra>","legendgroup":"count","marker":{"color":"darkgreen","pattern":{"shape":""}},"name":"count","offsetgroup":"count","orientation":"v","showlegend":true,"textposition":"auto","texttemplate":"%{y}","type":"bar","x":["No","Yes"],"xaxis":"x","y":[3641,3402],"yaxis":"y"}],"layout":{"autosize":false,"barmode":"relative","legend":{"title":{"text":"variable"},"tracegroupgap":0},"margin":{"t":60},"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"xaxis":{"anchor":"y","domain":[0,1],"title":{"text":"Partner"}},"yaxis":{"anchor":"x","domain":[0,1],"title":{"text":"Count (#)"}}}},"text/html":["<div>                            <div id=\"c645288e-7058-4469-81a6-1fd5758d46bd\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"c645288e-7058-4469-81a6-1fd5758d46bd\")) {                    Plotly.newPlot(                        \"c645288e-7058-4469-81a6-1fd5758d46bd\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=count\\u003cbr\\u003ePartner=%{x}\\u003cbr\\u003eCount (#)=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"count\",\"marker\":{\"color\":\"darkgreen\",\"pattern\":{\"shape\":\"\"}},\"name\":\"count\",\"offsetgroup\":\"count\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"texttemplate\":\"%{y}\",\"x\":[\"No\",\"Yes\"],\"xaxis\":\"x\",\"y\":[3641,3402],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Partner\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Count (#)\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\",\"showlegend\":false,\"autosize\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('c645288e-7058-4469-81a6-1fd5758d46bd');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Dependents\n","No     4933\n","Yes    2110\n","Name: count, dtype: int64\n","\n"]},{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"alignmentgroup":"True","hovertemplate":"variable=count<br>Dependents=%{x}<br>Count (#)=%{y}<extra></extra>","legendgroup":"count","marker":{"color":"darkgreen","pattern":{"shape":""}},"name":"count","offsetgroup":"count","orientation":"v","showlegend":true,"textposition":"auto","texttemplate":"%{y}","type":"bar","x":["No","Yes"],"xaxis":"x","y":[4933,2110],"yaxis":"y"}],"layout":{"autosize":false,"barmode":"relative","legend":{"title":{"text":"variable"},"tracegroupgap":0},"margin":{"t":60},"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"xaxis":{"anchor":"y","domain":[0,1],"title":{"text":"Dependents"}},"yaxis":{"anchor":"x","domain":[0,1],"title":{"text":"Count (#)"}}}},"text/html":["<div>                            <div id=\"e789c29b-44fa-4f5f-8cbf-93d1c9db9f82\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"e789c29b-44fa-4f5f-8cbf-93d1c9db9f82\")) {                    Plotly.newPlot(                        \"e789c29b-44fa-4f5f-8cbf-93d1c9db9f82\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=count\\u003cbr\\u003eDependents=%{x}\\u003cbr\\u003eCount (#)=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"count\",\"marker\":{\"color\":\"darkgreen\",\"pattern\":{\"shape\":\"\"}},\"name\":\"count\",\"offsetgroup\":\"count\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"texttemplate\":\"%{y}\",\"x\":[\"No\",\"Yes\"],\"xaxis\":\"x\",\"y\":[4933,2110],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Dependents\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Count (#)\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\",\"showlegend\":false,\"autosize\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('e789c29b-44fa-4f5f-8cbf-93d1c9db9f82');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"alignmentgroup":"True","hovertemplate":"variable=count<br>Dependents=%{x}<br>Count (#)=%{y}<extra></extra>","legendgroup":"count","marker":{"color":"darkgreen","pattern":{"shape":""}},"name":"count","offsetgroup":"count","orientation":"v","showlegend":true,"textposition":"auto","texttemplate":"%{y}","type":"bar","x":["No","Yes"],"xaxis":"x","y":[4933,2110],"yaxis":"y"}],"layout":{"autosize":false,"barmode":"relative","legend":{"title":{"text":"variable"},"tracegroupgap":0},"margin":{"t":60},"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"xaxis":{"anchor":"y","domain":[0,1],"title":{"text":"Dependents"}},"yaxis":{"anchor":"x","domain":[0,1],"title":{"text":"Count (#)"}}}},"text/html":["<div>                            <div id=\"e6341ea4-7c7f-4abb-a30e-450f007bd1b5\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"e6341ea4-7c7f-4abb-a30e-450f007bd1b5\")) {                    Plotly.newPlot(                        \"e6341ea4-7c7f-4abb-a30e-450f007bd1b5\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=count\\u003cbr\\u003eDependents=%{x}\\u003cbr\\u003eCount (#)=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"count\",\"marker\":{\"color\":\"darkgreen\",\"pattern\":{\"shape\":\"\"}},\"name\":\"count\",\"offsetgroup\":\"count\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"texttemplate\":\"%{y}\",\"x\":[\"No\",\"Yes\"],\"xaxis\":\"x\",\"y\":[4933,2110],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Dependents\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Count (#)\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\",\"showlegend\":false,\"autosize\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('e6341ea4-7c7f-4abb-a30e-450f007bd1b5');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"}],"source":["for i in categorical:\n","    #print(i, ':')\n","    print(personal_data[i].value_counts())\n","    fig = px.bar(personal_data[i].value_counts(), labels={'value':'Count (#)'}, text_auto=True).update_layout(showlegend=False,autosize=False).update_traces(marker_color='darkgreen')\n","    print()\n","    fig.show()\n","    fig.show()"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-12-01T00:02:41.352220Z","iopub.status.busy":"2023-12-01T00:02:41.351772Z","iopub.status.idle":"2023-12-01T00:02:41.368592Z","shell.execute_reply":"2023-12-01T00:02:41.367394Z","shell.execute_reply.started":"2023-12-01T00:02:41.352187Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>SeniorCitizen</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>7043.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>0.162147</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.368612</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       SeniorCitizen\n","count    7043.000000\n","mean        0.162147\n","std         0.368612\n","min         0.000000\n","25%         0.000000\n","50%         0.000000\n","75%         0.000000\n","max         1.000000"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["personal_data.describe()"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-12-01T00:02:43.186760Z","iopub.status.busy":"2023-12-01T00:02:43.186382Z","iopub.status.idle":"2023-12-01T00:02:43.198043Z","shell.execute_reply":"2023-12-01T00:02:43.197002Z","shell.execute_reply.started":"2023-12-01T00:02:43.186729Z"},"trusted":true},"outputs":[{"data":{"text/plain":["customerID       0\n","gender           0\n","SeniorCitizen    0\n","Partner          0\n","Dependents       0\n","dtype: int64"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["personal_data.isna().sum()"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-12-01T00:02:44.472779Z","iopub.status.busy":"2023-12-01T00:02:44.472365Z","iopub.status.idle":"2023-12-01T00:02:44.491860Z","shell.execute_reply":"2023-12-01T00:02:44.490748Z","shell.execute_reply.started":"2023-12-01T00:02:44.472746Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>customerID</th>\n","      <th>gender</th>\n","      <th>SeniorCitizen</th>\n","      <th>Partner</th>\n","      <th>Dependents</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>7590-VHVEG</td>\n","      <td>Female</td>\n","      <td>0</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5575-GNVDE</td>\n","      <td>Male</td>\n","      <td>0</td>\n","      <td>No</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3668-QPYBK</td>\n","      <td>Male</td>\n","      <td>0</td>\n","      <td>No</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>7795-CFOCW</td>\n","      <td>Male</td>\n","      <td>0</td>\n","      <td>No</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>9237-HQITU</td>\n","      <td>Female</td>\n","      <td>0</td>\n","      <td>No</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7038</th>\n","      <td>6840-RESVB</td>\n","      <td>Male</td>\n","      <td>0</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>7039</th>\n","      <td>2234-XADUH</td>\n","      <td>Female</td>\n","      <td>0</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>7040</th>\n","      <td>4801-JZAZL</td>\n","      <td>Female</td>\n","      <td>0</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>7041</th>\n","      <td>8361-LTMKD</td>\n","      <td>Male</td>\n","      <td>1</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>7042</th>\n","      <td>3186-AJIEK</td>\n","      <td>Male</td>\n","      <td>0</td>\n","      <td>No</td>\n","      <td>No</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7043 rows × 5 columns</p>\n","</div>"],"text/plain":["      customerID  gender  SeniorCitizen Partner Dependents\n","0     7590-VHVEG  Female              0     Yes         No\n","1     5575-GNVDE    Male              0      No         No\n","2     3668-QPYBK    Male              0      No         No\n","3     7795-CFOCW    Male              0      No         No\n","4     9237-HQITU  Female              0      No         No\n","...          ...     ...            ...     ...        ...\n","7038  6840-RESVB    Male              0     Yes        Yes\n","7039  2234-XADUH  Female              0     Yes        Yes\n","7040  4801-JZAZL  Female              0     Yes        Yes\n","7041  8361-LTMKD    Male              1     Yes         No\n","7042  3186-AJIEK    Male              0      No         No\n","\n","[7043 rows x 5 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["display(personal_data)"]},{"cell_type":"markdown","metadata":{},"source":["`Preprocessing`"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2023-12-01T00:02:46.035248Z","iopub.status.busy":"2023-12-01T00:02:46.034611Z","iopub.status.idle":"2023-12-01T00:02:46.042734Z","shell.execute_reply":"2023-12-01T00:02:46.041244Z","shell.execute_reply.started":"2023-12-01T00:02:46.035215Z"},"trusted":true},"outputs":[],"source":["personal_df = personal_data.copy()\n","# column renaming\n","personal_df = personal_df.rename(columns={\"customerID\": \"customer_id\", \"SeniorCitizen\": \"senior_citizen\",\n","                                          \"Partner\": \"partner\", \"Dependents\": \"dependents\"})"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2023-12-01T00:05:45.267943Z","iopub.status.busy":"2023-12-01T00:05:45.267552Z","iopub.status.idle":"2023-12-01T00:05:45.330839Z","shell.execute_reply":"2023-12-01T00:05:45.329844Z","shell.execute_reply.started":"2023-12-01T00:05:45.267913Z"},"trusted":true},"outputs":[{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"domain":{"x":[0,1],"y":[0,1]},"hovertemplate":"label=%{label}<extra></extra>","labels":["Male","Female"],"legendgroup":"","name":"","showlegend":true,"type":"pie"}],"layout":{"autosize":false,"legend":{"orientation":"h","tracegroupgap":0,"x":1,"xanchor":"right","y":1.02,"yanchor":"bottom"},"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"title":{"text":"Gender Mix"}}},"text/html":["<div>                            <div id=\"fcb76c81-83d6-4e90-9a45-562e62f0f35e\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"fcb76c81-83d6-4e90-9a45-562e62f0f35e\")) {                    Plotly.newPlot(                        \"fcb76c81-83d6-4e90-9a45-562e62f0f35e\",                        [{\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"hovertemplate\":\"label=%{label}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"labels\":[\"Male\",\"Female\"],\"legendgroup\":\"\",\"name\":\"\",\"showlegend\":true,\"type\":\"pie\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"legend\":{\"tracegroupgap\":0,\"orientation\":\"h\",\"yanchor\":\"bottom\",\"y\":1.02,\"xanchor\":\"right\",\"x\":1},\"title\":{\"text\":\"Gender Mix\"},\"autosize\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('fcb76c81-83d6-4e90-9a45-562e62f0f35e');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"}],"source":["personal_grp = personal_df.groupby(['partner','gender']).size().reset_index().groupby('gender')[[0]].max()\n","\n","labels = ['Male', 'Female']\n","fig = px.pie(personal_grp, names=labels, title='Gender Mix')\n","fig.update_layout(legend=dict(\n","    orientation=\"h\",\n","    yanchor=\"bottom\",\n","    y=1.02,\n","    xanchor=\"right\",\n","    x=1\n","),autosize=False)\n","\n","fig.show()"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 1000x600 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["crosstab = pd.crosstab(personal_df['partner'], personal_df['gender'])\n","fig, ax = plt.subplots(figsize=(10, 6))\n","g = sns.heatmap(crosstab, cbar=False, cmap=\"Blues\", linewidths=0.3, annot=True, fmt='d', ax=ax)\n","\n","g.set_ylabel('Has Partner')\n","g.set_xlabel('Gender')\n","\n","ax.text(x=0.5, y=1.1, s='Personal Data', fontsize=16, weight='bold', ha='center', va='bottom', transform=ax.transAxes)\n","ax.text(x=0.5, y=1.05, s='Heatmap Analysis', fontsize=8, alpha=0.75, ha='center', va='bottom', transform=ax.transAxes)\n","\n","plt.yticks(rotation=0)\n","plt.xticks(rotation=0)\n","plt.show()"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2023-12-01T00:04:37.551263Z","iopub.status.busy":"2023-12-01T00:04:37.550905Z","iopub.status.idle":"2023-12-01T00:04:37.573245Z","shell.execute_reply":"2023-12-01T00:04:37.572312Z","shell.execute_reply.started":"2023-12-01T00:04:37.551237Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>customer_id</th>\n","      <th>gender</th>\n","      <th>senior_citizen</th>\n","      <th>partner</th>\n","      <th>dependents</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>7590-VHVEG</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5575-GNVDE</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3668-QPYBK</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>7795-CFOCW</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>9237-HQITU</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7038</th>\n","      <td>6840-RESVB</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7039</th>\n","      <td>2234-XADUH</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7040</th>\n","      <td>4801-JZAZL</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7041</th>\n","      <td>8361-LTMKD</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7042</th>\n","      <td>3186-AJIEK</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7043 rows × 5 columns</p>\n","</div>"],"text/plain":["     customer_id  gender  senior_citizen  partner  dependents\n","0     7590-VHVEG       0               0        1           0\n","1     5575-GNVDE       1               0        0           0\n","2     3668-QPYBK       1               0        0           0\n","3     7795-CFOCW       1               0        0           0\n","4     9237-HQITU       0               0        0           0\n","...          ...     ...             ...      ...         ...\n","7038  6840-RESVB       1               0        1           1\n","7039  2234-XADUH       0               0        1           1\n","7040  4801-JZAZL       0               0        1           1\n","7041  8361-LTMKD       1               1        1           0\n","7042  3186-AJIEK       1               0        0           0\n","\n","[7043 rows x 5 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["# label encoding\n","personal_df = MultiColumnLabelEncoder(columns = ['gender','senior_citizen', 'partner', 'dependents']).fit_transform(personal_df)\n","\n","display(personal_df)"]},{"cell_type":"markdown","metadata":{},"source":["`Summary`\n","\n","Similar instances of column revisions for personal_data but we preemtively being feature encoding through a function that handles multiple column encoding. These values then become inputs the eventual models can handle and make sense of."]},{"cell_type":"markdown","metadata":{},"source":["-----------"]},{"cell_type":"markdown","metadata":{},"source":["# Internet data"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2023-12-01T00:05:49.500662Z","iopub.status.busy":"2023-12-01T00:05:49.500284Z","iopub.status.idle":"2023-12-01T00:05:49.516111Z","shell.execute_reply":"2023-12-01T00:05:49.514940Z","shell.execute_reply.started":"2023-12-01T00:05:49.500630Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 5517 entries, 0 to 5516\n","Data columns (total 8 columns):\n"," #   Column            Non-Null Count  Dtype \n","---  ------            --------------  ----- \n"," 0   customerID        5517 non-null   object\n"," 1   InternetService   5517 non-null   object\n"," 2   OnlineSecurity    5517 non-null   object\n"," 3   OnlineBackup      5517 non-null   object\n"," 4   DeviceProtection  5517 non-null   object\n"," 5   TechSupport       5517 non-null   object\n"," 6   StreamingTV       5517 non-null   object\n"," 7   StreamingMovies   5517 non-null   object\n","dtypes: object(8)\n","memory usage: 344.9+ KB\n"]}],"source":["internet_data.info()"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Categorical Features: ['InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies']\n","Non-Categorical Features: ['customerID']\n","Discrete Features: []\n","Continuous Features: []\n"]}],"source":["categorical, non_categorical, discrete, continuous = classify_features(internet_data)\n","\n","print(\"Categorical Features:\", categorical)\n","print(\"Non-Categorical Features:\", non_categorical)\n","print(\"Discrete Features:\", discrete)\n","print(\"Continuous Features:\", continuous)"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["InternetService\n","Fiber optic    3096\n","DSL            2421\n","Name: count, dtype: int64\n","\n"]},{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"alignmentgroup":"True","hovertemplate":"variable=count<br>InternetService=%{x}<br>Count (#)=%{y}<extra></extra>","legendgroup":"count","marker":{"color":"darkblue","pattern":{"shape":""}},"name":"count","offsetgroup":"count","orientation":"v","showlegend":true,"textposition":"auto","texttemplate":"%{y}","type":"bar","x":["Fiber optic","DSL"],"xaxis":"x","y":[3096,2421],"yaxis":"y"}],"layout":{"autosize":false,"barmode":"relative","legend":{"title":{"text":"variable"},"tracegroupgap":0},"margin":{"t":60},"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"xaxis":{"anchor":"y","domain":[0,1],"title":{"text":"InternetService"}},"yaxis":{"anchor":"x","domain":[0,1],"title":{"text":"Count (#)"}}}},"text/html":["<div>                            <div id=\"04471be4-5135-499f-b131-940885cb62a3\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"04471be4-5135-499f-b131-940885cb62a3\")) {                    Plotly.newPlot(                        \"04471be4-5135-499f-b131-940885cb62a3\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=count\\u003cbr\\u003eInternetService=%{x}\\u003cbr\\u003eCount (#)=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"count\",\"marker\":{\"color\":\"darkblue\",\"pattern\":{\"shape\":\"\"}},\"name\":\"count\",\"offsetgroup\":\"count\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"texttemplate\":\"%{y}\",\"x\":[\"Fiber optic\",\"DSL\"],\"xaxis\":\"x\",\"y\":[3096,2421],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"InternetService\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Count (#)\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\",\"showlegend\":false,\"autosize\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('04471be4-5135-499f-b131-940885cb62a3');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"alignmentgroup":"True","hovertemplate":"variable=count<br>InternetService=%{x}<br>Count (#)=%{y}<extra></extra>","legendgroup":"count","marker":{"color":"darkblue","pattern":{"shape":""}},"name":"count","offsetgroup":"count","orientation":"v","showlegend":true,"textposition":"auto","texttemplate":"%{y}","type":"bar","x":["Fiber optic","DSL"],"xaxis":"x","y":[3096,2421],"yaxis":"y"}],"layout":{"autosize":false,"barmode":"relative","legend":{"title":{"text":"variable"},"tracegroupgap":0},"margin":{"t":60},"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"xaxis":{"anchor":"y","domain":[0,1],"title":{"text":"InternetService"}},"yaxis":{"anchor":"x","domain":[0,1],"title":{"text":"Count (#)"}}}},"text/html":["<div>                            <div id=\"54c20400-179c-426a-9c4e-c27599ea7e1e\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"54c20400-179c-426a-9c4e-c27599ea7e1e\")) {                    Plotly.newPlot(                        \"54c20400-179c-426a-9c4e-c27599ea7e1e\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=count\\u003cbr\\u003eInternetService=%{x}\\u003cbr\\u003eCount (#)=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"count\",\"marker\":{\"color\":\"darkblue\",\"pattern\":{\"shape\":\"\"}},\"name\":\"count\",\"offsetgroup\":\"count\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"texttemplate\":\"%{y}\",\"x\":[\"Fiber optic\",\"DSL\"],\"xaxis\":\"x\",\"y\":[3096,2421],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"InternetService\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Count (#)\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\",\"showlegend\":false,\"autosize\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('54c20400-179c-426a-9c4e-c27599ea7e1e');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["OnlineSecurity\n","No     3498\n","Yes    2019\n","Name: count, dtype: int64\n","\n"]},{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"alignmentgroup":"True","hovertemplate":"variable=count<br>OnlineSecurity=%{x}<br>Count (#)=%{y}<extra></extra>","legendgroup":"count","marker":{"color":"darkblue","pattern":{"shape":""}},"name":"count","offsetgroup":"count","orientation":"v","showlegend":true,"textposition":"auto","texttemplate":"%{y}","type":"bar","x":["No","Yes"],"xaxis":"x","y":[3498,2019],"yaxis":"y"}],"layout":{"autosize":false,"barmode":"relative","legend":{"title":{"text":"variable"},"tracegroupgap":0},"margin":{"t":60},"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"xaxis":{"anchor":"y","domain":[0,1],"title":{"text":"OnlineSecurity"}},"yaxis":{"anchor":"x","domain":[0,1],"title":{"text":"Count (#)"}}}},"text/html":["<div>                            <div id=\"8bb5eca3-1d4d-4776-a87c-7f79de4cc97c\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"8bb5eca3-1d4d-4776-a87c-7f79de4cc97c\")) {                    Plotly.newPlot(                        \"8bb5eca3-1d4d-4776-a87c-7f79de4cc97c\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=count\\u003cbr\\u003eOnlineSecurity=%{x}\\u003cbr\\u003eCount (#)=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"count\",\"marker\":{\"color\":\"darkblue\",\"pattern\":{\"shape\":\"\"}},\"name\":\"count\",\"offsetgroup\":\"count\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"texttemplate\":\"%{y}\",\"x\":[\"No\",\"Yes\"],\"xaxis\":\"x\",\"y\":[3498,2019],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"OnlineSecurity\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Count (#)\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\",\"showlegend\":false,\"autosize\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('8bb5eca3-1d4d-4776-a87c-7f79de4cc97c');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"alignmentgroup":"True","hovertemplate":"variable=count<br>OnlineSecurity=%{x}<br>Count (#)=%{y}<extra></extra>","legendgroup":"count","marker":{"color":"darkblue","pattern":{"shape":""}},"name":"count","offsetgroup":"count","orientation":"v","showlegend":true,"textposition":"auto","texttemplate":"%{y}","type":"bar","x":["No","Yes"],"xaxis":"x","y":[3498,2019],"yaxis":"y"}],"layout":{"autosize":false,"barmode":"relative","legend":{"title":{"text":"variable"},"tracegroupgap":0},"margin":{"t":60},"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"xaxis":{"anchor":"y","domain":[0,1],"title":{"text":"OnlineSecurity"}},"yaxis":{"anchor":"x","domain":[0,1],"title":{"text":"Count (#)"}}}},"text/html":["<div>                            <div id=\"bc5e22a5-598d-468c-9f23-b310d386f763\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"bc5e22a5-598d-468c-9f23-b310d386f763\")) {                    Plotly.newPlot(                        \"bc5e22a5-598d-468c-9f23-b310d386f763\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=count\\u003cbr\\u003eOnlineSecurity=%{x}\\u003cbr\\u003eCount (#)=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"count\",\"marker\":{\"color\":\"darkblue\",\"pattern\":{\"shape\":\"\"}},\"name\":\"count\",\"offsetgroup\":\"count\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"texttemplate\":\"%{y}\",\"x\":[\"No\",\"Yes\"],\"xaxis\":\"x\",\"y\":[3498,2019],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"OnlineSecurity\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Count (#)\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\",\"showlegend\":false,\"autosize\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('bc5e22a5-598d-468c-9f23-b310d386f763');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["OnlineBackup\n","No     3088\n","Yes    2429\n","Name: count, dtype: int64\n","\n"]},{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"alignmentgroup":"True","hovertemplate":"variable=count<br>OnlineBackup=%{x}<br>Count (#)=%{y}<extra></extra>","legendgroup":"count","marker":{"color":"darkblue","pattern":{"shape":""}},"name":"count","offsetgroup":"count","orientation":"v","showlegend":true,"textposition":"auto","texttemplate":"%{y}","type":"bar","x":["No","Yes"],"xaxis":"x","y":[3088,2429],"yaxis":"y"}],"layout":{"autosize":false,"barmode":"relative","legend":{"title":{"text":"variable"},"tracegroupgap":0},"margin":{"t":60},"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"xaxis":{"anchor":"y","domain":[0,1],"title":{"text":"OnlineBackup"}},"yaxis":{"anchor":"x","domain":[0,1],"title":{"text":"Count (#)"}}}},"text/html":["<div>                            <div id=\"a16edc03-69dd-49cb-bd82-ff18138c7be9\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"a16edc03-69dd-49cb-bd82-ff18138c7be9\")) {                    Plotly.newPlot(                        \"a16edc03-69dd-49cb-bd82-ff18138c7be9\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=count\\u003cbr\\u003eOnlineBackup=%{x}\\u003cbr\\u003eCount (#)=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"count\",\"marker\":{\"color\":\"darkblue\",\"pattern\":{\"shape\":\"\"}},\"name\":\"count\",\"offsetgroup\":\"count\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"texttemplate\":\"%{y}\",\"x\":[\"No\",\"Yes\"],\"xaxis\":\"x\",\"y\":[3088,2429],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"OnlineBackup\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Count (#)\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\",\"showlegend\":false,\"autosize\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('a16edc03-69dd-49cb-bd82-ff18138c7be9');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"alignmentgroup":"True","hovertemplate":"variable=count<br>OnlineBackup=%{x}<br>Count (#)=%{y}<extra></extra>","legendgroup":"count","marker":{"color":"darkblue","pattern":{"shape":""}},"name":"count","offsetgroup":"count","orientation":"v","showlegend":true,"textposition":"auto","texttemplate":"%{y}","type":"bar","x":["No","Yes"],"xaxis":"x","y":[3088,2429],"yaxis":"y"}],"layout":{"autosize":false,"barmode":"relative","legend":{"title":{"text":"variable"},"tracegroupgap":0},"margin":{"t":60},"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"xaxis":{"anchor":"y","domain":[0,1],"title":{"text":"OnlineBackup"}},"yaxis":{"anchor":"x","domain":[0,1],"title":{"text":"Count (#)"}}}},"text/html":["<div>                            <div id=\"40543ef6-9d84-44f8-9790-c89a4ad61fe7\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"40543ef6-9d84-44f8-9790-c89a4ad61fe7\")) {                    Plotly.newPlot(                        \"40543ef6-9d84-44f8-9790-c89a4ad61fe7\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=count\\u003cbr\\u003eOnlineBackup=%{x}\\u003cbr\\u003eCount (#)=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"count\",\"marker\":{\"color\":\"darkblue\",\"pattern\":{\"shape\":\"\"}},\"name\":\"count\",\"offsetgroup\":\"count\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"texttemplate\":\"%{y}\",\"x\":[\"No\",\"Yes\"],\"xaxis\":\"x\",\"y\":[3088,2429],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"OnlineBackup\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Count (#)\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\",\"showlegend\":false,\"autosize\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('40543ef6-9d84-44f8-9790-c89a4ad61fe7');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["DeviceProtection\n","No     3095\n","Yes    2422\n","Name: count, dtype: int64\n","\n"]},{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"alignmentgroup":"True","hovertemplate":"variable=count<br>DeviceProtection=%{x}<br>Count (#)=%{y}<extra></extra>","legendgroup":"count","marker":{"color":"darkblue","pattern":{"shape":""}},"name":"count","offsetgroup":"count","orientation":"v","showlegend":true,"textposition":"auto","texttemplate":"%{y}","type":"bar","x":["No","Yes"],"xaxis":"x","y":[3095,2422],"yaxis":"y"}],"layout":{"autosize":false,"barmode":"relative","legend":{"title":{"text":"variable"},"tracegroupgap":0},"margin":{"t":60},"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"xaxis":{"anchor":"y","domain":[0,1],"title":{"text":"DeviceProtection"}},"yaxis":{"anchor":"x","domain":[0,1],"title":{"text":"Count (#)"}}}},"text/html":["<div>                            <div id=\"a19d6e8a-59ef-4ce1-a4aa-fe8bd53fe5f5\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"a19d6e8a-59ef-4ce1-a4aa-fe8bd53fe5f5\")) {                    Plotly.newPlot(                        \"a19d6e8a-59ef-4ce1-a4aa-fe8bd53fe5f5\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=count\\u003cbr\\u003eDeviceProtection=%{x}\\u003cbr\\u003eCount (#)=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"count\",\"marker\":{\"color\":\"darkblue\",\"pattern\":{\"shape\":\"\"}},\"name\":\"count\",\"offsetgroup\":\"count\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"texttemplate\":\"%{y}\",\"x\":[\"No\",\"Yes\"],\"xaxis\":\"x\",\"y\":[3095,2422],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"DeviceProtection\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Count (#)\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\",\"showlegend\":false,\"autosize\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('a19d6e8a-59ef-4ce1-a4aa-fe8bd53fe5f5');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"alignmentgroup":"True","hovertemplate":"variable=count<br>DeviceProtection=%{x}<br>Count (#)=%{y}<extra></extra>","legendgroup":"count","marker":{"color":"darkblue","pattern":{"shape":""}},"name":"count","offsetgroup":"count","orientation":"v","showlegend":true,"textposition":"auto","texttemplate":"%{y}","type":"bar","x":["No","Yes"],"xaxis":"x","y":[3095,2422],"yaxis":"y"}],"layout":{"autosize":false,"barmode":"relative","legend":{"title":{"text":"variable"},"tracegroupgap":0},"margin":{"t":60},"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"xaxis":{"anchor":"y","domain":[0,1],"title":{"text":"DeviceProtection"}},"yaxis":{"anchor":"x","domain":[0,1],"title":{"text":"Count (#)"}}}},"text/html":["<div>                            <div id=\"cc09c8d1-08c7-46fc-8c2a-a67e57cbc0fd\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"cc09c8d1-08c7-46fc-8c2a-a67e57cbc0fd\")) {                    Plotly.newPlot(                        \"cc09c8d1-08c7-46fc-8c2a-a67e57cbc0fd\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=count\\u003cbr\\u003eDeviceProtection=%{x}\\u003cbr\\u003eCount (#)=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"count\",\"marker\":{\"color\":\"darkblue\",\"pattern\":{\"shape\":\"\"}},\"name\":\"count\",\"offsetgroup\":\"count\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"texttemplate\":\"%{y}\",\"x\":[\"No\",\"Yes\"],\"xaxis\":\"x\",\"y\":[3095,2422],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"DeviceProtection\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Count (#)\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\",\"showlegend\":false,\"autosize\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('cc09c8d1-08c7-46fc-8c2a-a67e57cbc0fd');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["TechSupport\n","No     3473\n","Yes    2044\n","Name: count, dtype: int64\n","\n"]},{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"alignmentgroup":"True","hovertemplate":"variable=count<br>TechSupport=%{x}<br>Count (#)=%{y}<extra></extra>","legendgroup":"count","marker":{"color":"darkblue","pattern":{"shape":""}},"name":"count","offsetgroup":"count","orientation":"v","showlegend":true,"textposition":"auto","texttemplate":"%{y}","type":"bar","x":["No","Yes"],"xaxis":"x","y":[3473,2044],"yaxis":"y"}],"layout":{"autosize":false,"barmode":"relative","legend":{"title":{"text":"variable"},"tracegroupgap":0},"margin":{"t":60},"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"xaxis":{"anchor":"y","domain":[0,1],"title":{"text":"TechSupport"}},"yaxis":{"anchor":"x","domain":[0,1],"title":{"text":"Count (#)"}}}},"text/html":["<div>                            <div id=\"71145d1d-4d47-4da3-a349-a1d44c005178\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"71145d1d-4d47-4da3-a349-a1d44c005178\")) {                    Plotly.newPlot(                        \"71145d1d-4d47-4da3-a349-a1d44c005178\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=count\\u003cbr\\u003eTechSupport=%{x}\\u003cbr\\u003eCount (#)=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"count\",\"marker\":{\"color\":\"darkblue\",\"pattern\":{\"shape\":\"\"}},\"name\":\"count\",\"offsetgroup\":\"count\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"texttemplate\":\"%{y}\",\"x\":[\"No\",\"Yes\"],\"xaxis\":\"x\",\"y\":[3473,2044],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"TechSupport\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Count (#)\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\",\"showlegend\":false,\"autosize\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('71145d1d-4d47-4da3-a349-a1d44c005178');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"alignmentgroup":"True","hovertemplate":"variable=count<br>TechSupport=%{x}<br>Count (#)=%{y}<extra></extra>","legendgroup":"count","marker":{"color":"darkblue","pattern":{"shape":""}},"name":"count","offsetgroup":"count","orientation":"v","showlegend":true,"textposition":"auto","texttemplate":"%{y}","type":"bar","x":["No","Yes"],"xaxis":"x","y":[3473,2044],"yaxis":"y"}],"layout":{"autosize":false,"barmode":"relative","legend":{"title":{"text":"variable"},"tracegroupgap":0},"margin":{"t":60},"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"xaxis":{"anchor":"y","domain":[0,1],"title":{"text":"TechSupport"}},"yaxis":{"anchor":"x","domain":[0,1],"title":{"text":"Count (#)"}}}},"text/html":["<div>                            <div id=\"12a24d9a-b34b-4b62-b040-eae656656886\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"12a24d9a-b34b-4b62-b040-eae656656886\")) {                    Plotly.newPlot(                        \"12a24d9a-b34b-4b62-b040-eae656656886\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=count\\u003cbr\\u003eTechSupport=%{x}\\u003cbr\\u003eCount (#)=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"count\",\"marker\":{\"color\":\"darkblue\",\"pattern\":{\"shape\":\"\"}},\"name\":\"count\",\"offsetgroup\":\"count\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"texttemplate\":\"%{y}\",\"x\":[\"No\",\"Yes\"],\"xaxis\":\"x\",\"y\":[3473,2044],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"TechSupport\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Count (#)\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\",\"showlegend\":false,\"autosize\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('12a24d9a-b34b-4b62-b040-eae656656886');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["StreamingTV\n","No     2810\n","Yes    2707\n","Name: count, dtype: int64\n","\n"]},{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"alignmentgroup":"True","hovertemplate":"variable=count<br>StreamingTV=%{x}<br>Count (#)=%{y}<extra></extra>","legendgroup":"count","marker":{"color":"darkblue","pattern":{"shape":""}},"name":"count","offsetgroup":"count","orientation":"v","showlegend":true,"textposition":"auto","texttemplate":"%{y}","type":"bar","x":["No","Yes"],"xaxis":"x","y":[2810,2707],"yaxis":"y"}],"layout":{"autosize":false,"barmode":"relative","legend":{"title":{"text":"variable"},"tracegroupgap":0},"margin":{"t":60},"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"xaxis":{"anchor":"y","domain":[0,1],"title":{"text":"StreamingTV"}},"yaxis":{"anchor":"x","domain":[0,1],"title":{"text":"Count (#)"}}}},"text/html":["<div>                            <div id=\"2e389592-1fa7-4fd9-9791-a7af6c4ca2f0\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"2e389592-1fa7-4fd9-9791-a7af6c4ca2f0\")) {                    Plotly.newPlot(                        \"2e389592-1fa7-4fd9-9791-a7af6c4ca2f0\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=count\\u003cbr\\u003eStreamingTV=%{x}\\u003cbr\\u003eCount (#)=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"count\",\"marker\":{\"color\":\"darkblue\",\"pattern\":{\"shape\":\"\"}},\"name\":\"count\",\"offsetgroup\":\"count\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"texttemplate\":\"%{y}\",\"x\":[\"No\",\"Yes\"],\"xaxis\":\"x\",\"y\":[2810,2707],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"StreamingTV\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Count (#)\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\",\"showlegend\":false,\"autosize\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('2e389592-1fa7-4fd9-9791-a7af6c4ca2f0');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"alignmentgroup":"True","hovertemplate":"variable=count<br>StreamingTV=%{x}<br>Count (#)=%{y}<extra></extra>","legendgroup":"count","marker":{"color":"darkblue","pattern":{"shape":""}},"name":"count","offsetgroup":"count","orientation":"v","showlegend":true,"textposition":"auto","texttemplate":"%{y}","type":"bar","x":["No","Yes"],"xaxis":"x","y":[2810,2707],"yaxis":"y"}],"layout":{"autosize":false,"barmode":"relative","legend":{"title":{"text":"variable"},"tracegroupgap":0},"margin":{"t":60},"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"xaxis":{"anchor":"y","domain":[0,1],"title":{"text":"StreamingTV"}},"yaxis":{"anchor":"x","domain":[0,1],"title":{"text":"Count (#)"}}}},"text/html":["<div>                            <div id=\"7ce0efe2-7d66-4da2-aab4-813a85d010ad\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"7ce0efe2-7d66-4da2-aab4-813a85d010ad\")) {                    Plotly.newPlot(                        \"7ce0efe2-7d66-4da2-aab4-813a85d010ad\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=count\\u003cbr\\u003eStreamingTV=%{x}\\u003cbr\\u003eCount (#)=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"count\",\"marker\":{\"color\":\"darkblue\",\"pattern\":{\"shape\":\"\"}},\"name\":\"count\",\"offsetgroup\":\"count\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"texttemplate\":\"%{y}\",\"x\":[\"No\",\"Yes\"],\"xaxis\":\"x\",\"y\":[2810,2707],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"StreamingTV\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Count (#)\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\",\"showlegend\":false,\"autosize\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('7ce0efe2-7d66-4da2-aab4-813a85d010ad');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["StreamingMovies\n","No     2785\n","Yes    2732\n","Name: count, dtype: int64\n","\n"]},{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"alignmentgroup":"True","hovertemplate":"variable=count<br>StreamingMovies=%{x}<br>Count (#)=%{y}<extra></extra>","legendgroup":"count","marker":{"color":"darkblue","pattern":{"shape":""}},"name":"count","offsetgroup":"count","orientation":"v","showlegend":true,"textposition":"auto","texttemplate":"%{y}","type":"bar","x":["No","Yes"],"xaxis":"x","y":[2785,2732],"yaxis":"y"}],"layout":{"autosize":false,"barmode":"relative","legend":{"title":{"text":"variable"},"tracegroupgap":0},"margin":{"t":60},"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"xaxis":{"anchor":"y","domain":[0,1],"title":{"text":"StreamingMovies"}},"yaxis":{"anchor":"x","domain":[0,1],"title":{"text":"Count (#)"}}}},"text/html":["<div>                            <div id=\"ffbbe753-0a24-4876-bd3e-b69576236960\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"ffbbe753-0a24-4876-bd3e-b69576236960\")) {                    Plotly.newPlot(                        \"ffbbe753-0a24-4876-bd3e-b69576236960\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=count\\u003cbr\\u003eStreamingMovies=%{x}\\u003cbr\\u003eCount (#)=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"count\",\"marker\":{\"color\":\"darkblue\",\"pattern\":{\"shape\":\"\"}},\"name\":\"count\",\"offsetgroup\":\"count\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"texttemplate\":\"%{y}\",\"x\":[\"No\",\"Yes\"],\"xaxis\":\"x\",\"y\":[2785,2732],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"StreamingMovies\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Count (#)\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\",\"showlegend\":false,\"autosize\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('ffbbe753-0a24-4876-bd3e-b69576236960');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"alignmentgroup":"True","hovertemplate":"variable=count<br>StreamingMovies=%{x}<br>Count (#)=%{y}<extra></extra>","legendgroup":"count","marker":{"color":"darkblue","pattern":{"shape":""}},"name":"count","offsetgroup":"count","orientation":"v","showlegend":true,"textposition":"auto","texttemplate":"%{y}","type":"bar","x":["No","Yes"],"xaxis":"x","y":[2785,2732],"yaxis":"y"}],"layout":{"autosize":false,"barmode":"relative","legend":{"title":{"text":"variable"},"tracegroupgap":0},"margin":{"t":60},"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"xaxis":{"anchor":"y","domain":[0,1],"title":{"text":"StreamingMovies"}},"yaxis":{"anchor":"x","domain":[0,1],"title":{"text":"Count (#)"}}}},"text/html":["<div>                            <div id=\"5e0f538f-9603-440a-a1c4-13eadc70986a\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"5e0f538f-9603-440a-a1c4-13eadc70986a\")) {                    Plotly.newPlot(                        \"5e0f538f-9603-440a-a1c4-13eadc70986a\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=count\\u003cbr\\u003eStreamingMovies=%{x}\\u003cbr\\u003eCount (#)=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"count\",\"marker\":{\"color\":\"darkblue\",\"pattern\":{\"shape\":\"\"}},\"name\":\"count\",\"offsetgroup\":\"count\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"texttemplate\":\"%{y}\",\"x\":[\"No\",\"Yes\"],\"xaxis\":\"x\",\"y\":[2785,2732],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"StreamingMovies\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Count (#)\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\",\"showlegend\":false,\"autosize\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('5e0f538f-9603-440a-a1c4-13eadc70986a');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"}],"source":["for i in categorical:\n","    #print(i, ':')\n","    print(internet_data[i].value_counts())\n","    fig = px.bar(internet_data[i].value_counts(), labels={'value':'Count (#)'}, text_auto=True).update_layout(showlegend=False,autosize=False).update_traces(marker_color='darkblue')\n","    print()\n","    fig.show()\n","    fig.show()"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2023-12-01T00:05:51.309934Z","iopub.status.busy":"2023-12-01T00:05:51.308826Z","iopub.status.idle":"2023-12-01T00:05:51.348867Z","shell.execute_reply":"2023-12-01T00:05:51.347729Z","shell.execute_reply.started":"2023-12-01T00:05:51.309882Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>customerID</th>\n","      <th>InternetService</th>\n","      <th>OnlineSecurity</th>\n","      <th>OnlineBackup</th>\n","      <th>DeviceProtection</th>\n","      <th>TechSupport</th>\n","      <th>StreamingTV</th>\n","      <th>StreamingMovies</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>5517</td>\n","      <td>5517</td>\n","      <td>5517</td>\n","      <td>5517</td>\n","      <td>5517</td>\n","      <td>5517</td>\n","      <td>5517</td>\n","      <td>5517</td>\n","    </tr>\n","    <tr>\n","      <th>unique</th>\n","      <td>5517</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>top</th>\n","      <td>7590-VHVEG</td>\n","      <td>Fiber optic</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>freq</th>\n","      <td>1</td>\n","      <td>3096</td>\n","      <td>3498</td>\n","      <td>3088</td>\n","      <td>3095</td>\n","      <td>3473</td>\n","      <td>2810</td>\n","      <td>2785</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        customerID InternetService OnlineSecurity OnlineBackup  \\\n","count         5517            5517           5517         5517   \n","unique        5517               2              2            2   \n","top     7590-VHVEG     Fiber optic             No           No   \n","freq             1            3096           3498         3088   \n","\n","       DeviceProtection TechSupport StreamingTV StreamingMovies  \n","count              5517        5517        5517            5517  \n","unique                2           2           2               2  \n","top                  No          No          No              No  \n","freq               3095        3473        2810            2785  "]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["internet_data.describe()"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2023-12-01T00:05:52.393204Z","iopub.status.busy":"2023-12-01T00:05:52.392734Z","iopub.status.idle":"2023-12-01T00:05:52.408559Z","shell.execute_reply":"2023-12-01T00:05:52.407412Z","shell.execute_reply.started":"2023-12-01T00:05:52.393168Z"},"trusted":true},"outputs":[{"data":{"text/plain":["customerID          0\n","InternetService     0\n","OnlineSecurity      0\n","OnlineBackup        0\n","DeviceProtection    0\n","TechSupport         0\n","StreamingTV         0\n","StreamingMovies     0\n","dtype: int64"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["internet_data.isna().sum()"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>customerID</th>\n","      <th>InternetService</th>\n","      <th>OnlineSecurity</th>\n","      <th>OnlineBackup</th>\n","      <th>DeviceProtection</th>\n","      <th>TechSupport</th>\n","      <th>StreamingTV</th>\n","      <th>StreamingMovies</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>7590-VHVEG</td>\n","      <td>DSL</td>\n","      <td>No</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5575-GNVDE</td>\n","      <td>DSL</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3668-QPYBK</td>\n","      <td>DSL</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>7795-CFOCW</td>\n","      <td>DSL</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>9237-HQITU</td>\n","      <td>Fiber optic</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>5512</th>\n","      <td>6840-RESVB</td>\n","      <td>DSL</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>5513</th>\n","      <td>2234-XADUH</td>\n","      <td>Fiber optic</td>\n","      <td>No</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>5514</th>\n","      <td>4801-JZAZL</td>\n","      <td>DSL</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>5515</th>\n","      <td>8361-LTMKD</td>\n","      <td>Fiber optic</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>5516</th>\n","      <td>3186-AJIEK</td>\n","      <td>Fiber optic</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5517 rows × 8 columns</p>\n","</div>"],"text/plain":["      customerID InternetService OnlineSecurity OnlineBackup DeviceProtection  \\\n","0     7590-VHVEG             DSL             No          Yes               No   \n","1     5575-GNVDE             DSL            Yes           No              Yes   \n","2     3668-QPYBK             DSL            Yes          Yes               No   \n","3     7795-CFOCW             DSL            Yes           No              Yes   \n","4     9237-HQITU     Fiber optic             No           No               No   \n","...          ...             ...            ...          ...              ...   \n","5512  6840-RESVB             DSL            Yes           No              Yes   \n","5513  2234-XADUH     Fiber optic             No          Yes              Yes   \n","5514  4801-JZAZL             DSL            Yes           No               No   \n","5515  8361-LTMKD     Fiber optic             No           No               No   \n","5516  3186-AJIEK     Fiber optic            Yes           No              Yes   \n","\n","     TechSupport StreamingTV StreamingMovies  \n","0             No          No              No  \n","1             No          No              No  \n","2             No          No              No  \n","3            Yes          No              No  \n","4             No          No              No  \n","...          ...         ...             ...  \n","5512         Yes         Yes             Yes  \n","5513          No         Yes             Yes  \n","5514          No          No              No  \n","5515          No          No              No  \n","5516         Yes         Yes             Yes  \n","\n","[5517 rows x 8 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["display(internet_data)"]},{"cell_type":"markdown","metadata":{},"source":["`Preprocessing`"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2023-12-01T00:07:35.879986Z","iopub.status.busy":"2023-12-01T00:07:35.879598Z","iopub.status.idle":"2023-12-01T00:07:35.899097Z","shell.execute_reply":"2023-12-01T00:07:35.898124Z","shell.execute_reply.started":"2023-12-01T00:07:35.879954Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>customer_id</th>\n","      <th>internet_service</th>\n","      <th>online_security</th>\n","      <th>online_backup</th>\n","      <th>device_protection</th>\n","      <th>tech_support</th>\n","      <th>streaming_tv</th>\n","      <th>streaming_movies</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>7590-VHVEG</td>\n","      <td>DSL</td>\n","      <td>No</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5575-GNVDE</td>\n","      <td>DSL</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3668-QPYBK</td>\n","      <td>DSL</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>7795-CFOCW</td>\n","      <td>DSL</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>9237-HQITU</td>\n","      <td>Fiber optic</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>5512</th>\n","      <td>6840-RESVB</td>\n","      <td>DSL</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>5513</th>\n","      <td>2234-XADUH</td>\n","      <td>Fiber optic</td>\n","      <td>No</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>5514</th>\n","      <td>4801-JZAZL</td>\n","      <td>DSL</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>5515</th>\n","      <td>8361-LTMKD</td>\n","      <td>Fiber optic</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>5516</th>\n","      <td>3186-AJIEK</td>\n","      <td>Fiber optic</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5517 rows × 8 columns</p>\n","</div>"],"text/plain":["     customer_id internet_service online_security online_backup  \\\n","0     7590-VHVEG              DSL              No           Yes   \n","1     5575-GNVDE              DSL             Yes            No   \n","2     3668-QPYBK              DSL             Yes           Yes   \n","3     7795-CFOCW              DSL             Yes            No   \n","4     9237-HQITU      Fiber optic              No            No   \n","...          ...              ...             ...           ...   \n","5512  6840-RESVB              DSL             Yes            No   \n","5513  2234-XADUH      Fiber optic              No           Yes   \n","5514  4801-JZAZL              DSL             Yes            No   \n","5515  8361-LTMKD      Fiber optic              No            No   \n","5516  3186-AJIEK      Fiber optic             Yes            No   \n","\n","     device_protection tech_support streaming_tv streaming_movies  \n","0                   No           No           No               No  \n","1                  Yes           No           No               No  \n","2                   No           No           No               No  \n","3                  Yes          Yes           No               No  \n","4                   No           No           No               No  \n","...                ...          ...          ...              ...  \n","5512               Yes          Yes          Yes              Yes  \n","5513               Yes           No          Yes              Yes  \n","5514                No           No           No               No  \n","5515                No           No           No               No  \n","5516               Yes          Yes          Yes              Yes  \n","\n","[5517 rows x 8 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["internet_df = internet_data.copy()\n","# column renaming\n","internet_df = internet_df.rename(columns={\"customerID\": \"customer_id\", \"InternetService\": \"internet_service\", \"OnlineSecurity\": \"online_security\", \"OnlineBackup\": \"online_backup\",\n","                                         \"DeviceProtection\": \"device_protection\", \"TechSupport\": \"tech_support\", \"StreamingTV\": \"streaming_tv\",\n","                                         \"StreamingMovies\": \"streaming_movies\"})\n","\n","display(internet_df)"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2023-12-01T00:07:37.945942Z","iopub.status.busy":"2023-12-01T00:07:37.945531Z","iopub.status.idle":"2023-12-01T00:07:38.030203Z","shell.execute_reply":"2023-12-01T00:07:38.029209Z","shell.execute_reply.started":"2023-12-01T00:07:37.945894Z"},"trusted":true},"outputs":[{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"alignmentgroup":"True","hovertemplate":"variable=0<br>internet_service=%{x}<br>value=%{y}<extra></extra>","legendgroup":"0","marker":{"color":"#636efa","pattern":{"shape":""}},"name":"0","offsetgroup":"0","orientation":"v","showlegend":true,"textposition":"auto","texttemplate":"%{y}","type":"bar","x":["DSL","Fiber optic"],"xaxis":"x","y":[1241,2257],"yaxis":"y"}],"layout":{"autosize":false,"barmode":"relative","legend":{"title":{"text":"variable"},"tracegroupgap":0},"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"title":{"text":"Customer Internet Service Type"},"xaxis":{"anchor":"y","domain":[0,1],"title":{"text":"internet_service"}},"yaxis":{"anchor":"x","domain":[0,1],"title":{"text":"value"}}}},"text/html":["<div>                            <div id=\"053af3fb-8f98-48a0-9fdc-eaaf50f87c92\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"053af3fb-8f98-48a0-9fdc-eaaf50f87c92\")) {                    Plotly.newPlot(                        \"053af3fb-8f98-48a0-9fdc-eaaf50f87c92\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=0\\u003cbr\\u003einternet_service=%{x}\\u003cbr\\u003evalue=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"0\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"0\",\"offsetgroup\":\"0\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"texttemplate\":\"%{y}\",\"x\":[\"DSL\",\"Fiber optic\"],\"xaxis\":\"x\",\"y\":[1241,2257],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"internet_service\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"value\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Customer Internet Service Type\"},\"barmode\":\"relative\",\"showlegend\":false,\"autosize\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('053af3fb-8f98-48a0-9fdc-eaaf50f87c92');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"}],"source":["internet_grp = internet_df.groupby(['online_security','internet_service']).size().reset_index().groupby('internet_service')[[0]].max()\n","\n","fig = px.bar(internet_grp, title=\"Customer Internet Service Type\",text_auto = True)\n","fig.update_layout(showlegend=False, autosize=False)\n","fig.show()"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 1000x600 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["crosstab = pd.crosstab(internet_df['online_security'], internet_df['internet_service'])\n","fig, ax = plt.subplots(figsize=(10, 6))\n","g = sns.heatmap(crosstab, cbar=False, cmap=\"Grays\", linewidths=0.0029, annot=True, fmt='d', linecolor='lightgray', ax=ax)\n","\n","g.set_ylabel('Selected Online Security')\n","g.set_xlabel('Service Type')\n","\n","ax.text(x=0.5, y=1.1, s='Internet Data', fontsize=16, weight='bold', ha='center', va='bottom', transform=ax.transAxes)\n","ax.text(x=0.5, y=1.05, s='Heatmap Analysis', fontsize=8, alpha=0.75, ha='center', va='bottom', transform=ax.transAxes)\n","\n","plt.yticks(rotation=0)\n","plt.xticks(rotation=0)\n","plt.show()"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2023-12-01T00:08:00.452624Z","iopub.status.busy":"2023-12-01T00:08:00.452241Z","iopub.status.idle":"2023-12-01T00:08:00.485532Z","shell.execute_reply":"2023-12-01T00:08:00.484493Z","shell.execute_reply.started":"2023-12-01T00:08:00.452593Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>customer_id</th>\n","      <th>internet_service</th>\n","      <th>online_security</th>\n","      <th>online_backup</th>\n","      <th>device_protection</th>\n","      <th>tech_support</th>\n","      <th>streaming_tv</th>\n","      <th>streaming_movies</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>7590-VHVEG</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5575-GNVDE</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3668-QPYBK</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>7795-CFOCW</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>9237-HQITU</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>5512</th>\n","      <td>6840-RESVB</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5513</th>\n","      <td>2234-XADUH</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5514</th>\n","      <td>4801-JZAZL</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5515</th>\n","      <td>8361-LTMKD</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5516</th>\n","      <td>3186-AJIEK</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5517 rows × 8 columns</p>\n","</div>"],"text/plain":["     customer_id  internet_service  online_security  online_backup  \\\n","0     7590-VHVEG                 0                0              1   \n","1     5575-GNVDE                 0                1              0   \n","2     3668-QPYBK                 0                1              1   \n","3     7795-CFOCW                 0                1              0   \n","4     9237-HQITU                 1                0              0   \n","...          ...               ...              ...            ...   \n","5512  6840-RESVB                 0                1              0   \n","5513  2234-XADUH                 1                0              1   \n","5514  4801-JZAZL                 0                1              0   \n","5515  8361-LTMKD                 1                0              0   \n","5516  3186-AJIEK                 1                1              0   \n","\n","      device_protection  tech_support  streaming_tv  streaming_movies  \n","0                     0             0             0                 0  \n","1                     1             0             0                 0  \n","2                     0             0             0                 0  \n","3                     1             1             0                 0  \n","4                     0             0             0                 0  \n","...                 ...           ...           ...               ...  \n","5512                  1             1             1                 1  \n","5513                  1             0             1                 1  \n","5514                  0             0             0                 0  \n","5515                  0             0             0                 0  \n","5516                  1             1             1                 1  \n","\n","[5517 rows x 8 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["# label encoding\n","internet_df = MultiColumnLabelEncoder(columns = ['internet_service','online_security', 'online_backup', 'device_protection','tech_support', 'streaming_tv', 'streaming_movies']).fit_transform(internet_df)\n","\n","display(internet_df)"]},{"cell_type":"markdown","metadata":{},"source":["`Summary`\n","\n","Looking into our internet_data, we see a smaller number of rows and therefore have a smaller number of customer_ids (compared to all the other sets). \n","\n","We perform some renaming and label encoding to the columns. After doing so, we are making the assumption that those customer_ids that are not included in this dataset did not sign up for the internet services therefore we will also make the assumption that where we find NaNs in our final, merged set we can replace those with 'No' or 'Not subscribed'."]},{"cell_type":"markdown","metadata":{},"source":["-----------"]},{"cell_type":"markdown","metadata":{},"source":["# Phone data"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T17:45:14.722976Z","iopub.status.busy":"2023-11-30T17:45:14.722603Z","iopub.status.idle":"2023-11-30T17:45:14.734147Z","shell.execute_reply":"2023-11-30T17:45:14.733169Z","shell.execute_reply.started":"2023-11-30T17:45:14.722944Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 6361 entries, 0 to 6360\n","Data columns (total 2 columns):\n"," #   Column         Non-Null Count  Dtype \n","---  ------         --------------  ----- \n"," 0   customerID     6361 non-null   object\n"," 1   MultipleLines  6361 non-null   object\n","dtypes: object(2)\n","memory usage: 99.5+ KB\n"]}],"source":["phone_data.info()"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Categorical Features: ['MultipleLines']\n","Non-Categorical Features: ['customerID']\n","Discrete Features: []\n","Continuous Features: []\n"]}],"source":["categorical, non_categorical, discrete, continuous = classify_features(phone_data)\n","\n","print(\"Categorical Features:\", categorical)\n","print(\"Non-Categorical Features:\", non_categorical)\n","print(\"Discrete Features:\", discrete)\n","print(\"Continuous Features:\", continuous)"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T17:45:14.736282Z","iopub.status.busy":"2023-11-30T17:45:14.735380Z","iopub.status.idle":"2023-11-30T17:45:14.754870Z","shell.execute_reply":"2023-11-30T17:45:14.754005Z","shell.execute_reply.started":"2023-11-30T17:45:14.736256Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>customerID</th>\n","      <th>MultipleLines</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>6361</td>\n","      <td>6361</td>\n","    </tr>\n","    <tr>\n","      <th>unique</th>\n","      <td>6361</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>top</th>\n","      <td>5575-GNVDE</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>freq</th>\n","      <td>1</td>\n","      <td>3390</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        customerID MultipleLines\n","count         6361          6361\n","unique        6361             2\n","top     5575-GNVDE            No\n","freq             1          3390"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["phone_data.describe()"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T17:45:14.756310Z","iopub.status.busy":"2023-11-30T17:45:14.755987Z","iopub.status.idle":"2023-11-30T17:45:14.764593Z","shell.execute_reply":"2023-11-30T17:45:14.763774Z","shell.execute_reply.started":"2023-11-30T17:45:14.756278Z"},"trusted":true},"outputs":[{"data":{"text/plain":["customerID       0\n","MultipleLines    0\n","dtype: int64"]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["phone_data.isna().sum()"]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T17:45:14.766178Z","iopub.status.busy":"2023-11-30T17:45:14.765825Z","iopub.status.idle":"2023-11-30T17:45:14.778487Z","shell.execute_reply":"2023-11-30T17:45:14.777532Z","shell.execute_reply.started":"2023-11-30T17:45:14.766147Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>customerID</th>\n","      <th>MultipleLines</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5575-GNVDE</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3668-QPYBK</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>9237-HQITU</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9305-CDSKC</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1452-KIOVK</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>6356</th>\n","      <td>2569-WGERO</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>6357</th>\n","      <td>6840-RESVB</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>6358</th>\n","      <td>2234-XADUH</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>6359</th>\n","      <td>8361-LTMKD</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>6360</th>\n","      <td>3186-AJIEK</td>\n","      <td>No</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>6361 rows × 2 columns</p>\n","</div>"],"text/plain":["      customerID MultipleLines\n","0     5575-GNVDE            No\n","1     3668-QPYBK            No\n","2     9237-HQITU            No\n","3     9305-CDSKC           Yes\n","4     1452-KIOVK           Yes\n","...          ...           ...\n","6356  2569-WGERO            No\n","6357  6840-RESVB           Yes\n","6358  2234-XADUH           Yes\n","6359  8361-LTMKD           Yes\n","6360  3186-AJIEK            No\n","\n","[6361 rows x 2 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["display(phone_data)"]},{"cell_type":"markdown","metadata":{},"source":["`Preprocessing`"]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T17:45:14.780406Z","iopub.status.busy":"2023-11-30T17:45:14.779800Z","iopub.status.idle":"2023-11-30T17:45:14.793297Z","shell.execute_reply":"2023-11-30T17:45:14.792451Z","shell.execute_reply.started":"2023-11-30T17:45:14.780345Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>customer_id</th>\n","      <th>multiple_lines</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5575-GNVDE</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3668-QPYBK</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>9237-HQITU</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9305-CDSKC</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1452-KIOVK</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>6356</th>\n","      <td>2569-WGERO</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>6357</th>\n","      <td>6840-RESVB</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>6358</th>\n","      <td>2234-XADUH</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>6359</th>\n","      <td>8361-LTMKD</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>6360</th>\n","      <td>3186-AJIEK</td>\n","      <td>No</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>6361 rows × 2 columns</p>\n","</div>"],"text/plain":["     customer_id multiple_lines\n","0     5575-GNVDE             No\n","1     3668-QPYBK             No\n","2     9237-HQITU             No\n","3     9305-CDSKC            Yes\n","4     1452-KIOVK            Yes\n","...          ...            ...\n","6356  2569-WGERO             No\n","6357  6840-RESVB            Yes\n","6358  2234-XADUH            Yes\n","6359  8361-LTMKD            Yes\n","6360  3186-AJIEK             No\n","\n","[6361 rows x 2 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["phone_df = phone_data.copy()\n","# column renaming\n","phone_df = phone_df.rename(columns={\"customerID\": \"customer_id\", \"MultipleLines\": \"multiple_lines\"})\n","\n","display(phone_df)"]},{"cell_type":"code","execution_count":43,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T17:45:14.794678Z","iopub.status.busy":"2023-11-30T17:45:14.794395Z","iopub.status.idle":"2023-11-30T17:45:14.811233Z","shell.execute_reply":"2023-11-30T17:45:14.810336Z","shell.execute_reply.started":"2023-11-30T17:45:14.794633Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>customer_id</th>\n","      <th>multiple_lines</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5575-GNVDE</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3668-QPYBK</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>9237-HQITU</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9305-CDSKC</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1452-KIOVK</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>6356</th>\n","      <td>2569-WGERO</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6357</th>\n","      <td>6840-RESVB</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6358</th>\n","      <td>2234-XADUH</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6359</th>\n","      <td>8361-LTMKD</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6360</th>\n","      <td>3186-AJIEK</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>6361 rows × 2 columns</p>\n","</div>"],"text/plain":["     customer_id  multiple_lines\n","0     5575-GNVDE               0\n","1     3668-QPYBK               0\n","2     9237-HQITU               0\n","3     9305-CDSKC               1\n","4     1452-KIOVK               1\n","...          ...             ...\n","6356  2569-WGERO               0\n","6357  6840-RESVB               1\n","6358  2234-XADUH               1\n","6359  8361-LTMKD               1\n","6360  3186-AJIEK               0\n","\n","[6361 rows x 2 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["# label encoding\n","phone_df.multiple_lines = encoder.fit_transform(phone_df.multiple_lines.values)\n","display(phone_df)"]},{"cell_type":"markdown","metadata":{},"source":["`Summary`\n","\n","Our last DF in question, phone_data, has a smaller subset of data and one feature we are insterested in called 'multiple_lines'. We fix the column naming convention to mirror the edits we made to the other DFs and we encode our selected feature using label encoding. "]},{"cell_type":"markdown","metadata":{},"source":["-----------"]},{"cell_type":"markdown","metadata":{},"source":["# Merging"]},{"cell_type":"code","execution_count":44,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T17:45:14.812782Z","iopub.status.busy":"2023-11-30T17:45:14.812442Z","iopub.status.idle":"2023-11-30T17:45:14.867926Z","shell.execute_reply":"2023-11-30T17:45:14.867055Z","shell.execute_reply.started":"2023-11-30T17:45:14.812756Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>customer_id</th>\n","      <th>begin_date</th>\n","      <th>contract_type</th>\n","      <th>paperless_billing</th>\n","      <th>payment_method</th>\n","      <th>monthly_charges</th>\n","      <th>total_charges</th>\n","      <th>churn_target</th>\n","      <th>gender</th>\n","      <th>senior_citizen</th>\n","      <th>partner</th>\n","      <th>dependents</th>\n","      <th>internet_service</th>\n","      <th>online_security</th>\n","      <th>online_backup</th>\n","      <th>device_protection</th>\n","      <th>tech_support</th>\n","      <th>streaming_tv</th>\n","      <th>streaming_movies</th>\n","      <th>multiple_lines</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>7590-VHVEG</td>\n","      <td>2020-01-01</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>29.85</td>\n","      <td>29.85</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5575-GNVDE</td>\n","      <td>2017-04-01</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>56.95</td>\n","      <td>1889.50</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3668-QPYBK</td>\n","      <td>2019-10-01</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>53.85</td>\n","      <td>108.15</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>7795-CFOCW</td>\n","      <td>2016-05-01</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>42.30</td>\n","      <td>1840.75</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>9237-HQITU</td>\n","      <td>2019-09-01</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>70.70</td>\n","      <td>151.65</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7027</th>\n","      <td>6840-RESVB</td>\n","      <td>2018-02-01</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>84.80</td>\n","      <td>1990.50</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>7028</th>\n","      <td>2234-XADUH</td>\n","      <td>2014-02-01</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>103.20</td>\n","      <td>7362.90</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>7029</th>\n","      <td>4801-JZAZL</td>\n","      <td>2019-03-01</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>29.60</td>\n","      <td>346.45</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>7030</th>\n","      <td>8361-LTMKD</td>\n","      <td>2019-07-01</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>74.40</td>\n","      <td>306.60</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>7031</th>\n","      <td>3186-AJIEK</td>\n","      <td>2014-08-01</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>105.65</td>\n","      <td>6844.50</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7032 rows × 20 columns</p>\n","</div>"],"text/plain":["     customer_id begin_date  contract_type  paperless_billing  payment_method  \\\n","0     7590-VHVEG 2020-01-01              0                  1               2   \n","1     5575-GNVDE 2017-04-01              1                  0               3   \n","2     3668-QPYBK 2019-10-01              0                  1               3   \n","3     7795-CFOCW 2016-05-01              1                  0               0   \n","4     9237-HQITU 2019-09-01              0                  1               2   \n","...          ...        ...            ...                ...             ...   \n","7027  6840-RESVB 2018-02-01              1                  1               3   \n","7028  2234-XADUH 2014-02-01              1                  1               1   \n","7029  4801-JZAZL 2019-03-01              0                  1               2   \n","7030  8361-LTMKD 2019-07-01              0                  1               3   \n","7031  3186-AJIEK 2014-08-01              2                  1               0   \n","\n","      monthly_charges  total_charges  churn_target  gender  senior_citizen  \\\n","0               29.85          29.85             1       0               0   \n","1               56.95        1889.50             1       1               0   \n","2               53.85         108.15             0       1               0   \n","3               42.30        1840.75             1       1               0   \n","4               70.70         151.65             0       0               0   \n","...               ...            ...           ...     ...             ...   \n","7027            84.80        1990.50             1       1               0   \n","7028           103.20        7362.90             1       0               0   \n","7029            29.60         346.45             1       0               0   \n","7030            74.40         306.60             0       1               1   \n","7031           105.65        6844.50             1       1               0   \n","\n","      partner  dependents  internet_service  online_security  online_backup  \\\n","0           1           0               0.0              0.0            1.0   \n","1           0           0               0.0              1.0            0.0   \n","2           0           0               0.0              1.0            1.0   \n","3           0           0               0.0              1.0            0.0   \n","4           0           0               1.0              0.0            0.0   \n","...       ...         ...               ...              ...            ...   \n","7027        1           1               0.0              1.0            0.0   \n","7028        1           1               1.0              0.0            1.0   \n","7029        1           1               0.0              1.0            0.0   \n","7030        1           0               1.0              0.0            0.0   \n","7031        0           0               1.0              1.0            0.0   \n","\n","      device_protection  tech_support  streaming_tv  streaming_movies  \\\n","0                   0.0           0.0           0.0               0.0   \n","1                   1.0           0.0           0.0               0.0   \n","2                   0.0           0.0           0.0               0.0   \n","3                   1.0           1.0           0.0               0.0   \n","4                   0.0           0.0           0.0               0.0   \n","...                 ...           ...           ...               ...   \n","7027                1.0           1.0           1.0               1.0   \n","7028                1.0           0.0           1.0               1.0   \n","7029                0.0           0.0           0.0               0.0   \n","7030                0.0           0.0           0.0               0.0   \n","7031                1.0           1.0           1.0               1.0   \n","\n","      multiple_lines  \n","0                NaN  \n","1                0.0  \n","2                0.0  \n","3                NaN  \n","4                0.0  \n","...              ...  \n","7027             1.0  \n","7028             1.0  \n","7029             NaN  \n","7030             1.0  \n","7031             0.0  \n","\n","[7032 rows x 20 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["# merge data based off of customer_id, main DF should be contract_df\n","# contract, personal, phone merge to start\n","# null values from phone_df will need to be monitored with options to 1) remove (if small impact), 2) replace (average,std) or, 3) keep in place\n","\n","# merged_df = contract_df.merge(personal_df,\n","#                              on='customer_id',\n","#                              ).merge(phone_df, on='customer_id', how='left')\n","\n","# display(merged_df)\n","\n","# display(merged_df.query('multiple_lines.isna()')) # attempting to find commonality for NaN values under 'multiple_lines' -- nothing in common \n","\n","data_frames = [contract_df, personal_df, internet_df, phone_df]\n","\n","merged_df = reduce(lambda  left, right: pd.merge(left, right, on=['customer_id'],\n","                                            how='left'), data_frames)\n","\n","display(merged_df) # should include most of our 'customer_id' instances"]},{"cell_type":"code","execution_count":45,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T17:45:14.869214Z","iopub.status.busy":"2023-11-30T17:45:14.868956Z","iopub.status.idle":"2023-11-30T17:45:14.874991Z","shell.execute_reply":"2023-11-30T17:45:14.874103Z","shell.execute_reply.started":"2023-11-30T17:45:14.869192Z"},"trusted":true},"outputs":[],"source":["# dropping columns that don't impact analysis \n","merged_df = merged_df.drop('customer_id', axis=1)"]},{"cell_type":"code","execution_count":46,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T17:45:14.876580Z","iopub.status.busy":"2023-11-30T17:45:14.876261Z","iopub.status.idle":"2023-11-30T17:45:14.911323Z","shell.execute_reply":"2023-11-30T17:45:14.910491Z","shell.execute_reply.started":"2023-11-30T17:45:14.876522Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>begin_date</th>\n","      <th>contract_type</th>\n","      <th>paperless_billing</th>\n","      <th>payment_method</th>\n","      <th>monthly_charges</th>\n","      <th>total_charges</th>\n","      <th>churn_target</th>\n","      <th>gender</th>\n","      <th>senior_citizen</th>\n","      <th>partner</th>\n","      <th>dependents</th>\n","      <th>internet_service</th>\n","      <th>online_security</th>\n","      <th>online_backup</th>\n","      <th>device_protection</th>\n","      <th>tech_support</th>\n","      <th>streaming_tv</th>\n","      <th>streaming_movies</th>\n","      <th>multiple_lines</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2020-01-01</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>29.85</td>\n","      <td>29.85</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2017-04-01</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>56.95</td>\n","      <td>1889.50</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2019-10-01</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>53.85</td>\n","      <td>108.15</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2016-05-01</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>42.30</td>\n","      <td>1840.75</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2019-09-01</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>70.70</td>\n","      <td>151.65</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7027</th>\n","      <td>2018-02-01</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>84.80</td>\n","      <td>1990.50</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>7028</th>\n","      <td>2014-02-01</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>103.20</td>\n","      <td>7362.90</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>7029</th>\n","      <td>2019-03-01</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>29.60</td>\n","      <td>346.45</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>7030</th>\n","      <td>2019-07-01</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>74.40</td>\n","      <td>306.60</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>7031</th>\n","      <td>2014-08-01</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>105.65</td>\n","      <td>6844.50</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7032 rows × 19 columns</p>\n","</div>"],"text/plain":["     begin_date  contract_type  paperless_billing  payment_method  \\\n","0    2020-01-01              0                  1               2   \n","1    2017-04-01              1                  0               3   \n","2    2019-10-01              0                  1               3   \n","3    2016-05-01              1                  0               0   \n","4    2019-09-01              0                  1               2   \n","...         ...            ...                ...             ...   \n","7027 2018-02-01              1                  1               3   \n","7028 2014-02-01              1                  1               1   \n","7029 2019-03-01              0                  1               2   \n","7030 2019-07-01              0                  1               3   \n","7031 2014-08-01              2                  1               0   \n","\n","      monthly_charges  total_charges  churn_target  gender  senior_citizen  \\\n","0               29.85          29.85             1       0               0   \n","1               56.95        1889.50             1       1               0   \n","2               53.85         108.15             0       1               0   \n","3               42.30        1840.75             1       1               0   \n","4               70.70         151.65             0       0               0   \n","...               ...            ...           ...     ...             ...   \n","7027            84.80        1990.50             1       1               0   \n","7028           103.20        7362.90             1       0               0   \n","7029            29.60         346.45             1       0               0   \n","7030            74.40         306.60             0       1               1   \n","7031           105.65        6844.50             1       1               0   \n","\n","      partner  dependents  internet_service  online_security  online_backup  \\\n","0           1           0               0.0              0.0            1.0   \n","1           0           0               0.0              1.0            0.0   \n","2           0           0               0.0              1.0            1.0   \n","3           0           0               0.0              1.0            0.0   \n","4           0           0               1.0              0.0            0.0   \n","...       ...         ...               ...              ...            ...   \n","7027        1           1               0.0              1.0            0.0   \n","7028        1           1               1.0              0.0            1.0   \n","7029        1           1               0.0              1.0            0.0   \n","7030        1           0               1.0              0.0            0.0   \n","7031        0           0               1.0              1.0            0.0   \n","\n","      device_protection  tech_support  streaming_tv  streaming_movies  \\\n","0                   0.0           0.0           0.0               0.0   \n","1                   1.0           0.0           0.0               0.0   \n","2                   0.0           0.0           0.0               0.0   \n","3                   1.0           1.0           0.0               0.0   \n","4                   0.0           0.0           0.0               0.0   \n","...                 ...           ...           ...               ...   \n","7027                1.0           1.0           1.0               1.0   \n","7028                1.0           0.0           1.0               1.0   \n","7029                0.0           0.0           0.0               0.0   \n","7030                0.0           0.0           0.0               0.0   \n","7031                1.0           1.0           1.0               1.0   \n","\n","      multiple_lines  \n","0                0.0  \n","1                0.0  \n","2                0.0  \n","3                0.0  \n","4                0.0  \n","...              ...  \n","7027             1.0  \n","7028             1.0  \n","7029             0.0  \n","7030             1.0  \n","7031             0.0  \n","\n","[7032 rows x 19 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["# dropping rows with NaNs under 'multiple_lines' as a test, reverting back to this and filling in if there are score issues with models\n","# lines_filter = merged_df.query('multiple_lines.isna()')\n","# merged_df.drop(merged_df[merged_df['multiple_lines'].isna()].index, inplace=True)\n","\n","# dropping rows with NaNs under 'internet_service' as a test, reverting back to this and filling in if there are score issues with models\n","# service_filter = merged_df.query('internet_service.isna()') #1520 rows with NaNs, removal might be required \n","\n","# we are making the assumption that NaN under multiple_lines == No and NaN under the internet_df means they did not sign up, so == No as well\n","merged_df = merged_df.fillna(0)\n","\n","display(merged_df)"]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 1300x800 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["fig, ax = plt.subplots(figsize=(13, 8))\n","g = sns.regplot(data=merged_df, x=merged_df['begin_date'].dt.year,y='total_charges', order=2,\n","                x_jitter=.05\n","                #x_estimator=np.mean\n","                )\n","\n","g.set_ylabel('Total Charges')\n","g.set_xlabel('Beginning Year of Service')\n","\n","sns.despine()\n","\n","ax.text(x=0.5, y=1.1, s='Merged Data', fontsize=16, weight='bold', ha='center', va='bottom', transform=ax.transAxes)\n","ax.text(x=0.5, y=1.05, s='Regression Analysis', fontsize=8, alpha=0.75, ha='center', va='bottom', transform=ax.transAxes)\n","\n","plt.yticks(rotation=0)\n","plt.xticks(rotation=0)\n","plt.show()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["`Summary`\n","\n","We merged all but one of our DFs in our project with our 'contract_data' being the lead DF given the substantial information included. \n","We decide to keep all the matches on the DFs which, knowingly, gives us some NaNs based off of our 'phone_data' -- we keep in our merged DF for now to see how our models react to seeing such values. \n","\n","If issues arise, we will revisit this section and run through a few options for our NaNs. This includes removing the rows or replacing them."]},{"cell_type":"markdown","metadata":{},"source":["-----------"]},{"cell_type":"markdown","metadata":{},"source":["# Target Frequency"]},{"cell_type":"code","execution_count":48,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T17:45:14.912507Z","iopub.status.busy":"2023-11-30T17:45:14.912265Z","iopub.status.idle":"2023-11-30T17:45:14.970784Z","shell.execute_reply":"2023-11-30T17:45:14.969840Z","shell.execute_reply.started":"2023-11-30T17:45:14.912486Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Checking frequency:\n","churn_target\n","1    5163\n","0    1869\n","Name: count, dtype: int64\n"]},{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"domain":{"x":[0,1],"y":[0,1]},"hovertemplate":"label=%{label}<br>count=%{value}<extra></extra>","labels":["No Churn","Churn"],"legendgroup":"","name":"","showlegend":true,"type":"pie","values":[5163,1869]}],"layout":{"autosize":false,"legend":{"orientation":"h","tracegroupgap":0,"x":1,"xanchor":"right","y":1.02,"yanchor":"bottom"},"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"title":{"text":"Class Frequency"}}},"text/html":["<div>                            <div id=\"3dc68075-8e3f-4f88-a8bd-f368d9c99ac8\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"3dc68075-8e3f-4f88-a8bd-f368d9c99ac8\")) {                    Plotly.newPlot(                        \"3dc68075-8e3f-4f88-a8bd-f368d9c99ac8\",                        [{\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"hovertemplate\":\"label=%{label}\\u003cbr\\u003ecount=%{value}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"labels\":[\"No Churn\",\"Churn\"],\"legendgroup\":\"\",\"name\":\"\",\"showlegend\":true,\"values\":[5163,1869],\"type\":\"pie\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"legend\":{\"tracegroupgap\":0,\"orientation\":\"h\",\"yanchor\":\"bottom\",\"y\":1.02,\"xanchor\":\"right\",\"x\":1},\"title\":{\"text\":\"Class Frequency\"},\"autosize\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('3dc68075-8e3f-4f88-a8bd-f368d9c99ac8');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"}],"source":["class_frequency = merged_df['churn_target'].value_counts()\n","print('Checking frequency:')\n","print(class_frequency)\n","\n","#class_frequency.plot.pie(autopct='%.2f',textprops={'fontsize':12}, colors=['cyan', 'teal']) # calls for upsampling 'rare' or churn target values (26.58%)\n","\n","labels = ['No Churn', 'Churn']\n","fig = px.pie(class_frequency, values='count', names=labels, title='Class Frequency')\n","fig.update_layout(legend=dict(\n","    orientation=\"h\",\n","    yanchor=\"bottom\",\n","    y=1.02,\n","    xanchor=\"right\",\n","    x=1\n","), autosize=False)\n","\n","fig.show()"]},{"cell_type":"markdown","metadata":{},"source":["-----------"]},{"cell_type":"markdown","metadata":{},"source":["# Model Preparation"]},{"cell_type":"markdown","metadata":{},"source":["`Fixed Parameter`"]},{"cell_type":"code","execution_count":49,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T17:45:14.972240Z","iopub.status.busy":"2023-11-30T17:45:14.971954Z","iopub.status.idle":"2023-11-30T17:45:14.976422Z","shell.execute_reply":"2023-11-30T17:45:14.975545Z","shell.execute_reply.started":"2023-11-30T17:45:14.972215Z"},"trusted":true},"outputs":[],"source":["# random_state parameter for all models\n","random_state = 12345"]},{"cell_type":"markdown","metadata":{},"source":["`CV`"]},{"cell_type":"markdown","metadata":{},"source":["Rearranging the data so as to ensure that each fold is a good representative of the whole"]},{"cell_type":"code","execution_count":50,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T17:45:14.977975Z","iopub.status.busy":"2023-11-30T17:45:14.977635Z","iopub.status.idle":"2023-11-30T17:45:14.985544Z","shell.execute_reply":"2023-11-30T17:45:14.984645Z","shell.execute_reply.started":"2023-11-30T17:45:14.977949Z"},"trusted":true},"outputs":[],"source":["cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=5, random_state=random_state)"]},{"cell_type":"markdown","metadata":{},"source":["`Feature Engineering`"]},{"cell_type":"code","execution_count":51,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T17:45:14.986987Z","iopub.status.busy":"2023-11-30T17:45:14.986721Z","iopub.status.idle":"2023-11-30T17:45:15.026035Z","shell.execute_reply":"2023-11-30T17:45:15.025164Z","shell.execute_reply.started":"2023-11-30T17:45:14.986966Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>contract_type</th>\n","      <th>paperless_billing</th>\n","      <th>payment_method</th>\n","      <th>monthly_charges</th>\n","      <th>total_charges</th>\n","      <th>churn_target</th>\n","      <th>gender</th>\n","      <th>senior_citizen</th>\n","      <th>partner</th>\n","      <th>dependents</th>\n","      <th>...</th>\n","      <th>online_security</th>\n","      <th>online_backup</th>\n","      <th>device_protection</th>\n","      <th>tech_support</th>\n","      <th>streaming_tv</th>\n","      <th>streaming_movies</th>\n","      <th>multiple_lines</th>\n","      <th>begin_year</th>\n","      <th>begin_month</th>\n","      <th>begin_dayofweek</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>29.85</td>\n","      <td>29.85</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2020</td>\n","      <td>1</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>56.95</td>\n","      <td>1889.50</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2017</td>\n","      <td>4</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>53.85</td>\n","      <td>108.15</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2019</td>\n","      <td>10</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>42.30</td>\n","      <td>1840.75</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2016</td>\n","      <td>5</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>70.70</td>\n","      <td>151.65</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2019</td>\n","      <td>9</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7027</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>84.80</td>\n","      <td>1990.50</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>2018</td>\n","      <td>2</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>7028</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>103.20</td>\n","      <td>7362.90</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>2014</td>\n","      <td>2</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>7029</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>29.60</td>\n","      <td>346.45</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2019</td>\n","      <td>3</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>7030</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>74.40</td>\n","      <td>306.60</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>2019</td>\n","      <td>7</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7031</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>105.65</td>\n","      <td>6844.50</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>2014</td>\n","      <td>8</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7032 rows × 21 columns</p>\n","</div>"],"text/plain":["      contract_type  paperless_billing  payment_method  monthly_charges  \\\n","0                 0                  1               2            29.85   \n","1                 1                  0               3            56.95   \n","2                 0                  1               3            53.85   \n","3                 1                  0               0            42.30   \n","4                 0                  1               2            70.70   \n","...             ...                ...             ...              ...   \n","7027              1                  1               3            84.80   \n","7028              1                  1               1           103.20   \n","7029              0                  1               2            29.60   \n","7030              0                  1               3            74.40   \n","7031              2                  1               0           105.65   \n","\n","      total_charges  churn_target  gender  senior_citizen  partner  \\\n","0             29.85             1       0               0        1   \n","1           1889.50             1       1               0        0   \n","2            108.15             0       1               0        0   \n","3           1840.75             1       1               0        0   \n","4            151.65             0       0               0        0   \n","...             ...           ...     ...             ...      ...   \n","7027        1990.50             1       1               0        1   \n","7028        7362.90             1       0               0        1   \n","7029         346.45             1       0               0        1   \n","7030         306.60             0       1               1        1   \n","7031        6844.50             1       1               0        0   \n","\n","      dependents  ...  online_security  online_backup  device_protection  \\\n","0              0  ...              0.0            1.0                0.0   \n","1              0  ...              1.0            0.0                1.0   \n","2              0  ...              1.0            1.0                0.0   \n","3              0  ...              1.0            0.0                1.0   \n","4              0  ...              0.0            0.0                0.0   \n","...          ...  ...              ...            ...                ...   \n","7027           1  ...              1.0            0.0                1.0   \n","7028           1  ...              0.0            1.0                1.0   \n","7029           1  ...              1.0            0.0                0.0   \n","7030           0  ...              0.0            0.0                0.0   \n","7031           0  ...              1.0            0.0                1.0   \n","\n","      tech_support  streaming_tv  streaming_movies  multiple_lines  \\\n","0              0.0           0.0               0.0             0.0   \n","1              0.0           0.0               0.0             0.0   \n","2              0.0           0.0               0.0             0.0   \n","3              1.0           0.0               0.0             0.0   \n","4              0.0           0.0               0.0             0.0   \n","...            ...           ...               ...             ...   \n","7027           1.0           1.0               1.0             1.0   \n","7028           0.0           1.0               1.0             1.0   \n","7029           0.0           0.0               0.0             0.0   \n","7030           0.0           0.0               0.0             1.0   \n","7031           1.0           1.0               1.0             0.0   \n","\n","      begin_year  begin_month  begin_dayofweek  \n","0           2020            1                2  \n","1           2017            4                5  \n","2           2019           10                1  \n","3           2016            5                6  \n","4           2019            9                6  \n","...          ...          ...              ...  \n","7027        2018            2                3  \n","7028        2014            2                5  \n","7029        2019            3                4  \n","7030        2019            7                0  \n","7031        2014            8                4  \n","\n","[7032 rows x 21 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["# extracting date features from datetime column\n","def make_features(data, col):\n","    data['begin_year'] = data[col].dt.year\n","    data['begin_month'] = data[col].dt.month\n","    # data['begin_day'] = data[col].dt.day # no impact to model outputs\n","    data['begin_dayofweek'] = data[col].dt.dayofweek\n","    \n","#     for lag in range(1, max_lag + 1):\n","#         data['lag_{}'.format(lag)] = data['PJME_MW'].shift(lag)\n","\n","#     data['rolling_mean'] = data['PJME_MW'].shift().rolling(rolling_mean_size).mean()\n","#     #data['rolling_mean'] = data['PJME_MW'].rolling(rolling_mean_size).mean()\n","\n","make_features(merged_df, 'begin_date')\n","merged_df = merged_df.drop('begin_date', axis = 1) # removing as this has been replaced by the newly created features\n","\n","display(merged_df)"]},{"cell_type":"markdown","metadata":{},"source":["`Features and Target`"]},{"cell_type":"code","execution_count":52,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T17:45:15.027635Z","iopub.status.busy":"2023-11-30T17:45:15.027289Z","iopub.status.idle":"2023-11-30T17:45:15.033636Z","shell.execute_reply":"2023-11-30T17:45:15.032692Z","shell.execute_reply.started":"2023-11-30T17:45:15.027603Z"},"trusted":true},"outputs":[],"source":["features = merged_df.drop('churn_target', axis=1)\n","target = merged_df['churn_target']"]},{"cell_type":"markdown","metadata":{},"source":["`Data Splitting`"]},{"cell_type":"code","execution_count":53,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T17:45:15.035612Z","iopub.status.busy":"2023-11-30T17:45:15.035009Z","iopub.status.idle":"2023-11-30T17:45:15.053330Z","shell.execute_reply":"2023-11-30T17:45:15.052375Z","shell.execute_reply.started":"2023-11-30T17:45:15.035580Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(4218, 20)\n","(4218,)\n","(1407, 20)\n","(1407, 20)\n"]}],"source":["# splitting the data into a training, validation and test dataset\n","features_train, features_test, target_train, target_test = train_test_split(features, target, \n","                                                                            test_size=0.2, random_state=12345, stratify=target)\n","\n","features_train, features_valid, target_train, target_valid = train_test_split(features_train, target_train, \n","                                                                          test_size=0.25, random_state=12345, stratify=target_train)\n","\n","print(features_train.shape)\n","print(target_train.shape)\n","print(features_valid.shape)\n","print(features_test.shape)"]},{"cell_type":"code","execution_count":54,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T17:45:15.054620Z","iopub.status.busy":"2023-11-30T17:45:15.054353Z","iopub.status.idle":"2023-11-30T17:45:15.061776Z","shell.execute_reply":"2023-11-30T17:45:15.060865Z","shell.execute_reply.started":"2023-11-30T17:45:15.054597Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["> Class = 0 : 1121/4218 (26.6%)\n","> Class = 1 : 3097/4218 (73.4%)\n"]}],"source":["# target_train summary\n","classes = unique(target_train)\n","total = len(target_train)\n","for c in classes:\n","    n_examples = len(target_train[target_train==c])\n","    percent = n_examples / total * 100\n","    print('> Class = %d : %d/%d (%.1f%%)' % (c, n_examples, total, percent))"]},{"cell_type":"code","execution_count":55,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T17:45:15.063304Z","iopub.status.busy":"2023-11-30T17:45:15.063022Z","iopub.status.idle":"2023-11-30T17:45:15.072464Z","shell.execute_reply":"2023-11-30T17:45:15.071457Z","shell.execute_reply.started":"2023-11-30T17:45:15.063279Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Train: 0=1121, 1=3097, \n","Valid: 0=374, 1=1033, \n","Test: 0=374, 1=1033\n"]}],"source":["# summarize by set\n","train_0, train_1 = len(target_train[target_train==0]), len(target_train[target_train==1])\n","valid_0, valid_1 = len(target_valid[target_valid==0]), len(target_valid[target_valid==1])\n","test_0, test_1 = len(target_test[target_test==0]), len(target_test[target_test==1])\n","print('Train: 0=%d, 1=%d, \\nValid: 0=%d, 1=%d, \\nTest: 0=%d, 1=%d' % (train_0, train_1, valid_0, valid_1 , test_0, test_1))"]},{"cell_type":"markdown","metadata":{},"source":["`Scaling`"]},{"cell_type":"code","execution_count":56,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T17:45:15.073894Z","iopub.status.busy":"2023-11-30T17:45:15.073571Z","iopub.status.idle":"2023-11-30T17:45:15.128923Z","shell.execute_reply":"2023-11-30T17:45:15.127933Z","shell.execute_reply.started":"2023-11-30T17:45:15.073863Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(      contract_type  paperless_billing  payment_method  monthly_charges  \\\n"," 95                0                  1               2         0.604582   \n"," 4644              1                  1               1         0.013944   \n"," 5562              1                  1               2         0.613048   \n"," 320               1                  0               0         0.639442   \n"," 303               2                  0               1         0.418825   \n"," ...             ...                ...             ...              ...   \n"," 5421              0                  1               1         0.536853   \n"," 5945              0                  1               1         0.366036   \n"," 945               0                  1               2         0.804781   \n"," 6246              1                  1               3         0.919323   \n"," 6745              0                  1               0         0.712151   \n"," \n","       total_charges  gender  senior_citizen  partner  dependents  \\\n"," 95         0.104836       0               0        0           0   \n"," 4644       0.052995       0               0        0           0   \n"," 5562       0.564964       1               0        1           0   \n"," 320        0.499801       0               1        0           0   \n"," 303        0.471979       0               0        1           1   \n"," ...             ...     ...             ...      ...         ...   \n"," 5421       0.089477       1               0        0           0   \n"," 5945       0.132322       1               0        0           0   \n"," 945        0.389680       1               1        0           0   \n"," 6246       0.875986       1               1        1           0   \n"," 6745       0.221563       1               1        1           0   \n"," \n","       internet_service  online_security  online_backup  device_protection  \\\n"," 95                 1.0              1.0            0.0                0.0   \n"," 4644               0.0              0.0            0.0                0.0   \n"," 5562               0.0              0.0            1.0                1.0   \n"," 320                0.0              1.0            1.0                0.0   \n"," 303                0.0              0.0            1.0                1.0   \n"," ...                ...              ...            ...                ...   \n"," 5421               0.0              0.0            0.0                0.0   \n"," 5945               0.0              1.0            1.0                1.0   \n"," 945                1.0              0.0            0.0                1.0   \n"," 6246               1.0              1.0            0.0                1.0   \n"," 6745               1.0              0.0            0.0                0.0   \n"," \n","       tech_support  streaming_tv  streaming_movies  multiple_lines  \\\n"," 95             0.0           0.0               0.0             1.0   \n"," 4644           0.0           0.0               0.0             0.0   \n"," 5562           0.0           1.0               1.0             1.0   \n"," 320            1.0           1.0               1.0             1.0   \n"," 303            1.0           1.0               1.0             0.0   \n"," ...            ...           ...               ...             ...   \n"," 5421           0.0           1.0               1.0             1.0   \n"," 5945           1.0           1.0               0.0             0.0   \n"," 945            0.0           1.0               1.0             1.0   \n"," 6246           1.0           1.0               1.0             1.0   \n"," 6745           0.0           1.0               1.0             0.0   \n"," \n","       begin_year  begin_month  begin_dayofweek  \n"," 95      0.714286     1.000000         0.833333  \n"," 4644    0.714286     0.181818         0.500000  \n"," 5562    0.285714     0.000000         0.500000  \n"," 320     0.285714     0.363636         0.666667  \n"," 303     0.142857     0.454545         1.000000  \n"," ...          ...          ...              ...  \n"," 5421    0.857143     0.090909         0.666667  \n"," 5945    0.714286     0.454545         0.666667  \n"," 945     0.571429     0.090909         0.333333  \n"," 6246    0.142857     0.363636         0.500000  \n"," 6745    0.714286     0.272727         1.000000  \n"," \n"," [4218 rows x 20 columns],\n","       contract_type  paperless_billing  payment_method  monthly_charges  \\\n"," 469               0                  0               2         0.375498   \n"," 4590              0                  0               3         0.378486   \n"," 5822              0                  1               0         0.722610   \n"," 5084              0                  0               3         0.021912   \n"," 2003              0                  1               3         0.685757   \n"," ...             ...                ...             ...              ...   \n"," 1386              0                  1               2         0.672809   \n"," 1597              0                  1               2         0.717131   \n"," 4111              0                  0               1         0.563247   \n"," 6510              1                  1               2         0.728088   \n"," 6387              0                  1               1         0.734064   \n"," \n","       total_charges  gender  senior_citizen  partner  dependents  \\\n"," 469        0.082565       0               0        1           1   \n"," 4590       0.109740       1               0        0           0   \n"," 5822       0.091265       0               0        0           0   \n"," 5084       0.015220       0               0        1           1   \n"," 2003       0.037226       0               0        0           1   \n"," ...             ...     ...             ...      ...         ...   \n"," 1386       0.279415       1               0        1           0   \n"," 1597       0.315776       1               0        0           0   \n"," 4111       0.340742       0               0        0           0   \n"," 6510       0.663038       1               0        1           1   \n"," 6387       0.378747       0               1        1           0   \n"," \n","       internet_service  online_security  online_backup  device_protection  \\\n"," 469                0.0              0.0            0.0                0.0   \n"," 4590               0.0              1.0            0.0                0.0   \n"," 5822               1.0              0.0            0.0                0.0   \n"," 5084               0.0              0.0            0.0                0.0   \n"," 2003               1.0              0.0            0.0                1.0   \n"," ...                ...              ...            ...                ...   \n"," 1386               1.0              0.0            1.0                1.0   \n"," 1597               1.0              0.0            0.0                0.0   \n"," 4111               1.0              0.0            1.0                0.0   \n"," 6510               1.0              0.0            1.0                0.0   \n"," 6387               1.0              0.0            1.0                0.0   \n"," \n","       tech_support  streaming_tv  streaming_movies  multiple_lines  \\\n"," 469            0.0           0.0               1.0             0.0   \n"," 4590           0.0           0.0               0.0             1.0   \n"," 5822           0.0           1.0               1.0             0.0   \n"," 5084           0.0           0.0               0.0             0.0   \n"," 2003           1.0           0.0               0.0             1.0   \n"," ...            ...           ...               ...             ...   \n"," 1386           0.0           0.0               0.0             1.0   \n"," 1597           0.0           1.0               1.0             0.0   \n"," 4111           0.0           0.0               0.0             0.0   \n"," 6510           0.0           0.0               1.0             1.0   \n"," 6387           0.0           1.0               0.0             1.0   \n"," \n","       begin_year  begin_month  begin_dayofweek  \n"," 469     0.714286     1.000000         0.833333  \n"," 4590    0.714286     0.636364         0.333333  \n"," 5822    0.857143     0.181818         0.666667  \n"," 5084    0.857143     0.545455         0.000000  \n"," 2003    0.857143     0.454545         0.833333  \n"," ...          ...          ...              ...  \n"," 1386    0.571429     0.727273         0.666667  \n"," 1597    0.571429     0.272727         0.833333  \n"," 4111    0.428571     0.818182         0.833333  \n"," 6510    0.142857     0.909091         0.833333  \n"," 6387    0.571429     0.090909         0.333333  \n"," \n"," [1407 rows x 20 columns],\n","       contract_type  paperless_billing  payment_method  monthly_charges  \\\n"," 3307              0                  0               3         0.020418   \n"," 679               0                  0               2         0.615040   \n"," 4724              2                  0               1         0.016434   \n"," 569               2                  1               1         0.009960   \n"," 2928              2                  1               0         0.057271   \n"," ...             ...                ...             ...              ...   \n"," 2991              0                  1               3         0.421813   \n"," 6725              2                  0               1         0.687251   \n"," 5068              1                  1               2         0.752490   \n"," 4212              1                  0               2         0.566733   \n"," 205               1                  1               0         0.614542   \n"," \n","       total_charges  gender  senior_citizen  partner  dependents  \\\n"," 3307       0.000167       1               0        0           0   \n"," 679        0.007056       1               0        1           1   \n"," 4724       0.159065       0               0        1           1   \n"," 569        0.125133       0               0        1           1   \n"," 2928       0.189875       1               0        1           1   \n"," ...             ...     ...             ...      ...         ...   \n"," 2991       0.131261       0               0        0           0   \n"," 6725       0.728120       0               0        1           1   \n"," 5068       0.358374       0               0        1           1   \n"," 4212       0.433167       0               0        0           0   \n"," 205        0.307641       0               0        0           0   \n"," \n","       internet_service  online_security  online_backup  device_protection  \\\n"," 3307               0.0              0.0            0.0                0.0   \n"," 679                1.0              0.0            0.0                0.0   \n"," 4724               0.0              0.0            0.0                0.0   \n"," 569                0.0              0.0            0.0                0.0   \n"," 2928               0.0              0.0            0.0                0.0   \n"," ...                ...              ...            ...                ...   \n"," 2991               0.0              1.0            0.0                1.0   \n"," 6725               0.0              1.0            1.0                1.0   \n"," 5068               1.0              0.0            0.0                1.0   \n"," 4212               1.0              0.0            1.0                0.0   \n"," 205                1.0              0.0            1.0                0.0   \n"," \n","       tech_support  streaming_tv  streaming_movies  multiple_lines  \\\n"," 3307           0.0           0.0               0.0             0.0   \n"," 679            0.0           0.0               1.0             0.0   \n"," 4724           0.0           0.0               0.0             0.0   \n"," 569            0.0           0.0               0.0             0.0   \n"," 2928           0.0           0.0               0.0             1.0   \n"," ...            ...           ...               ...             ...   \n"," 2991           0.0           0.0               0.0             1.0   \n"," 6725           1.0           1.0               1.0             0.0   \n"," 5068           0.0           1.0               1.0             0.0   \n"," 4212           0.0           0.0               0.0             0.0   \n"," 205            1.0           0.0               0.0             0.0   \n"," \n","       begin_year  begin_month  begin_dayofweek  \n"," 3307    1.000000     0.000000         0.333333  \n"," 679     0.857143     1.000000         1.000000  \n"," 4724    0.142857     0.181818         0.833333  \n"," 569     0.285714     0.090909         1.000000  \n"," 2928    0.142857     0.454545         1.000000  \n"," ...          ...          ...              ...  \n"," 2991    0.714286     0.636364         0.333333  \n"," 6725    0.142857     0.181818         0.833333  \n"," 5068    0.571429     0.000000         1.000000  \n"," 4212    0.428571     0.090909         0.000000  \n"," 205     0.571429     0.363636         0.000000  \n"," \n"," [1407 rows x 20 columns])"]},"execution_count":56,"metadata":{},"output_type":"execute_result"}],"source":["numeric = ['monthly_charges', 'total_charges', 'begin_year','begin_month', 'begin_dayofweek']\n","\n","def scaling(x_train, x_valid, x_test):\n","    scaler = MinMaxScaler()\n","    scaler.fit(x_train[numeric])\n","    x_train[numeric] = scaler.transform(x_train[numeric])\n","    x_valid[numeric] = scaler.transform(x_valid[numeric])\n","    x_test[numeric] = scaler.transform(x_test[numeric])\n","    return x_train, x_valid, x_test\n","\n","scaling(features_train, features_valid, features_test)"]},{"cell_type":"markdown","metadata":{},"source":["`Summary`\n","\n","After taking into account class imbalancing, we've split the data into Train, Validation and Test datasets where each has been scaled in order to take value magnitute into account and create good inputs for our model training."]},{"cell_type":"markdown","metadata":{},"source":["# Dummy Model"]},{"cell_type":"code","execution_count":57,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T17:45:15.130534Z","iopub.status.busy":"2023-11-30T17:45:15.130173Z","iopub.status.idle":"2023-11-30T17:45:15.139236Z","shell.execute_reply":"2023-11-30T17:45:15.138270Z","shell.execute_reply.started":"2023-11-30T17:45:15.130498Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Dummy Model Score: 0.7341862117981521\n"]}],"source":["dummy = DummyClassifier(random_state=random_state,strategy=\"most_frequent\")\n","dummy.fit(features_train, target_train)\n","DummyClassifier(strategy='most_frequent')\n","dummy.predict(features_valid)\n","print('Dummy Model Score:', dummy.score(features_valid, target_valid))"]},{"cell_type":"markdown","metadata":{},"source":["# KNeighbors"]},{"cell_type":"code","execution_count":58,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Runtime:\n","CPU times: user 17min 8s, sys: 7.25 s, total: 17min 15s\n","Wall time: 2min 17s\n"]}],"source":["%%time\n","train_accuracies = {}\n","validation_accuracies = {}\n","neighbors = np.arange(1, 15)\n","\n","for neighbor in neighbors: \n","    knn = KNeighborsClassifier(n_neighbors=neighbor) # non-RandomizedSearchCV\n","    knn.fit(features_train, target_train)\n","    train_accuracies[neighbor] = knn.score(features_train, target_train)\n","    validation_accuracies[neighbor] = knn.score(features_valid, target_valid)\n","\n","print('Runtime:')"]},{"cell_type":"code","execution_count":59,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 1000x500 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["sns.set(style=\"white\", color_codes=True)\n","plt.rcParams['axes.linewidth'] = 0.1\n","plt.figure(figsize=(10, 5))\n","\n","plt.title(\"KNN: Varying Number of Neighbors\")\n","plt.plot(neighbors, train_accuracies.values(), label=\"Training Accuracy\")\n","plt.plot(neighbors, validation_accuracies.values(), label=\"Validation Accuracy\")\n","\n","plt.legend(fontsize=8)\n","plt.xlabel(\"Number of Neighbors\")\n","plt.ylabel(\"Accuracy\")\n","\n","plt.show()"]},{"cell_type":"code","execution_count":60,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Runtime:\n","CPU times: user 310 ms, sys: 200 ms, total: 510 ms\n","Wall time: 2.84 s\n"]}],"source":["%%time\n","knn = KNeighborsClassifier()\n","knn_params = [{\"n_neighbors\": np.arange(1,15), \n","                    \"metric\": ['cosine', 'euclidean', 'manhattan', 'minkowski'],\n","                     \"algorithm\": ['auto', 'ball_tree', 'kd_tree'],\n","                     \"weights\": ['uniform', 'distance'],\n","                   }]\n","knn_clf = RandomizedSearchCV(knn, knn_params, scoring='roc_auc', n_jobs=-1, cv=cv)\n","knn_clf.fit(features_train, target_train)\n","print('Runtime:')"]},{"cell_type":"code","execution_count":61,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Cross Validation Scores: [0.83178681 0.80505472 0.81572581 0.76857719 0.78829205 0.80299539\n"," 0.79019297 0.79749424 0.84408229 0.82717869 0.79562964 0.79550691\n"," 0.80334101 0.76785714 0.80334101 0.79114343 0.82472638 0.79942396\n"," 0.80766008 0.81341019 0.78673712 0.82574885 0.81748272 0.78335253\n"," 0.78539747 0.84719182 0.81359447 0.81625864 0.81534616 0.78422619\n"," 0.80672738 0.79088422 0.82556164 0.80712846 0.83074597 0.83675115\n"," 0.80918779 0.79183468 0.79834142 0.80332582 0.81885614 0.81180876\n"," 0.7812212  0.77551843 0.80662442 0.79668779 0.80986463 0.80959101\n"," 0.82200647 0.82296001]\n","Runtime:\n","CPU times: user 54.7 s, sys: 4.39 s, total: 59.1 s\n","Wall time: 1min 14s\n"]}],"source":["%%time\n","knn_scores = cross_val_score(knn_clf, features_train, target_train, cv=cv, scoring='roc_auc')\n","print('Cross Validation Scores: {}'.format(knn_scores))\n","print('Runtime:')"]},{"cell_type":"markdown","metadata":{},"source":["# ROC AUC Curve - KNeighbors"]},{"cell_type":"code","execution_count":62,"metadata":{},"outputs":[{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"fillpattern":{"shape":""},"hovertemplate":"False Positive Rate=%{x}<br>True Positive Rate=%{y}<extra></extra>","legendgroup":"","line":{"color":"#636efa"},"marker":{"symbol":"circle"},"mode":"lines","name":"","orientation":"v","showlegend":false,"stackgroup":"1","type":"scatter","x":[0,0.02406417112299465,0.02406417112299465,0.029411764705882353,0.029411764705882353,0.03208556149732621,0.03208556149732621,0.034759358288770054,0.034759358288770054,0.0374331550802139,0.0374331550802139,0.040106951871657755,0.040106951871657755,0.0427807486631016,0.0427807486631016,0.045454545454545456,0.045454545454545456,0.0481283422459893,0.0481283422459893,0.05080213903743316,0.05080213903743316,0.05614973262032086,0.05614973262032086,0.058823529411764705,0.058823529411764705,0.06149732620320856,0.06149732620320856,0.06417112299465241,0.06417112299465241,0.06684491978609626,0.06684491978609626,0.06951871657754011,0.06951871657754011,0.07219251336898395,0.07219251336898395,0.0748663101604278,0.0748663101604278,0.08021390374331551,0.08021390374331551,0.08288770053475936,0.08288770053475936,0.0855614973262032,0.0855614973262032,0.09090909090909091,0.09090909090909091,0.09358288770053476,0.09358288770053476,0.0962566844919786,0.0962566844919786,0.09893048128342247,0.09893048128342247,0.10160427807486631,0.10160427807486631,0.10427807486631016,0.10427807486631016,0.10695187165775401,0.10695187165775401,0.10962566844919786,0.10962566844919786,0.11229946524064172,0.11229946524064172,0.11497326203208556,0.11497326203208556,0.11764705882352941,0.11764705882352941,0.12032085561497326,0.12032085561497326,0.12299465240641712,0.12299465240641712,0.12566844919786097,0.12566844919786097,0.12834224598930483,0.12834224598930483,0.13636363636363635,0.13636363636363635,0.13903743315508021,0.13903743315508021,0.14171122994652408,0.14171122994652408,0.1443850267379679,0.1443850267379679,0.14705882352941177,0.14705882352941177,0.1497326203208556,0.1497326203208556,0.15240641711229946,0.15240641711229946,0.15508021390374332,0.15508021390374332,0.15775401069518716,0.15775401069518716,0.16042780748663102,0.16042780748663102,0.16310160427807488,0.16310160427807488,0.1657754010695187,0.1657754010695187,0.16844919786096257,0.16844919786096257,0.17379679144385027,0.17379679144385027,0.17647058823529413,0.17647058823529413,0.17914438502673796,0.17914438502673796,0.18181818181818182,0.18181818181818182,0.18449197860962566,0.18449197860962566,0.18716577540106952,0.18716577540106952,0.18983957219251338,0.18983957219251338,0.1925133689839572,0.1925133689839572,0.19518716577540107,0.19518716577540107,0.19786096256684493,0.19786096256684493,0.20053475935828877,0.20053475935828877,0.20855614973262032,0.20855614973262032,0.21122994652406418,0.21122994652406418,0.21390374331550802,0.21390374331550802,0.21657754010695188,0.21657754010695188,0.2192513368983957,0.2192513368983957,0.22192513368983957,0.22192513368983957,0.22459893048128343,0.22459893048128343,0.22727272727272727,0.22727272727272727,0.232620320855615,0.232620320855615,0.23529411764705882,0.23529411764705882,0.24064171122994651,0.24064171122994651,0.24331550802139038,0.24331550802139038,0.2540106951871658,0.2540106951871658,0.25935828877005346,0.25935828877005346,0.2620320855614973,0.2620320855614973,0.2647058823529412,0.2647058823529412,0.2700534759358289,0.2700534759358289,0.27540106951871657,0.27540106951871657,0.27807486631016043,0.27807486631016043,0.2807486631016043,0.2807486631016043,0.28342245989304815,0.28342245989304815,0.28609625668449196,0.28609625668449196,0.2887700534759358,0.2887700534759358,0.2914438502673797,0.2914438502673797,0.29411764705882354,0.29411764705882354,0.2967914438502674,0.2967914438502674,0.31016042780748665,0.31016042780748665,0.3155080213903743,0.3155080213903743,0.3181818181818182,0.3181818181818182,0.32887700534759357,0.32887700534759357,0.33689839572192515,0.33689839572192515,0.3422459893048128,0.3422459893048128,0.3449197860962567,0.3449197860962567,0.34759358288770054,0.34759358288770054,0.3502673796791444,0.3502673796791444,0.35294117647058826,0.35294117647058826,0.36363636363636365,0.36363636363636365,0.3663101604278075,0.3663101604278075,0.37433155080213903,0.37433155080213903,0.3770053475935829,0.3770053475935829,0.37967914438502676,0.37967914438502676,0.38235294117647056,0.38235294117647056,0.393048128342246,0.393048128342246,0.3983957219251337,0.3983957219251337,0.40106951871657753,0.40106951871657753,0.40641711229946526,0.40641711229946526,0.4090909090909091,0.4090909090909091,0.4117647058823529,0.4117647058823529,0.4144385026737968,0.4144385026737968,0.4197860962566845,0.4197860962566845,0.42513368983957217,0.42513368983957217,0.42780748663101603,0.42780748663101603,0.43315508021390375,0.43315508021390375,0.4385026737967914,0.4385026737967914,0.4411764705882353,0.4411764705882353,0.44919786096256686,0.44919786096256686,0.45187165775401067,0.45187165775401067,0.4572192513368984,0.4572192513368984,0.46524064171123,0.46524064171123,0.4732620320855615,0.4732620320855615,0.47593582887700536,0.47593582887700536,0.48128342245989303,0.48128342245989303,0.48663101604278075,0.48663101604278075,0.4946524064171123,0.4946524064171123,0.49732620320855614,0.49732620320855614,0.5026737967914439,0.5026737967914439,0.5080213903743316,0.5080213903743316,0.5106951871657754,0.5106951871657754,0.5133689839572193,0.5133689839572193,0.5294117647058824,0.5294117647058824,0.5347593582887701,0.5347593582887701,0.5374331550802139,0.5374331550802139,0.5454545454545454,0.5454545454545454,0.5668449197860963,0.5668449197860963,0.5748663101604278,0.5748663101604278,0.5855614973262032,0.5855614973262032,0.5909090909090909,0.5909090909090909,0.5935828877005348,0.5935828877005348,0.5962566844919787,0.5962566844919787,0.6042780748663101,0.6042780748663101,0.6122994652406417,0.6122994652406417,0.6203208556149733,0.6203208556149733,0.6256684491978609,0.6256684491978609,0.6470588235294118,0.6470588235294118,0.660427807486631,0.660427807486631,0.6631016042780749,0.6631016042780749,0.6657754010695187,0.6657754010695187,0.6684491978609626,0.6684491978609626,0.6764705882352942,0.6764705882352942,0.6871657754010695,0.6871657754010695,0.6925133689839572,0.6925133689839572,0.6951871657754011,0.6951871657754011,0.7245989304812834,0.7245989304812834,0.7272727272727273,0.7272727272727273,0.732620320855615,0.732620320855615,0.7379679144385026,0.7379679144385026,0.7406417112299465,0.7406417112299465,0.7459893048128342,0.7459893048128342,0.7647058823529411,0.7647058823529411,0.767379679144385,0.767379679144385,0.7754010695187166,0.7754010695187166,0.7834224598930482,0.7834224598930482,0.7967914438502673,0.7967914438502673,0.8021390374331551,0.8021390374331551,0.8262032085561497,0.8262032085561497,0.8368983957219251,0.8368983957219251,0.839572192513369,0.839572192513369,0.8663101604278075,0.8663101604278075,0.8689839572192514,0.8689839572192514,0.8716577540106952,0.8716577540106952,0.8743315508021391,0.8743315508021391,0.8796791443850267,0.8796791443850267,0.8823529411764706,0.8823529411764706,0.8850267379679144,0.8850267379679144,0.8877005347593583,0.8877005347593583,0.8903743315508021,0.8903743315508021,0.893048128342246,0.893048128342246,0.9037433155080213,0.9037433155080213,0.9224598930481284,0.9224598930481284,0.9251336898395722,0.9251336898395722,0.9358288770053476,0.9358288770053476,0.9411764705882353,0.9411764705882353,0.9438502673796791,0.9438502673796791,0.946524064171123,0.946524064171123,0.9518716577540107,0.9518716577540107,0.9732620320855615,0.9732620320855615,0.9946524064171123,1],"xaxis":"x","y":[0,0.29912875121006777,0.31752178121974833,0.31752178121974833,0.32236205227492737,0.32236205227492737,0.32623426911907066,0.32623426911907066,0.3281703775411423,0.3281703775411423,0.33204259438528555,0.33204259438528555,0.34172313649564373,0.34172313649564373,0.345595353339787,0.345595353339787,0.35818005808325265,0.35818005808325265,0.38334946757018395,0.38334946757018395,0.3978702807357212,0.3978702807357212,0.41142303969022265,0.41142303969022265,0.4259438528557599,0.4259438528557599,0.4356243949661181,0.4356243949661181,0.4394966118102614,0.4394966118102614,0.462729912875121,0.462729912875121,0.4743465634075508,0.4743465634075508,0.47725072604065827,0.47725072604065827,0.5072604065827686,0.5072604065827686,0.5150048402710552,0.5150048402710552,0.5324298160696999,0.5324298160696999,0.5401742497579864,0.5401742497579864,0.5527589545014521,0.5527589545014521,0.558567279767667,0.558567279767667,0.5653436592449177,0.5653436592449177,0.5701839303000968,0.5701839303000968,0.5750242013552759,0.5750242013552759,0.5788964181994192,0.5788964181994192,0.5837366892545982,0.5837366892545982,0.590513068731849,0.590513068731849,0.5924491771539206,0.5924491771539206,0.5953533397870281,0.5953533397870281,0.5963213939980639,0.5963213939980639,0.5972894482090997,0.5972894482090997,0.6001936108422071,0.6001936108422071,0.6030977734753146,0.6030977734753146,0.6069699903194579,0.6069699903194579,0.6224588576960309,0.6224588576960309,0.6234269119070668,0.6234269119070668,0.6253630203291385,0.6253630203291385,0.6321393998063891,0.6321393998063891,0.6447241045498547,0.6447241045498547,0.6495643756050339,0.6495643756050339,0.6563407550822846,0.6563407550822846,0.6573088092933205,0.6573088092933205,0.6611810261374637,0.6611810261374637,0.6631171345595354,0.6631171345595354,0.6689254598257502,0.6689254598257502,0.6698935140367861,0.6698935140367861,0.6766698935140368,0.6766698935140368,0.68054211035818,0.68054211035818,0.6824782187802517,0.6824782187802517,0.6853823814133592,0.6853823814133592,0.6873184898354308,0.6873184898354308,0.7018393030009681,0.7018393030009681,0.707647628267183,0.707647628267183,0.7086156824782188,0.7086156824782188,0.712487899322362,0.712487899322362,0.7144240077444337,0.7144240077444337,0.7153920619554696,0.7153920619554696,0.7173281703775412,0.7173281703775412,0.7318489835430784,0.7318489835430784,0.7357212003872217,0.7357212003872217,0.7424975798644724,0.7424975798644724,0.7579864472410455,0.7579864472410455,0.7637947725072604,0.7637947725072604,0.7666989351403679,0.7666989351403679,0.7696030977734754,0.7696030977734754,0.7705711519845111,0.7705711519845111,0.7744433688286544,0.7744433688286544,0.7763794772507261,0.7763794772507261,0.7792836398838335,0.7792836398838335,0.782187802516941,0.782187802516941,0.7841239109390126,0.7841239109390126,0.7850919651500484,0.7850919651500484,0.78702807357212,0.78702807357212,0.7889641819941917,0.7889641819941917,0.7957405614714425,0.7957405614714425,0.7986447241045499,0.7986447241045499,0.7996127783155856,0.7996127783155856,0.8015488867376573,0.8015488867376573,0.8025169409486931,0.8025169409486931,0.8054211035818006,0.8054211035818006,0.8063891577928364,0.8063891577928364,0.8073572120038722,0.8073572120038722,0.8102613746369797,0.8102613746369797,0.8151016456921588,0.8151016456921588,0.8160696999031946,0.8160696999031946,0.818973862536302,0.818973862536302,0.8238141335914811,0.8238141335914811,0.8247821878025169,0.8247821878025169,0.8286544046466602,0.8286544046466602,0.829622458857696,0.829622458857696,0.8315585672797676,0.8315585672797676,0.8363988383349468,0.8363988383349468,0.8402710551790901,0.8402710551790901,0.8412391093901258,0.8412391093901258,0.8431752178121975,0.8431752178121975,0.8441432720232332,0.8441432720232332,0.8489835430784124,0.8489835430784124,0.8499515972894482,0.8499515972894482,0.850919651500484,0.850919651500484,0.8518877057115198,0.8518877057115198,0.8528557599225557,0.8528557599225557,0.8606001936108422,0.8606001936108422,0.861568247821878,0.861568247821878,0.8635043562439496,0.8635043562439496,0.8654404646660213,0.8654404646660213,0.8664085188770572,0.8664085188770572,0.8702807357212003,0.8702807357212003,0.8712487899322362,0.8712487899322362,0.8770571151984511,0.8770571151984511,0.8789932236205228,0.8789932236205228,0.8809293320425944,0.8809293320425944,0.8818973862536302,0.8818973862536302,0.8867376573088093,0.8867376573088093,0.888673765730881,0.888673765730881,0.8954501452081317,0.8954501452081317,0.8973862536302033,0.8973862536302033,0.9002904162633107,0.9002904162633107,0.9012584704743466,0.9012584704743466,0.9022265246853823,0.9022265246853823,0.9031945788964182,0.9031945788964182,0.9119070667957405,0.9119070667957405,0.9157792836398838,0.9157792836398838,0.9167473378509197,0.9167473378509197,0.9177153920619555,0.9177153920619555,0.920619554695063,0.920619554695063,0.9215876089060987,0.9215876089060987,0.9225556631171346,0.9225556631171346,0.9235237173281704,0.9235237173281704,0.9244917715392061,0.9244917715392061,0.9273959341723137,0.9273959341723137,0.9283639883833494,0.9283639883833494,0.9303000968054211,0.9303000968054211,0.9332042594385286,0.9332042594385286,0.9341723136495643,0.9341723136495643,0.936108422071636,0.936108422071636,0.9370764762826719,0.9370764762826719,0.9380445304937076,0.9380445304937076,0.9390125847047435,0.9390125847047435,0.9409486931268151,0.9409486931268151,0.9428848015488868,0.9428848015488868,0.9448209099709584,0.9448209099709584,0.9457889641819942,0.9457889641819942,0.9467570183930301,0.9467570183930301,0.9477250726040658,0.9477250726040658,0.9496611810261375,0.9496611810261375,0.9506292352371732,0.9506292352371732,0.9535333978702807,0.9535333978702807,0.9554695062923524,0.9554695062923524,0.9583736689254598,0.9583736689254598,0.9593417231364957,0.9593417231364957,0.9603097773475314,0.9603097773475314,0.9622458857696031,0.9622458857696031,0.9632139399806389,0.9632139399806389,0.9641819941916747,0.9641819941916747,0.9651500484027106,0.9651500484027106,0.9670861568247822,0.9670861568247822,0.968054211035818,0.968054211035818,0.9690222652468539,0.9690222652468539,0.9719264278799613,0.9719264278799613,0.9738625363020329,0.9738625363020329,0.9748305905130688,0.9748305905130688,0.9757986447241046,0.9757986447241046,0.9767666989351403,0.9767666989351403,0.9777347531461762,0.9777347531461762,0.978702807357212,0.978702807357212,0.9796708615682478,0.9796708615682478,0.9816069699903195,0.9816069699903195,0.9825750242013552,0.9825750242013552,0.9835430784123911,0.9835430784123911,0.9845111326234269,0.9845111326234269,0.9854791868344628,0.9854791868344628,0.9864472410454985,0.9864472410454985,0.9874152952565344,0.9874152952565344,0.9883833494675702,0.9883833494675702,0.989351403678606,0.989351403678606,0.9903194578896418,0.9903194578896418,0.9912875121006777,0.9912875121006777,0.9932236205227493,0.9932236205227493,0.9941916747337851,0.9941916747337851,0.995159728944821,0.995159728944821,0.9961277831558567,0.9961277831558567,0.9970958373668926,0.9970958373668926,0.9990319457889641,0.9990319457889641,1,1,1],"yaxis":"y"}],"layout":{"height":600,"legend":{"tracegroupgap":0},"shapes":[{"line":{"dash":"dash"},"type":"line","x0":0,"x1":1,"y0":0,"y1":1}],"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"title":{"text":"ROC Curve (AUC=0.8327)"},"width":800,"xaxis":{"anchor":"y","constrain":"domain","domain":[0,1],"title":{"text":"False Positive Rate"}},"yaxis":{"anchor":"x","domain":[0,1],"scaleanchor":"x","scaleratio":1,"title":{"text":"True Positive Rate"}}}},"text/html":["<div>                            <div id=\"0d700bc3-5057-4e76-ba5a-146c658bb0ae\" class=\"plotly-graph-div\" style=\"height:600px; width:800px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"0d700bc3-5057-4e76-ba5a-146c658bb0ae\")) {                    Plotly.newPlot(                        \"0d700bc3-5057-4e76-ba5a-146c658bb0ae\",                        [{\"fillpattern\":{\"shape\":\"\"},\"hovertemplate\":\"False Positive Rate=%{x}\\u003cbr\\u003eTrue Positive Rate=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"stackgroup\":\"1\",\"x\":[0.0,0.02406417112299465,0.02406417112299465,0.029411764705882353,0.029411764705882353,0.03208556149732621,0.03208556149732621,0.034759358288770054,0.034759358288770054,0.0374331550802139,0.0374331550802139,0.040106951871657755,0.040106951871657755,0.0427807486631016,0.0427807486631016,0.045454545454545456,0.045454545454545456,0.0481283422459893,0.0481283422459893,0.05080213903743316,0.05080213903743316,0.05614973262032086,0.05614973262032086,0.058823529411764705,0.058823529411764705,0.06149732620320856,0.06149732620320856,0.06417112299465241,0.06417112299465241,0.06684491978609626,0.06684491978609626,0.06951871657754011,0.06951871657754011,0.07219251336898395,0.07219251336898395,0.0748663101604278,0.0748663101604278,0.08021390374331551,0.08021390374331551,0.08288770053475936,0.08288770053475936,0.0855614973262032,0.0855614973262032,0.09090909090909091,0.09090909090909091,0.09358288770053476,0.09358288770053476,0.0962566844919786,0.0962566844919786,0.09893048128342247,0.09893048128342247,0.10160427807486631,0.10160427807486631,0.10427807486631016,0.10427807486631016,0.10695187165775401,0.10695187165775401,0.10962566844919786,0.10962566844919786,0.11229946524064172,0.11229946524064172,0.11497326203208556,0.11497326203208556,0.11764705882352941,0.11764705882352941,0.12032085561497326,0.12032085561497326,0.12299465240641712,0.12299465240641712,0.12566844919786097,0.12566844919786097,0.12834224598930483,0.12834224598930483,0.13636363636363635,0.13636363636363635,0.13903743315508021,0.13903743315508021,0.14171122994652408,0.14171122994652408,0.1443850267379679,0.1443850267379679,0.14705882352941177,0.14705882352941177,0.1497326203208556,0.1497326203208556,0.15240641711229946,0.15240641711229946,0.15508021390374332,0.15508021390374332,0.15775401069518716,0.15775401069518716,0.16042780748663102,0.16042780748663102,0.16310160427807488,0.16310160427807488,0.1657754010695187,0.1657754010695187,0.16844919786096257,0.16844919786096257,0.17379679144385027,0.17379679144385027,0.17647058823529413,0.17647058823529413,0.17914438502673796,0.17914438502673796,0.18181818181818182,0.18181818181818182,0.18449197860962566,0.18449197860962566,0.18716577540106952,0.18716577540106952,0.18983957219251338,0.18983957219251338,0.1925133689839572,0.1925133689839572,0.19518716577540107,0.19518716577540107,0.19786096256684493,0.19786096256684493,0.20053475935828877,0.20053475935828877,0.20855614973262032,0.20855614973262032,0.21122994652406418,0.21122994652406418,0.21390374331550802,0.21390374331550802,0.21657754010695188,0.21657754010695188,0.2192513368983957,0.2192513368983957,0.22192513368983957,0.22192513368983957,0.22459893048128343,0.22459893048128343,0.22727272727272727,0.22727272727272727,0.232620320855615,0.232620320855615,0.23529411764705882,0.23529411764705882,0.24064171122994651,0.24064171122994651,0.24331550802139038,0.24331550802139038,0.2540106951871658,0.2540106951871658,0.25935828877005346,0.25935828877005346,0.2620320855614973,0.2620320855614973,0.2647058823529412,0.2647058823529412,0.2700534759358289,0.2700534759358289,0.27540106951871657,0.27540106951871657,0.27807486631016043,0.27807486631016043,0.2807486631016043,0.2807486631016043,0.28342245989304815,0.28342245989304815,0.28609625668449196,0.28609625668449196,0.2887700534759358,0.2887700534759358,0.2914438502673797,0.2914438502673797,0.29411764705882354,0.29411764705882354,0.2967914438502674,0.2967914438502674,0.31016042780748665,0.31016042780748665,0.3155080213903743,0.3155080213903743,0.3181818181818182,0.3181818181818182,0.32887700534759357,0.32887700534759357,0.33689839572192515,0.33689839572192515,0.3422459893048128,0.3422459893048128,0.3449197860962567,0.3449197860962567,0.34759358288770054,0.34759358288770054,0.3502673796791444,0.3502673796791444,0.35294117647058826,0.35294117647058826,0.36363636363636365,0.36363636363636365,0.3663101604278075,0.3663101604278075,0.37433155080213903,0.37433155080213903,0.3770053475935829,0.3770053475935829,0.37967914438502676,0.37967914438502676,0.38235294117647056,0.38235294117647056,0.393048128342246,0.393048128342246,0.3983957219251337,0.3983957219251337,0.40106951871657753,0.40106951871657753,0.40641711229946526,0.40641711229946526,0.4090909090909091,0.4090909090909091,0.4117647058823529,0.4117647058823529,0.4144385026737968,0.4144385026737968,0.4197860962566845,0.4197860962566845,0.42513368983957217,0.42513368983957217,0.42780748663101603,0.42780748663101603,0.43315508021390375,0.43315508021390375,0.4385026737967914,0.4385026737967914,0.4411764705882353,0.4411764705882353,0.44919786096256686,0.44919786096256686,0.45187165775401067,0.45187165775401067,0.4572192513368984,0.4572192513368984,0.46524064171123,0.46524064171123,0.4732620320855615,0.4732620320855615,0.47593582887700536,0.47593582887700536,0.48128342245989303,0.48128342245989303,0.48663101604278075,0.48663101604278075,0.4946524064171123,0.4946524064171123,0.49732620320855614,0.49732620320855614,0.5026737967914439,0.5026737967914439,0.5080213903743316,0.5080213903743316,0.5106951871657754,0.5106951871657754,0.5133689839572193,0.5133689839572193,0.5294117647058824,0.5294117647058824,0.5347593582887701,0.5347593582887701,0.5374331550802139,0.5374331550802139,0.5454545454545454,0.5454545454545454,0.5668449197860963,0.5668449197860963,0.5748663101604278,0.5748663101604278,0.5855614973262032,0.5855614973262032,0.5909090909090909,0.5909090909090909,0.5935828877005348,0.5935828877005348,0.5962566844919787,0.5962566844919787,0.6042780748663101,0.6042780748663101,0.6122994652406417,0.6122994652406417,0.6203208556149733,0.6203208556149733,0.6256684491978609,0.6256684491978609,0.6470588235294118,0.6470588235294118,0.660427807486631,0.660427807486631,0.6631016042780749,0.6631016042780749,0.6657754010695187,0.6657754010695187,0.6684491978609626,0.6684491978609626,0.6764705882352942,0.6764705882352942,0.6871657754010695,0.6871657754010695,0.6925133689839572,0.6925133689839572,0.6951871657754011,0.6951871657754011,0.7245989304812834,0.7245989304812834,0.7272727272727273,0.7272727272727273,0.732620320855615,0.732620320855615,0.7379679144385026,0.7379679144385026,0.7406417112299465,0.7406417112299465,0.7459893048128342,0.7459893048128342,0.7647058823529411,0.7647058823529411,0.767379679144385,0.767379679144385,0.7754010695187166,0.7754010695187166,0.7834224598930482,0.7834224598930482,0.7967914438502673,0.7967914438502673,0.8021390374331551,0.8021390374331551,0.8262032085561497,0.8262032085561497,0.8368983957219251,0.8368983957219251,0.839572192513369,0.839572192513369,0.8663101604278075,0.8663101604278075,0.8689839572192514,0.8689839572192514,0.8716577540106952,0.8716577540106952,0.8743315508021391,0.8743315508021391,0.8796791443850267,0.8796791443850267,0.8823529411764706,0.8823529411764706,0.8850267379679144,0.8850267379679144,0.8877005347593583,0.8877005347593583,0.8903743315508021,0.8903743315508021,0.893048128342246,0.893048128342246,0.9037433155080213,0.9037433155080213,0.9224598930481284,0.9224598930481284,0.9251336898395722,0.9251336898395722,0.9358288770053476,0.9358288770053476,0.9411764705882353,0.9411764705882353,0.9438502673796791,0.9438502673796791,0.946524064171123,0.946524064171123,0.9518716577540107,0.9518716577540107,0.9732620320855615,0.9732620320855615,0.9946524064171123,1.0],\"xaxis\":\"x\",\"y\":[0.0,0.29912875121006777,0.31752178121974833,0.31752178121974833,0.32236205227492737,0.32236205227492737,0.32623426911907066,0.32623426911907066,0.3281703775411423,0.3281703775411423,0.33204259438528555,0.33204259438528555,0.34172313649564373,0.34172313649564373,0.345595353339787,0.345595353339787,0.35818005808325265,0.35818005808325265,0.38334946757018395,0.38334946757018395,0.3978702807357212,0.3978702807357212,0.41142303969022265,0.41142303969022265,0.4259438528557599,0.4259438528557599,0.4356243949661181,0.4356243949661181,0.4394966118102614,0.4394966118102614,0.462729912875121,0.462729912875121,0.4743465634075508,0.4743465634075508,0.47725072604065827,0.47725072604065827,0.5072604065827686,0.5072604065827686,0.5150048402710552,0.5150048402710552,0.5324298160696999,0.5324298160696999,0.5401742497579864,0.5401742497579864,0.5527589545014521,0.5527589545014521,0.558567279767667,0.558567279767667,0.5653436592449177,0.5653436592449177,0.5701839303000968,0.5701839303000968,0.5750242013552759,0.5750242013552759,0.5788964181994192,0.5788964181994192,0.5837366892545982,0.5837366892545982,0.590513068731849,0.590513068731849,0.5924491771539206,0.5924491771539206,0.5953533397870281,0.5953533397870281,0.5963213939980639,0.5963213939980639,0.5972894482090997,0.5972894482090997,0.6001936108422071,0.6001936108422071,0.6030977734753146,0.6030977734753146,0.6069699903194579,0.6069699903194579,0.6224588576960309,0.6224588576960309,0.6234269119070668,0.6234269119070668,0.6253630203291385,0.6253630203291385,0.6321393998063891,0.6321393998063891,0.6447241045498547,0.6447241045498547,0.6495643756050339,0.6495643756050339,0.6563407550822846,0.6563407550822846,0.6573088092933205,0.6573088092933205,0.6611810261374637,0.6611810261374637,0.6631171345595354,0.6631171345595354,0.6689254598257502,0.6689254598257502,0.6698935140367861,0.6698935140367861,0.6766698935140368,0.6766698935140368,0.68054211035818,0.68054211035818,0.6824782187802517,0.6824782187802517,0.6853823814133592,0.6853823814133592,0.6873184898354308,0.6873184898354308,0.7018393030009681,0.7018393030009681,0.707647628267183,0.707647628267183,0.7086156824782188,0.7086156824782188,0.712487899322362,0.712487899322362,0.7144240077444337,0.7144240077444337,0.7153920619554696,0.7153920619554696,0.7173281703775412,0.7173281703775412,0.7318489835430784,0.7318489835430784,0.7357212003872217,0.7357212003872217,0.7424975798644724,0.7424975798644724,0.7579864472410455,0.7579864472410455,0.7637947725072604,0.7637947725072604,0.7666989351403679,0.7666989351403679,0.7696030977734754,0.7696030977734754,0.7705711519845111,0.7705711519845111,0.7744433688286544,0.7744433688286544,0.7763794772507261,0.7763794772507261,0.7792836398838335,0.7792836398838335,0.782187802516941,0.782187802516941,0.7841239109390126,0.7841239109390126,0.7850919651500484,0.7850919651500484,0.78702807357212,0.78702807357212,0.7889641819941917,0.7889641819941917,0.7957405614714425,0.7957405614714425,0.7986447241045499,0.7986447241045499,0.7996127783155856,0.7996127783155856,0.8015488867376573,0.8015488867376573,0.8025169409486931,0.8025169409486931,0.8054211035818006,0.8054211035818006,0.8063891577928364,0.8063891577928364,0.8073572120038722,0.8073572120038722,0.8102613746369797,0.8102613746369797,0.8151016456921588,0.8151016456921588,0.8160696999031946,0.8160696999031946,0.818973862536302,0.818973862536302,0.8238141335914811,0.8238141335914811,0.8247821878025169,0.8247821878025169,0.8286544046466602,0.8286544046466602,0.829622458857696,0.829622458857696,0.8315585672797676,0.8315585672797676,0.8363988383349468,0.8363988383349468,0.8402710551790901,0.8402710551790901,0.8412391093901258,0.8412391093901258,0.8431752178121975,0.8431752178121975,0.8441432720232332,0.8441432720232332,0.8489835430784124,0.8489835430784124,0.8499515972894482,0.8499515972894482,0.850919651500484,0.850919651500484,0.8518877057115198,0.8518877057115198,0.8528557599225557,0.8528557599225557,0.8606001936108422,0.8606001936108422,0.861568247821878,0.861568247821878,0.8635043562439496,0.8635043562439496,0.8654404646660213,0.8654404646660213,0.8664085188770572,0.8664085188770572,0.8702807357212003,0.8702807357212003,0.8712487899322362,0.8712487899322362,0.8770571151984511,0.8770571151984511,0.8789932236205228,0.8789932236205228,0.8809293320425944,0.8809293320425944,0.8818973862536302,0.8818973862536302,0.8867376573088093,0.8867376573088093,0.888673765730881,0.888673765730881,0.8954501452081317,0.8954501452081317,0.8973862536302033,0.8973862536302033,0.9002904162633107,0.9002904162633107,0.9012584704743466,0.9012584704743466,0.9022265246853823,0.9022265246853823,0.9031945788964182,0.9031945788964182,0.9119070667957405,0.9119070667957405,0.9157792836398838,0.9157792836398838,0.9167473378509197,0.9167473378509197,0.9177153920619555,0.9177153920619555,0.920619554695063,0.920619554695063,0.9215876089060987,0.9215876089060987,0.9225556631171346,0.9225556631171346,0.9235237173281704,0.9235237173281704,0.9244917715392061,0.9244917715392061,0.9273959341723137,0.9273959341723137,0.9283639883833494,0.9283639883833494,0.9303000968054211,0.9303000968054211,0.9332042594385286,0.9332042594385286,0.9341723136495643,0.9341723136495643,0.936108422071636,0.936108422071636,0.9370764762826719,0.9370764762826719,0.9380445304937076,0.9380445304937076,0.9390125847047435,0.9390125847047435,0.9409486931268151,0.9409486931268151,0.9428848015488868,0.9428848015488868,0.9448209099709584,0.9448209099709584,0.9457889641819942,0.9457889641819942,0.9467570183930301,0.9467570183930301,0.9477250726040658,0.9477250726040658,0.9496611810261375,0.9496611810261375,0.9506292352371732,0.9506292352371732,0.9535333978702807,0.9535333978702807,0.9554695062923524,0.9554695062923524,0.9583736689254598,0.9583736689254598,0.9593417231364957,0.9593417231364957,0.9603097773475314,0.9603097773475314,0.9622458857696031,0.9622458857696031,0.9632139399806389,0.9632139399806389,0.9641819941916747,0.9641819941916747,0.9651500484027106,0.9651500484027106,0.9670861568247822,0.9670861568247822,0.968054211035818,0.968054211035818,0.9690222652468539,0.9690222652468539,0.9719264278799613,0.9719264278799613,0.9738625363020329,0.9738625363020329,0.9748305905130688,0.9748305905130688,0.9757986447241046,0.9757986447241046,0.9767666989351403,0.9767666989351403,0.9777347531461762,0.9777347531461762,0.978702807357212,0.978702807357212,0.9796708615682478,0.9796708615682478,0.9816069699903195,0.9816069699903195,0.9825750242013552,0.9825750242013552,0.9835430784123911,0.9835430784123911,0.9845111326234269,0.9845111326234269,0.9854791868344628,0.9854791868344628,0.9864472410454985,0.9864472410454985,0.9874152952565344,0.9874152952565344,0.9883833494675702,0.9883833494675702,0.989351403678606,0.989351403678606,0.9903194578896418,0.9903194578896418,0.9912875121006777,0.9912875121006777,0.9932236205227493,0.9932236205227493,0.9941916747337851,0.9941916747337851,0.995159728944821,0.995159728944821,0.9961277831558567,0.9961277831558567,0.9970958373668926,0.9970958373668926,0.9990319457889641,0.9990319457889641,1.0,1.0,1.0],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"False Positive Rate\"},\"constrain\":\"domain\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"True Positive Rate\"},\"scaleanchor\":\"x\",\"scaleratio\":1},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"ROC Curve (AUC=0.8327)\"},\"height\":600,\"width\":800,\"shapes\":[{\"line\":{\"dash\":\"dash\"},\"type\":\"line\",\"x0\":0,\"x1\":1,\"y0\":0,\"y1\":1}],\"showlegend\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('0d700bc3-5057-4e76-ba5a-146c658bb0ae');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"fillpattern":{"shape":""},"hovertemplate":"Recall=%{x}<br>Precision=%{y}<extra></extra>","legendgroup":"","line":{"color":"#636efa"},"marker":{"symbol":"circle"},"mode":"lines","name":"","orientation":"v","showlegend":false,"stackgroup":"1","type":"scatter","x":[1,1,1,1,1,1,1,1,1,1,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9980638915779284,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9961277831558567,0.9961277831558567,0.995159728944821,0.995159728944821,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9932236205227493,0.9932236205227493,0.9932236205227493,0.9932236205227493,0.9932236205227493,0.9922555663117134,0.9912875121006777,0.9912875121006777,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.989351403678606,0.989351403678606,0.989351403678606,0.989351403678606,0.989351403678606,0.9883833494675702,0.9883833494675702,0.9874152952565344,0.9874152952565344,0.9864472410454985,0.9864472410454985,0.9854791868344628,0.9854791868344628,0.9845111326234269,0.9845111326234269,0.9835430784123911,0.9835430784123911,0.9835430784123911,0.9825750242013552,0.9825750242013552,0.9816069699903195,0.9816069699903195,0.9806389157792836,0.9796708615682478,0.9796708615682478,0.978702807357212,0.978702807357212,0.978702807357212,0.978702807357212,0.978702807357212,0.978702807357212,0.978702807357212,0.978702807357212,0.978702807357212,0.978702807357212,0.978702807357212,0.9777347531461762,0.9777347531461762,0.9767666989351403,0.9767666989351403,0.9767666989351403,0.9767666989351403,0.9767666989351403,0.9757986447241046,0.9757986447241046,0.9757986447241046,0.9757986447241046,0.9757986447241046,0.9757986447241046,0.9757986447241046,0.9757986447241046,0.9757986447241046,0.9757986447241046,0.9748305905130688,0.9748305905130688,0.9748305905130688,0.9738625363020329,0.9738625363020329,0.9738625363020329,0.9738625363020329,0.9738625363020329,0.9738625363020329,0.972894482090997,0.9719264278799613,0.9719264278799613,0.9719264278799613,0.9719264278799613,0.9709583736689255,0.9699903194578896,0.9690222652468539,0.9690222652468539,0.9690222652468539,0.9690222652468539,0.968054211035818,0.968054211035818,0.9670861568247822,0.9670861568247822,0.9670861568247822,0.9670861568247822,0.9670861568247822,0.9670861568247822,0.9670861568247822,0.9670861568247822,0.9661181026137464,0.9651500484027106,0.9651500484027106,0.9651500484027106,0.9641819941916747,0.9641819941916747,0.9632139399806389,0.9632139399806389,0.9632139399806389,0.9622458857696031,0.9622458857696031,0.9622458857696031,0.9612778315585673,0.9603097773475314,0.9603097773475314,0.9593417231364957,0.9593417231364957,0.9593417231364957,0.9593417231364957,0.9593417231364957,0.9593417231364957,0.9593417231364957,0.9593417231364957,0.9593417231364957,0.9593417231364957,0.9593417231364957,0.9593417231364957,0.9583736689254598,0.9583736689254598,0.957405614714424,0.9564375605033882,0.9554695062923524,0.9554695062923524,0.9554695062923524,0.9545014520813165,0.9535333978702807,0.9535333978702807,0.9535333978702807,0.9535333978702807,0.9535333978702807,0.952565343659245,0.9515972894482091,0.9506292352371732,0.9506292352371732,0.9506292352371732,0.9506292352371732,0.9496611810261375,0.9496611810261375,0.9486931268151017,0.9477250726040658,0.9477250726040658,0.9467570183930301,0.9467570183930301,0.9457889641819942,0.9457889641819942,0.9457889641819942,0.9457889641819942,0.9457889641819942,0.9457889641819942,0.9448209099709584,0.9448209099709584,0.9448209099709584,0.9448209099709584,0.9448209099709584,0.9448209099709584,0.9448209099709584,0.9448209099709584,0.9448209099709584,0.9438528557599225,0.9428848015488868,0.9428848015488868,0.9428848015488868,0.9419167473378509,0.9409486931268151,0.9409486931268151,0.9409486931268151,0.9409486931268151,0.9399806389157793,0.9390125847047435,0.9390125847047435,0.9390125847047435,0.9390125847047435,0.9380445304937076,0.9380445304937076,0.9380445304937076,0.9380445304937076,0.9370764762826719,0.9370764762826719,0.936108422071636,0.936108422071636,0.9351403678606002,0.9341723136495643,0.9341723136495643,0.9341723136495643,0.9332042594385286,0.9332042594385286,0.9332042594385286,0.9332042594385286,0.9332042594385286,0.9322362052274927,0.9312681510164569,0.9303000968054211,0.9303000968054211,0.9303000968054211,0.9303000968054211,0.9293320425943853,0.9283639883833494,0.9283639883833494,0.9283639883833494,0.9283639883833494,0.9283639883833494,0.9283639883833494,0.9283639883833494,0.9283639883833494,0.9283639883833494,0.9273959341723137,0.9273959341723137,0.9273959341723137,0.9273959341723137,0.9264278799612778,0.925459825750242,0.9244917715392061,0.9244917715392061,0.9235237173281704,0.9235237173281704,0.9235237173281704,0.9225556631171346,0.9225556631171346,0.9225556631171346,0.9225556631171346,0.9225556631171346,0.9225556631171346,0.9225556631171346,0.9215876089060987,0.9215876089060987,0.920619554695063,0.920619554695063,0.9196515004840271,0.9186834462729913,0.9177153920619555,0.9177153920619555,0.9177153920619555,0.9167473378509197,0.9167473378509197,0.9167473378509197,0.9157792836398838,0.9157792836398838,0.914811229428848,0.9138431752178122,0.9128751210067764,0.9119070667957405,0.9119070667957405,0.9119070667957405,0.9119070667957405,0.9109390125847048,0.9099709583736689,0.9090029041626331,0.9080348499515973,0.9070667957405615,0.9060987415295256,0.9051306873184899,0.904162633107454,0.9031945788964182,0.9031945788964182,0.9031945788964182,0.9022265246853823,0.9022265246853823,0.9022265246853823,0.9012584704743466,0.9012584704743466,0.9002904162633107,0.9002904162633107,0.9002904162633107,0.9002904162633107,0.8993223620522749,0.8983543078412392,0.8973862536302033,0.8973862536302033,0.8973862536302033,0.8973862536302033,0.8964181994191674,0.8954501452081317,0.8954501452081317,0.8954501452081317,0.8944820909970959,0.89351403678606,0.8925459825750242,0.8915779283639884,0.8906098741529526,0.8896418199419167,0.888673765730881,0.888673765730881,0.8877057115198451,0.8867376573088093,0.8867376573088093,0.8867376573088093,0.8867376573088093,0.8857696030977735,0.8848015488867377,0.8838334946757018,0.882865440464666,0.8818973862536302,0.8818973862536302,0.8809293320425944,0.8809293320425944,0.8809293320425944,0.8799612778315585,0.8789932236205228,0.8789932236205228,0.8789932236205228,0.8780251694094869,0.8770571151984511,0.8770571151984511,0.8760890609874153,0.8751210067763795,0.8741529525653436,0.8731848983543078,0.872216844143272,0.8712487899322362,0.8712487899322362,0.8712487899322362,0.8702807357212003,0.8702807357212003,0.8702807357212003,0.8693126815101646,0.8683446272991288,0.8673765730880929,0.8664085188770572,0.8664085188770572,0.8654404646660213,0.8654404646660213,0.8644724104549855,0.8635043562439496,0.8635043562439496,0.8625363020329139,0.861568247821878,0.861568247821878,0.861568247821878,0.8606001936108422,0.8606001936108422,0.8596321393998064,0.8586640851887706,0.8576960309777347,0.856727976766699,0.8557599225556631,0.8547918683446273,0.8538238141335914,0.8528557599225557,0.8528557599225557,0.8528557599225557,0.8518877057115198,0.8518877057115198,0.8518877057115198,0.8518877057115198,0.8518877057115198,0.850919651500484,0.850919651500484,0.8499515972894482,0.8499515972894482,0.8489835430784124,0.8489835430784124,0.8480154888673765,0.8470474346563408,0.846079380445305,0.8451113262342691,0.8441432720232332,0.8441432720232332,0.8441432720232332,0.8441432720232332,0.8431752178121975,0.8431752178121975,0.8422071636011617,0.8412391093901258,0.8412391093901258,0.8412391093901258,0.8412391093901258,0.8412391093901258,0.8402710551790901,0.8402710551790901,0.8393030009680542,0.8383349467570184,0.8373668925459826,0.8363988383349468,0.8363988383349468,0.8354307841239109,0.8344627299128751,0.8334946757018393,0.8325266214908035,0.8315585672797676,0.8315585672797676,0.8305905130687319,0.829622458857696,0.829622458857696,0.8286544046466602,0.8286544046466602,0.8286544046466602,0.8276863504356244,0.8267182962245886,0.8257502420135527,0.8247821878025169,0.8247821878025169,0.8247821878025169,0.8247821878025169,0.8238141335914811,0.8238141335914811,0.8238141335914811,0.8238141335914811,0.8238141335914811,0.8228460793804453,0.8218780251694094,0.8209099709583737,0.8199419167473379,0.818973862536302,0.818973862536302,0.8180058083252663,0.8170377541142304,0.8160696999031946,0.8160696999031946,0.8160696999031946,0.8151016456921588,0.8151016456921588,0.8151016456921588,0.8151016456921588,0.8151016456921588,0.8151016456921588,0.814133591481123,0.8131655372700871,0.8121974830590513,0.8112294288480155,0.8102613746369797,0.8102613746369797,0.8092933204259438,0.8083252662149081,0.8073572120038722,0.8073572120038722,0.8063891577928364,0.8063891577928364,0.8054211035818006,0.8054211035818006,0.8044530493707648,0.8034849951597289,0.8025169409486931,0.8025169409486931,0.8015488867376573,0.8015488867376573,0.8005808325266215,0.7996127783155856,0.7996127783155856,0.7986447241045499,0.7986447241045499,0.797676669893514,0.7967086156824782,0.7957405614714425,0.7957405614714425,0.7957405614714425,0.7947725072604066,0.7938044530493708,0.7928363988383349,0.7918683446272992,0.7909002904162633,0.7899322362052275,0.7889641819941917,0.7889641819941917,0.7889641819941917,0.7879961277831559,0.78702807357212,0.78702807357212,0.7860600193610843,0.7850919651500484,0.7850919651500484,0.7841239109390126,0.7841239109390126,0.7841239109390126,0.7831558567279767,0.782187802516941,0.782187802516941,0.782187802516941,0.782187802516941,0.782187802516941,0.7812197483059051,0.7802516940948693,0.7792836398838335,0.7792836398838335,0.7783155856727977,0.7773475314617618,0.7763794772507261,0.7763794772507261,0.7763794772507261,0.7754114230396902,0.7744433688286544,0.7744433688286544,0.7734753146176185,0.7725072604065828,0.771539206195547,0.7705711519845111,0.7705711519845111,0.7705711519845111,0.7696030977734754,0.7696030977734754,0.7686350435624395,0.7676669893514037,0.7666989351403679,0.7666989351403679,0.7657308809293321,0.7647628267182962,0.7637947725072604,0.7637947725072604,0.7628267182962246,0.7618586640851888,0.7608906098741529,0.7599225556631172,0.7589545014520813,0.7579864472410455,0.7579864472410455,0.7570183930300097,0.7560503388189739,0.755082284607938,0.7541142303969022,0.7531461761858664,0.7521781219748306,0.7512100677637947,0.750242013552759,0.7492739593417231,0.7483059051306873,0.7473378509196515,0.7463697967086157,0.7454017424975798,0.744433688286544,0.7434656340755083,0.7424975798644724,0.7424975798644724,0.7415295256534365,0.7405614714424008,0.739593417231365,0.7386253630203291,0.7376573088092934,0.7366892545982575,0.7357212003872217,0.7357212003872217,0.7347531461761858,0.7337850919651501,0.7328170377541142,0.7318489835430784,0.7318489835430784,0.7308809293320426,0.7299128751210068,0.7289448209099709,0.7279767666989352,0.7270087124878993,0.7260406582768635,0.7250726040658277,0.7241045498547919,0.723136495643756,0.7221684414327202,0.7212003872216844,0.7202323330106486,0.7192642787996127,0.718296224588577,0.7173281703775412,0.7173281703775412,0.7173281703775412,0.7173281703775412,0.7163601161665053,0.7153920619554696,0.7153920619554696,0.7144240077444337,0.7144240077444337,0.7134559535333979,0.712487899322362,0.712487899322362,0.7115198451113263,0.7105517909002904,0.7095837366892546,0.7086156824782188,0.7086156824782188,0.707647628267183,0.707647628267183,0.7066795740561471,0.7057115198451114,0.7047434656340755,0.7037754114230397,0.7028073572120038,0.7018393030009681,0.7018393030009681,0.7008712487899322,0.6999031945788964,0.6989351403678606,0.6979670861568248,0.6969990319457889,0.6960309777347532,0.6950629235237173,0.6940948693126815,0.6931268151016456,0.6921587608906099,0.691190706679574,0.6902226524685382,0.6892545982575025,0.6882865440464666,0.6873184898354308,0.6873184898354308,0.686350435624395,0.6853823814133592,0.6853823814133592,0.6844143272023233,0.6834462729912875,0.6824782187802517,0.6824782187802517,0.6815101645692159,0.68054211035818,0.68054211035818,0.6795740561471443,0.6786060019361084,0.6776379477250726,0.6766698935140368,0.6766698935140368,0.6766698935140368,0.675701839303001,0.6747337850919651,0.6737657308809293,0.6727976766698935,0.6718296224588577,0.6708615682478218,0.6698935140367861,0.6698935140367861,0.6689254598257502,0.6689254598257502,0.6679574056147144,0.6669893514036787,0.6660212971926428,0.665053242981607,0.6640851887705711,0.6631171345595354,0.6631171345595354,0.6621490803484995,0.6611810261374637,0.6611810261374637,0.6602129719264279,0.6592449177153921,0.6582768635043562,0.6573088092933205,0.6573088092933205,0.6563407550822846,0.6563407550822846,0.6553727008712488,0.6544046466602129,0.6534365924491772,0.6524685382381413,0.6515004840271055,0.6505324298160697,0.6495643756050339,0.6495643756050339,0.648596321393998,0.6476282671829623,0.6466602129719264,0.6456921587608906,0.6447241045498547,0.6447241045498547,0.643756050338819,0.6427879961277831,0.6418199419167473,0.6408518877057116,0.6398838334946757,0.6389157792836399,0.6379477250726041,0.6369796708615683,0.6360116166505324,0.6350435624394967,0.6340755082284608,0.633107454017425,0.6321393998063891,0.6321393998063891,0.6311713455953534,0.6302032913843175,0.6292352371732817,0.6282671829622459,0.6272991287512101,0.6263310745401742,0.6253630203291385,0.6253630203291385,0.6243949661181026,0.6234269119070668,0.6234269119070668,0.6224588576960309,0.6224588576960309,0.6214908034849952,0.6205227492739593,0.6195546950629235,0.6185866408518877,0.6176185866408519,0.616650532429816,0.6156824782187803,0.6147144240077445,0.6137463697967086,0.6127783155856728,0.611810261374637,0.6108422071636012,0.6098741529525653,0.6089060987415296,0.6079380445304937,0.6069699903194579,0.6069699903194579,0.6069699903194579,0.6069699903194579,0.6060019361084221,0.6050338818973863,0.6040658276863504,0.6030977734753146,0.6030977734753146,0.6021297192642788,0.601161665053243,0.6001936108422071,0.6001936108422071,0.5992255566311714,0.5982575024201355,0.5972894482090997,0.5972894482090997,0.5963213939980639,0.5963213939980639,0.5953533397870281,0.5953533397870281,0.5943852855759922,0.5934172313649564,0.5924491771539206,0.5924491771539206,0.5914811229428848,0.590513068731849,0.590513068731849,0.5895450145208132,0.5885769603097774,0.5876089060987415,0.5866408518877058,0.5856727976766699,0.5847047434656341,0.5837366892545982,0.5837366892545982,0.5827686350435625,0.5818005808325266,0.5808325266214908,0.579864472410455,0.5788964181994192,0.5788964181994192,0.5779283639883833,0.5769603097773476,0.5759922555663117,0.5750242013552759,0.5750242013552759,0.57405614714424,0.5730880929332043,0.5721200387221684,0.5711519845111326,0.5701839303000968,0.5701839303000968,0.569215876089061,0.5682478218780251,0.5672797676669894,0.5663117134559535,0.5653436592449177,0.5653436592449177,0.5643756050338818,0.5634075508228461,0.5624394966118103,0.5614714424007744,0.5605033881897387,0.5595353339787028,0.558567279767667,0.558567279767667,0.5575992255566312,0.5566311713455954,0.5556631171345595,0.5546950629235237,0.5537270087124879,0.5527589545014521,0.5527589545014521,0.5517909002904162,0.5508228460793805,0.5498547918683446,0.5488867376573088,0.547918683446273,0.5469506292352372,0.5459825750242013,0.5450145208131656,0.5440464666021297,0.5430784123910939,0.542110358180058,0.5411423039690223,0.5401742497579864,0.5401742497579864,0.5401742497579864,0.5392061955469506,0.5382381413359149,0.537270087124879,0.5363020329138432,0.5353339787028074,0.5343659244917716,0.5333978702807357,0.5324298160696999,0.5324298160696999,0.5314617618586641,0.5304937076476283,0.5295256534365924,0.5285575992255567,0.5275895450145208,0.526621490803485,0.5256534365924492,0.5246853823814134,0.5237173281703775,0.5227492739593417,0.5217812197483059,0.5208131655372701,0.5198451113262342,0.5188770571151985,0.5179090029041626,0.5169409486931268,0.515972894482091,0.5150048402710552,0.5150048402710552,0.5140367860600193,0.5130687318489835,0.5121006776379478,0.5111326234269119,0.510164569215876,0.5091965150048403,0.5082284607938045,0.5072604065827686,0.5072604065827686,0.5072604065827686,0.5062923523717329,0.505324298160697,0.5043562439496612,0.5033881897386253,0.5024201355275896,0.5014520813165537,0.5004840271055179,0.4995159728944821,0.4985479186834463,0.4975798644724105,0.49661181026137463,0.49564375605033884,0.494675701839303,0.4937076476282672,0.4927395934172314,0.49177153920619554,0.49080348499515974,0.4898354307841239,0.4888673765730881,0.4878993223620523,0.48693126815101645,0.48596321393998065,0.4849951597289448,0.484027105517909,0.4830590513068732,0.48209099709583736,0.48112294288480156,0.4801548886737657,0.4791868344627299,0.4782187802516941,0.47725072604065827,0.47725072604065827,0.4762826718296225,0.4753146176185866,0.4743465634075508,0.4743465634075508,0.47337850919651503,0.4724104549854792,0.4714424007744434,0.47047434656340753,0.46950629235237173,0.46853823814133594,0.4675701839303001,0.4666021297192643,0.46563407550822844,0.46466602129719264,0.46369796708615685,0.462729912875121,0.462729912875121,0.4617618586640852,0.46079380445304935,0.45982575024201355,0.45885769603097776,0.4578896418199419,0.4569215876089061,0.45595353339787026,0.45498547918683446,0.45401742497579867,0.4530493707647628,0.452081316553727,0.45111326234269117,0.45014520813165537,0.4491771539206196,0.4482090997095837,0.44724104549854793,0.4462729912875121,0.4453049370764763,0.4443368828654405,0.44336882865440463,0.44240077444336884,0.441432720232333,0.4404646660212972,0.4394966118102614,0.4394966118102614,0.43852855759922554,0.43756050338818975,0.4365924491771539,0.4356243949661181,0.4356243949661181,0.4346563407550823,0.43368828654404645,0.43272023233301066,0.4317521781219748,0.430784123910939,0.4298160696999032,0.42884801548886736,0.42787996127783157,0.4269119070667957,0.4259438528557599,0.4259438528557599,0.4249757986447241,0.42400774443368827,0.4230396902226525,0.4220716360116166,0.42110358180058083,0.42013552758954503,0.4191674733785092,0.4181994191674734,0.41723136495643753,0.41626331074540174,0.41529525653436594,0.4143272023233301,0.4133591481122943,0.41239109390125844,0.41142303969022265,0.41142303969022265,0.41045498547918685,0.409486931268151,0.4085188770571152,0.4075508228460794,0.40658276863504356,0.40561471442400776,0.4046466602129719,0.4036786060019361,0.4027105517909003,0.40174249757986447,0.40077444336882867,0.3998063891577928,0.398838334946757,0.3978702807357212,0.3978702807357212,0.3978702807357212,0.3969022265246854,0.3959341723136496,0.39496611810261373,0.39399806389157793,0.39303000968054214,0.3920619554695063,0.3910939012584705,0.39012584704743464,0.38915779283639884,0.38818973862536305,0.3872216844143272,0.3862536302032914,0.38528557599225555,0.38431752178121975,0.38334946757018395,0.38334946757018395,0.3823814133591481,0.3814133591481123,0.38044530493707646,0.37947725072604066,0.37850919651500486,0.377541142303969,0.3765730880929332,0.37560503388189737,0.37463697967086157,0.3736689254598258,0.3727008712487899,0.3717328170377541,0.3707647628267183,0.3697967086156825,0.3688286544046467,0.36786060019361083,0.36689254598257504,0.3659244917715392,0.3649564375605034,0.3639883833494676,0.36302032913843174,0.36205227492739595,0.3610842207163601,0.3601161665053243,0.3591481122942885,0.35818005808325265,0.35818005808325265,0.35721200387221685,0.356243949661181,0.3552758954501452,0.3543078412391094,0.35333978702807356,0.35237173281703776,0.3514036786060019,0.3504356243949661,0.3494675701839303,0.34849951597289447,0.3475314617618587,0.3465634075508228,0.345595353339787,0.345595353339787,0.34462729912875123,0.3436592449177154,0.3426911907066796,0.34172313649564373,0.34172313649564373,0.34075508228460794,0.33978702807357214,0.3388189738625363,0.3378509196515005,0.33688286544046464,0.33591481122942884,0.33494675701839305,0.3339787028073572,0.3330106485963214,0.33204259438528555,0.33204259438528555,0.33107454017424975,0.33010648596321396,0.3291384317521781,0.3281703775411423,0.3281703775411423,0.32720232333010646,0.32623426911907066,0.32623426911907066,0.32526621490803487,0.324298160696999,0.3233301064859632,0.32236205227492737,0.32236205227492737,0.3213939980638916,0.3204259438528558,0.3194578896418199,0.31848983543078413,0.31752178121974833,0.31752178121974833,0.31752178121974833,0.3165537270087125,0.3155856727976767,0.31461761858664083,0.31364956437560504,0.31268151016456924,0.3117134559535334,0.3107454017424976,0.30977734753146174,0.30880929332042595,0.30784123910939015,0.3068731848983543,0.3059051306873185,0.30493707647628265,0.30396902226524686,0.30300096805421106,0.3020329138431752,0.3010648596321394,0.30009680542110356,0.29912875121006777,0],"xaxis":"x","y":[0.7341862117981521,0.7352313167259786,0.7357549857549858,0.7362794012829651,0.7368045649072753,0.7373304782298359,0.7378571428571429,0.7383845604002859,0.7389127324749643,0.7394416607015032,0.7392550143266475,0.7397849462365591,0.7403156384505022,0.7408470926058865,0.7413793103448276,0.7419122933141624,0.7424460431654676,0.7429805615550756,0.7435158501440923,0.7433309300648883,0.7431457431457431,0.7436823104693141,0.7442196531791907,0.7440347071583514,0.7445730824891461,0.7443881245474294,0.744927536231884,0.7447425670775925,0.7452830188679245,0.7458242556281772,0.7456395348837209,0.7461818181818182,0.7467248908296943,0.7472687545520758,0.7478134110787172,0.7476294675419402,0.7474452554744525,0.747991234477721,0.7478070175438597,0.7483540599853694,0.7489019033674963,0.7494505494505495,0.75,0.7505502567865003,0.751101321585903,0.75165319617928,0.7514705882352941,0.7520235467255335,0.7525773195876289,0.7531319086219602,0.7536873156342183,0.7535055350553506,0.7540620384047267,0.753880266075388,0.7544378698224852,0.7542561065877128,0.7548148148148148,0.7546330615270571,0.755192878338279,0.755011135857461,0.7555720653789004,0.7553903345724907,0.7559523809523809,0.7565152643335815,0.7563338301043219,0.7568978374347501,0.7567164179104477,0.7572815533980582,0.7571001494768311,0.7569184741959611,0.7574850299401198,0.7573033707865169,0.7578710644677661,0.7584396099024756,0.759009009009009,0.7595792637114951,0.7601503759398496,0.7607223476297968,0.7612951807228916,0.7618688771665411,0.7624434389140271,0.7630188679245283,0.7628398791540786,0.763416477702192,0.7632375189107413,0.7638152914458743,0.7643939393939394,0.7649734647460197,0.7655538694992413,0.765375854214123,0.7659574468085106,0.7665399239543726,0.7671232876712328,0.7677075399847677,0.7682926829268293,0.7688787185354691,0.7694656488549618,0.7700534759358288,0.7706422018348624,0.7704667176740627,0.7710566615620215,0.7716475095785441,0.7714723926380368,0.7720644666155027,0.7726574500768049,0.7732513451191392,0.7738461538461539,0.7744418783679754,0.7742681047765794,0.7740940632228219,0.7746913580246914,0.7752895752895753,0.7758887171561051,0.7757153905645785,0.7755417956656346,0.7753679318357862,0.775968992248062,0.7765709852598914,0.7771739130434783,0.777000777000777,0.7776049766718507,0.777431906614786,0.7780373831775701,0.7786438035853468,0.7792511700468019,0.7798594847775175,0.78046875,0.781078967943706,0.7816901408450704,0.7815191855912295,0.7813479623824452,0.7819607843137255,0.782574568288854,0.7824037706205813,0.7830188679245284,0.7828481510621558,0.7834645669291339,0.7840819542947203,0.7839116719242902,0.7845303867403315,0.7851500789889415,0.7849802371541502,0.7848101265822784,0.7854315122723674,0.7852614896988906,0.7858842188739096,0.7865079365079365,0.7871326449563145,0.787758346581876,0.7883850437549722,0.7890127388535032,0.7896414342629482,0.7902711323763956,0.790901835594573,0.7915335463258786,0.7921662669864109,0.792,0.7926341072858286,0.7924679487179487,0.7923015236567763,0.7921348314606742,0.7927710843373494,0.7934083601286174,0.7932421560740145,0.7930756843800322,0.7937147461724415,0.7943548387096774,0.7949959644874899,0.7956381260096931,0.7954729183508489,0.7953074433656958,0.7951417004048583,0.7957860615883307,0.7964314679643146,0.797077922077922,0.7969130787977254,0.7975609756097561,0.7973962571196095,0.7972312703583062,0.797881010594947,0.797716150081566,0.7983673469387755,0.798202614379085,0.7988552739165985,0.7995090016366612,0.8001638001638002,0.8008196721311476,0.8014766201804758,0.8013136288998358,0.8019720624486442,0.8026315789473685,0.8032921810699588,0.8039538714991763,0.8046166529266282,0.8052805280528053,0.805945499587118,0.8066115702479338,0.8064516129032258,0.8062913907284768,0.8069594034797017,0.8076285240464345,0.8074688796680498,0.8073089700996677,0.8079800498753117,0.8086522462562395,0.8093255620316403,0.8091666666666667,0.8090075062552127,0.8096828046744574,0.810359231411863,0.8110367892976589,0.8108786610878661,0.8115577889447236,0.8122380553227159,0.8129194630872483,0.8127623845507976,0.8134453781512605,0.8132884777123633,0.813973063973064,0.8138163437236732,0.8136593591905565,0.8143459915611815,0.8150337837837838,0.8148774302620456,0.8155668358714044,0.8162574089754445,0.8169491525423729,0.8176420695504665,0.8174872665534805,0.8173322005097706,0.8171768707482994,0.8178723404255319,0.8185689948892675,0.8192668371696504,0.8191126279863481,0.8189581554227157,0.8196581196581196,0.8203592814371258,0.8210616438356164,0.8217652099400171,0.8224699828473413,0.8231759656652361,0.8238831615120275,0.8245915735167669,0.8244406196213425,0.8251507321274764,0.8258620689655173,0.8265746333045729,0.8264248704663213,0.8262748487467588,0.8261245674740484,0.8268398268398268,0.8266897746967071,0.8274067649609714,0.828125,0.8279756733275413,0.828695652173913,0.8294168842471714,0.8301393728222997,0.8308631211857018,0.8315881326352531,0.8323144104803494,0.8321678321678322,0.8328958880139983,0.8327495621716288,0.8334794040315513,0.8333333333333334,0.8331870061457419,0.8330404217926186,0.8337730870712401,0.8345070422535211,0.8343612334801762,0.8350970017636684,0.8358340688437775,0.8356890459363958,0.8364279398762158,0.8362831858407079,0.8361381753764393,0.8359929078014184,0.8358473824312334,0.8365896980461812,0.8373333333333334,0.8380782918149466,0.8379341050756901,0.8377896613190731,0.8376449598572703,0.8375,0.837354781054513,0.8372093023255814,0.8370635631154879,0.8369175627240143,0.8367713004484305,0.8375224416517055,0.8382749326145552,0.8381294964028777,0.8388838883888389,0.8396396396396396,0.8394950405770965,0.8402527075812274,0.8401084010840109,0.840867992766727,0.8416289592760181,0.842391304347826,0.8422484134179511,0.8421052631578947,0.8419618528610354,0.8427272727272728,0.8434940855323021,0.8442622950819673,0.8441203281677302,0.843978102189781,0.8447488584474886,0.8455210237659964,0.8453796889295517,0.8452380952380952,0.845096241979835,0.844954128440367,0.8448117539026629,0.8446691176470589,0.8445262189512419,0.8453038674033149,0.8451612903225807,0.8450184501845018,0.8457987072945522,0.8465804066543438,0.84736355226642,0.8472222222222222,0.8470806302131604,0.8469387755102041,0.8467966573816156,0.8466542750929368,0.8474418604651163,0.8472998137802608,0.848089468779124,0.8488805970149254,0.8487394957983193,0.8485981308411215,0.8493919550982226,0.850187265917603,0.8500468603561387,0.849906191369606,0.8507042253521127,0.8505639097744361,0.8504233301975541,0.8502824858757062,0.8501413760603205,0.85,0.8498583569405099,0.8506616257088847,0.8514664143803217,0.8513257575757576,0.852132701421801,0.8529411764705882,0.8528015194681862,0.8526615969581749,0.8525214081826832,0.8523809523809524,0.8531935176358436,0.8530534351145038,0.8538681948424068,0.8537284894837476,0.8535885167464115,0.8544061302681992,0.8542665388302972,0.8541266794625719,0.8549471661863592,0.8557692307692307,0.8556304138594802,0.8564547206165704,0.8563162970106075,0.8561776061776062,0.8560386473429952,0.8558994197292069,0.8557599225556631,0.8556201550387597,0.8554801163918526,0.8553398058252427,0.8561710398445093,0.8570038910505836,0.8568646543330087,0.8576998050682261,0.8585365853658536,0.859375,0.8602150537634409,0.860078277886497,0.8609206660137121,0.8607843137254902,0.8616290480863592,0.8614931237721022,0.8623402163225172,0.8622047244094488,0.8620689655172413,0.8619329388560157,0.861796643632774,0.8616600790513834,0.8625123639960435,0.8633663366336634,0.8642220019821606,0.8640873015873016,0.8649453823237339,0.8648111332007953,0.8646766169154229,0.8655378486055777,0.8664007976071785,0.8672654690618763,0.8681318681318682,0.868,0.8688688688688688,0.8687374749498998,0.8686058174523571,0.8684738955823293,0.8683417085427135,0.869215291750503,0.8690835850956697,0.8689516129032258,0.8688193743693239,0.8686868686868687,0.8685540950455005,0.8694331983805668,0.8693009118541033,0.8691683569979716,0.8700507614213198,0.8699186991869918,0.8708036622583927,0.8716904276985743,0.8715596330275229,0.8714285714285714,0.8712972420837589,0.8711656441717791,0.872057318321392,0.8729508196721312,0.8738461538461538,0.8737166324435318,0.8746145940390545,0.8755144032921811,0.8764160659114315,0.877319587628866,0.8771929824561403,0.8770661157024794,0.8769389865563598,0.8768115942028986,0.8766839378238342,0.8775933609958506,0.877466251298027,0.8773388773388774,0.8772112382934444,0.878125,0.8790406673618353,0.8789144050104384,0.8798328108672936,0.8807531380753139,0.881675392670157,0.8825995807127882,0.8835257082896117,0.8834033613445378,0.8832807570977917,0.8831578947368421,0.8830347734457323,0.8829113924050633,0.883843717001056,0.8837209302325582,0.8835978835978836,0.8834745762711864,0.8844114528101803,0.8842887473460722,0.8852284803400637,0.8851063829787233,0.88604898828541,0.8859275053304904,0.8858057630736392,0.8856837606837606,0.8866310160427807,0.8865096359743041,0.887459807073955,0.8873390557939914,0.8872180451127819,0.8881720430107527,0.8880516684607105,0.8890086206896551,0.8888888888888888,0.8887688984881209,0.8886486486486487,0.8896103896103896,0.8905742145178764,0.8904555314533622,0.8903365906623235,0.8902173913043478,0.8900979325353645,0.8899782135076253,0.8898582333696837,0.8897379912663755,0.8907103825136612,0.8916849015317286,0.891566265060241,0.8914473684210527,0.8924259055982436,0.8923076923076924,0.8921892189218922,0.8931718061674009,0.8930540242557883,0.8940397350993378,0.8950276243093923,0.8949115044247787,0.8947951273532669,0.8957871396895787,0.8967813540510544,0.8977777777777778,0.8987764182424917,0.8986636971046771,0.8985507246376812,0.8984375,0.8994413407821229,0.8993288590604027,0.8992161254199328,0.899103139013453,0.9001122334455668,0.9011235955056179,0.9010123734533183,0.9009009009009009,0.9019165727170236,0.9018058690744921,0.9016949152542373,0.9015837104072398,0.9014722536806342,0.9024943310657596,0.9035187287173666,0.9034090909090909,0.9044368600682594,0.9043280182232346,0.9042189281641961,0.9041095890410958,0.9051428571428571,0.9050343249427918,0.9049255441008018,0.9048165137614679,0.9058553386911596,0.9057471264367816,0.905638665132336,0.9055299539170507,0.9054209919261822,0.9053117782909931,0.9052023121387284,0.90625,0.9061413673232909,0.9060324825986079,0.9059233449477352,0.9058139534883721,0.9057043073341094,0.9055944055944056,0.9054842473745625,0.905373831775701,0.9052631578947369,0.905152224824356,0.9050410316529894,0.9049295774647887,0.9048178613396005,0.9047058823529411,0.9045936395759717,0.9044811320754716,0.9055489964580874,0.9054373522458629,0.9053254437869822,0.9052132701421801,0.9051008303677343,0.9049881235154394,0.9048751486325802,0.9047619047619048,0.9058402860548271,0.905727923627685,0.9056152927120669,0.9055023923444976,0.9053892215568863,0.9064748201438849,0.9063625450180072,0.90625,0.9061371841155235,0.9060240963855422,0.9059107358262968,0.9057971014492754,0.905683192261185,0.9055690072639225,0.9054545454545454,0.9053398058252428,0.905224787363305,0.9051094890510949,0.904993909866017,0.9048780487804878,0.9047619047619048,0.9058679706601467,0.9069767441860465,0.9080882352941176,0.9079754601226994,0.9078624078624079,0.9089790897908979,0.9088669950738916,0.9099876695437731,0.9098765432098765,0.9097651421508035,0.9108910891089109,0.9107806691449815,0.9106699751861043,0.9105590062111801,0.9104477611940298,0.9115815691158157,0.9114713216957606,0.9126092384519351,0.9125,0.9123904881101377,0.9122807017543859,0.9121706398996235,0.9120603015075377,0.9119496855345912,0.9130982367758187,0.9129886506935687,0.9128787878787878,0.9127686472819216,0.9126582278481012,0.9125475285171103,0.9124365482233503,0.9123252858958069,0.9122137404580153,0.9121019108280255,0.9119897959183674,0.9118773946360154,0.9117647058823529,0.911651728553137,0.9115384615384615,0.9114249037227214,0.9125964010282777,0.9124839124839125,0.9123711340206185,0.9135483870967742,0.91343669250646,0.9133247089262613,0.9132124352331606,0.914396887159533,0.9142857142857143,0.9141742522756827,0.9153645833333334,0.9152542372881356,0.9151436031331592,0.9150326797385621,0.9149214659685864,0.9161205766710354,0.9173228346456693,0.9172141918528253,0.9171052631578948,0.9169960474308301,0.91688654353562,0.916776750330251,0.9166666666666666,0.9165562913907285,0.9177718832891246,0.9176626826029216,0.9188829787234043,0.918774966711052,0.9186666666666666,0.9185580774365821,0.9184491978609626,0.9183400267737617,0.9182305630026809,0.9194630872483222,0.9193548387096774,0.9192462987886945,0.9204851752021563,0.9203778677462888,0.9202702702702703,0.9201623815967523,0.9200542005420054,0.921302578018996,0.9211956521739131,0.9224489795918367,0.9223433242506812,0.922237380627558,0.9221311475409836,0.9220246238030095,0.9219178082191781,0.9218106995884774,0.9217032967032966,0.922971114167813,0.9228650137741047,0.9227586206896552,0.9226519337016574,0.9225449515905948,0.9224376731301939,0.9237170596393898,0.9236111111111112,0.9235048678720446,0.9233983286908078,0.9232914923291492,0.9231843575418994,0.9230769230769231,0.9229691876750701,0.9228611500701263,0.922752808988764,0.9226441631504922,0.9225352112676056,0.922425952045134,0.922316384180791,0.9236209335219236,0.9235127478753541,0.9234042553191489,0.9232954545454546,0.9231863442389758,0.9230769230769231,0.9229671897289586,0.9228571428571428,0.9241773962804005,0.9240687679083095,0.9239598278335724,0.9252873563218391,0.9251798561151079,0.9265129682997119,0.9264069264069265,0.9263005780346821,0.9261939218523878,0.9260869565217391,0.9259796806966618,0.9258720930232558,0.925764192139738,0.9256559766763849,0.9255474452554745,0.9254385964912281,0.9253294289897511,0.9252199413489736,0.9251101321585903,0.925,0.9248895434462445,0.9247787610619469,0.9261447562776958,0.9275147928994083,0.9288888888888889,0.9287833827893175,0.9286775631500743,0.9285714285714286,0.9284649776453056,0.9298507462686567,0.929745889387145,0.9296407185628742,0.9295352323838081,0.9309309309309309,0.9308270676691729,0.9307228915662651,0.9306184012066365,0.93202416918429,0.9319213313161876,0.9333333333333333,0.9332321699544764,0.9346504559270516,0.9345509893455098,0.9344512195121951,0.934351145038168,0.9357798165137615,0.9356814701378254,0.9355828220858896,0.9370199692780338,0.936923076923077,0.9368258859784283,0.9367283950617284,0.9366306027820711,0.9365325077399381,0.9364341085271318,0.9363354037267081,0.937791601866252,0.9376947040498442,0.9375975039001561,0.9375,0.9374021909233177,0.9373040752351097,0.9387755102040817,0.9386792452830188,0.9385826771653544,0.9384858044164038,0.9383886255924171,0.939873417721519,0.9397781299524565,0.9396825396825397,0.9395866454689984,0.9394904458598726,0.9393939393939394,0.9408945686900958,0.9408,0.9407051282051282,0.9406099518459069,0.9405144694533762,0.9404186795491143,0.9419354838709677,0.9418416801292407,0.941747572815534,0.9416531604538088,0.9415584415584416,0.9414634146341463,0.9413680781758957,0.9412724306688418,0.9428104575163399,0.9427168576104746,0.9426229508196722,0.9425287356321839,0.9424342105263158,0.942339373970346,0.9422442244224423,0.943801652892562,0.9437086092715232,0.9436152570480929,0.9435215946843853,0.9434276206322796,0.9433333333333334,0.9432387312186978,0.9431438127090301,0.9430485762144054,0.9429530201342282,0.9428571428571428,0.9427609427609428,0.9426644182124789,0.9425675675675675,0.9441624365482234,0.9457627118644067,0.9456706281833617,0.9455782312925171,0.9454855195911414,0.9453924914675768,0.9452991452991453,0.9452054794520548,0.9451114922813036,0.9450171821305842,0.9466437177280551,0.946551724137931,0.9464594127806563,0.9463667820069204,0.9462738301559792,0.9461805555555556,0.9460869565217391,0.945993031358885,0.9458987783595113,0.9458041958041958,0.9457092819614711,0.9456140350877194,0.945518453427065,0.9454225352112676,0.9453262786596119,0.9452296819787986,0.9451327433628318,0.9450354609929078,0.9449378330373002,0.9466192170818505,0.946524064171123,0.9464285714285714,0.9463327370304114,0.946236559139785,0.9461400359066428,0.9460431654676259,0.9459459459459459,0.9458483754512635,0.9475587703435805,0.9492753623188406,0.9491833030852994,0.9490909090909091,0.9489981785063752,0.948905109489051,0.9488117001828154,0.9487179487179487,0.9486238532110092,0.9485294117647058,0.9484346224677717,0.948339483394834,0.9482439926062847,0.9481481481481482,0.948051948051948,0.9479553903345725,0.9478584729981379,0.9477611940298507,0.9476635514018692,0.947565543071161,0.9474671669793621,0.9473684210526315,0.9472693032015066,0.9471698113207547,0.947069943289225,0.946969696969697,0.9468690702087287,0.9467680608365019,0.9466666666666667,0.9465648854961832,0.9464627151051626,0.946360153256705,0.946257197696737,0.948076923076923,0.9479768786127167,0.9478764478764479,0.9477756286266924,0.9496124031007752,0.9495145631067962,0.9494163424124513,0.949317738791423,0.94921875,0.949119373776908,0.9490196078431372,0.9489194499017681,0.9488188976377953,0.9487179487179487,0.9486166007905138,0.9485148514851485,0.9484126984126984,0.9502982107355865,0.950199203187251,0.9500998003992016,0.95,0.9498997995991983,0.9497991967871486,0.9496981891348089,0.9495967741935484,0.9494949494949495,0.9493927125506073,0.949290060851927,0.9491869918699187,0.9490835030549898,0.9489795918367347,0.9488752556237219,0.9487704918032787,0.9486652977412731,0.948559670781893,0.9484536082474226,0.9483471074380165,0.94824016563147,0.9481327800829875,0.9480249480249481,0.9479166666666666,0.9478079331941545,0.9497907949790795,0.949685534591195,0.9495798319327731,0.9494736842105264,0.9493670886075949,0.9513742071881607,0.951271186440678,0.9511677282377919,0.951063829787234,0.9509594882729211,0.9508547008547008,0.9507494646680942,0.9506437768240343,0.9505376344086022,0.9504310344827587,0.9503239740820735,0.9523809523809523,0.9522776572668112,0.9521739130434783,0.9520697167755992,0.9519650655021834,0.9518599562363238,0.9517543859649122,0.9516483516483516,0.9515418502202643,0.9514348785871964,0.9513274336283186,0.9512195121951219,0.9511111111111111,0.9510022271714922,0.9508928571428571,0.9507829977628636,0.952914798206278,0.952808988764045,0.9527027027027027,0.9525959367945824,0.9524886877828054,0.9523809523809523,0.9522727272727273,0.9521640091116174,0.952054794520548,0.9519450800915332,0.9518348623853211,0.9517241379310345,0.9516129032258065,0.9515011547344111,0.9513888888888888,0.9535962877030162,0.9558139534883721,0.9557109557109557,0.955607476635514,0.955503512880562,0.9553990610328639,0.9552941176470588,0.9551886792452831,0.9550827423167849,0.9549763033175356,0.9548693586698337,0.9547619047619048,0.954653937947494,0.9545454545454546,0.9544364508393285,0.9543269230769231,0.9542168674698795,0.9565217391304348,0.9564164648910412,0.9563106796116505,0.9562043795620438,0.9560975609756097,0.9559902200488998,0.9558823529411765,0.9557739557739557,0.9556650246305419,0.9555555555555556,0.9554455445544554,0.9553349875930521,0.9552238805970149,0.9551122194513716,0.955,0.9548872180451128,0.9547738693467337,0.9546599496221663,0.9545454545454546,0.9544303797468354,0.9543147208121827,0.9541984732824428,0.9540816326530612,0.9539641943734015,0.9538461538461539,0.9537275064267352,0.9536082474226805,0.9560723514211886,0.9559585492227979,0.9558441558441558,0.9557291666666666,0.9556135770234987,0.9554973821989529,0.9553805774278216,0.9552631578947368,0.9551451187335093,0.955026455026455,0.9549071618037135,0.9547872340425532,0.9546666666666667,0.9545454545454546,0.9571045576407506,0.956989247311828,0.9568733153638814,0.9567567567567568,0.9566395663956639,0.9592391304347826,0.9591280653950953,0.9590163934426229,0.958904109589041,0.9587912087912088,0.9586776859504132,0.9585635359116023,0.9584487534626038,0.9583333333333334,0.958217270194986,0.9581005586592178,0.9607843137254902,0.9606741573033708,0.9605633802816902,0.96045197740113,0.9603399433427762,0.9630681818181818,0.9629629629629629,0.9628571428571429,0.9656160458452722,0.9655172413793104,0.9654178674351584,0.9653179190751445,0.9652173913043478,0.9680232558139535,0.967930029154519,0.9678362573099415,0.967741935483871,0.9676470588235294,0.967551622418879,0.9704142011834319,0.973293768545994,0.9732142857142857,0.9731343283582089,0.9730538922155688,0.972972972972973,0.9728915662650602,0.972809667673716,0.9727272727272728,0.9726443768996961,0.9725609756097561,0.9724770642201835,0.9723926380368099,0.9723076923076923,0.9722222222222222,0.9721362229102167,0.9720496894409938,0.9719626168224299,0.971875,0.9717868338557993,0.9716981132075472,1],"yaxis":"y"}],"layout":{"height":600,"legend":{"tracegroupgap":0},"shapes":[{"line":{"dash":"dash"},"type":"line","x0":0,"x1":1,"y0":1,"y1":0}],"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"title":{"text":"Precision-Recall Curve (AUC=0.8327)"},"width":800,"xaxis":{"anchor":"y","constrain":"domain","domain":[0,1],"title":{"text":"Recall"}},"yaxis":{"anchor":"x","domain":[0,1],"scaleanchor":"x","scaleratio":1,"title":{"text":"Precision"}}}},"text/html":["<div>                            <div id=\"2351bb4b-87c1-4ffd-b056-d37164fbaf06\" class=\"plotly-graph-div\" style=\"height:600px; width:800px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"2351bb4b-87c1-4ffd-b056-d37164fbaf06\")) {                    Plotly.newPlot(                        \"2351bb4b-87c1-4ffd-b056-d37164fbaf06\",                        [{\"fillpattern\":{\"shape\":\"\"},\"hovertemplate\":\"Recall=%{x}\\u003cbr\\u003ePrecision=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"stackgroup\":\"1\",\"x\":[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9980638915779284,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9961277831558567,0.9961277831558567,0.995159728944821,0.995159728944821,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9932236205227493,0.9932236205227493,0.9932236205227493,0.9932236205227493,0.9932236205227493,0.9922555663117134,0.9912875121006777,0.9912875121006777,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.989351403678606,0.989351403678606,0.989351403678606,0.989351403678606,0.989351403678606,0.9883833494675702,0.9883833494675702,0.9874152952565344,0.9874152952565344,0.9864472410454985,0.9864472410454985,0.9854791868344628,0.9854791868344628,0.9845111326234269,0.9845111326234269,0.9835430784123911,0.9835430784123911,0.9835430784123911,0.9825750242013552,0.9825750242013552,0.9816069699903195,0.9816069699903195,0.9806389157792836,0.9796708615682478,0.9796708615682478,0.978702807357212,0.978702807357212,0.978702807357212,0.978702807357212,0.978702807357212,0.978702807357212,0.978702807357212,0.978702807357212,0.978702807357212,0.978702807357212,0.978702807357212,0.9777347531461762,0.9777347531461762,0.9767666989351403,0.9767666989351403,0.9767666989351403,0.9767666989351403,0.9767666989351403,0.9757986447241046,0.9757986447241046,0.9757986447241046,0.9757986447241046,0.9757986447241046,0.9757986447241046,0.9757986447241046,0.9757986447241046,0.9757986447241046,0.9757986447241046,0.9748305905130688,0.9748305905130688,0.9748305905130688,0.9738625363020329,0.9738625363020329,0.9738625363020329,0.9738625363020329,0.9738625363020329,0.9738625363020329,0.972894482090997,0.9719264278799613,0.9719264278799613,0.9719264278799613,0.9719264278799613,0.9709583736689255,0.9699903194578896,0.9690222652468539,0.9690222652468539,0.9690222652468539,0.9690222652468539,0.968054211035818,0.968054211035818,0.9670861568247822,0.9670861568247822,0.9670861568247822,0.9670861568247822,0.9670861568247822,0.9670861568247822,0.9670861568247822,0.9670861568247822,0.9661181026137464,0.9651500484027106,0.9651500484027106,0.9651500484027106,0.9641819941916747,0.9641819941916747,0.9632139399806389,0.9632139399806389,0.9632139399806389,0.9622458857696031,0.9622458857696031,0.9622458857696031,0.9612778315585673,0.9603097773475314,0.9603097773475314,0.9593417231364957,0.9593417231364957,0.9593417231364957,0.9593417231364957,0.9593417231364957,0.9593417231364957,0.9593417231364957,0.9593417231364957,0.9593417231364957,0.9593417231364957,0.9593417231364957,0.9593417231364957,0.9583736689254598,0.9583736689254598,0.957405614714424,0.9564375605033882,0.9554695062923524,0.9554695062923524,0.9554695062923524,0.9545014520813165,0.9535333978702807,0.9535333978702807,0.9535333978702807,0.9535333978702807,0.9535333978702807,0.952565343659245,0.9515972894482091,0.9506292352371732,0.9506292352371732,0.9506292352371732,0.9506292352371732,0.9496611810261375,0.9496611810261375,0.9486931268151017,0.9477250726040658,0.9477250726040658,0.9467570183930301,0.9467570183930301,0.9457889641819942,0.9457889641819942,0.9457889641819942,0.9457889641819942,0.9457889641819942,0.9457889641819942,0.9448209099709584,0.9448209099709584,0.9448209099709584,0.9448209099709584,0.9448209099709584,0.9448209099709584,0.9448209099709584,0.9448209099709584,0.9448209099709584,0.9438528557599225,0.9428848015488868,0.9428848015488868,0.9428848015488868,0.9419167473378509,0.9409486931268151,0.9409486931268151,0.9409486931268151,0.9409486931268151,0.9399806389157793,0.9390125847047435,0.9390125847047435,0.9390125847047435,0.9390125847047435,0.9380445304937076,0.9380445304937076,0.9380445304937076,0.9380445304937076,0.9370764762826719,0.9370764762826719,0.936108422071636,0.936108422071636,0.9351403678606002,0.9341723136495643,0.9341723136495643,0.9341723136495643,0.9332042594385286,0.9332042594385286,0.9332042594385286,0.9332042594385286,0.9332042594385286,0.9322362052274927,0.9312681510164569,0.9303000968054211,0.9303000968054211,0.9303000968054211,0.9303000968054211,0.9293320425943853,0.9283639883833494,0.9283639883833494,0.9283639883833494,0.9283639883833494,0.9283639883833494,0.9283639883833494,0.9283639883833494,0.9283639883833494,0.9283639883833494,0.9273959341723137,0.9273959341723137,0.9273959341723137,0.9273959341723137,0.9264278799612778,0.925459825750242,0.9244917715392061,0.9244917715392061,0.9235237173281704,0.9235237173281704,0.9235237173281704,0.9225556631171346,0.9225556631171346,0.9225556631171346,0.9225556631171346,0.9225556631171346,0.9225556631171346,0.9225556631171346,0.9215876089060987,0.9215876089060987,0.920619554695063,0.920619554695063,0.9196515004840271,0.9186834462729913,0.9177153920619555,0.9177153920619555,0.9177153920619555,0.9167473378509197,0.9167473378509197,0.9167473378509197,0.9157792836398838,0.9157792836398838,0.914811229428848,0.9138431752178122,0.9128751210067764,0.9119070667957405,0.9119070667957405,0.9119070667957405,0.9119070667957405,0.9109390125847048,0.9099709583736689,0.9090029041626331,0.9080348499515973,0.9070667957405615,0.9060987415295256,0.9051306873184899,0.904162633107454,0.9031945788964182,0.9031945788964182,0.9031945788964182,0.9022265246853823,0.9022265246853823,0.9022265246853823,0.9012584704743466,0.9012584704743466,0.9002904162633107,0.9002904162633107,0.9002904162633107,0.9002904162633107,0.8993223620522749,0.8983543078412392,0.8973862536302033,0.8973862536302033,0.8973862536302033,0.8973862536302033,0.8964181994191674,0.8954501452081317,0.8954501452081317,0.8954501452081317,0.8944820909970959,0.89351403678606,0.8925459825750242,0.8915779283639884,0.8906098741529526,0.8896418199419167,0.888673765730881,0.888673765730881,0.8877057115198451,0.8867376573088093,0.8867376573088093,0.8867376573088093,0.8867376573088093,0.8857696030977735,0.8848015488867377,0.8838334946757018,0.882865440464666,0.8818973862536302,0.8818973862536302,0.8809293320425944,0.8809293320425944,0.8809293320425944,0.8799612778315585,0.8789932236205228,0.8789932236205228,0.8789932236205228,0.8780251694094869,0.8770571151984511,0.8770571151984511,0.8760890609874153,0.8751210067763795,0.8741529525653436,0.8731848983543078,0.872216844143272,0.8712487899322362,0.8712487899322362,0.8712487899322362,0.8702807357212003,0.8702807357212003,0.8702807357212003,0.8693126815101646,0.8683446272991288,0.8673765730880929,0.8664085188770572,0.8664085188770572,0.8654404646660213,0.8654404646660213,0.8644724104549855,0.8635043562439496,0.8635043562439496,0.8625363020329139,0.861568247821878,0.861568247821878,0.861568247821878,0.8606001936108422,0.8606001936108422,0.8596321393998064,0.8586640851887706,0.8576960309777347,0.856727976766699,0.8557599225556631,0.8547918683446273,0.8538238141335914,0.8528557599225557,0.8528557599225557,0.8528557599225557,0.8518877057115198,0.8518877057115198,0.8518877057115198,0.8518877057115198,0.8518877057115198,0.850919651500484,0.850919651500484,0.8499515972894482,0.8499515972894482,0.8489835430784124,0.8489835430784124,0.8480154888673765,0.8470474346563408,0.846079380445305,0.8451113262342691,0.8441432720232332,0.8441432720232332,0.8441432720232332,0.8441432720232332,0.8431752178121975,0.8431752178121975,0.8422071636011617,0.8412391093901258,0.8412391093901258,0.8412391093901258,0.8412391093901258,0.8412391093901258,0.8402710551790901,0.8402710551790901,0.8393030009680542,0.8383349467570184,0.8373668925459826,0.8363988383349468,0.8363988383349468,0.8354307841239109,0.8344627299128751,0.8334946757018393,0.8325266214908035,0.8315585672797676,0.8315585672797676,0.8305905130687319,0.829622458857696,0.829622458857696,0.8286544046466602,0.8286544046466602,0.8286544046466602,0.8276863504356244,0.8267182962245886,0.8257502420135527,0.8247821878025169,0.8247821878025169,0.8247821878025169,0.8247821878025169,0.8238141335914811,0.8238141335914811,0.8238141335914811,0.8238141335914811,0.8238141335914811,0.8228460793804453,0.8218780251694094,0.8209099709583737,0.8199419167473379,0.818973862536302,0.818973862536302,0.8180058083252663,0.8170377541142304,0.8160696999031946,0.8160696999031946,0.8160696999031946,0.8151016456921588,0.8151016456921588,0.8151016456921588,0.8151016456921588,0.8151016456921588,0.8151016456921588,0.814133591481123,0.8131655372700871,0.8121974830590513,0.8112294288480155,0.8102613746369797,0.8102613746369797,0.8092933204259438,0.8083252662149081,0.8073572120038722,0.8073572120038722,0.8063891577928364,0.8063891577928364,0.8054211035818006,0.8054211035818006,0.8044530493707648,0.8034849951597289,0.8025169409486931,0.8025169409486931,0.8015488867376573,0.8015488867376573,0.8005808325266215,0.7996127783155856,0.7996127783155856,0.7986447241045499,0.7986447241045499,0.797676669893514,0.7967086156824782,0.7957405614714425,0.7957405614714425,0.7957405614714425,0.7947725072604066,0.7938044530493708,0.7928363988383349,0.7918683446272992,0.7909002904162633,0.7899322362052275,0.7889641819941917,0.7889641819941917,0.7889641819941917,0.7879961277831559,0.78702807357212,0.78702807357212,0.7860600193610843,0.7850919651500484,0.7850919651500484,0.7841239109390126,0.7841239109390126,0.7841239109390126,0.7831558567279767,0.782187802516941,0.782187802516941,0.782187802516941,0.782187802516941,0.782187802516941,0.7812197483059051,0.7802516940948693,0.7792836398838335,0.7792836398838335,0.7783155856727977,0.7773475314617618,0.7763794772507261,0.7763794772507261,0.7763794772507261,0.7754114230396902,0.7744433688286544,0.7744433688286544,0.7734753146176185,0.7725072604065828,0.771539206195547,0.7705711519845111,0.7705711519845111,0.7705711519845111,0.7696030977734754,0.7696030977734754,0.7686350435624395,0.7676669893514037,0.7666989351403679,0.7666989351403679,0.7657308809293321,0.7647628267182962,0.7637947725072604,0.7637947725072604,0.7628267182962246,0.7618586640851888,0.7608906098741529,0.7599225556631172,0.7589545014520813,0.7579864472410455,0.7579864472410455,0.7570183930300097,0.7560503388189739,0.755082284607938,0.7541142303969022,0.7531461761858664,0.7521781219748306,0.7512100677637947,0.750242013552759,0.7492739593417231,0.7483059051306873,0.7473378509196515,0.7463697967086157,0.7454017424975798,0.744433688286544,0.7434656340755083,0.7424975798644724,0.7424975798644724,0.7415295256534365,0.7405614714424008,0.739593417231365,0.7386253630203291,0.7376573088092934,0.7366892545982575,0.7357212003872217,0.7357212003872217,0.7347531461761858,0.7337850919651501,0.7328170377541142,0.7318489835430784,0.7318489835430784,0.7308809293320426,0.7299128751210068,0.7289448209099709,0.7279767666989352,0.7270087124878993,0.7260406582768635,0.7250726040658277,0.7241045498547919,0.723136495643756,0.7221684414327202,0.7212003872216844,0.7202323330106486,0.7192642787996127,0.718296224588577,0.7173281703775412,0.7173281703775412,0.7173281703775412,0.7173281703775412,0.7163601161665053,0.7153920619554696,0.7153920619554696,0.7144240077444337,0.7144240077444337,0.7134559535333979,0.712487899322362,0.712487899322362,0.7115198451113263,0.7105517909002904,0.7095837366892546,0.7086156824782188,0.7086156824782188,0.707647628267183,0.707647628267183,0.7066795740561471,0.7057115198451114,0.7047434656340755,0.7037754114230397,0.7028073572120038,0.7018393030009681,0.7018393030009681,0.7008712487899322,0.6999031945788964,0.6989351403678606,0.6979670861568248,0.6969990319457889,0.6960309777347532,0.6950629235237173,0.6940948693126815,0.6931268151016456,0.6921587608906099,0.691190706679574,0.6902226524685382,0.6892545982575025,0.6882865440464666,0.6873184898354308,0.6873184898354308,0.686350435624395,0.6853823814133592,0.6853823814133592,0.6844143272023233,0.6834462729912875,0.6824782187802517,0.6824782187802517,0.6815101645692159,0.68054211035818,0.68054211035818,0.6795740561471443,0.6786060019361084,0.6776379477250726,0.6766698935140368,0.6766698935140368,0.6766698935140368,0.675701839303001,0.6747337850919651,0.6737657308809293,0.6727976766698935,0.6718296224588577,0.6708615682478218,0.6698935140367861,0.6698935140367861,0.6689254598257502,0.6689254598257502,0.6679574056147144,0.6669893514036787,0.6660212971926428,0.665053242981607,0.6640851887705711,0.6631171345595354,0.6631171345595354,0.6621490803484995,0.6611810261374637,0.6611810261374637,0.6602129719264279,0.6592449177153921,0.6582768635043562,0.6573088092933205,0.6573088092933205,0.6563407550822846,0.6563407550822846,0.6553727008712488,0.6544046466602129,0.6534365924491772,0.6524685382381413,0.6515004840271055,0.6505324298160697,0.6495643756050339,0.6495643756050339,0.648596321393998,0.6476282671829623,0.6466602129719264,0.6456921587608906,0.6447241045498547,0.6447241045498547,0.643756050338819,0.6427879961277831,0.6418199419167473,0.6408518877057116,0.6398838334946757,0.6389157792836399,0.6379477250726041,0.6369796708615683,0.6360116166505324,0.6350435624394967,0.6340755082284608,0.633107454017425,0.6321393998063891,0.6321393998063891,0.6311713455953534,0.6302032913843175,0.6292352371732817,0.6282671829622459,0.6272991287512101,0.6263310745401742,0.6253630203291385,0.6253630203291385,0.6243949661181026,0.6234269119070668,0.6234269119070668,0.6224588576960309,0.6224588576960309,0.6214908034849952,0.6205227492739593,0.6195546950629235,0.6185866408518877,0.6176185866408519,0.616650532429816,0.6156824782187803,0.6147144240077445,0.6137463697967086,0.6127783155856728,0.611810261374637,0.6108422071636012,0.6098741529525653,0.6089060987415296,0.6079380445304937,0.6069699903194579,0.6069699903194579,0.6069699903194579,0.6069699903194579,0.6060019361084221,0.6050338818973863,0.6040658276863504,0.6030977734753146,0.6030977734753146,0.6021297192642788,0.601161665053243,0.6001936108422071,0.6001936108422071,0.5992255566311714,0.5982575024201355,0.5972894482090997,0.5972894482090997,0.5963213939980639,0.5963213939980639,0.5953533397870281,0.5953533397870281,0.5943852855759922,0.5934172313649564,0.5924491771539206,0.5924491771539206,0.5914811229428848,0.590513068731849,0.590513068731849,0.5895450145208132,0.5885769603097774,0.5876089060987415,0.5866408518877058,0.5856727976766699,0.5847047434656341,0.5837366892545982,0.5837366892545982,0.5827686350435625,0.5818005808325266,0.5808325266214908,0.579864472410455,0.5788964181994192,0.5788964181994192,0.5779283639883833,0.5769603097773476,0.5759922555663117,0.5750242013552759,0.5750242013552759,0.57405614714424,0.5730880929332043,0.5721200387221684,0.5711519845111326,0.5701839303000968,0.5701839303000968,0.569215876089061,0.5682478218780251,0.5672797676669894,0.5663117134559535,0.5653436592449177,0.5653436592449177,0.5643756050338818,0.5634075508228461,0.5624394966118103,0.5614714424007744,0.5605033881897387,0.5595353339787028,0.558567279767667,0.558567279767667,0.5575992255566312,0.5566311713455954,0.5556631171345595,0.5546950629235237,0.5537270087124879,0.5527589545014521,0.5527589545014521,0.5517909002904162,0.5508228460793805,0.5498547918683446,0.5488867376573088,0.547918683446273,0.5469506292352372,0.5459825750242013,0.5450145208131656,0.5440464666021297,0.5430784123910939,0.542110358180058,0.5411423039690223,0.5401742497579864,0.5401742497579864,0.5401742497579864,0.5392061955469506,0.5382381413359149,0.537270087124879,0.5363020329138432,0.5353339787028074,0.5343659244917716,0.5333978702807357,0.5324298160696999,0.5324298160696999,0.5314617618586641,0.5304937076476283,0.5295256534365924,0.5285575992255567,0.5275895450145208,0.526621490803485,0.5256534365924492,0.5246853823814134,0.5237173281703775,0.5227492739593417,0.5217812197483059,0.5208131655372701,0.5198451113262342,0.5188770571151985,0.5179090029041626,0.5169409486931268,0.515972894482091,0.5150048402710552,0.5150048402710552,0.5140367860600193,0.5130687318489835,0.5121006776379478,0.5111326234269119,0.510164569215876,0.5091965150048403,0.5082284607938045,0.5072604065827686,0.5072604065827686,0.5072604065827686,0.5062923523717329,0.505324298160697,0.5043562439496612,0.5033881897386253,0.5024201355275896,0.5014520813165537,0.5004840271055179,0.4995159728944821,0.4985479186834463,0.4975798644724105,0.49661181026137463,0.49564375605033884,0.494675701839303,0.4937076476282672,0.4927395934172314,0.49177153920619554,0.49080348499515974,0.4898354307841239,0.4888673765730881,0.4878993223620523,0.48693126815101645,0.48596321393998065,0.4849951597289448,0.484027105517909,0.4830590513068732,0.48209099709583736,0.48112294288480156,0.4801548886737657,0.4791868344627299,0.4782187802516941,0.47725072604065827,0.47725072604065827,0.4762826718296225,0.4753146176185866,0.4743465634075508,0.4743465634075508,0.47337850919651503,0.4724104549854792,0.4714424007744434,0.47047434656340753,0.46950629235237173,0.46853823814133594,0.4675701839303001,0.4666021297192643,0.46563407550822844,0.46466602129719264,0.46369796708615685,0.462729912875121,0.462729912875121,0.4617618586640852,0.46079380445304935,0.45982575024201355,0.45885769603097776,0.4578896418199419,0.4569215876089061,0.45595353339787026,0.45498547918683446,0.45401742497579867,0.4530493707647628,0.452081316553727,0.45111326234269117,0.45014520813165537,0.4491771539206196,0.4482090997095837,0.44724104549854793,0.4462729912875121,0.4453049370764763,0.4443368828654405,0.44336882865440463,0.44240077444336884,0.441432720232333,0.4404646660212972,0.4394966118102614,0.4394966118102614,0.43852855759922554,0.43756050338818975,0.4365924491771539,0.4356243949661181,0.4356243949661181,0.4346563407550823,0.43368828654404645,0.43272023233301066,0.4317521781219748,0.430784123910939,0.4298160696999032,0.42884801548886736,0.42787996127783157,0.4269119070667957,0.4259438528557599,0.4259438528557599,0.4249757986447241,0.42400774443368827,0.4230396902226525,0.4220716360116166,0.42110358180058083,0.42013552758954503,0.4191674733785092,0.4181994191674734,0.41723136495643753,0.41626331074540174,0.41529525653436594,0.4143272023233301,0.4133591481122943,0.41239109390125844,0.41142303969022265,0.41142303969022265,0.41045498547918685,0.409486931268151,0.4085188770571152,0.4075508228460794,0.40658276863504356,0.40561471442400776,0.4046466602129719,0.4036786060019361,0.4027105517909003,0.40174249757986447,0.40077444336882867,0.3998063891577928,0.398838334946757,0.3978702807357212,0.3978702807357212,0.3978702807357212,0.3969022265246854,0.3959341723136496,0.39496611810261373,0.39399806389157793,0.39303000968054214,0.3920619554695063,0.3910939012584705,0.39012584704743464,0.38915779283639884,0.38818973862536305,0.3872216844143272,0.3862536302032914,0.38528557599225555,0.38431752178121975,0.38334946757018395,0.38334946757018395,0.3823814133591481,0.3814133591481123,0.38044530493707646,0.37947725072604066,0.37850919651500486,0.377541142303969,0.3765730880929332,0.37560503388189737,0.37463697967086157,0.3736689254598258,0.3727008712487899,0.3717328170377541,0.3707647628267183,0.3697967086156825,0.3688286544046467,0.36786060019361083,0.36689254598257504,0.3659244917715392,0.3649564375605034,0.3639883833494676,0.36302032913843174,0.36205227492739595,0.3610842207163601,0.3601161665053243,0.3591481122942885,0.35818005808325265,0.35818005808325265,0.35721200387221685,0.356243949661181,0.3552758954501452,0.3543078412391094,0.35333978702807356,0.35237173281703776,0.3514036786060019,0.3504356243949661,0.3494675701839303,0.34849951597289447,0.3475314617618587,0.3465634075508228,0.345595353339787,0.345595353339787,0.34462729912875123,0.3436592449177154,0.3426911907066796,0.34172313649564373,0.34172313649564373,0.34075508228460794,0.33978702807357214,0.3388189738625363,0.3378509196515005,0.33688286544046464,0.33591481122942884,0.33494675701839305,0.3339787028073572,0.3330106485963214,0.33204259438528555,0.33204259438528555,0.33107454017424975,0.33010648596321396,0.3291384317521781,0.3281703775411423,0.3281703775411423,0.32720232333010646,0.32623426911907066,0.32623426911907066,0.32526621490803487,0.324298160696999,0.3233301064859632,0.32236205227492737,0.32236205227492737,0.3213939980638916,0.3204259438528558,0.3194578896418199,0.31848983543078413,0.31752178121974833,0.31752178121974833,0.31752178121974833,0.3165537270087125,0.3155856727976767,0.31461761858664083,0.31364956437560504,0.31268151016456924,0.3117134559535334,0.3107454017424976,0.30977734753146174,0.30880929332042595,0.30784123910939015,0.3068731848983543,0.3059051306873185,0.30493707647628265,0.30396902226524686,0.30300096805421106,0.3020329138431752,0.3010648596321394,0.30009680542110356,0.29912875121006777,0.0],\"xaxis\":\"x\",\"y\":[0.7341862117981521,0.7352313167259786,0.7357549857549858,0.7362794012829651,0.7368045649072753,0.7373304782298359,0.7378571428571429,0.7383845604002859,0.7389127324749643,0.7394416607015032,0.7392550143266475,0.7397849462365591,0.7403156384505022,0.7408470926058865,0.7413793103448276,0.7419122933141624,0.7424460431654676,0.7429805615550756,0.7435158501440923,0.7433309300648883,0.7431457431457431,0.7436823104693141,0.7442196531791907,0.7440347071583514,0.7445730824891461,0.7443881245474294,0.744927536231884,0.7447425670775925,0.7452830188679245,0.7458242556281772,0.7456395348837209,0.7461818181818182,0.7467248908296943,0.7472687545520758,0.7478134110787172,0.7476294675419402,0.7474452554744525,0.747991234477721,0.7478070175438597,0.7483540599853694,0.7489019033674963,0.7494505494505495,0.75,0.7505502567865003,0.751101321585903,0.75165319617928,0.7514705882352941,0.7520235467255335,0.7525773195876289,0.7531319086219602,0.7536873156342183,0.7535055350553506,0.7540620384047267,0.753880266075388,0.7544378698224852,0.7542561065877128,0.7548148148148148,0.7546330615270571,0.755192878338279,0.755011135857461,0.7555720653789004,0.7553903345724907,0.7559523809523809,0.7565152643335815,0.7563338301043219,0.7568978374347501,0.7567164179104477,0.7572815533980582,0.7571001494768311,0.7569184741959611,0.7574850299401198,0.7573033707865169,0.7578710644677661,0.7584396099024756,0.759009009009009,0.7595792637114951,0.7601503759398496,0.7607223476297968,0.7612951807228916,0.7618688771665411,0.7624434389140271,0.7630188679245283,0.7628398791540786,0.763416477702192,0.7632375189107413,0.7638152914458743,0.7643939393939394,0.7649734647460197,0.7655538694992413,0.765375854214123,0.7659574468085106,0.7665399239543726,0.7671232876712328,0.7677075399847677,0.7682926829268293,0.7688787185354691,0.7694656488549618,0.7700534759358288,0.7706422018348624,0.7704667176740627,0.7710566615620215,0.7716475095785441,0.7714723926380368,0.7720644666155027,0.7726574500768049,0.7732513451191392,0.7738461538461539,0.7744418783679754,0.7742681047765794,0.7740940632228219,0.7746913580246914,0.7752895752895753,0.7758887171561051,0.7757153905645785,0.7755417956656346,0.7753679318357862,0.775968992248062,0.7765709852598914,0.7771739130434783,0.777000777000777,0.7776049766718507,0.777431906614786,0.7780373831775701,0.7786438035853468,0.7792511700468019,0.7798594847775175,0.78046875,0.781078967943706,0.7816901408450704,0.7815191855912295,0.7813479623824452,0.7819607843137255,0.782574568288854,0.7824037706205813,0.7830188679245284,0.7828481510621558,0.7834645669291339,0.7840819542947203,0.7839116719242902,0.7845303867403315,0.7851500789889415,0.7849802371541502,0.7848101265822784,0.7854315122723674,0.7852614896988906,0.7858842188739096,0.7865079365079365,0.7871326449563145,0.787758346581876,0.7883850437549722,0.7890127388535032,0.7896414342629482,0.7902711323763956,0.790901835594573,0.7915335463258786,0.7921662669864109,0.792,0.7926341072858286,0.7924679487179487,0.7923015236567763,0.7921348314606742,0.7927710843373494,0.7934083601286174,0.7932421560740145,0.7930756843800322,0.7937147461724415,0.7943548387096774,0.7949959644874899,0.7956381260096931,0.7954729183508489,0.7953074433656958,0.7951417004048583,0.7957860615883307,0.7964314679643146,0.797077922077922,0.7969130787977254,0.7975609756097561,0.7973962571196095,0.7972312703583062,0.797881010594947,0.797716150081566,0.7983673469387755,0.798202614379085,0.7988552739165985,0.7995090016366612,0.8001638001638002,0.8008196721311476,0.8014766201804758,0.8013136288998358,0.8019720624486442,0.8026315789473685,0.8032921810699588,0.8039538714991763,0.8046166529266282,0.8052805280528053,0.805945499587118,0.8066115702479338,0.8064516129032258,0.8062913907284768,0.8069594034797017,0.8076285240464345,0.8074688796680498,0.8073089700996677,0.8079800498753117,0.8086522462562395,0.8093255620316403,0.8091666666666667,0.8090075062552127,0.8096828046744574,0.810359231411863,0.8110367892976589,0.8108786610878661,0.8115577889447236,0.8122380553227159,0.8129194630872483,0.8127623845507976,0.8134453781512605,0.8132884777123633,0.813973063973064,0.8138163437236732,0.8136593591905565,0.8143459915611815,0.8150337837837838,0.8148774302620456,0.8155668358714044,0.8162574089754445,0.8169491525423729,0.8176420695504665,0.8174872665534805,0.8173322005097706,0.8171768707482994,0.8178723404255319,0.8185689948892675,0.8192668371696504,0.8191126279863481,0.8189581554227157,0.8196581196581196,0.8203592814371258,0.8210616438356164,0.8217652099400171,0.8224699828473413,0.8231759656652361,0.8238831615120275,0.8245915735167669,0.8244406196213425,0.8251507321274764,0.8258620689655173,0.8265746333045729,0.8264248704663213,0.8262748487467588,0.8261245674740484,0.8268398268398268,0.8266897746967071,0.8274067649609714,0.828125,0.8279756733275413,0.828695652173913,0.8294168842471714,0.8301393728222997,0.8308631211857018,0.8315881326352531,0.8323144104803494,0.8321678321678322,0.8328958880139983,0.8327495621716288,0.8334794040315513,0.8333333333333334,0.8331870061457419,0.8330404217926186,0.8337730870712401,0.8345070422535211,0.8343612334801762,0.8350970017636684,0.8358340688437775,0.8356890459363958,0.8364279398762158,0.8362831858407079,0.8361381753764393,0.8359929078014184,0.8358473824312334,0.8365896980461812,0.8373333333333334,0.8380782918149466,0.8379341050756901,0.8377896613190731,0.8376449598572703,0.8375,0.837354781054513,0.8372093023255814,0.8370635631154879,0.8369175627240143,0.8367713004484305,0.8375224416517055,0.8382749326145552,0.8381294964028777,0.8388838883888389,0.8396396396396396,0.8394950405770965,0.8402527075812274,0.8401084010840109,0.840867992766727,0.8416289592760181,0.842391304347826,0.8422484134179511,0.8421052631578947,0.8419618528610354,0.8427272727272728,0.8434940855323021,0.8442622950819673,0.8441203281677302,0.843978102189781,0.8447488584474886,0.8455210237659964,0.8453796889295517,0.8452380952380952,0.845096241979835,0.844954128440367,0.8448117539026629,0.8446691176470589,0.8445262189512419,0.8453038674033149,0.8451612903225807,0.8450184501845018,0.8457987072945522,0.8465804066543438,0.84736355226642,0.8472222222222222,0.8470806302131604,0.8469387755102041,0.8467966573816156,0.8466542750929368,0.8474418604651163,0.8472998137802608,0.848089468779124,0.8488805970149254,0.8487394957983193,0.8485981308411215,0.8493919550982226,0.850187265917603,0.8500468603561387,0.849906191369606,0.8507042253521127,0.8505639097744361,0.8504233301975541,0.8502824858757062,0.8501413760603205,0.85,0.8498583569405099,0.8506616257088847,0.8514664143803217,0.8513257575757576,0.852132701421801,0.8529411764705882,0.8528015194681862,0.8526615969581749,0.8525214081826832,0.8523809523809524,0.8531935176358436,0.8530534351145038,0.8538681948424068,0.8537284894837476,0.8535885167464115,0.8544061302681992,0.8542665388302972,0.8541266794625719,0.8549471661863592,0.8557692307692307,0.8556304138594802,0.8564547206165704,0.8563162970106075,0.8561776061776062,0.8560386473429952,0.8558994197292069,0.8557599225556631,0.8556201550387597,0.8554801163918526,0.8553398058252427,0.8561710398445093,0.8570038910505836,0.8568646543330087,0.8576998050682261,0.8585365853658536,0.859375,0.8602150537634409,0.860078277886497,0.8609206660137121,0.8607843137254902,0.8616290480863592,0.8614931237721022,0.8623402163225172,0.8622047244094488,0.8620689655172413,0.8619329388560157,0.861796643632774,0.8616600790513834,0.8625123639960435,0.8633663366336634,0.8642220019821606,0.8640873015873016,0.8649453823237339,0.8648111332007953,0.8646766169154229,0.8655378486055777,0.8664007976071785,0.8672654690618763,0.8681318681318682,0.868,0.8688688688688688,0.8687374749498998,0.8686058174523571,0.8684738955823293,0.8683417085427135,0.869215291750503,0.8690835850956697,0.8689516129032258,0.8688193743693239,0.8686868686868687,0.8685540950455005,0.8694331983805668,0.8693009118541033,0.8691683569979716,0.8700507614213198,0.8699186991869918,0.8708036622583927,0.8716904276985743,0.8715596330275229,0.8714285714285714,0.8712972420837589,0.8711656441717791,0.872057318321392,0.8729508196721312,0.8738461538461538,0.8737166324435318,0.8746145940390545,0.8755144032921811,0.8764160659114315,0.877319587628866,0.8771929824561403,0.8770661157024794,0.8769389865563598,0.8768115942028986,0.8766839378238342,0.8775933609958506,0.877466251298027,0.8773388773388774,0.8772112382934444,0.878125,0.8790406673618353,0.8789144050104384,0.8798328108672936,0.8807531380753139,0.881675392670157,0.8825995807127882,0.8835257082896117,0.8834033613445378,0.8832807570977917,0.8831578947368421,0.8830347734457323,0.8829113924050633,0.883843717001056,0.8837209302325582,0.8835978835978836,0.8834745762711864,0.8844114528101803,0.8842887473460722,0.8852284803400637,0.8851063829787233,0.88604898828541,0.8859275053304904,0.8858057630736392,0.8856837606837606,0.8866310160427807,0.8865096359743041,0.887459807073955,0.8873390557939914,0.8872180451127819,0.8881720430107527,0.8880516684607105,0.8890086206896551,0.8888888888888888,0.8887688984881209,0.8886486486486487,0.8896103896103896,0.8905742145178764,0.8904555314533622,0.8903365906623235,0.8902173913043478,0.8900979325353645,0.8899782135076253,0.8898582333696837,0.8897379912663755,0.8907103825136612,0.8916849015317286,0.891566265060241,0.8914473684210527,0.8924259055982436,0.8923076923076924,0.8921892189218922,0.8931718061674009,0.8930540242557883,0.8940397350993378,0.8950276243093923,0.8949115044247787,0.8947951273532669,0.8957871396895787,0.8967813540510544,0.8977777777777778,0.8987764182424917,0.8986636971046771,0.8985507246376812,0.8984375,0.8994413407821229,0.8993288590604027,0.8992161254199328,0.899103139013453,0.9001122334455668,0.9011235955056179,0.9010123734533183,0.9009009009009009,0.9019165727170236,0.9018058690744921,0.9016949152542373,0.9015837104072398,0.9014722536806342,0.9024943310657596,0.9035187287173666,0.9034090909090909,0.9044368600682594,0.9043280182232346,0.9042189281641961,0.9041095890410958,0.9051428571428571,0.9050343249427918,0.9049255441008018,0.9048165137614679,0.9058553386911596,0.9057471264367816,0.905638665132336,0.9055299539170507,0.9054209919261822,0.9053117782909931,0.9052023121387284,0.90625,0.9061413673232909,0.9060324825986079,0.9059233449477352,0.9058139534883721,0.9057043073341094,0.9055944055944056,0.9054842473745625,0.905373831775701,0.9052631578947369,0.905152224824356,0.9050410316529894,0.9049295774647887,0.9048178613396005,0.9047058823529411,0.9045936395759717,0.9044811320754716,0.9055489964580874,0.9054373522458629,0.9053254437869822,0.9052132701421801,0.9051008303677343,0.9049881235154394,0.9048751486325802,0.9047619047619048,0.9058402860548271,0.905727923627685,0.9056152927120669,0.9055023923444976,0.9053892215568863,0.9064748201438849,0.9063625450180072,0.90625,0.9061371841155235,0.9060240963855422,0.9059107358262968,0.9057971014492754,0.905683192261185,0.9055690072639225,0.9054545454545454,0.9053398058252428,0.905224787363305,0.9051094890510949,0.904993909866017,0.9048780487804878,0.9047619047619048,0.9058679706601467,0.9069767441860465,0.9080882352941176,0.9079754601226994,0.9078624078624079,0.9089790897908979,0.9088669950738916,0.9099876695437731,0.9098765432098765,0.9097651421508035,0.9108910891089109,0.9107806691449815,0.9106699751861043,0.9105590062111801,0.9104477611940298,0.9115815691158157,0.9114713216957606,0.9126092384519351,0.9125,0.9123904881101377,0.9122807017543859,0.9121706398996235,0.9120603015075377,0.9119496855345912,0.9130982367758187,0.9129886506935687,0.9128787878787878,0.9127686472819216,0.9126582278481012,0.9125475285171103,0.9124365482233503,0.9123252858958069,0.9122137404580153,0.9121019108280255,0.9119897959183674,0.9118773946360154,0.9117647058823529,0.911651728553137,0.9115384615384615,0.9114249037227214,0.9125964010282777,0.9124839124839125,0.9123711340206185,0.9135483870967742,0.91343669250646,0.9133247089262613,0.9132124352331606,0.914396887159533,0.9142857142857143,0.9141742522756827,0.9153645833333334,0.9152542372881356,0.9151436031331592,0.9150326797385621,0.9149214659685864,0.9161205766710354,0.9173228346456693,0.9172141918528253,0.9171052631578948,0.9169960474308301,0.91688654353562,0.916776750330251,0.9166666666666666,0.9165562913907285,0.9177718832891246,0.9176626826029216,0.9188829787234043,0.918774966711052,0.9186666666666666,0.9185580774365821,0.9184491978609626,0.9183400267737617,0.9182305630026809,0.9194630872483222,0.9193548387096774,0.9192462987886945,0.9204851752021563,0.9203778677462888,0.9202702702702703,0.9201623815967523,0.9200542005420054,0.921302578018996,0.9211956521739131,0.9224489795918367,0.9223433242506812,0.922237380627558,0.9221311475409836,0.9220246238030095,0.9219178082191781,0.9218106995884774,0.9217032967032966,0.922971114167813,0.9228650137741047,0.9227586206896552,0.9226519337016574,0.9225449515905948,0.9224376731301939,0.9237170596393898,0.9236111111111112,0.9235048678720446,0.9233983286908078,0.9232914923291492,0.9231843575418994,0.9230769230769231,0.9229691876750701,0.9228611500701263,0.922752808988764,0.9226441631504922,0.9225352112676056,0.922425952045134,0.922316384180791,0.9236209335219236,0.9235127478753541,0.9234042553191489,0.9232954545454546,0.9231863442389758,0.9230769230769231,0.9229671897289586,0.9228571428571428,0.9241773962804005,0.9240687679083095,0.9239598278335724,0.9252873563218391,0.9251798561151079,0.9265129682997119,0.9264069264069265,0.9263005780346821,0.9261939218523878,0.9260869565217391,0.9259796806966618,0.9258720930232558,0.925764192139738,0.9256559766763849,0.9255474452554745,0.9254385964912281,0.9253294289897511,0.9252199413489736,0.9251101321585903,0.925,0.9248895434462445,0.9247787610619469,0.9261447562776958,0.9275147928994083,0.9288888888888889,0.9287833827893175,0.9286775631500743,0.9285714285714286,0.9284649776453056,0.9298507462686567,0.929745889387145,0.9296407185628742,0.9295352323838081,0.9309309309309309,0.9308270676691729,0.9307228915662651,0.9306184012066365,0.93202416918429,0.9319213313161876,0.9333333333333333,0.9332321699544764,0.9346504559270516,0.9345509893455098,0.9344512195121951,0.934351145038168,0.9357798165137615,0.9356814701378254,0.9355828220858896,0.9370199692780338,0.936923076923077,0.9368258859784283,0.9367283950617284,0.9366306027820711,0.9365325077399381,0.9364341085271318,0.9363354037267081,0.937791601866252,0.9376947040498442,0.9375975039001561,0.9375,0.9374021909233177,0.9373040752351097,0.9387755102040817,0.9386792452830188,0.9385826771653544,0.9384858044164038,0.9383886255924171,0.939873417721519,0.9397781299524565,0.9396825396825397,0.9395866454689984,0.9394904458598726,0.9393939393939394,0.9408945686900958,0.9408,0.9407051282051282,0.9406099518459069,0.9405144694533762,0.9404186795491143,0.9419354838709677,0.9418416801292407,0.941747572815534,0.9416531604538088,0.9415584415584416,0.9414634146341463,0.9413680781758957,0.9412724306688418,0.9428104575163399,0.9427168576104746,0.9426229508196722,0.9425287356321839,0.9424342105263158,0.942339373970346,0.9422442244224423,0.943801652892562,0.9437086092715232,0.9436152570480929,0.9435215946843853,0.9434276206322796,0.9433333333333334,0.9432387312186978,0.9431438127090301,0.9430485762144054,0.9429530201342282,0.9428571428571428,0.9427609427609428,0.9426644182124789,0.9425675675675675,0.9441624365482234,0.9457627118644067,0.9456706281833617,0.9455782312925171,0.9454855195911414,0.9453924914675768,0.9452991452991453,0.9452054794520548,0.9451114922813036,0.9450171821305842,0.9466437177280551,0.946551724137931,0.9464594127806563,0.9463667820069204,0.9462738301559792,0.9461805555555556,0.9460869565217391,0.945993031358885,0.9458987783595113,0.9458041958041958,0.9457092819614711,0.9456140350877194,0.945518453427065,0.9454225352112676,0.9453262786596119,0.9452296819787986,0.9451327433628318,0.9450354609929078,0.9449378330373002,0.9466192170818505,0.946524064171123,0.9464285714285714,0.9463327370304114,0.946236559139785,0.9461400359066428,0.9460431654676259,0.9459459459459459,0.9458483754512635,0.9475587703435805,0.9492753623188406,0.9491833030852994,0.9490909090909091,0.9489981785063752,0.948905109489051,0.9488117001828154,0.9487179487179487,0.9486238532110092,0.9485294117647058,0.9484346224677717,0.948339483394834,0.9482439926062847,0.9481481481481482,0.948051948051948,0.9479553903345725,0.9478584729981379,0.9477611940298507,0.9476635514018692,0.947565543071161,0.9474671669793621,0.9473684210526315,0.9472693032015066,0.9471698113207547,0.947069943289225,0.946969696969697,0.9468690702087287,0.9467680608365019,0.9466666666666667,0.9465648854961832,0.9464627151051626,0.946360153256705,0.946257197696737,0.948076923076923,0.9479768786127167,0.9478764478764479,0.9477756286266924,0.9496124031007752,0.9495145631067962,0.9494163424124513,0.949317738791423,0.94921875,0.949119373776908,0.9490196078431372,0.9489194499017681,0.9488188976377953,0.9487179487179487,0.9486166007905138,0.9485148514851485,0.9484126984126984,0.9502982107355865,0.950199203187251,0.9500998003992016,0.95,0.9498997995991983,0.9497991967871486,0.9496981891348089,0.9495967741935484,0.9494949494949495,0.9493927125506073,0.949290060851927,0.9491869918699187,0.9490835030549898,0.9489795918367347,0.9488752556237219,0.9487704918032787,0.9486652977412731,0.948559670781893,0.9484536082474226,0.9483471074380165,0.94824016563147,0.9481327800829875,0.9480249480249481,0.9479166666666666,0.9478079331941545,0.9497907949790795,0.949685534591195,0.9495798319327731,0.9494736842105264,0.9493670886075949,0.9513742071881607,0.951271186440678,0.9511677282377919,0.951063829787234,0.9509594882729211,0.9508547008547008,0.9507494646680942,0.9506437768240343,0.9505376344086022,0.9504310344827587,0.9503239740820735,0.9523809523809523,0.9522776572668112,0.9521739130434783,0.9520697167755992,0.9519650655021834,0.9518599562363238,0.9517543859649122,0.9516483516483516,0.9515418502202643,0.9514348785871964,0.9513274336283186,0.9512195121951219,0.9511111111111111,0.9510022271714922,0.9508928571428571,0.9507829977628636,0.952914798206278,0.952808988764045,0.9527027027027027,0.9525959367945824,0.9524886877828054,0.9523809523809523,0.9522727272727273,0.9521640091116174,0.952054794520548,0.9519450800915332,0.9518348623853211,0.9517241379310345,0.9516129032258065,0.9515011547344111,0.9513888888888888,0.9535962877030162,0.9558139534883721,0.9557109557109557,0.955607476635514,0.955503512880562,0.9553990610328639,0.9552941176470588,0.9551886792452831,0.9550827423167849,0.9549763033175356,0.9548693586698337,0.9547619047619048,0.954653937947494,0.9545454545454546,0.9544364508393285,0.9543269230769231,0.9542168674698795,0.9565217391304348,0.9564164648910412,0.9563106796116505,0.9562043795620438,0.9560975609756097,0.9559902200488998,0.9558823529411765,0.9557739557739557,0.9556650246305419,0.9555555555555556,0.9554455445544554,0.9553349875930521,0.9552238805970149,0.9551122194513716,0.955,0.9548872180451128,0.9547738693467337,0.9546599496221663,0.9545454545454546,0.9544303797468354,0.9543147208121827,0.9541984732824428,0.9540816326530612,0.9539641943734015,0.9538461538461539,0.9537275064267352,0.9536082474226805,0.9560723514211886,0.9559585492227979,0.9558441558441558,0.9557291666666666,0.9556135770234987,0.9554973821989529,0.9553805774278216,0.9552631578947368,0.9551451187335093,0.955026455026455,0.9549071618037135,0.9547872340425532,0.9546666666666667,0.9545454545454546,0.9571045576407506,0.956989247311828,0.9568733153638814,0.9567567567567568,0.9566395663956639,0.9592391304347826,0.9591280653950953,0.9590163934426229,0.958904109589041,0.9587912087912088,0.9586776859504132,0.9585635359116023,0.9584487534626038,0.9583333333333334,0.958217270194986,0.9581005586592178,0.9607843137254902,0.9606741573033708,0.9605633802816902,0.96045197740113,0.9603399433427762,0.9630681818181818,0.9629629629629629,0.9628571428571429,0.9656160458452722,0.9655172413793104,0.9654178674351584,0.9653179190751445,0.9652173913043478,0.9680232558139535,0.967930029154519,0.9678362573099415,0.967741935483871,0.9676470588235294,0.967551622418879,0.9704142011834319,0.973293768545994,0.9732142857142857,0.9731343283582089,0.9730538922155688,0.972972972972973,0.9728915662650602,0.972809667673716,0.9727272727272728,0.9726443768996961,0.9725609756097561,0.9724770642201835,0.9723926380368099,0.9723076923076923,0.9722222222222222,0.9721362229102167,0.9720496894409938,0.9719626168224299,0.971875,0.9717868338557993,0.9716981132075472,1.0],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Recall\"},\"constrain\":\"domain\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Precision\"},\"scaleanchor\":\"x\",\"scaleratio\":1},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Precision-Recall Curve (AUC=0.8327)\"},\"height\":600,\"width\":800,\"shapes\":[{\"line\":{\"dash\":\"dash\"},\"type\":\"line\",\"x0\":0,\"x1\":1,\"y0\":1,\"y1\":0}],\"showlegend\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('2351bb4b-87c1-4ffd-b056-d37164fbaf06');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"}],"source":["target_score = knn_clf.predict_proba(features_valid)[:, 1]\n","\n","fpr, tpr, thresholds = roc_curve(target_valid, target_score)\n","\n","fig = px.area(\n","    x=fpr, y=tpr,\n","    title=f'ROC Curve (AUC={auc(fpr, tpr):.4f})',\n","    labels=dict(x='False Positive Rate', y='True Positive Rate'),\n","    width=800, height=600\n",")\n","fig.add_shape(\n","    type='line', line=dict(dash='dash'),\n","    x0=0, x1=1, y0=0, y1=1\n",")\n","\n","fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n","fig.update_xaxes(constrain='domain')\n","fig.update_layout(showlegend=False)\n","fig.show()\n","\n","precision, recall, thresholds = precision_recall_curve(target_valid, target_score)\n","\n","fig = px.area(\n","    x=recall, y=precision,\n","    title=f'Precision-Recall Curve (AUC={auc(fpr, tpr):.4f})',\n","    labels=dict(x='Recall', y='Precision'),\n","    width=800, height=600\n",")\n","fig.add_shape(\n","    type='line', line=dict(dash='dash'),\n","    x0=0, x1=1, y0=1, y1=0\n",")\n","fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n","fig.update_xaxes(constrain='domain')\n","fig.update_layout(showlegend=False)\n","fig.show()"]},{"cell_type":"code","execution_count":63,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Best hyperparameters: {'weights': 'distance', 'n_neighbors': 14, 'metric': 'manhattan', 'algorithm': 'kd_tree'}\n","\n","Best score: 0.8113113317506466\n","\n","Average Cross Validation Score: 0.8060876658838358\n","\n","ROC AUC Score - Validation Dataset: 0.8326547463128524\n"]}],"source":["# summary\n","print('Best hyperparameters:',  knn_clf.best_params_)\n","print()\n","print('Best score:', knn_clf.best_score_)\n","print()\n","print('Average Cross Validation Score: {}'.format(knn_scores.mean()))\n","print()\n","print('ROC AUC Score - Validation Dataset:',  roc_auc_score(target_valid, knn_clf.predict_proba(features_valid)[:, 1]))"]},{"cell_type":"markdown","metadata":{},"source":["--------"]},{"cell_type":"markdown","metadata":{},"source":["# Random Forest"]},{"cell_type":"code","execution_count":64,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T17:47:07.682082Z","iopub.status.busy":"2023-11-30T17:47:07.681288Z","iopub.status.idle":"2023-11-30T17:47:21.988070Z","shell.execute_reply":"2023-11-30T17:47:21.987028Z","shell.execute_reply.started":"2023-11-30T17:47:07.682047Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Runtime:\n","CPU times: user 1.04 s, sys: 257 ms, total: 1.3 s\n","Wall time: 16.5 s\n"]}],"source":["%%time\n","forest_model = RandomForestClassifier(random_state=random_state)\n","forest_parameters = [{'max_depth': [2,6,12,18,30],\n","                     'min_samples_split': [2,6,12],\n","                     \"criterion\": ['gini', 'entropy', 'log_loss'],\n","                     \"warm_start\": [True, False],\n","                     'n_estimators': [50,100,200]}]\n","\n","forest_clf = RandomizedSearchCV(forest_model, forest_parameters, scoring='roc_auc', n_jobs=-1, cv=cv)\n","forest_clf.fit(features_train, target_train)\n","# create a variable for the best model\n","best_for = forest_clf.best_estimator_\n","for_pred = best_for.predict(features_valid)\n","print('Runtime:')"]},{"cell_type":"code","execution_count":65,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 1000x500 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["sns.set(style=\"white\", color_codes=True)\n","plt.rcParams['axes.linewidth'] = 0.1\n","\n","fig, ax = plt.subplots(figsize = (10,5))\n","disp = CalibrationDisplay.from_estimator(forest_clf, features_valid, target_valid, ax=ax)\n","plt.title('Calibration Chart - Random Forest Classifier', fontsize=10)\n","ax.set_xlabel('Mean predicted probability (Positive class: 1)', fontsize=10)\n","ax.set_ylabel('Fraction of positives (Positive class: 1)',fontsize=10)\n","\n","ax.tick_params(color='gray', labelcolor='gray')\n","for spine in ax.spines.values():\n","    spine.set_edgecolor('gray')\n","\n","\n","fig.tight_layout()\n","plt.legend(fontsize=8)\n","plt.show()"]},{"cell_type":"code","execution_count":66,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T16:51:02.675236Z","iopub.status.busy":"2023-11-30T16:51:02.674939Z","iopub.status.idle":"2023-11-30T16:51:28.806061Z","shell.execute_reply":"2023-11-30T16:51:28.805200Z","shell.execute_reply.started":"2023-11-30T16:51:02.675211Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Cross Validation Scores: [0.88701779 0.86640265 0.88940092 0.84344758 0.87862903 0.87919067\n"," 0.86424251 0.84251152 0.89613673 0.88196371 0.83515193 0.86029666\n"," 0.89203629 0.87079493 0.88859447 0.87049251 0.89919355 0.86601382\n"," 0.90471856 0.87202381 0.84351462 0.896803   0.8889977  0.8749424\n"," 0.87351671 0.90600518 0.88781682 0.88974654 0.87455213 0.83183079\n"," 0.87531861 0.85427707 0.87151498 0.89668779 0.89811348 0.8905962\n"," 0.865625   0.865553   0.87138812 0.87749942 0.87534725 0.88326613\n"," 0.85733007 0.84854551 0.87587846 0.8812212  0.88701037 0.90756048\n"," 0.8802589  0.884911  ]\n"]}],"source":["forest_scores = cross_val_score(forest_model, features_train, target_train, cv=cv, scoring='roc_auc')\n","print('Cross Validation Scores: {}'.format(forest_scores))"]},{"cell_type":"code","execution_count":67,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T16:51:28.815144Z","iopub.status.busy":"2023-11-30T16:51:28.814760Z","iopub.status.idle":"2023-11-30T16:51:28.886083Z","shell.execute_reply":"2023-11-30T16:51:28.885261Z","shell.execute_reply.started":"2023-11-30T16:51:28.815112Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Best hyperparameters: {'warm_start': False, 'n_estimators': 100, 'min_samples_split': 2, 'max_depth': 18, 'criterion': 'log_loss'}\n","\n","Best score: 0.8759037823104928\n","\n","Average Cross Validation Score: 0.8760777711552042\n","\n","ROC AUC Score - Validation Dataset: 0.8976502684150314\n"]}],"source":["# summary\n","print('Best hyperparameters:',  forest_clf.best_params_)\n","print()\n","print('Best score:', forest_clf.best_score_)\n","print()\n","print('Average Cross Validation Score: {}'.format(forest_scores.mean()))\n","print()\n","print('ROC AUC Score - Validation Dataset:',  roc_auc_score(target_valid, forest_clf.predict_proba(features_valid)[:, 1]))"]},{"cell_type":"markdown","metadata":{},"source":["# ROC AUC Curve - RandomForestClassifier"]},{"cell_type":"code","execution_count":68,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T16:51:28.887485Z","iopub.status.busy":"2023-11-30T16:51:28.887134Z","iopub.status.idle":"2023-11-30T16:51:29.109214Z","shell.execute_reply":"2023-11-30T16:51:29.108341Z","shell.execute_reply.started":"2023-11-30T16:51:28.887453Z"},"trusted":true},"outputs":[{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"fillpattern":{"shape":""},"hovertemplate":"False Positive Rate=%{x}<br>True Positive Rate=%{y}<extra></extra>","legendgroup":"","line":{"color":"#636efa"},"marker":{"symbol":"circle"},"mode":"lines","name":"","orientation":"v","showlegend":false,"stackgroup":"1","type":"scatter","x":[0,0,0,0.008021390374331552,0.008021390374331552,0.0106951871657754,0.0106951871657754,0.016042780748663103,0.016042780748663103,0.01871657754010695,0.01871657754010695,0.026737967914438502,0.026737967914438502,0.03208556149732621,0.03208556149732621,0.034759358288770054,0.034759358288770054,0.040106951871657755,0.040106951871657755,0.040106951871657755,0.040106951871657755,0.040106951871657755,0.040106951871657755,0.0427807486631016,0.0427807486631016,0.0427807486631016,0.045454545454545456,0.045454545454545456,0.0481283422459893,0.0481283422459893,0.05080213903743316,0.05614973262032086,0.05614973262032086,0.058823529411764705,0.058823529411764705,0.06149732620320856,0.06149732620320856,0.06684491978609626,0.06684491978609626,0.06951871657754011,0.06951871657754011,0.0748663101604278,0.07754010695187166,0.07754010695187166,0.07754010695187166,0.08021390374331551,0.08021390374331551,0.08288770053475936,0.08823529411764706,0.08823529411764706,0.08823529411764706,0.08823529411764706,0.08823529411764706,0.08823529411764706,0.09090909090909091,0.09090909090909091,0.09358288770053476,0.09358288770053476,0.09358288770053476,0.0962566844919786,0.0962566844919786,0.0962566844919786,0.09893048128342247,0.09893048128342247,0.10160427807486631,0.10160427807486631,0.10160427807486631,0.10427807486631016,0.10427807486631016,0.10695187165775401,0.10695187165775401,0.10695187165775401,0.10962566844919786,0.10962566844919786,0.11497326203208556,0.11497326203208556,0.12032085561497326,0.12032085561497326,0.12299465240641712,0.12299465240641712,0.12299465240641712,0.12299465240641712,0.12566844919786097,0.12566844919786097,0.12834224598930483,0.12834224598930483,0.13101604278074866,0.13101604278074866,0.13368983957219252,0.13368983957219252,0.13636363636363635,0.13636363636363635,0.13903743315508021,0.13903743315508021,0.14171122994652408,0.14171122994652408,0.14705882352941177,0.14705882352941177,0.1497326203208556,0.1497326203208556,0.15240641711229946,0.15240641711229946,0.1657754010695187,0.1657754010695187,0.16844919786096257,0.16844919786096257,0.1711229946524064,0.1711229946524064,0.18181818181818182,0.18181818181818182,0.18716577540106952,0.18716577540106952,0.18716577540106952,0.18716577540106952,0.18716577540106952,0.18716577540106952,0.18716577540106952,0.18716577540106952,0.1925133689839572,0.1925133689839572,0.19786096256684493,0.19786096256684493,0.20053475935828877,0.20053475935828877,0.20320855614973263,0.20320855614973263,0.20588235294117646,0.20855614973262032,0.20855614973262032,0.21122994652406418,0.21122994652406418,0.21122994652406418,0.21390374331550802,0.21390374331550802,0.21390374331550802,0.2192513368983957,0.2192513368983957,0.22192513368983957,0.22192513368983957,0.22459893048128343,0.22459893048128343,0.22459893048128343,0.22459893048128343,0.22727272727272727,0.22727272727272727,0.23529411764705882,0.23529411764705882,0.23796791443850268,0.23796791443850268,0.24064171122994651,0.24064171122994651,0.24331550802139038,0.24331550802139038,0.24866310160427807,0.24866310160427807,0.24866310160427807,0.25133689839572193,0.25133689839572193,0.2540106951871658,0.2540106951871658,0.25935828877005346,0.25935828877005346,0.2620320855614973,0.2620320855614973,0.2620320855614973,0.2620320855614973,0.2700534759358289,0.2700534759358289,0.2727272727272727,0.2727272727272727,0.27807486631016043,0.27807486631016043,0.27807486631016043,0.28609625668449196,0.28609625668449196,0.28609625668449196,0.2914438502673797,0.2914438502673797,0.2967914438502674,0.2967914438502674,0.30213903743315507,0.30213903743315507,0.3048128342245989,0.3048128342245989,0.3181818181818182,0.3181818181818182,0.3181818181818182,0.3181818181818182,0.3235294117647059,0.3235294117647059,0.32887700534759357,0.32887700534759357,0.3315508021390374,0.3315508021390374,0.33689839572192515,0.33689839572192515,0.3422459893048128,0.3422459893048128,0.3422459893048128,0.34759358288770054,0.3502673796791444,0.35561497326203206,0.35561497326203206,0.3716577540106952,0.3716577540106952,0.37433155080213903,0.37433155080213903,0.38235294117647056,0.38235294117647056,0.3850267379679144,0.3850267379679144,0.40106951871657753,0.40106951871657753,0.4037433155080214,0.4037433155080214,0.4117647058823529,0.4117647058823529,0.42245989304812837,0.42245989304812837,0.42513368983957217,0.42513368983957217,0.4304812834224599,0.4304812834224599,0.43315508021390375,0.43315508021390375,0.4358288770053476,0.4358288770053476,0.44385026737967914,0.44385026737967914,0.446524064171123,0.446524064171123,0.45187165775401067,0.45187165775401067,0.4572192513368984,0.4572192513368984,0.4679144385026738,0.4679144385026738,0.4732620320855615,0.4732620320855615,0.4732620320855615,0.48128342245989303,0.48128342245989303,0.4839572192513369,0.4839572192513369,0.4893048128342246,0.4946524064171123,0.5080213903743316,0.5080213903743316,0.516042780748663,0.516042780748663,0.5187165775401069,0.5187165775401069,0.5481283422459893,0.5481283422459893,0.5508021390374331,0.5508021390374331,0.5721925133689839,0.5721925133689839,0.5828877005347594,0.5828877005347594,0.5935828877005348,0.5935828877005348,0.6096256684491979,0.6096256684491979,0.6443850267379679,0.6497326203208557,0.6550802139037433,0.6550802139037433,0.6818181818181818,0.6898395721925134,0.6898395721925134,0.6978609625668449,0.7032085561497327,0.7032085561497327,0.7085561497326203,0.7085561497326203,0.7165775401069518,0.7219251336898396,0.732620320855615,0.7486631016042781,0.7967914438502673,0.7967914438502673,0.7994652406417112,0.7994652406417112,0.8288770053475936,0.8368983957219251,0.8449197860962567,0.8502673796791443,0.8529411764705882,0.8582887700534759,0.8609625668449198,0.8663101604278075,0.8743315508021391,0.8850267379679144,0.893048128342246,0.9037433155080213,0.9064171122994652,0.9171122994652406,0.9197860962566845,0.9251336898395722,0.9331550802139037,0.9385026737967914,0.9438502673796791,0.9491978609625669,0.9652406417112299,0.9705882352941176,0.9866310160427807,0.9946524064171123,1],"xaxis":"x","y":[0,0.1355275895450145,0.13649564375605033,0.21297192642787996,0.2149080348499516,0.2158760890609874,0.21684414327202323,0.2787996127783156,0.2807357212003872,0.31461761858664083,0.3155856727976767,0.3426911907066796,0.3465634075508228,0.37560503388189737,0.377541142303969,0.40561471442400776,0.409486931268151,0.4346563407550823,0.43756050338818975,0.4530493707647628,0.4569215876089061,0.47725072604065827,0.4782187802516941,0.4791868344627299,0.48596321393998065,0.4995159728944821,0.5004840271055179,0.5014520813165537,0.5014520813165537,0.5033881897386253,0.5033881897386253,0.5188770571151985,0.5208131655372701,0.5208131655372701,0.5217812197483059,0.5217812197483059,0.526621490803485,0.5430784123910939,0.547918683446273,0.5701839303000968,0.5750242013552759,0.5866408518877058,0.5866408518877058,0.5885769603097774,0.5914811229428848,0.5914811229428848,0.5953533397870281,0.5953533397870281,0.6137463697967086,0.6195546950629235,0.6263310745401742,0.6272991287512101,0.6311713455953534,0.6321393998063891,0.6379477250726041,0.6447241045498547,0.6447241045498547,0.6466602129719264,0.6495643756050339,0.6505324298160697,0.6524685382381413,0.6553727008712488,0.6553727008712488,0.6582768635043562,0.665053242981607,0.6669893514036787,0.6698935140367861,0.6698935140367861,0.6718296224588577,0.6718296224588577,0.6776379477250726,0.68054211035818,0.68054211035818,0.6873184898354308,0.6969990319457889,0.6999031945788964,0.6999031945788964,0.7008712487899322,0.7008712487899322,0.7028073572120038,0.7134559535333979,0.7153920619554696,0.7153920619554696,0.7173281703775412,0.7173281703775412,0.7250726040658277,0.7347531461761858,0.7366892545982575,0.7366892545982575,0.7376573088092934,0.7376573088092934,0.7386253630203291,0.7386253630203291,0.7405614714424008,0.7473378509196515,0.7492739593417231,0.7492739593417231,0.7521781219748306,0.7521781219748306,0.7541142303969022,0.7541142303969022,0.7570183930300097,0.7628267182962246,0.7647628267182962,0.7647628267182962,0.7657308809293321,0.7657308809293321,0.7696030977734754,0.782187802516941,0.78702807357212,0.7909002904162633,0.7967086156824782,0.8005808325266215,0.8015488867376573,0.8034849951597289,0.8073572120038722,0.8131655372700871,0.814133591481123,0.814133591481123,0.8170377541142304,0.8170377541142304,0.8180058083252663,0.8199419167473379,0.8276863504356244,0.8276863504356244,0.8305905130687319,0.8344627299128751,0.8344627299128751,0.8373668925459826,0.8373668925459826,0.8412391093901258,0.8431752178121975,0.8431752178121975,0.8451113262342691,0.8470474346563408,0.8470474346563408,0.8480154888673765,0.8480154888673765,0.850919651500484,0.850919651500484,0.8538238141335914,0.856727976766699,0.8576960309777347,0.8576960309777347,0.8586640851887706,0.8586640851887706,0.861568247821878,0.861568247821878,0.8635043562439496,0.8635043562439496,0.8664085188770572,0.8673765730880929,0.8731848983543078,0.8731848983543078,0.8818973862536302,0.8848015488867377,0.8848015488867377,0.8867376573088093,0.8877057115198451,0.888673765730881,0.888673765730881,0.8906098741529526,0.8906098741529526,0.89351403678606,0.8954501452081317,0.8983543078412392,0.8983543078412392,0.9022265246853823,0.904162633107454,0.9060987415295256,0.9060987415295256,0.9080348499515973,0.9099709583736689,0.9099709583736689,0.9109390125847048,0.9138431752178122,0.9138431752178122,0.914811229428848,0.914811229428848,0.9157792836398838,0.9157792836398838,0.9177153920619555,0.9186834462729913,0.9196515004840271,0.9196515004840271,0.9225556631171346,0.9264278799612778,0.9283639883833494,0.9283639883833494,0.9303000968054211,0.9303000968054211,0.9322362052274927,0.936108422071636,0.9380445304937076,0.9380445304937076,0.9390125847047435,0.9390125847047435,0.9409486931268151,0.9428848015488868,0.9428848015488868,0.9457889641819942,0.9457889641819942,0.9467570183930301,0.9467570183930301,0.9477250726040658,0.9477250726040658,0.9496611810261375,0.9496611810261375,0.9506292352371732,0.9506292352371732,0.952565343659245,0.952565343659245,0.9545014520813165,0.9554695062923524,0.9583736689254598,0.9583736689254598,0.9593417231364957,0.9593417231364957,0.9603097773475314,0.9603097773475314,0.9612778315585673,0.9632139399806389,0.9651500484027106,0.9651500484027106,0.9661181026137464,0.9661181026137464,0.9699903194578896,0.9699903194578896,0.9709583736689255,0.9709583736689255,0.972894482090997,0.972894482090997,0.9738625363020329,0.9738625363020329,0.9748305905130688,0.9748305905130688,0.9767666989351403,0.9767666989351403,0.9777347531461762,0.9806389157792836,0.9806389157792836,0.9825750242013552,0.9825750242013552,0.9845111326234269,0.9845111326234269,0.9845111326234269,0.9845111326234269,0.9854791868344628,0.9854791868344628,0.9864472410454985,0.9864472410454985,0.9874152952565344,0.9874152952565344,0.9883833494675702,0.989351403678606,0.9903194578896418,0.9903194578896418,0.9912875121006777,0.9912875121006777,0.9922555663117134,0.9922555663117134,0.9932236205227493,0.9932236205227493,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.995159728944821,0.995159728944821,0.995159728944821,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9970958373668926,0.9970958373668926,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9990319457889641,0.9990319457889641,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],"yaxis":"y"}],"layout":{"height":600,"legend":{"tracegroupgap":0},"shapes":[{"line":{"dash":"dash"},"type":"line","x0":0,"x1":1,"y0":0,"y1":1}],"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"title":{"text":"ROC Curve (AUC=0.8977)"},"width":800,"xaxis":{"anchor":"y","constrain":"domain","domain":[0,1],"title":{"text":"False Positive Rate"}},"yaxis":{"anchor":"x","domain":[0,1],"scaleanchor":"x","scaleratio":1,"title":{"text":"True Positive Rate"}}}},"text/html":["<div>                            <div id=\"5bf90637-acb8-4996-a44c-7dcebc368570\" class=\"plotly-graph-div\" style=\"height:600px; width:800px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"5bf90637-acb8-4996-a44c-7dcebc368570\")) {                    Plotly.newPlot(                        \"5bf90637-acb8-4996-a44c-7dcebc368570\",                        [{\"fillpattern\":{\"shape\":\"\"},\"hovertemplate\":\"False Positive Rate=%{x}\\u003cbr\\u003eTrue Positive Rate=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"stackgroup\":\"1\",\"x\":[0.0,0.0,0.0,0.008021390374331552,0.008021390374331552,0.0106951871657754,0.0106951871657754,0.016042780748663103,0.016042780748663103,0.01871657754010695,0.01871657754010695,0.026737967914438502,0.026737967914438502,0.03208556149732621,0.03208556149732621,0.034759358288770054,0.034759358288770054,0.040106951871657755,0.040106951871657755,0.040106951871657755,0.040106951871657755,0.040106951871657755,0.040106951871657755,0.0427807486631016,0.0427807486631016,0.0427807486631016,0.045454545454545456,0.045454545454545456,0.0481283422459893,0.0481283422459893,0.05080213903743316,0.05614973262032086,0.05614973262032086,0.058823529411764705,0.058823529411764705,0.06149732620320856,0.06149732620320856,0.06684491978609626,0.06684491978609626,0.06951871657754011,0.06951871657754011,0.0748663101604278,0.07754010695187166,0.07754010695187166,0.07754010695187166,0.08021390374331551,0.08021390374331551,0.08288770053475936,0.08823529411764706,0.08823529411764706,0.08823529411764706,0.08823529411764706,0.08823529411764706,0.08823529411764706,0.09090909090909091,0.09090909090909091,0.09358288770053476,0.09358288770053476,0.09358288770053476,0.0962566844919786,0.0962566844919786,0.0962566844919786,0.09893048128342247,0.09893048128342247,0.10160427807486631,0.10160427807486631,0.10160427807486631,0.10427807486631016,0.10427807486631016,0.10695187165775401,0.10695187165775401,0.10695187165775401,0.10962566844919786,0.10962566844919786,0.11497326203208556,0.11497326203208556,0.12032085561497326,0.12032085561497326,0.12299465240641712,0.12299465240641712,0.12299465240641712,0.12299465240641712,0.12566844919786097,0.12566844919786097,0.12834224598930483,0.12834224598930483,0.13101604278074866,0.13101604278074866,0.13368983957219252,0.13368983957219252,0.13636363636363635,0.13636363636363635,0.13903743315508021,0.13903743315508021,0.14171122994652408,0.14171122994652408,0.14705882352941177,0.14705882352941177,0.1497326203208556,0.1497326203208556,0.15240641711229946,0.15240641711229946,0.1657754010695187,0.1657754010695187,0.16844919786096257,0.16844919786096257,0.1711229946524064,0.1711229946524064,0.18181818181818182,0.18181818181818182,0.18716577540106952,0.18716577540106952,0.18716577540106952,0.18716577540106952,0.18716577540106952,0.18716577540106952,0.18716577540106952,0.18716577540106952,0.1925133689839572,0.1925133689839572,0.19786096256684493,0.19786096256684493,0.20053475935828877,0.20053475935828877,0.20320855614973263,0.20320855614973263,0.20588235294117646,0.20855614973262032,0.20855614973262032,0.21122994652406418,0.21122994652406418,0.21122994652406418,0.21390374331550802,0.21390374331550802,0.21390374331550802,0.2192513368983957,0.2192513368983957,0.22192513368983957,0.22192513368983957,0.22459893048128343,0.22459893048128343,0.22459893048128343,0.22459893048128343,0.22727272727272727,0.22727272727272727,0.23529411764705882,0.23529411764705882,0.23796791443850268,0.23796791443850268,0.24064171122994651,0.24064171122994651,0.24331550802139038,0.24331550802139038,0.24866310160427807,0.24866310160427807,0.24866310160427807,0.25133689839572193,0.25133689839572193,0.2540106951871658,0.2540106951871658,0.25935828877005346,0.25935828877005346,0.2620320855614973,0.2620320855614973,0.2620320855614973,0.2620320855614973,0.2700534759358289,0.2700534759358289,0.2727272727272727,0.2727272727272727,0.27807486631016043,0.27807486631016043,0.27807486631016043,0.28609625668449196,0.28609625668449196,0.28609625668449196,0.2914438502673797,0.2914438502673797,0.2967914438502674,0.2967914438502674,0.30213903743315507,0.30213903743315507,0.3048128342245989,0.3048128342245989,0.3181818181818182,0.3181818181818182,0.3181818181818182,0.3181818181818182,0.3235294117647059,0.3235294117647059,0.32887700534759357,0.32887700534759357,0.3315508021390374,0.3315508021390374,0.33689839572192515,0.33689839572192515,0.3422459893048128,0.3422459893048128,0.3422459893048128,0.34759358288770054,0.3502673796791444,0.35561497326203206,0.35561497326203206,0.3716577540106952,0.3716577540106952,0.37433155080213903,0.37433155080213903,0.38235294117647056,0.38235294117647056,0.3850267379679144,0.3850267379679144,0.40106951871657753,0.40106951871657753,0.4037433155080214,0.4037433155080214,0.4117647058823529,0.4117647058823529,0.42245989304812837,0.42245989304812837,0.42513368983957217,0.42513368983957217,0.4304812834224599,0.4304812834224599,0.43315508021390375,0.43315508021390375,0.4358288770053476,0.4358288770053476,0.44385026737967914,0.44385026737967914,0.446524064171123,0.446524064171123,0.45187165775401067,0.45187165775401067,0.4572192513368984,0.4572192513368984,0.4679144385026738,0.4679144385026738,0.4732620320855615,0.4732620320855615,0.4732620320855615,0.48128342245989303,0.48128342245989303,0.4839572192513369,0.4839572192513369,0.4893048128342246,0.4946524064171123,0.5080213903743316,0.5080213903743316,0.516042780748663,0.516042780748663,0.5187165775401069,0.5187165775401069,0.5481283422459893,0.5481283422459893,0.5508021390374331,0.5508021390374331,0.5721925133689839,0.5721925133689839,0.5828877005347594,0.5828877005347594,0.5935828877005348,0.5935828877005348,0.6096256684491979,0.6096256684491979,0.6443850267379679,0.6497326203208557,0.6550802139037433,0.6550802139037433,0.6818181818181818,0.6898395721925134,0.6898395721925134,0.6978609625668449,0.7032085561497327,0.7032085561497327,0.7085561497326203,0.7085561497326203,0.7165775401069518,0.7219251336898396,0.732620320855615,0.7486631016042781,0.7967914438502673,0.7967914438502673,0.7994652406417112,0.7994652406417112,0.8288770053475936,0.8368983957219251,0.8449197860962567,0.8502673796791443,0.8529411764705882,0.8582887700534759,0.8609625668449198,0.8663101604278075,0.8743315508021391,0.8850267379679144,0.893048128342246,0.9037433155080213,0.9064171122994652,0.9171122994652406,0.9197860962566845,0.9251336898395722,0.9331550802139037,0.9385026737967914,0.9438502673796791,0.9491978609625669,0.9652406417112299,0.9705882352941176,0.9866310160427807,0.9946524064171123,1.0],\"xaxis\":\"x\",\"y\":[0.0,0.1355275895450145,0.13649564375605033,0.21297192642787996,0.2149080348499516,0.2158760890609874,0.21684414327202323,0.2787996127783156,0.2807357212003872,0.31461761858664083,0.3155856727976767,0.3426911907066796,0.3465634075508228,0.37560503388189737,0.377541142303969,0.40561471442400776,0.409486931268151,0.4346563407550823,0.43756050338818975,0.4530493707647628,0.4569215876089061,0.47725072604065827,0.4782187802516941,0.4791868344627299,0.48596321393998065,0.4995159728944821,0.5004840271055179,0.5014520813165537,0.5014520813165537,0.5033881897386253,0.5033881897386253,0.5188770571151985,0.5208131655372701,0.5208131655372701,0.5217812197483059,0.5217812197483059,0.526621490803485,0.5430784123910939,0.547918683446273,0.5701839303000968,0.5750242013552759,0.5866408518877058,0.5866408518877058,0.5885769603097774,0.5914811229428848,0.5914811229428848,0.5953533397870281,0.5953533397870281,0.6137463697967086,0.6195546950629235,0.6263310745401742,0.6272991287512101,0.6311713455953534,0.6321393998063891,0.6379477250726041,0.6447241045498547,0.6447241045498547,0.6466602129719264,0.6495643756050339,0.6505324298160697,0.6524685382381413,0.6553727008712488,0.6553727008712488,0.6582768635043562,0.665053242981607,0.6669893514036787,0.6698935140367861,0.6698935140367861,0.6718296224588577,0.6718296224588577,0.6776379477250726,0.68054211035818,0.68054211035818,0.6873184898354308,0.6969990319457889,0.6999031945788964,0.6999031945788964,0.7008712487899322,0.7008712487899322,0.7028073572120038,0.7134559535333979,0.7153920619554696,0.7153920619554696,0.7173281703775412,0.7173281703775412,0.7250726040658277,0.7347531461761858,0.7366892545982575,0.7366892545982575,0.7376573088092934,0.7376573088092934,0.7386253630203291,0.7386253630203291,0.7405614714424008,0.7473378509196515,0.7492739593417231,0.7492739593417231,0.7521781219748306,0.7521781219748306,0.7541142303969022,0.7541142303969022,0.7570183930300097,0.7628267182962246,0.7647628267182962,0.7647628267182962,0.7657308809293321,0.7657308809293321,0.7696030977734754,0.782187802516941,0.78702807357212,0.7909002904162633,0.7967086156824782,0.8005808325266215,0.8015488867376573,0.8034849951597289,0.8073572120038722,0.8131655372700871,0.814133591481123,0.814133591481123,0.8170377541142304,0.8170377541142304,0.8180058083252663,0.8199419167473379,0.8276863504356244,0.8276863504356244,0.8305905130687319,0.8344627299128751,0.8344627299128751,0.8373668925459826,0.8373668925459826,0.8412391093901258,0.8431752178121975,0.8431752178121975,0.8451113262342691,0.8470474346563408,0.8470474346563408,0.8480154888673765,0.8480154888673765,0.850919651500484,0.850919651500484,0.8538238141335914,0.856727976766699,0.8576960309777347,0.8576960309777347,0.8586640851887706,0.8586640851887706,0.861568247821878,0.861568247821878,0.8635043562439496,0.8635043562439496,0.8664085188770572,0.8673765730880929,0.8731848983543078,0.8731848983543078,0.8818973862536302,0.8848015488867377,0.8848015488867377,0.8867376573088093,0.8877057115198451,0.888673765730881,0.888673765730881,0.8906098741529526,0.8906098741529526,0.89351403678606,0.8954501452081317,0.8983543078412392,0.8983543078412392,0.9022265246853823,0.904162633107454,0.9060987415295256,0.9060987415295256,0.9080348499515973,0.9099709583736689,0.9099709583736689,0.9109390125847048,0.9138431752178122,0.9138431752178122,0.914811229428848,0.914811229428848,0.9157792836398838,0.9157792836398838,0.9177153920619555,0.9186834462729913,0.9196515004840271,0.9196515004840271,0.9225556631171346,0.9264278799612778,0.9283639883833494,0.9283639883833494,0.9303000968054211,0.9303000968054211,0.9322362052274927,0.936108422071636,0.9380445304937076,0.9380445304937076,0.9390125847047435,0.9390125847047435,0.9409486931268151,0.9428848015488868,0.9428848015488868,0.9457889641819942,0.9457889641819942,0.9467570183930301,0.9467570183930301,0.9477250726040658,0.9477250726040658,0.9496611810261375,0.9496611810261375,0.9506292352371732,0.9506292352371732,0.952565343659245,0.952565343659245,0.9545014520813165,0.9554695062923524,0.9583736689254598,0.9583736689254598,0.9593417231364957,0.9593417231364957,0.9603097773475314,0.9603097773475314,0.9612778315585673,0.9632139399806389,0.9651500484027106,0.9651500484027106,0.9661181026137464,0.9661181026137464,0.9699903194578896,0.9699903194578896,0.9709583736689255,0.9709583736689255,0.972894482090997,0.972894482090997,0.9738625363020329,0.9738625363020329,0.9748305905130688,0.9748305905130688,0.9767666989351403,0.9767666989351403,0.9777347531461762,0.9806389157792836,0.9806389157792836,0.9825750242013552,0.9825750242013552,0.9845111326234269,0.9845111326234269,0.9845111326234269,0.9845111326234269,0.9854791868344628,0.9854791868344628,0.9864472410454985,0.9864472410454985,0.9874152952565344,0.9874152952565344,0.9883833494675702,0.989351403678606,0.9903194578896418,0.9903194578896418,0.9912875121006777,0.9912875121006777,0.9922555663117134,0.9922555663117134,0.9932236205227493,0.9932236205227493,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.995159728944821,0.995159728944821,0.995159728944821,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9970958373668926,0.9970958373668926,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9990319457889641,0.9990319457889641,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"False Positive Rate\"},\"constrain\":\"domain\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"True Positive Rate\"},\"scaleanchor\":\"x\",\"scaleratio\":1},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"ROC Curve (AUC=0.8977)\"},\"height\":600,\"width\":800,\"shapes\":[{\"line\":{\"dash\":\"dash\"},\"type\":\"line\",\"x0\":0,\"x1\":1,\"y0\":0,\"y1\":1}],\"showlegend\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('5bf90637-acb8-4996-a44c-7dcebc368570');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"fillpattern":{"shape":""},"hovertemplate":"Recall=%{x}<br>Precision=%{y}<extra></extra>","legendgroup":"","line":{"color":"#636efa"},"marker":{"symbol":"circle"},"mode":"lines","name":"","orientation":"v","showlegend":false,"stackgroup":"1","type":"scatter","x":[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0.9990319457889641,0.9990319457889641,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9932236205227493,0.9932236205227493,0.9932236205227493,0.9932236205227493,0.9932236205227493,0.9932236205227493,0.9932236205227493,0.9922555663117134,0.9922555663117134,0.9922555663117134,0.9922555663117134,0.9922555663117134,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.989351403678606,0.9883833494675702,0.9874152952565344,0.9874152952565344,0.9874152952565344,0.9874152952565344,0.9874152952565344,0.9874152952565344,0.9874152952565344,0.9874152952565344,0.9874152952565344,0.9874152952565344,0.9874152952565344,0.9874152952565344,0.9864472410454985,0.9864472410454985,0.9854791868344628,0.9854791868344628,0.9854791868344628,0.9854791868344628,0.9845111326234269,0.9845111326234269,0.9845111326234269,0.9845111326234269,0.9845111326234269,0.9845111326234269,0.9845111326234269,0.9845111326234269,0.9845111326234269,0.9835430784123911,0.9825750242013552,0.9825750242013552,0.9816069699903195,0.9806389157792836,0.9806389157792836,0.9806389157792836,0.9806389157792836,0.9777347531461762,0.9767666989351403,0.9767666989351403,0.9767666989351403,0.9757986447241046,0.9748305905130688,0.9748305905130688,0.9748305905130688,0.9748305905130688,0.9748305905130688,0.9738625363020329,0.9738625363020329,0.9738625363020329,0.972894482090997,0.972894482090997,0.972894482090997,0.9719264278799613,0.9709583736689255,0.9709583736689255,0.9699903194578896,0.9699903194578896,0.9699903194578896,0.9699903194578896,0.9690222652468539,0.968054211035818,0.9670861568247822,0.9661181026137464,0.9661181026137464,0.9651500484027106,0.9651500484027106,0.9641819941916747,0.9632139399806389,0.9612778315585673,0.9603097773475314,0.9603097773475314,0.9593417231364957,0.9593417231364957,0.9593417231364957,0.9593417231364957,0.9593417231364957,0.9583736689254598,0.9583736689254598,0.9583736689254598,0.9583736689254598,0.957405614714424,0.9564375605033882,0.9554695062923524,0.9545014520813165,0.9535333978702807,0.952565343659245,0.952565343659245,0.952565343659245,0.952565343659245,0.952565343659245,0.952565343659245,0.952565343659245,0.9515972894482091,0.9506292352371732,0.9506292352371732,0.9496611810261375,0.9496611810261375,0.9496611810261375,0.9496611810261375,0.9477250726040658,0.9477250726040658,0.9467570183930301,0.9467570183930301,0.9467570183930301,0.9467570183930301,0.9467570183930301,0.9467570183930301,0.9467570183930301,0.9457889641819942,0.9457889641819942,0.9457889641819942,0.9428848015488868,0.9428848015488868,0.9428848015488868,0.9409486931268151,0.9399806389157793,0.9390125847047435,0.9390125847047435,0.9390125847047435,0.9380445304937076,0.9380445304937076,0.9380445304937076,0.9370764762826719,0.936108422071636,0.9322362052274927,0.9312681510164569,0.9303000968054211,0.9303000968054211,0.9303000968054211,0.9293320425943853,0.9283639883833494,0.9283639883833494,0.9283639883833494,0.9273959341723137,0.9264278799612778,0.9225556631171346,0.9215876089060987,0.920619554695063,0.9196515004840271,0.9196515004840271,0.9196515004840271,0.9196515004840271,0.9196515004840271,0.9196515004840271,0.9186834462729913,0.9177153920619555,0.9167473378509197,0.9157792836398838,0.9157792836398838,0.9157792836398838,0.914811229428848,0.914811229428848,0.914811229428848,0.9138431752178122,0.9138431752178122,0.9138431752178122,0.9109390125847048,0.9099709583736689,0.9099709583736689,0.9099709583736689,0.9099709583736689,0.9080348499515973,0.9070667957405615,0.9060987415295256,0.9060987415295256,0.9060987415295256,0.9051306873184899,0.904162633107454,0.9022265246853823,0.9012584704743466,0.9002904162633107,0.8993223620522749,0.8983543078412392,0.8983543078412392,0.8983543078412392,0.8983543078412392,0.8973862536302033,0.8964181994191674,0.8954501452081317,0.89351403678606,0.8925459825750242,0.8915779283639884,0.8906098741529526,0.8906098741529526,0.8896418199419167,0.888673765730881,0.888673765730881,0.888673765730881,0.8877057115198451,0.8867376573088093,0.8857696030977735,0.8848015488867377,0.8848015488867377,0.8818973862536302,0.8809293320425944,0.8799612778315585,0.8789932236205228,0.8780251694094869,0.8770571151984511,0.8760890609874153,0.8751210067763795,0.8741529525653436,0.8731848983543078,0.8731848983543078,0.8731848983543078,0.872216844143272,0.8712487899322362,0.8702807357212003,0.8693126815101646,0.8683446272991288,0.8673765730880929,0.8664085188770572,0.8654404646660213,0.8644724104549855,0.8635043562439496,0.8635043562439496,0.8625363020329139,0.861568247821878,0.861568247821878,0.8606001936108422,0.8596321393998064,0.8586640851887706,0.8586640851887706,0.8586640851887706,0.8586640851887706,0.8576960309777347,0.8576960309777347,0.856727976766699,0.8538238141335914,0.8528557599225557,0.8518877057115198,0.850919651500484,0.850919651500484,0.8499515972894482,0.8489835430784124,0.8480154888673765,0.8480154888673765,0.8470474346563408,0.8470474346563408,0.8470474346563408,0.8451113262342691,0.8441432720232332,0.8431752178121975,0.8431752178121975,0.8412391093901258,0.8373668925459826,0.8373668925459826,0.8363988383349468,0.8354307841239109,0.8344627299128751,0.8344627299128751,0.8305905130687319,0.829622458857696,0.8286544046466602,0.8276863504356244,0.8276863504356244,0.8267182962245886,0.8257502420135527,0.8247821878025169,0.8238141335914811,0.8228460793804453,0.8218780251694094,0.8209099709583737,0.8199419167473379,0.8180058083252663,0.8170377541142304,0.8170377541142304,0.8170377541142304,0.8160696999031946,0.8151016456921588,0.814133591481123,0.814133591481123,0.814133591481123,0.8131655372700871,0.8073572120038722,0.8063891577928364,0.8054211035818006,0.8044530493707648,0.8034849951597289,0.8015488867376573,0.8005808325266215,0.7967086156824782,0.7957405614714425,0.7947725072604066,0.7938044530493708,0.7928363988383349,0.7918683446272992,0.7909002904162633,0.78702807357212,0.7860600193610843,0.7850919651500484,0.7841239109390126,0.7831558567279767,0.782187802516941,0.7696030977734754,0.7686350435624395,0.7676669893514037,0.7666989351403679,0.7657308809293321,0.7657308809293321,0.7647628267182962,0.7647628267182962,0.7637947725072604,0.7628267182962246,0.7570183930300097,0.7560503388189739,0.755082284607938,0.7541142303969022,0.7541142303969022,0.7531461761858664,0.7521781219748306,0.7521781219748306,0.7512100677637947,0.750242013552759,0.7492739593417231,0.7492739593417231,0.7483059051306873,0.7473378509196515,0.7405614714424008,0.739593417231365,0.7386253630203291,0.7386253630203291,0.7376573088092934,0.7376573088092934,0.7366892545982575,0.7366892545982575,0.7357212003872217,0.7347531461761858,0.7250726040658277,0.7241045498547919,0.723136495643756,0.7221684414327202,0.7212003872216844,0.7202323330106486,0.7192642787996127,0.718296224588577,0.7173281703775412,0.7173281703775412,0.7163601161665053,0.7153920619554696,0.7153920619554696,0.7144240077444337,0.7134559535333979,0.7028073572120038,0.7018393030009681,0.7008712487899322,0.7008712487899322,0.6999031945788964,0.6999031945788964,0.6999031945788964,0.6989351403678606,0.6979670861568248,0.6969990319457889,0.6873184898354308,0.686350435624395,0.6853823814133592,0.6844143272023233,0.6834462729912875,0.6824782187802517,0.6815101645692159,0.68054211035818,0.68054211035818,0.6795740561471443,0.6786060019361084,0.6776379477250726,0.6718296224588577,0.6718296224588577,0.6708615682478218,0.6698935140367861,0.6698935140367861,0.6689254598257502,0.6679574056147144,0.6669893514036787,0.665053242981607,0.6582768635043562,0.6573088092933205,0.6563407550822846,0.6553727008712488,0.6553727008712488,0.6524685382381413,0.6515004840271055,0.6505324298160697,0.6495643756050339,0.6466602129719264,0.6456921587608906,0.6447241045498547,0.6447241045498547,0.643756050338819,0.6427879961277831,0.6418199419167473,0.6408518877057116,0.6398838334946757,0.6389157792836399,0.6379477250726041,0.6321393998063891,0.6311713455953534,0.6272991287512101,0.6263310745401742,0.6195546950629235,0.6185866408518877,0.6176185866408519,0.616650532429816,0.6156824782187803,0.6147144240077445,0.6137463697967086,0.5953533397870281,0.5953533397870281,0.5943852855759922,0.5934172313649564,0.5924491771539206,0.5914811229428848,0.5914811229428848,0.5885769603097774,0.5876089060987415,0.5866408518877058,0.5866408518877058,0.5750242013552759,0.57405614714424,0.5730880929332043,0.5721200387221684,0.5711519845111326,0.5701839303000968,0.547918683446273,0.5469506292352372,0.5459825750242013,0.5450145208131656,0.5440464666021297,0.5430784123910939,0.526621490803485,0.5256534365924492,0.5246853823814134,0.5237173281703775,0.5227492739593417,0.5217812197483059,0.5217812197483059,0.5208131655372701,0.5208131655372701,0.5198451113262342,0.5188770571151985,0.5033881897386253,0.5033881897386253,0.5024201355275896,0.5014520813165537,0.5014520813165537,0.5004840271055179,0.4995159728944821,0.48596321393998065,0.4849951597289448,0.484027105517909,0.4830590513068732,0.48209099709583736,0.48112294288480156,0.4801548886737657,0.4791868344627299,0.4782187802516941,0.47725072604065827,0.4569215876089061,0.45595353339787026,0.45498547918683446,0.45401742497579867,0.4530493707647628,0.43756050338818975,0.4365924491771539,0.4356243949661181,0.4346563407550823,0.409486931268151,0.4085188770571152,0.4075508228460794,0.40658276863504356,0.40561471442400776,0.377541142303969,0.3765730880929332,0.37560503388189737,0.3465634075508228,0.345595353339787,0.34462729912875123,0.3436592449177154,0.3426911907066796,0.3155856727976767,0.31461761858664083,0.2807357212003872,0.2797676669893514,0.2787996127783156,0.21684414327202323,0.2158760890609874,0.2149080348499516,0.21393998063891578,0.21297192642787996,0.13649564375605033,0.1355275895450145,0],"xaxis":"x","y":[0.7341862117981521,0.7352313167259786,0.7357549857549858,0.7362794012829651,0.7368045649072753,0.7399713467048711,0.7405017921146954,0.7410329985652798,0.7442363112391931,0.7447728911319395,0.7453102453102453,0.7463872832369942,0.7469269703543022,0.7474674384949349,0.7490935460478607,0.7501815541031227,0.7507267441860465,0.7529154518950437,0.7534646243617797,0.7556693489392831,0.7562225475841874,0.7567765567765568,0.7573313782991202,0.7595588235294117,0.7601177336276674,0.7606774668630338,0.7612380250552689,0.7623616236162362,0.7629246676514032,0.7640532544378699,0.764618800888231,0.765752409191994,0.766320474777448,0.7668893838158871,0.7674591381872214,0.7691734921816828,0.7697466467958272,0.7703206562266965,0.7708955223880597,0.7714712471994025,0.7720478325859492,0.7726252804786836,0.7732035928143712,0.7737827715355805,0.7743628185907047,0.7749437359339835,0.7755255255255256,0.7753568745304282,0.7759398496240602,0.7757712565838977,0.776355421686747,0.7769404672192917,0.777526395173454,0.7781132075471698,0.7787009063444109,0.7792894935752078,0.7798789712556732,0.7804693414080243,0.781060606060606,0.7816527672479151,0.7822458270106222,0.782839787395596,0.7834346504559271,0.7840304182509505,0.784627092846271,0.7852246763137852,0.7858231707317073,0.7864225781845919,0.7900383141762453,0.7906441717791411,0.7912509593246354,0.7918586789554531,0.792467332820907,0.7936874518860662,0.7942989214175655,0.79491133384734,0.7955246913580247,0.7953667953667953,0.7959814528593508,0.7965970610982211,0.7964396284829721,0.7976744186046512,0.7982932505818464,0.7989130434782609,0.7995337995337995,0.7993779160186625,0.8012470771628994,0.8018720748829953,0.8024980483996877,0.803125,0.8037529319781079,0.8043818466353677,0.8050117462803446,0.8056426332288401,0.8062745098039216,0.8069073783359497,0.8075412411626081,0.8073899371069182,0.8080251770259638,0.8086614173228347,0.8099369085173501,0.8105761641673244,0.811216429699842,0.8118577075098814,0.8125,0.8131433095803642,0.8137876386687797,0.8144329896907216,0.8150793650793651,0.8157267672756155,0.8163751987281399,0.817024661893397,0.8176751592356688,0.8183266932270916,0.8181818181818182,0.8188347964884277,0.8194888178913738,0.8201438848920863,0.8208,0.8214571657325861,0.8221153846153846,0.8219727345629511,0.8226324237560193,0.8232931726907631,0.8239549839228296,0.82461786001609,0.8244766505636071,0.8251410153102336,0.8258064516129032,0.8264729620661824,0.827140549273021,0.8270008084074374,0.8276699029126213,0.8283400809716599,0.8290113452188006,0.829683698296837,0.8303571428571429,0.8310316815597075,0.8317073170731707,0.8323840520748577,0.8322475570032574,0.83278955954323,0.8326530612244898,0.8333333333333334,0.8340147179067866,0.8346972176759411,0.8353808353808354,0.8360655737704918,0.8367514356029533,0.8374384236453202,0.838126540673788,0.8388157894736842,0.8395061728395061,0.8401976935749588,0.8400659521846661,0.8407590759075908,0.8406275805119736,0.8413223140495868,0.8420181968569065,0.8427152317880795,0.8425849212924607,0.8432835820895522,0.8439834024896266,0.8446843853820598,0.8453865336658354,0.846089850249584,0.8475,0.8482068390325271,0.8489148580968281,0.8487886382623224,0.8486622073578596,0.8493723849372385,0.8492462311557789,0.8491198658843252,0.8498322147651006,0.8505457598656591,0.8512605042016806,0.8508845829823083,0.8507588532883642,0.8514767932489451,0.8521959459459459,0.8520710059171598,0.8519458544839256,0.8526672311600338,0.8533898305084746,0.8541136556403732,0.8548387096774194,0.8547153780798641,0.8554421768707483,0.8561702127659574,0.8560477001703578,0.8567774936061381,0.8575085324232082,0.8573868488471392,0.8572649572649572,0.8579982891360137,0.8578767123287672,0.8586118251928021,0.8593481989708405,0.8600858369098713,0.8599656357388317,0.8598452278589854,0.8597246127366609,0.859603789836348,0.8603448275862069,0.8602243313201036,0.8609671848013817,0.8608470181503889,0.860726643598616,0.8619791666666666,0.8618592528236316,0.8626086956521739,0.8624891209747607,0.8632404181184669,0.8639930252833479,0.8647469458987783,0.8655021834061135,0.8653846153846154,0.8661417322834646,0.8669001751313485,0.8676599474145487,0.8675438596491228,0.8674275680421423,0.867311072056239,0.8679577464788732,0.8678414096916299,0.8677248677248677,0.8684907325684025,0.8692579505300353,0.870026525198939,0.8707964601769912,0.8715677590788308,0.8723404255319149,0.8722271517302573,0.872113676731794,0.8728888888888889,0.8727758007117438,0.8735529830810329,0.8743315508021391,0.8751115075825157,0.8748882931188561,0.8756708407871199,0.8755595344673232,0.8763440860215054,0.8771300448430494,0.8779174147217235,0.8787061994609164,0.8794964028776978,0.8802880288028803,0.8801801801801802,0.8809738503155996,0.881768953068592,0.8822463768115942,0.8830462375339981,0.8838475499092558,0.8836363636363637,0.8835304822565969,0.8834244080145719,0.8842297174111212,0.885036496350365,0.8849315068493151,0.8857404021937842,0.8865507776761208,0.8864468864468864,0.8863428047662695,0.8867403314917127,0.8866359447004608,0.8865313653136532,0.8873499538319483,0.8881700554528651,0.8880666049953746,0.887962962962963,0.8887859128822985,0.8896103896103896,0.8895078922934077,0.8894052044609665,0.8889925373134329,0.8888888888888888,0.888785046728972,0.8886810102899907,0.8895131086142322,0.8903467666354264,0.8911819887429644,0.892018779342723,0.8928571428571429,0.8927563499529633,0.8934967012252591,0.8933962264150943,0.8932955618508026,0.8941398865784499,0.8949858088930936,0.8948863636363636,0.8957345971563981,0.896584440227704,0.8964862298195632,0.8973384030418251,0.8981921979067554,0.8979007633587787,0.897803247373448,0.8986615678776291,0.8995215311004785,0.9003831417624522,0.9001919385796545,0.9000960614793467,0.9,0.9008662175168431,0.9017341040462428,0.9016393442622951,0.9015444015444015,0.9022265246853823,0.9021317829457365,0.9020368574199806,0.9019417475728155,0.901846452866861,0.9027237354085603,0.9036027263875365,0.9044834307992202,0.904390243902439,0.904296875,0.9042033235581622,0.9040156709108716,0.903921568627451,0.9038272816486752,0.9037328094302554,0.904621435594887,0.9045275590551181,0.9044334975369458,0.9053254437869822,0.9062191510365252,0.9061264822134387,0.906930693069307,0.9068384539147671,0.9067460317460317,0.9076464746772592,0.9073705179282868,0.9072781655034895,0.907185628742515,0.9070929070929071,0.907,0.9069069069069069,0.906813627254509,0.9067201604814443,0.9066265060240963,0.9065326633165829,0.9074446680080482,0.9083585095669687,0.9082661290322581,0.9081735620585267,0.908080808080808,0.9079878665318504,0.9078947368421053,0.9078014184397163,0.9086294416243654,0.9085365853658537,0.9084435401831129,0.9083503054989817,0.90927624872579,0.9091836734693878,0.9090909090909091,0.9100204498977505,0.90992835209826,0.9098360655737705,0.9097435897435897,0.9106776180698152,0.9116135662898253,0.9125514403292181,0.9124613800205973,0.9134020618556701,0.913312693498452,0.9130434782608695,0.9129533678756476,0.9128630705394191,0.9127725856697819,0.9137214137214137,0.9136316337148803,0.9135416666666667,0.913451511991658,0.9144050104384134,0.9143155694879833,0.9152719665271967,0.9162303664921466,0.9160545645330536,0.9159663865546218,0.9158780231335436,0.9168421052631579,0.9166666666666666,0.9163135593220338,0.9172852598091198,0.9171974522292994,0.9171094580233794,0.9170212765957447,0.9179978700745474,0.9186295503211992,0.9185423365487674,0.9184549356223176,0.9183673469387755,0.9193548387096774,0.9192680301399354,0.9191810344827587,0.919093851132686,0.9190064794816415,0.918918918918919,0.9188311688311688,0.9187432286023836,0.9186550976138829,0.9194776931447225,0.9193899782135077,0.920392584514722,0.9213973799126638,0.921311475409836,0.9212253829321663,0.9211391018619934,0.9221491228070176,0.9231613611416026,0.9230769230769231,0.922566371681416,0.9224806201550387,0.9223946784922394,0.9223085460599334,0.9222222222222223,0.9220489977728286,0.9219620958751393,0.921612541993281,0.92152466367713,0.9214365881032548,0.9213483146067416,0.9212598425196851,0.9211711711711712,0.9210822998872604,0.9228149829738933,0.9227272727272727,0.9226393629124005,0.9225512528473804,0.9224629418472063,0.9223744292237442,0.9254947613504074,0.9254079254079254,0.9253208868144691,0.9252336448598131,0.9251461988304094,0.9262295081967213,0.9261430246189918,0.9272300469483568,0.927144535840188,0.9270588235294117,0.932061978545888,0.931980906921241,0.931899641577061,0.9318181818181818,0.932934131736527,0.9328537170263789,0.9327731092436975,0.9338942307692307,0.9338146811070999,0.9337349397590361,0.9336550060313631,0.9359129383313181,0.9358353510895884,0.9357575757575758,0.9363525091799265,0.9362745098039216,0.9361963190184049,0.9373464373464373,0.9372693726937269,0.9384236453201971,0.938347718865598,0.9395061728395062,0.9394313967861557,0.9393564356435643,0.9397741530740276,0.9396984924623115,0.939622641509434,0.9395465994962217,0.9394703656998739,0.9393939393939394,0.9393173198482933,0.9392405063291139,0.9391634980988594,0.9403553299492385,0.940279542566709,0.9402035623409669,0.9414012738853503,0.9413265306122449,0.9412515964240102,0.9404145077720207,0.940337224383917,0.9402597402597402,0.94148244473342,0.94140625,0.9426336375488917,0.943864229765013,0.9437908496732026,0.943717277486911,0.9436435124508519,0.9454061251664447,0.9453333333333334,0.945260347129506,0.9451871657754011,0.9451137884872824,0.9450402144772118,0.9449664429530201,0.9448924731182796,0.946164199192463,0.9460916442048517,0.9460188933873145,0.9459459459459459,0.9455040871934605,0.946793997271487,0.9467213114754098,0.9466484268125855,0.947945205479452,0.9478737997256516,0.9478021978021978,0.9477303988995873,0.9475862068965517,0.9483960948396095,0.9483240223463687,0.9482517482517483,0.9481792717086834,0.9495091164095372,0.9492957746478873,0.9492242595204513,0.9491525423728814,0.9504249291784702,0.9502133712660028,0.9501424501424501,0.9500713266761769,0.9514285714285714,0.9513590844062947,0.9512893982808023,0.9512195121951219,0.9511494252873564,0.9510791366906475,0.9510086455331412,0.950937950937951,0.9518950437317785,0.9518248175182482,0.9515418502202643,0.9514705882352941,0.950965824665676,0.9508928571428571,0.9508196721311475,0.9507462686567164,0.9506726457399103,0.9505988023952096,0.9505247376311844,0.9520123839009288,0.9534883720930233,0.953416149068323,0.9533437013996889,0.9532710280373832,0.953198127925117,0.9546875,0.9544740973312402,0.9544025157232704,0.9543307086614173,0.9558359621451105,0.9580645161290322,0.9579967689822294,0.9579288025889967,0.9578606158833063,0.9577922077922078,0.9577235772357724,0.9576988155668359,0.9576271186440678,0.9575551782682513,0.9574829931972789,0.9574105621805792,0.9573378839590444,0.9594356261022927,0.9593639575971732,0.95929203539823,0.9592198581560284,0.9591474245115453,0.9590747330960854,0.9607843137254902,0.9607142857142857,0.962432915921288,0.9623655913978495,0.9622980251346499,0.9647495361781077,0.966542750929368,0.9664804469273743,0.9664179104477612,0.9682242990654205,0.9681647940074907,0.9699248120300752,0.9691119691119691,0.9690522243713733,0.9689922480620154,0.9689320388349515,0.9688715953307393,0.9688109161793372,0.96875,0.9686888454011742,0.9705304518664047,0.9704724409448819,0.9691991786447639,0.9691358024691358,0.9690721649484536,0.96900826446281,0.968944099378882,0.9678800856531049,0.9678111587982833,0.967741935483871,0.9676724137931034,0.9701834862385321,0.9701149425287356,0.9700460829493087,0.9699769053117783,0.9699074074074074,0.9701492537313433,0.970074812967581,0.97,0.9728260869565217,0.9727520435967303,0.9726775956284153,0.9726027397260274,0.9725274725274725,0.978978978978979,0.9789156626506024,0.9797297297297297,0.9796610169491525,0.9795918367346939,0.9824561403508771,0.9823788546255506,0.9866666666666667,0.9866071428571429,0.9865470852017937,1,1,1],"yaxis":"y"}],"layout":{"height":600,"legend":{"tracegroupgap":0},"shapes":[{"line":{"dash":"dash"},"type":"line","x0":0,"x1":1,"y0":1,"y1":0}],"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"title":{"text":"Precision-Recall Curve (AUC=0.8977)"},"width":800,"xaxis":{"anchor":"y","constrain":"domain","domain":[0,1],"title":{"text":"Recall"}},"yaxis":{"anchor":"x","domain":[0,1],"scaleanchor":"x","scaleratio":1,"title":{"text":"Precision"}}}},"text/html":["<div>                            <div id=\"5b515c7e-a709-46e7-b9db-8d44506fd107\" class=\"plotly-graph-div\" style=\"height:600px; width:800px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"5b515c7e-a709-46e7-b9db-8d44506fd107\")) {                    Plotly.newPlot(                        \"5b515c7e-a709-46e7-b9db-8d44506fd107\",                        [{\"fillpattern\":{\"shape\":\"\"},\"hovertemplate\":\"Recall=%{x}\\u003cbr\\u003ePrecision=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"stackgroup\":\"1\",\"x\":[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9990319457889641,0.9990319457889641,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9932236205227493,0.9932236205227493,0.9932236205227493,0.9932236205227493,0.9932236205227493,0.9932236205227493,0.9932236205227493,0.9922555663117134,0.9922555663117134,0.9922555663117134,0.9922555663117134,0.9922555663117134,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.989351403678606,0.9883833494675702,0.9874152952565344,0.9874152952565344,0.9874152952565344,0.9874152952565344,0.9874152952565344,0.9874152952565344,0.9874152952565344,0.9874152952565344,0.9874152952565344,0.9874152952565344,0.9874152952565344,0.9874152952565344,0.9864472410454985,0.9864472410454985,0.9854791868344628,0.9854791868344628,0.9854791868344628,0.9854791868344628,0.9845111326234269,0.9845111326234269,0.9845111326234269,0.9845111326234269,0.9845111326234269,0.9845111326234269,0.9845111326234269,0.9845111326234269,0.9845111326234269,0.9835430784123911,0.9825750242013552,0.9825750242013552,0.9816069699903195,0.9806389157792836,0.9806389157792836,0.9806389157792836,0.9806389157792836,0.9777347531461762,0.9767666989351403,0.9767666989351403,0.9767666989351403,0.9757986447241046,0.9748305905130688,0.9748305905130688,0.9748305905130688,0.9748305905130688,0.9748305905130688,0.9738625363020329,0.9738625363020329,0.9738625363020329,0.972894482090997,0.972894482090997,0.972894482090997,0.9719264278799613,0.9709583736689255,0.9709583736689255,0.9699903194578896,0.9699903194578896,0.9699903194578896,0.9699903194578896,0.9690222652468539,0.968054211035818,0.9670861568247822,0.9661181026137464,0.9661181026137464,0.9651500484027106,0.9651500484027106,0.9641819941916747,0.9632139399806389,0.9612778315585673,0.9603097773475314,0.9603097773475314,0.9593417231364957,0.9593417231364957,0.9593417231364957,0.9593417231364957,0.9593417231364957,0.9583736689254598,0.9583736689254598,0.9583736689254598,0.9583736689254598,0.957405614714424,0.9564375605033882,0.9554695062923524,0.9545014520813165,0.9535333978702807,0.952565343659245,0.952565343659245,0.952565343659245,0.952565343659245,0.952565343659245,0.952565343659245,0.952565343659245,0.9515972894482091,0.9506292352371732,0.9506292352371732,0.9496611810261375,0.9496611810261375,0.9496611810261375,0.9496611810261375,0.9477250726040658,0.9477250726040658,0.9467570183930301,0.9467570183930301,0.9467570183930301,0.9467570183930301,0.9467570183930301,0.9467570183930301,0.9467570183930301,0.9457889641819942,0.9457889641819942,0.9457889641819942,0.9428848015488868,0.9428848015488868,0.9428848015488868,0.9409486931268151,0.9399806389157793,0.9390125847047435,0.9390125847047435,0.9390125847047435,0.9380445304937076,0.9380445304937076,0.9380445304937076,0.9370764762826719,0.936108422071636,0.9322362052274927,0.9312681510164569,0.9303000968054211,0.9303000968054211,0.9303000968054211,0.9293320425943853,0.9283639883833494,0.9283639883833494,0.9283639883833494,0.9273959341723137,0.9264278799612778,0.9225556631171346,0.9215876089060987,0.920619554695063,0.9196515004840271,0.9196515004840271,0.9196515004840271,0.9196515004840271,0.9196515004840271,0.9196515004840271,0.9186834462729913,0.9177153920619555,0.9167473378509197,0.9157792836398838,0.9157792836398838,0.9157792836398838,0.914811229428848,0.914811229428848,0.914811229428848,0.9138431752178122,0.9138431752178122,0.9138431752178122,0.9109390125847048,0.9099709583736689,0.9099709583736689,0.9099709583736689,0.9099709583736689,0.9080348499515973,0.9070667957405615,0.9060987415295256,0.9060987415295256,0.9060987415295256,0.9051306873184899,0.904162633107454,0.9022265246853823,0.9012584704743466,0.9002904162633107,0.8993223620522749,0.8983543078412392,0.8983543078412392,0.8983543078412392,0.8983543078412392,0.8973862536302033,0.8964181994191674,0.8954501452081317,0.89351403678606,0.8925459825750242,0.8915779283639884,0.8906098741529526,0.8906098741529526,0.8896418199419167,0.888673765730881,0.888673765730881,0.888673765730881,0.8877057115198451,0.8867376573088093,0.8857696030977735,0.8848015488867377,0.8848015488867377,0.8818973862536302,0.8809293320425944,0.8799612778315585,0.8789932236205228,0.8780251694094869,0.8770571151984511,0.8760890609874153,0.8751210067763795,0.8741529525653436,0.8731848983543078,0.8731848983543078,0.8731848983543078,0.872216844143272,0.8712487899322362,0.8702807357212003,0.8693126815101646,0.8683446272991288,0.8673765730880929,0.8664085188770572,0.8654404646660213,0.8644724104549855,0.8635043562439496,0.8635043562439496,0.8625363020329139,0.861568247821878,0.861568247821878,0.8606001936108422,0.8596321393998064,0.8586640851887706,0.8586640851887706,0.8586640851887706,0.8586640851887706,0.8576960309777347,0.8576960309777347,0.856727976766699,0.8538238141335914,0.8528557599225557,0.8518877057115198,0.850919651500484,0.850919651500484,0.8499515972894482,0.8489835430784124,0.8480154888673765,0.8480154888673765,0.8470474346563408,0.8470474346563408,0.8470474346563408,0.8451113262342691,0.8441432720232332,0.8431752178121975,0.8431752178121975,0.8412391093901258,0.8373668925459826,0.8373668925459826,0.8363988383349468,0.8354307841239109,0.8344627299128751,0.8344627299128751,0.8305905130687319,0.829622458857696,0.8286544046466602,0.8276863504356244,0.8276863504356244,0.8267182962245886,0.8257502420135527,0.8247821878025169,0.8238141335914811,0.8228460793804453,0.8218780251694094,0.8209099709583737,0.8199419167473379,0.8180058083252663,0.8170377541142304,0.8170377541142304,0.8170377541142304,0.8160696999031946,0.8151016456921588,0.814133591481123,0.814133591481123,0.814133591481123,0.8131655372700871,0.8073572120038722,0.8063891577928364,0.8054211035818006,0.8044530493707648,0.8034849951597289,0.8015488867376573,0.8005808325266215,0.7967086156824782,0.7957405614714425,0.7947725072604066,0.7938044530493708,0.7928363988383349,0.7918683446272992,0.7909002904162633,0.78702807357212,0.7860600193610843,0.7850919651500484,0.7841239109390126,0.7831558567279767,0.782187802516941,0.7696030977734754,0.7686350435624395,0.7676669893514037,0.7666989351403679,0.7657308809293321,0.7657308809293321,0.7647628267182962,0.7647628267182962,0.7637947725072604,0.7628267182962246,0.7570183930300097,0.7560503388189739,0.755082284607938,0.7541142303969022,0.7541142303969022,0.7531461761858664,0.7521781219748306,0.7521781219748306,0.7512100677637947,0.750242013552759,0.7492739593417231,0.7492739593417231,0.7483059051306873,0.7473378509196515,0.7405614714424008,0.739593417231365,0.7386253630203291,0.7386253630203291,0.7376573088092934,0.7376573088092934,0.7366892545982575,0.7366892545982575,0.7357212003872217,0.7347531461761858,0.7250726040658277,0.7241045498547919,0.723136495643756,0.7221684414327202,0.7212003872216844,0.7202323330106486,0.7192642787996127,0.718296224588577,0.7173281703775412,0.7173281703775412,0.7163601161665053,0.7153920619554696,0.7153920619554696,0.7144240077444337,0.7134559535333979,0.7028073572120038,0.7018393030009681,0.7008712487899322,0.7008712487899322,0.6999031945788964,0.6999031945788964,0.6999031945788964,0.6989351403678606,0.6979670861568248,0.6969990319457889,0.6873184898354308,0.686350435624395,0.6853823814133592,0.6844143272023233,0.6834462729912875,0.6824782187802517,0.6815101645692159,0.68054211035818,0.68054211035818,0.6795740561471443,0.6786060019361084,0.6776379477250726,0.6718296224588577,0.6718296224588577,0.6708615682478218,0.6698935140367861,0.6698935140367861,0.6689254598257502,0.6679574056147144,0.6669893514036787,0.665053242981607,0.6582768635043562,0.6573088092933205,0.6563407550822846,0.6553727008712488,0.6553727008712488,0.6524685382381413,0.6515004840271055,0.6505324298160697,0.6495643756050339,0.6466602129719264,0.6456921587608906,0.6447241045498547,0.6447241045498547,0.643756050338819,0.6427879961277831,0.6418199419167473,0.6408518877057116,0.6398838334946757,0.6389157792836399,0.6379477250726041,0.6321393998063891,0.6311713455953534,0.6272991287512101,0.6263310745401742,0.6195546950629235,0.6185866408518877,0.6176185866408519,0.616650532429816,0.6156824782187803,0.6147144240077445,0.6137463697967086,0.5953533397870281,0.5953533397870281,0.5943852855759922,0.5934172313649564,0.5924491771539206,0.5914811229428848,0.5914811229428848,0.5885769603097774,0.5876089060987415,0.5866408518877058,0.5866408518877058,0.5750242013552759,0.57405614714424,0.5730880929332043,0.5721200387221684,0.5711519845111326,0.5701839303000968,0.547918683446273,0.5469506292352372,0.5459825750242013,0.5450145208131656,0.5440464666021297,0.5430784123910939,0.526621490803485,0.5256534365924492,0.5246853823814134,0.5237173281703775,0.5227492739593417,0.5217812197483059,0.5217812197483059,0.5208131655372701,0.5208131655372701,0.5198451113262342,0.5188770571151985,0.5033881897386253,0.5033881897386253,0.5024201355275896,0.5014520813165537,0.5014520813165537,0.5004840271055179,0.4995159728944821,0.48596321393998065,0.4849951597289448,0.484027105517909,0.4830590513068732,0.48209099709583736,0.48112294288480156,0.4801548886737657,0.4791868344627299,0.4782187802516941,0.47725072604065827,0.4569215876089061,0.45595353339787026,0.45498547918683446,0.45401742497579867,0.4530493707647628,0.43756050338818975,0.4365924491771539,0.4356243949661181,0.4346563407550823,0.409486931268151,0.4085188770571152,0.4075508228460794,0.40658276863504356,0.40561471442400776,0.377541142303969,0.3765730880929332,0.37560503388189737,0.3465634075508228,0.345595353339787,0.34462729912875123,0.3436592449177154,0.3426911907066796,0.3155856727976767,0.31461761858664083,0.2807357212003872,0.2797676669893514,0.2787996127783156,0.21684414327202323,0.2158760890609874,0.2149080348499516,0.21393998063891578,0.21297192642787996,0.13649564375605033,0.1355275895450145,0.0],\"xaxis\":\"x\",\"y\":[0.7341862117981521,0.7352313167259786,0.7357549857549858,0.7362794012829651,0.7368045649072753,0.7399713467048711,0.7405017921146954,0.7410329985652798,0.7442363112391931,0.7447728911319395,0.7453102453102453,0.7463872832369942,0.7469269703543022,0.7474674384949349,0.7490935460478607,0.7501815541031227,0.7507267441860465,0.7529154518950437,0.7534646243617797,0.7556693489392831,0.7562225475841874,0.7567765567765568,0.7573313782991202,0.7595588235294117,0.7601177336276674,0.7606774668630338,0.7612380250552689,0.7623616236162362,0.7629246676514032,0.7640532544378699,0.764618800888231,0.765752409191994,0.766320474777448,0.7668893838158871,0.7674591381872214,0.7691734921816828,0.7697466467958272,0.7703206562266965,0.7708955223880597,0.7714712471994025,0.7720478325859492,0.7726252804786836,0.7732035928143712,0.7737827715355805,0.7743628185907047,0.7749437359339835,0.7755255255255256,0.7753568745304282,0.7759398496240602,0.7757712565838977,0.776355421686747,0.7769404672192917,0.777526395173454,0.7781132075471698,0.7787009063444109,0.7792894935752078,0.7798789712556732,0.7804693414080243,0.781060606060606,0.7816527672479151,0.7822458270106222,0.782839787395596,0.7834346504559271,0.7840304182509505,0.784627092846271,0.7852246763137852,0.7858231707317073,0.7864225781845919,0.7900383141762453,0.7906441717791411,0.7912509593246354,0.7918586789554531,0.792467332820907,0.7936874518860662,0.7942989214175655,0.79491133384734,0.7955246913580247,0.7953667953667953,0.7959814528593508,0.7965970610982211,0.7964396284829721,0.7976744186046512,0.7982932505818464,0.7989130434782609,0.7995337995337995,0.7993779160186625,0.8012470771628994,0.8018720748829953,0.8024980483996877,0.803125,0.8037529319781079,0.8043818466353677,0.8050117462803446,0.8056426332288401,0.8062745098039216,0.8069073783359497,0.8075412411626081,0.8073899371069182,0.8080251770259638,0.8086614173228347,0.8099369085173501,0.8105761641673244,0.811216429699842,0.8118577075098814,0.8125,0.8131433095803642,0.8137876386687797,0.8144329896907216,0.8150793650793651,0.8157267672756155,0.8163751987281399,0.817024661893397,0.8176751592356688,0.8183266932270916,0.8181818181818182,0.8188347964884277,0.8194888178913738,0.8201438848920863,0.8208,0.8214571657325861,0.8221153846153846,0.8219727345629511,0.8226324237560193,0.8232931726907631,0.8239549839228296,0.82461786001609,0.8244766505636071,0.8251410153102336,0.8258064516129032,0.8264729620661824,0.827140549273021,0.8270008084074374,0.8276699029126213,0.8283400809716599,0.8290113452188006,0.829683698296837,0.8303571428571429,0.8310316815597075,0.8317073170731707,0.8323840520748577,0.8322475570032574,0.83278955954323,0.8326530612244898,0.8333333333333334,0.8340147179067866,0.8346972176759411,0.8353808353808354,0.8360655737704918,0.8367514356029533,0.8374384236453202,0.838126540673788,0.8388157894736842,0.8395061728395061,0.8401976935749588,0.8400659521846661,0.8407590759075908,0.8406275805119736,0.8413223140495868,0.8420181968569065,0.8427152317880795,0.8425849212924607,0.8432835820895522,0.8439834024896266,0.8446843853820598,0.8453865336658354,0.846089850249584,0.8475,0.8482068390325271,0.8489148580968281,0.8487886382623224,0.8486622073578596,0.8493723849372385,0.8492462311557789,0.8491198658843252,0.8498322147651006,0.8505457598656591,0.8512605042016806,0.8508845829823083,0.8507588532883642,0.8514767932489451,0.8521959459459459,0.8520710059171598,0.8519458544839256,0.8526672311600338,0.8533898305084746,0.8541136556403732,0.8548387096774194,0.8547153780798641,0.8554421768707483,0.8561702127659574,0.8560477001703578,0.8567774936061381,0.8575085324232082,0.8573868488471392,0.8572649572649572,0.8579982891360137,0.8578767123287672,0.8586118251928021,0.8593481989708405,0.8600858369098713,0.8599656357388317,0.8598452278589854,0.8597246127366609,0.859603789836348,0.8603448275862069,0.8602243313201036,0.8609671848013817,0.8608470181503889,0.860726643598616,0.8619791666666666,0.8618592528236316,0.8626086956521739,0.8624891209747607,0.8632404181184669,0.8639930252833479,0.8647469458987783,0.8655021834061135,0.8653846153846154,0.8661417322834646,0.8669001751313485,0.8676599474145487,0.8675438596491228,0.8674275680421423,0.867311072056239,0.8679577464788732,0.8678414096916299,0.8677248677248677,0.8684907325684025,0.8692579505300353,0.870026525198939,0.8707964601769912,0.8715677590788308,0.8723404255319149,0.8722271517302573,0.872113676731794,0.8728888888888889,0.8727758007117438,0.8735529830810329,0.8743315508021391,0.8751115075825157,0.8748882931188561,0.8756708407871199,0.8755595344673232,0.8763440860215054,0.8771300448430494,0.8779174147217235,0.8787061994609164,0.8794964028776978,0.8802880288028803,0.8801801801801802,0.8809738503155996,0.881768953068592,0.8822463768115942,0.8830462375339981,0.8838475499092558,0.8836363636363637,0.8835304822565969,0.8834244080145719,0.8842297174111212,0.885036496350365,0.8849315068493151,0.8857404021937842,0.8865507776761208,0.8864468864468864,0.8863428047662695,0.8867403314917127,0.8866359447004608,0.8865313653136532,0.8873499538319483,0.8881700554528651,0.8880666049953746,0.887962962962963,0.8887859128822985,0.8896103896103896,0.8895078922934077,0.8894052044609665,0.8889925373134329,0.8888888888888888,0.888785046728972,0.8886810102899907,0.8895131086142322,0.8903467666354264,0.8911819887429644,0.892018779342723,0.8928571428571429,0.8927563499529633,0.8934967012252591,0.8933962264150943,0.8932955618508026,0.8941398865784499,0.8949858088930936,0.8948863636363636,0.8957345971563981,0.896584440227704,0.8964862298195632,0.8973384030418251,0.8981921979067554,0.8979007633587787,0.897803247373448,0.8986615678776291,0.8995215311004785,0.9003831417624522,0.9001919385796545,0.9000960614793467,0.9,0.9008662175168431,0.9017341040462428,0.9016393442622951,0.9015444015444015,0.9022265246853823,0.9021317829457365,0.9020368574199806,0.9019417475728155,0.901846452866861,0.9027237354085603,0.9036027263875365,0.9044834307992202,0.904390243902439,0.904296875,0.9042033235581622,0.9040156709108716,0.903921568627451,0.9038272816486752,0.9037328094302554,0.904621435594887,0.9045275590551181,0.9044334975369458,0.9053254437869822,0.9062191510365252,0.9061264822134387,0.906930693069307,0.9068384539147671,0.9067460317460317,0.9076464746772592,0.9073705179282868,0.9072781655034895,0.907185628742515,0.9070929070929071,0.907,0.9069069069069069,0.906813627254509,0.9067201604814443,0.9066265060240963,0.9065326633165829,0.9074446680080482,0.9083585095669687,0.9082661290322581,0.9081735620585267,0.908080808080808,0.9079878665318504,0.9078947368421053,0.9078014184397163,0.9086294416243654,0.9085365853658537,0.9084435401831129,0.9083503054989817,0.90927624872579,0.9091836734693878,0.9090909090909091,0.9100204498977505,0.90992835209826,0.9098360655737705,0.9097435897435897,0.9106776180698152,0.9116135662898253,0.9125514403292181,0.9124613800205973,0.9134020618556701,0.913312693498452,0.9130434782608695,0.9129533678756476,0.9128630705394191,0.9127725856697819,0.9137214137214137,0.9136316337148803,0.9135416666666667,0.913451511991658,0.9144050104384134,0.9143155694879833,0.9152719665271967,0.9162303664921466,0.9160545645330536,0.9159663865546218,0.9158780231335436,0.9168421052631579,0.9166666666666666,0.9163135593220338,0.9172852598091198,0.9171974522292994,0.9171094580233794,0.9170212765957447,0.9179978700745474,0.9186295503211992,0.9185423365487674,0.9184549356223176,0.9183673469387755,0.9193548387096774,0.9192680301399354,0.9191810344827587,0.919093851132686,0.9190064794816415,0.918918918918919,0.9188311688311688,0.9187432286023836,0.9186550976138829,0.9194776931447225,0.9193899782135077,0.920392584514722,0.9213973799126638,0.921311475409836,0.9212253829321663,0.9211391018619934,0.9221491228070176,0.9231613611416026,0.9230769230769231,0.922566371681416,0.9224806201550387,0.9223946784922394,0.9223085460599334,0.9222222222222223,0.9220489977728286,0.9219620958751393,0.921612541993281,0.92152466367713,0.9214365881032548,0.9213483146067416,0.9212598425196851,0.9211711711711712,0.9210822998872604,0.9228149829738933,0.9227272727272727,0.9226393629124005,0.9225512528473804,0.9224629418472063,0.9223744292237442,0.9254947613504074,0.9254079254079254,0.9253208868144691,0.9252336448598131,0.9251461988304094,0.9262295081967213,0.9261430246189918,0.9272300469483568,0.927144535840188,0.9270588235294117,0.932061978545888,0.931980906921241,0.931899641577061,0.9318181818181818,0.932934131736527,0.9328537170263789,0.9327731092436975,0.9338942307692307,0.9338146811070999,0.9337349397590361,0.9336550060313631,0.9359129383313181,0.9358353510895884,0.9357575757575758,0.9363525091799265,0.9362745098039216,0.9361963190184049,0.9373464373464373,0.9372693726937269,0.9384236453201971,0.938347718865598,0.9395061728395062,0.9394313967861557,0.9393564356435643,0.9397741530740276,0.9396984924623115,0.939622641509434,0.9395465994962217,0.9394703656998739,0.9393939393939394,0.9393173198482933,0.9392405063291139,0.9391634980988594,0.9403553299492385,0.940279542566709,0.9402035623409669,0.9414012738853503,0.9413265306122449,0.9412515964240102,0.9404145077720207,0.940337224383917,0.9402597402597402,0.94148244473342,0.94140625,0.9426336375488917,0.943864229765013,0.9437908496732026,0.943717277486911,0.9436435124508519,0.9454061251664447,0.9453333333333334,0.945260347129506,0.9451871657754011,0.9451137884872824,0.9450402144772118,0.9449664429530201,0.9448924731182796,0.946164199192463,0.9460916442048517,0.9460188933873145,0.9459459459459459,0.9455040871934605,0.946793997271487,0.9467213114754098,0.9466484268125855,0.947945205479452,0.9478737997256516,0.9478021978021978,0.9477303988995873,0.9475862068965517,0.9483960948396095,0.9483240223463687,0.9482517482517483,0.9481792717086834,0.9495091164095372,0.9492957746478873,0.9492242595204513,0.9491525423728814,0.9504249291784702,0.9502133712660028,0.9501424501424501,0.9500713266761769,0.9514285714285714,0.9513590844062947,0.9512893982808023,0.9512195121951219,0.9511494252873564,0.9510791366906475,0.9510086455331412,0.950937950937951,0.9518950437317785,0.9518248175182482,0.9515418502202643,0.9514705882352941,0.950965824665676,0.9508928571428571,0.9508196721311475,0.9507462686567164,0.9506726457399103,0.9505988023952096,0.9505247376311844,0.9520123839009288,0.9534883720930233,0.953416149068323,0.9533437013996889,0.9532710280373832,0.953198127925117,0.9546875,0.9544740973312402,0.9544025157232704,0.9543307086614173,0.9558359621451105,0.9580645161290322,0.9579967689822294,0.9579288025889967,0.9578606158833063,0.9577922077922078,0.9577235772357724,0.9576988155668359,0.9576271186440678,0.9575551782682513,0.9574829931972789,0.9574105621805792,0.9573378839590444,0.9594356261022927,0.9593639575971732,0.95929203539823,0.9592198581560284,0.9591474245115453,0.9590747330960854,0.9607843137254902,0.9607142857142857,0.962432915921288,0.9623655913978495,0.9622980251346499,0.9647495361781077,0.966542750929368,0.9664804469273743,0.9664179104477612,0.9682242990654205,0.9681647940074907,0.9699248120300752,0.9691119691119691,0.9690522243713733,0.9689922480620154,0.9689320388349515,0.9688715953307393,0.9688109161793372,0.96875,0.9686888454011742,0.9705304518664047,0.9704724409448819,0.9691991786447639,0.9691358024691358,0.9690721649484536,0.96900826446281,0.968944099378882,0.9678800856531049,0.9678111587982833,0.967741935483871,0.9676724137931034,0.9701834862385321,0.9701149425287356,0.9700460829493087,0.9699769053117783,0.9699074074074074,0.9701492537313433,0.970074812967581,0.97,0.9728260869565217,0.9727520435967303,0.9726775956284153,0.9726027397260274,0.9725274725274725,0.978978978978979,0.9789156626506024,0.9797297297297297,0.9796610169491525,0.9795918367346939,0.9824561403508771,0.9823788546255506,0.9866666666666667,0.9866071428571429,0.9865470852017937,1.0,1.0,1.0],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Recall\"},\"constrain\":\"domain\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Precision\"},\"scaleanchor\":\"x\",\"scaleratio\":1},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Precision-Recall Curve (AUC=0.8977)\"},\"height\":600,\"width\":800,\"shapes\":[{\"line\":{\"dash\":\"dash\"},\"type\":\"line\",\"x0\":0,\"x1\":1,\"y0\":1,\"y1\":0}],\"showlegend\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('5b515c7e-a709-46e7-b9db-8d44506fd107');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"}],"source":["target_score = forest_clf.predict_proba(features_valid)[:, 1]\n","\n","fpr, tpr, thresholds = roc_curve(target_valid, target_score)\n","\n","fig = px.area(\n","    x=fpr, y=tpr,\n","    title=f'ROC Curve (AUC={auc(fpr, tpr):.4f})',\n","    labels=dict(x='False Positive Rate', y='True Positive Rate'),\n","    width=800, height=600\n",")\n","fig.add_shape(\n","    type='line', line=dict(dash='dash'),\n","    x0=0, x1=1, y0=0, y1=1\n",")\n","\n","fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n","fig.update_xaxes(constrain='domain')\n","fig.update_layout(showlegend=False)\n","fig.show()\n","\n","precision, recall, thresholds = precision_recall_curve(target_valid, target_score)\n","\n","fig = px.area(\n","    x=recall, y=precision,\n","    title=f'Precision-Recall Curve (AUC={auc(fpr, tpr):.4f})',\n","    labels=dict(x='Recall', y='Precision'),\n","    width=800, height=600\n",")\n","fig.add_shape(\n","    type='line', line=dict(dash='dash'),\n","    x0=0, x1=1, y0=1, y1=0\n",")\n","fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n","fig.update_xaxes(constrain='domain')\n","fig.update_layout(showlegend=False)\n","fig.show()"]},{"cell_type":"markdown","metadata":{},"source":["-----------"]},{"cell_type":"markdown","metadata":{},"source":["# Decision Tree"]},{"cell_type":"code","execution_count":69,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T16:51:29.110557Z","iopub.status.busy":"2023-11-30T16:51:29.110290Z","iopub.status.idle":"2023-11-30T16:51:33.787645Z","shell.execute_reply":"2023-11-30T16:51:33.786705Z","shell.execute_reply.started":"2023-11-30T16:51:29.110532Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Runtime:\n","CPU times: user 166 ms, sys: 55.5 ms, total: 221 ms\n","Wall time: 1.07 s\n"]}],"source":["%%time\n","tree_model = DecisionTreeClassifier(random_state=random_state)\n","tree_parameters = [{'max_depth': [2,6,12,18,22,35],\n","                     'min_samples_split': [2,6,12],\n","                     \"criterion\": ['gini', 'entropy', 'log_loss'],\n","                     \"splitter\": ['best', 'random'],\n","                   }]\n","\n","tree_clf = RandomizedSearchCV(tree_model, tree_parameters, scoring='roc_auc', n_jobs=-1, cv=cv)\n","tree_clf.fit(features_train, target_train)\n","# create a variable for the best model\n","best_tree = tree_clf.best_estimator_\n","tree_pred = best_tree.predict(features_valid)\n","print('Runtime:')"]},{"cell_type":"code","execution_count":70,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 1000x500 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["sns.set(style=\"white\", color_codes=True)\n","plt.rcParams['axes.linewidth'] = 0.1\n","\n","fig, ax = plt.subplots(figsize = (10,5))\n","disp = CalibrationDisplay.from_estimator(tree_clf, features_valid, target_valid, ax=ax)\n","plt.title('Calibration Chart - Decision Tree Classifier', fontsize=10)\n","ax.set_xlabel('Mean predicted probability (Positive class: 1)', fontsize=10)\n","ax.set_ylabel('Fraction of positives (Positive class: 1)',fontsize=10)\n","\n","ax.tick_params(color='gray', labelcolor='gray')\n","for spine in ax.spines.values():\n","    spine.set_edgecolor('gray')\n","\n","\n","fig.tight_layout()\n","plt.legend(fontsize=8)\n","plt.show()"]},{"cell_type":"code","execution_count":71,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T16:51:33.789028Z","iopub.status.busy":"2023-11-30T16:51:33.788754Z","iopub.status.idle":"2023-11-30T16:51:35.084919Z","shell.execute_reply":"2023-11-30T16:51:35.083993Z","shell.execute_reply.started":"2023-11-30T16:51:33.789006Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Cross Validation Scores: [0.76152018 0.74971198 0.77724654 0.72453917 0.77750576 0.78245968\n"," 0.74115783 0.74190668 0.79236015 0.72746186 0.74220294 0.7484735\n"," 0.76621544 0.69415323 0.75256336 0.74637097 0.73545507 0.74104263\n"," 0.8058108  0.75062124 0.73454191 0.78245968 0.76794355 0.73459101\n"," 0.75207373 0.79585253 0.73185484 0.78493664 0.76518435 0.74007455\n"," 0.7264513  0.74104263 0.75368664 0.72404954 0.79014977 0.75889977\n"," 0.78332373 0.74003456 0.72344545 0.74576687 0.73530086 0.76422811\n"," 0.72690092 0.70259217 0.71362327 0.78741359 0.76782834 0.79634217\n"," 0.75307732 0.77009651]\n"]}],"source":["tree_scores = cross_val_score(tree_model, features_train, target_train, cv=cv, scoring='roc_auc')\n","print('Cross Validation Scores: {}'.format(tree_scores))"]},{"cell_type":"code","execution_count":72,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T16:51:35.086379Z","iopub.status.busy":"2023-11-30T16:51:35.086103Z","iopub.status.idle":"2023-11-30T16:51:35.097642Z","shell.execute_reply":"2023-11-30T16:51:35.096722Z","shell.execute_reply.started":"2023-11-30T16:51:35.086355Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Best hyperparameters: {'splitter': 'random', 'min_samples_split': 12, 'max_depth': 6, 'criterion': 'gini'}\n","\n","Best score: 0.8243687408349147\n","\n","Average Cross Validation Score: 0.7530509062867848\n","\n","ROC AUC Score - Validation Dataset: 0.8430742709827044\n"]}],"source":["# summary\n","print('Best hyperparameters:',  tree_clf.best_params_)\n","print()\n","print('Best score:',  tree_clf.best_score_)\n","print()\n","print('Average Cross Validation Score: {}'.format(tree_scores.mean()))\n","print()\n","print('ROC AUC Score - Validation Dataset:',  roc_auc_score(target_valid, tree_clf.predict_proba(features_valid)[:, 1]))"]},{"cell_type":"markdown","metadata":{},"source":["# ROC AUC Curve - DecisionTreeClassifier"]},{"cell_type":"code","execution_count":73,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T16:51:35.099923Z","iopub.status.busy":"2023-11-30T16:51:35.099527Z","iopub.status.idle":"2023-11-30T16:51:35.224449Z","shell.execute_reply":"2023-11-30T16:51:35.223687Z","shell.execute_reply.started":"2023-11-30T16:51:35.099892Z"},"trusted":true},"outputs":[{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"fillpattern":{"shape":""},"hovertemplate":"False Positive Rate=%{x}<br>True Positive Rate=%{y}<extra></extra>","legendgroup":"","line":{"color":"#636efa"},"marker":{"symbol":"circle"},"mode":"lines","name":"","orientation":"v","showlegend":false,"stackgroup":"1","type":"scatter","x":[0,0.034759358288770054,0.0374331550802139,0.0374331550802139,0.0427807486631016,0.0427807486631016,0.0427807486631016,0.0427807486631016,0.045454545454545456,0.045454545454545456,0.0481283422459893,0.0748663101604278,0.07754010695187166,0.08021390374331551,0.08288770053475936,0.08288770053475936,0.08288770053475936,0.09358288770053476,0.0962566844919786,0.10160427807486631,0.15775401069518716,0.16042780748663102,0.20320855614973263,0.24598930481283424,0.24598930481283424,0.2700534759358289,0.2727272727272727,0.2727272727272727,0.2807486631016043,0.44385026737967914,0.44385026737967914,0.6363636363636364,0.6390374331550802,0.6711229946524064,1],"xaxis":"x","y":[0,0.24104549854791868,0.2846079380445305,0.32526621490803487,0.35237173281703776,0.3862536302032914,0.40658276863504356,0.409486931268151,0.4259438528557599,0.43756050338818975,0.4530493707647628,0.5333978702807357,0.5450145208131656,0.5701839303000968,0.5779283639883833,0.5914811229428848,0.5924491771539206,0.6050338818973863,0.6089060987415296,0.6176185866408519,0.6824782187802517,0.6989351403678606,0.7666989351403679,0.7899322362052275,0.7909002904162633,0.8063891577928364,0.8151016456921588,0.8170377541142304,0.8238141335914811,0.8877057115198451,0.8906098741529526,0.9564375605033882,0.9603097773475314,0.9661181026137464,1],"yaxis":"y"}],"layout":{"height":600,"legend":{"tracegroupgap":0},"shapes":[{"line":{"dash":"dash"},"type":"line","x0":0,"x1":1,"y0":0,"y1":1}],"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"title":{"text":"ROC Curve (AUC=0.8431)"},"width":800,"xaxis":{"anchor":"y","constrain":"domain","domain":[0,1],"title":{"text":"False Positive Rate"}},"yaxis":{"anchor":"x","domain":[0,1],"scaleanchor":"x","scaleratio":1,"title":{"text":"True Positive Rate"}}}},"text/html":["<div>                            <div id=\"39c35689-c6bf-4421-9f90-61f505f16242\" class=\"plotly-graph-div\" style=\"height:600px; width:800px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"39c35689-c6bf-4421-9f90-61f505f16242\")) {                    Plotly.newPlot(                        \"39c35689-c6bf-4421-9f90-61f505f16242\",                        [{\"fillpattern\":{\"shape\":\"\"},\"hovertemplate\":\"False Positive Rate=%{x}\\u003cbr\\u003eTrue Positive Rate=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"stackgroup\":\"1\",\"x\":[0.0,0.034759358288770054,0.0374331550802139,0.0374331550802139,0.0427807486631016,0.0427807486631016,0.0427807486631016,0.0427807486631016,0.045454545454545456,0.045454545454545456,0.0481283422459893,0.0748663101604278,0.07754010695187166,0.08021390374331551,0.08288770053475936,0.08288770053475936,0.08288770053475936,0.09358288770053476,0.0962566844919786,0.10160427807486631,0.15775401069518716,0.16042780748663102,0.20320855614973263,0.24598930481283424,0.24598930481283424,0.2700534759358289,0.2727272727272727,0.2727272727272727,0.2807486631016043,0.44385026737967914,0.44385026737967914,0.6363636363636364,0.6390374331550802,0.6711229946524064,1.0],\"xaxis\":\"x\",\"y\":[0.0,0.24104549854791868,0.2846079380445305,0.32526621490803487,0.35237173281703776,0.3862536302032914,0.40658276863504356,0.409486931268151,0.4259438528557599,0.43756050338818975,0.4530493707647628,0.5333978702807357,0.5450145208131656,0.5701839303000968,0.5779283639883833,0.5914811229428848,0.5924491771539206,0.6050338818973863,0.6089060987415296,0.6176185866408519,0.6824782187802517,0.6989351403678606,0.7666989351403679,0.7899322362052275,0.7909002904162633,0.8063891577928364,0.8151016456921588,0.8170377541142304,0.8238141335914811,0.8877057115198451,0.8906098741529526,0.9564375605033882,0.9603097773475314,0.9661181026137464,1.0],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"False Positive Rate\"},\"constrain\":\"domain\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"True Positive Rate\"},\"scaleanchor\":\"x\",\"scaleratio\":1},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"ROC Curve (AUC=0.8431)\"},\"height\":600,\"width\":800,\"shapes\":[{\"line\":{\"dash\":\"dash\"},\"type\":\"line\",\"x0\":0,\"x1\":1,\"y0\":0,\"y1\":1}],\"showlegend\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('39c35689-c6bf-4421-9f90-61f505f16242');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"fillpattern":{"shape":""},"hovertemplate":"Recall=%{x}<br>Precision=%{y}<extra></extra>","legendgroup":"","line":{"color":"#636efa"},"marker":{"symbol":"circle"},"mode":"lines","name":"","orientation":"v","showlegend":false,"stackgroup":"1","type":"scatter","x":[1,0.9661181026137464,0.9603097773475314,0.9564375605033882,0.8906098741529526,0.8877057115198451,0.8238141335914811,0.8170377541142304,0.8151016456921588,0.8063891577928364,0.7909002904162633,0.7899322362052275,0.7666989351403679,0.6989351403678606,0.6824782187802517,0.6176185866408519,0.6089060987415296,0.6050338818973863,0.5924491771539206,0.5914811229428848,0.5779283639883833,0.5701839303000968,0.5450145208131656,0.5333978702807357,0.4530493707647628,0.43756050338818975,0.4259438528557599,0.409486931268151,0.40658276863504356,0.3862536302032914,0.35237173281703776,0.32526621490803487,0.2846079380445305,0.24104549854791868,0],"xaxis":"x","y":[0.7341862117981521,0.7990392313851081,0.8058489033306255,0.8058727569331158,0.8471454880294659,0.8467220683287165,0.8901673640167364,0.8921775898520085,0.8919491525423728,0.8918629550321199,0.8987898789878987,0.8986784140969163,0.9124423963133641,0.9232736572890026,0.9227748691099477,0.9437869822485208,0.9458646616541353,0.946969696969697,0.9517884914463453,0.9517133956386293,0.9506369426751592,0.9515347334410339,0.9510135135135135,0.9516407599309153,0.9629629629629629,0.9637526652452025,0.962800875273523,0.9635535307517085,0.963302752293578,0.9614457831325302,0.9578947368421052,0.96,0.9545454545454546,0.950381679389313,1],"yaxis":"y"}],"layout":{"height":600,"legend":{"tracegroupgap":0},"shapes":[{"line":{"dash":"dash"},"type":"line","x0":0,"x1":1,"y0":1,"y1":0}],"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"title":{"text":"Precision-Recall Curve (AUC=0.8431)"},"width":800,"xaxis":{"anchor":"y","constrain":"domain","domain":[0,1],"title":{"text":"Recall"}},"yaxis":{"anchor":"x","domain":[0,1],"scaleanchor":"x","scaleratio":1,"title":{"text":"Precision"}}}},"text/html":["<div>                            <div id=\"7fcf6b8a-65f4-4195-942b-1f43b525586e\" class=\"plotly-graph-div\" style=\"height:600px; width:800px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"7fcf6b8a-65f4-4195-942b-1f43b525586e\")) {                    Plotly.newPlot(                        \"7fcf6b8a-65f4-4195-942b-1f43b525586e\",                        [{\"fillpattern\":{\"shape\":\"\"},\"hovertemplate\":\"Recall=%{x}\\u003cbr\\u003ePrecision=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"stackgroup\":\"1\",\"x\":[1.0,0.9661181026137464,0.9603097773475314,0.9564375605033882,0.8906098741529526,0.8877057115198451,0.8238141335914811,0.8170377541142304,0.8151016456921588,0.8063891577928364,0.7909002904162633,0.7899322362052275,0.7666989351403679,0.6989351403678606,0.6824782187802517,0.6176185866408519,0.6089060987415296,0.6050338818973863,0.5924491771539206,0.5914811229428848,0.5779283639883833,0.5701839303000968,0.5450145208131656,0.5333978702807357,0.4530493707647628,0.43756050338818975,0.4259438528557599,0.409486931268151,0.40658276863504356,0.3862536302032914,0.35237173281703776,0.32526621490803487,0.2846079380445305,0.24104549854791868,0.0],\"xaxis\":\"x\",\"y\":[0.7341862117981521,0.7990392313851081,0.8058489033306255,0.8058727569331158,0.8471454880294659,0.8467220683287165,0.8901673640167364,0.8921775898520085,0.8919491525423728,0.8918629550321199,0.8987898789878987,0.8986784140969163,0.9124423963133641,0.9232736572890026,0.9227748691099477,0.9437869822485208,0.9458646616541353,0.946969696969697,0.9517884914463453,0.9517133956386293,0.9506369426751592,0.9515347334410339,0.9510135135135135,0.9516407599309153,0.9629629629629629,0.9637526652452025,0.962800875273523,0.9635535307517085,0.963302752293578,0.9614457831325302,0.9578947368421052,0.96,0.9545454545454546,0.950381679389313,1.0],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Recall\"},\"constrain\":\"domain\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Precision\"},\"scaleanchor\":\"x\",\"scaleratio\":1},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Precision-Recall Curve (AUC=0.8431)\"},\"height\":600,\"width\":800,\"shapes\":[{\"line\":{\"dash\":\"dash\"},\"type\":\"line\",\"x0\":0,\"x1\":1,\"y0\":1,\"y1\":0}],\"showlegend\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('7fcf6b8a-65f4-4195-942b-1f43b525586e');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"}],"source":["target_score = tree_clf.predict_proba(features_valid)[:, 1]\n","\n","fpr, tpr, thresholds = roc_curve(target_valid, target_score)\n","\n","fig = px.area(\n","    x=fpr, y=tpr,\n","    title=f'ROC Curve (AUC={auc(fpr, tpr):.4f})',\n","    labels=dict(x='False Positive Rate', y='True Positive Rate'),\n","    width=800, height=600\n",")\n","fig.add_shape(\n","    type='line', line=dict(dash='dash'),\n","    x0=0, x1=1, y0=0, y1=1\n",")\n","\n","fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n","fig.update_xaxes(constrain='domain')\n","fig.update_layout(showlegend=False)\n","fig.show()\n","\n","precision, recall, thresholds = precision_recall_curve(target_valid, target_score)\n","\n","fig = px.area(\n","    x=recall, y=precision,\n","    title=f'Precision-Recall Curve (AUC={auc(fpr, tpr):.4f})',\n","    labels=dict(x='Recall', y='Precision'),\n","    width=800, height=600\n",")\n","fig.add_shape(\n","    type='line', line=dict(dash='dash'),\n","    x0=0, x1=1, y0=1, y1=0\n",")\n","fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n","fig.update_xaxes(constrain='domain')\n","fig.update_layout(showlegend=False)\n","fig.show()"]},{"cell_type":"markdown","metadata":{},"source":["-----------"]},{"cell_type":"markdown","metadata":{},"source":["# Extra Trees"]},{"cell_type":"code","execution_count":74,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T16:51:35.225674Z","iopub.status.busy":"2023-11-30T16:51:35.225423Z","iopub.status.idle":"2023-11-30T16:52:58.400487Z","shell.execute_reply":"2023-11-30T16:52:58.399533Z","shell.execute_reply.started":"2023-11-30T16:51:35.225641Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Runtime:\n","CPU times: user 769 ms, sys: 364 ms, total: 1.13 s\n","Wall time: 13.3 s\n"]}],"source":["%%time\n","extra_trees_model = ExtraTreesClassifier(random_state=random_state)\n","extra_trees_parameters = [{'max_depth': [2,6,8,12,18,30],\n","                     'min_samples_split': [2,6,8,12],\n","                     \"criterion\": ['gini', 'entropy', 'log_loss'],\n","                     \"warm_start\": [True, False],\n","                     'n_estimators': [50,100,200]}]\n","\n","extra_trees_clf = RandomizedSearchCV(extra_trees_model, extra_trees_parameters, scoring='roc_auc', n_jobs=-1, cv=cv)\n","extra_trees_clf.fit(features_train, target_train)\n","# create a variable for the best model\n","best_ext = extra_trees_clf.best_estimator_\n","ext_pred = best_ext.predict(features_valid)\n","print('Runtime:')"]},{"cell_type":"code","execution_count":75,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 1000x500 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["sns.set(style=\"white\", color_codes=True)\n","plt.rcParams['axes.linewidth'] = 0.1\n","\n","fig, ax = plt.subplots(figsize = (10,5))\n","disp = CalibrationDisplay.from_estimator(extra_trees_clf, features_valid, target_valid, ax=ax)\n","plt.title('Calibration Chart - Extra Trees Classifier', fontsize=10)\n","ax.set_xlabel('Mean predicted probability (Positive class: 1)', fontsize=10)\n","ax.set_ylabel('Fraction of positives (Positive class: 1)',fontsize=10)\n","\n","ax.tick_params(color='gray', labelcolor='gray')\n","for spine in ax.spines.values():\n","    spine.set_edgecolor('gray')\n","\n","\n","fig.tight_layout()\n","plt.legend(fontsize=8)\n","plt.show()"]},{"cell_type":"code","execution_count":76,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T16:52:58.402048Z","iopub.status.busy":"2023-11-30T16:52:58.401764Z","iopub.status.idle":"2023-11-30T16:53:23.273446Z","shell.execute_reply":"2023-11-30T16:53:23.272464Z","shell.execute_reply.started":"2023-11-30T16:52:58.402022Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Cross Validation Scores: [0.86500845 0.83686636 0.85711406 0.82880184 0.84677419 0.84474366\n"," 0.8422235  0.8139977  0.87829404 0.86738615 0.8049947  0.83702477\n"," 0.86673387 0.8265553  0.86496256 0.83313652 0.86828917 0.83366935\n"," 0.8825994  0.83418574 0.83532377 0.86350806 0.86647465 0.85596198\n"," 0.83706797 0.87138537 0.86238479 0.8671803  0.83862113 0.79510518\n"," 0.84864106 0.82436636 0.8405962  0.86353687 0.86965726 0.85709965\n"," 0.84448445 0.85020161 0.85273636 0.85234628 0.85839276 0.85734447\n"," 0.82521601 0.82070853 0.83175403 0.84179147 0.85817972 0.86784274\n"," 0.8469718  0.86162159]\n"]}],"source":["extra_trees_scores = cross_val_score(extra_trees_model, features_train, target_train, cv=cv, scoring='roc_auc')\n","print('Cross Validation Scores: {}'.format(extra_trees_scores))"]},{"cell_type":"code","execution_count":77,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T16:53:23.274951Z","iopub.status.busy":"2023-11-30T16:53:23.274646Z","iopub.status.idle":"2023-11-30T16:53:23.354259Z","shell.execute_reply":"2023-11-30T16:53:23.353326Z","shell.execute_reply.started":"2023-11-30T16:53:23.274927Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Best hyperparameters: {'warm_start': True, 'n_estimators': 100, 'min_samples_split': 12, 'max_depth': 30, 'criterion': 'log_loss'}\n","\n","Best score: 0.8557071883616962\n","\n","Average Cross Validation Score: 0.8479972754101266\n","\n","ROC AUC Score - Validation Dataset: 0.8818637373104659\n"]}],"source":["# summary\n","print('Best hyperparameters:',  extra_trees_clf.best_params_)\n","print()\n","print('Best score:',  extra_trees_clf.best_score_)\n","print()\n","print('Average Cross Validation Score: {}'.format(extra_trees_scores.mean()))\n","print()\n","print('ROC AUC Score - Validation Dataset:',  roc_auc_score(target_valid, extra_trees_clf.predict_proba(features_valid)[:, 1]))"]},{"cell_type":"markdown","metadata":{},"source":["# ROC AUC Curve - ExtraTreesClassifier"]},{"cell_type":"code","execution_count":78,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T16:53:23.356396Z","iopub.status.busy":"2023-11-30T16:53:23.356005Z","iopub.status.idle":"2023-11-30T16:53:23.560598Z","shell.execute_reply":"2023-11-30T16:53:23.559701Z","shell.execute_reply.started":"2023-11-30T16:53:23.356359Z"},"trusted":true},"outputs":[{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"fillpattern":{"shape":""},"hovertemplate":"False Positive Rate=%{x}<br>True Positive Rate=%{y}<extra></extra>","legendgroup":"","line":{"color":"#636efa"},"marker":{"symbol":"circle"},"mode":"lines","name":"","orientation":"v","showlegend":false,"stackgroup":"1","type":"scatter","x":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.00267379679144385,0.00267379679144385,0.0053475935828877,0.0053475935828877,0.008021390374331552,0.008021390374331552,0.0106951871657754,0.0106951871657754,0.013368983957219251,0.013368983957219251,0.016042780748663103,0.016042780748663103,0.01871657754010695,0.01871657754010695,0.0213903743315508,0.0213903743315508,0.02406417112299465,0.02406417112299465,0.026737967914438502,0.026737967914438502,0.026737967914438502,0.026737967914438502,0.029411764705882353,0.029411764705882353,0.03208556149732621,0.03208556149732621,0.034759358288770054,0.034759358288770054,0.0374331550802139,0.0374331550802139,0.040106951871657755,0.040106951871657755,0.0427807486631016,0.0427807486631016,0.045454545454545456,0.045454545454545456,0.0481283422459893,0.0481283422459893,0.05080213903743316,0.05080213903743316,0.053475935828877004,0.053475935828877004,0.05614973262032086,0.05614973262032086,0.058823529411764705,0.058823529411764705,0.06149732620320856,0.06149732620320856,0.06417112299465241,0.06417112299465241,0.06684491978609626,0.06684491978609626,0.06951871657754011,0.06951871657754011,0.07219251336898395,0.07219251336898395,0.0748663101604278,0.0748663101604278,0.07754010695187166,0.07754010695187166,0.08288770053475936,0.08288770053475936,0.0855614973262032,0.0855614973262032,0.08823529411764706,0.08823529411764706,0.09090909090909091,0.09090909090909091,0.09358288770053476,0.09358288770053476,0.0962566844919786,0.0962566844919786,0.09893048128342247,0.09893048128342247,0.10160427807486631,0.10160427807486631,0.10427807486631016,0.10427807486631016,0.10695187165775401,0.10695187165775401,0.11229946524064172,0.11229946524064172,0.11764705882352941,0.11764705882352941,0.12032085561497326,0.12032085561497326,0.12299465240641712,0.12299465240641712,0.12566844919786097,0.12566844919786097,0.12834224598930483,0.12834224598930483,0.13101604278074866,0.13101604278074866,0.13368983957219252,0.13368983957219252,0.13636363636363635,0.13636363636363635,0.13903743315508021,0.13903743315508021,0.14171122994652408,0.14171122994652408,0.1443850267379679,0.1443850267379679,0.14705882352941177,0.14705882352941177,0.1497326203208556,0.1497326203208556,0.15240641711229946,0.15240641711229946,0.15775401069518716,0.15775401069518716,0.16042780748663102,0.16042780748663102,0.16310160427807488,0.16310160427807488,0.1657754010695187,0.1657754010695187,0.16844919786096257,0.16844919786096257,0.1711229946524064,0.1711229946524064,0.17379679144385027,0.17379679144385027,0.17647058823529413,0.17647058823529413,0.18181818181818182,0.18181818181818182,0.18449197860962566,0.18449197860962566,0.18716577540106952,0.18716577540106952,0.1925133689839572,0.1925133689839572,0.19518716577540107,0.19518716577540107,0.19786096256684493,0.19786096256684493,0.20320855614973263,0.20320855614973263,0.20588235294117646,0.20588235294117646,0.20855614973262032,0.20855614973262032,0.21122994652406418,0.21122994652406418,0.21390374331550802,0.21390374331550802,0.21657754010695188,0.21657754010695188,0.22727272727272727,0.22727272727272727,0.22994652406417113,0.22994652406417113,0.232620320855615,0.232620320855615,0.23796791443850268,0.23796791443850268,0.24064171122994651,0.24064171122994651,0.24331550802139038,0.24331550802139038,0.24598930481283424,0.24598930481283424,0.25133689839572193,0.25133689839572193,0.25668449197860965,0.25668449197860965,0.25935828877005346,0.25935828877005346,0.2620320855614973,0.2620320855614973,0.2647058823529412,0.2647058823529412,0.26737967914438504,0.26737967914438504,0.2700534759358289,0.2700534759358289,0.27807486631016043,0.27807486631016043,0.28609625668449196,0.28609625668449196,0.2914438502673797,0.2914438502673797,0.29411764705882354,0.29411764705882354,0.2967914438502674,0.2967914438502674,0.2994652406417112,0.2994652406417112,0.30213903743315507,0.30213903743315507,0.3074866310160428,0.3074866310160428,0.31016042780748665,0.31016042780748665,0.3155080213903743,0.3155080213903743,0.32620320855614976,0.32620320855614976,0.3342245989304813,0.3342245989304813,0.33689839572192515,0.33689839572192515,0.34759358288770054,0.34759358288770054,0.3502673796791444,0.3502673796791444,0.35294117647058826,0.35294117647058826,0.3582887700534759,0.3582887700534759,0.36363636363636365,0.36363636363636365,0.3663101604278075,0.3663101604278075,0.3716577540106952,0.3716577540106952,0.37433155080213903,0.37433155080213903,0.38235294117647056,0.38235294117647056,0.3877005347593583,0.3877005347593583,0.393048128342246,0.393048128342246,0.3983957219251337,0.3983957219251337,0.4037433155080214,0.4037433155080214,0.41711229946524064,0.41711229946524064,0.42245989304812837,0.42245989304812837,0.42513368983957217,0.42513368983957217,0.42780748663101603,0.42780748663101603,0.4304812834224599,0.4304812834224599,0.4358288770053476,0.4358288770053476,0.4411764705882353,0.4411764705882353,0.44919786096256686,0.44919786096256686,0.45454545454545453,0.45454545454545453,0.45989304812834225,0.45989304812834225,0.4625668449197861,0.4625668449197861,0.4786096256684492,0.4786096256684492,0.48128342245989303,0.48128342245989303,0.4839572192513369,0.4839572192513369,0.49732620320855614,0.49732620320855614,0.5213903743315508,0.5213903743315508,0.5240641711229946,0.5240641711229946,0.5294117647058824,0.5294117647058824,0.5347593582887701,0.5347593582887701,0.5374331550802139,0.5374331550802139,0.5427807486631016,0.5427807486631016,0.5481283422459893,0.5481283422459893,0.553475935828877,0.553475935828877,0.5561497326203209,0.5561497326203209,0.5588235294117647,0.5588235294117647,0.5614973262032086,0.5614973262032086,0.5641711229946524,0.5641711229946524,0.5855614973262032,0.5855614973262032,0.5962566844919787,0.5962566844919787,0.6042780748663101,0.6042780748663101,0.6363636363636364,0.6363636363636364,0.6390374331550802,0.6390374331550802,0.660427807486631,0.660427807486631,0.6657754010695187,0.6657754010695187,0.6871657754010695,0.6871657754010695,0.6925133689839572,0.6925133689839572,0.6978609625668449,0.6978609625668449,0.7005347593582888,0.7005347593582888,0.7085561497326203,0.7085561497326203,0.7219251336898396,0.7219251336898396,0.7406417112299465,0.7406417112299465,0.7700534759358288,0.7700534759358288,0.7834224598930482,0.7834224598930482,0.786096256684492,0.786096256684492,0.8021390374331551,0.8021390374331551,0.8315508021390374,0.8315508021390374,0.8342245989304813,0.8342245989304813,0.8663101604278075,0.8663101604278075,0.8850267379679144,0.8850267379679144,0.9064171122994652,0.9064171122994652,1],"xaxis":"x","y":[0,0.021297192642787996,0.022265246853823813,0.02904162633107454,0.03291384317521781,0.03388189738625363,0.03581800580832527,0.036786060019361085,0.03872216844143272,0.04065827686350436,0.044530493707647625,0.061955469506292354,0.06389157792836399,0.07163601161665054,0.07357212003872217,0.08712487899322362,0.08906098741529525,0.09970958373668926,0.10164569215876089,0.13165537270087124,0.1335914811229429,0.13746369796708616,0.13746369796708616,0.1713455953533398,0.1713455953533398,0.17618586640851888,0.17618586640851888,0.20038722168441434,0.20038722168441434,0.24878993223620524,0.24878993223620524,0.2749273959341723,0.2749273959341723,0.2787996127783156,0.2787996127783156,0.3020329138431752,0.3020329138431752,0.33688286544046464,0.33688286544046464,0.34075508228460794,0.34075508228460794,0.34462729912875123,0.3465634075508228,0.3543078412391094,0.3543078412391094,0.4075508228460794,0.4075508228460794,0.42400774443368827,0.42400774443368827,0.43852855759922554,0.43852855759922554,0.4617618586640852,0.4617618586640852,0.4791868344627299,0.4791868344627299,0.4888673765730881,0.4888673765730881,0.5072604065827686,0.5072604065827686,0.510164569215876,0.510164569215876,0.5188770571151985,0.5188770571151985,0.5256534365924492,0.5256534365924492,0.5285575992255567,0.5285575992255567,0.5324298160696999,0.5324298160696999,0.5401742497579864,0.5401742497579864,0.5508228460793805,0.5508228460793805,0.5517909002904162,0.5517909002904162,0.5595353339787028,0.5595353339787028,0.5605033881897387,0.5605033881897387,0.5614714424007744,0.5614714424007744,0.5769603097773476,0.5769603097773476,0.5818005808325266,0.5818005808325266,0.5934172313649564,0.5934172313649564,0.6001936108422071,0.6001936108422071,0.6127783155856728,0.6127783155856728,0.6205227492739593,0.6205227492739593,0.6243949661181026,0.6243949661181026,0.6263310745401742,0.6263310745401742,0.6311713455953534,0.6311713455953534,0.6379477250726041,0.6379477250726041,0.6495643756050339,0.6495643756050339,0.6524685382381413,0.6524685382381413,0.6592449177153921,0.6592449177153921,0.6698935140367861,0.6698935140367861,0.6718296224588577,0.6718296224588577,0.7057115198451114,0.7057115198451114,0.7095837366892546,0.7095837366892546,0.7105517909002904,0.7105517909002904,0.712487899322362,0.712487899322362,0.7144240077444337,0.7144240077444337,0.7212003872216844,0.7212003872216844,0.723136495643756,0.723136495643756,0.7270087124878993,0.7270087124878993,0.7279767666989352,0.7279767666989352,0.7308809293320426,0.7308809293320426,0.7454017424975798,0.7454017424975798,0.7463697967086157,0.7463697967086157,0.7483059051306873,0.7483059051306873,0.755082284607938,0.755082284607938,0.7560503388189739,0.7560503388189739,0.7579864472410455,0.7579864472410455,0.7666989351403679,0.7666989351403679,0.7686350435624395,0.7686350435624395,0.7705711519845111,0.7705711519845111,0.771539206195547,0.771539206195547,0.7725072604065828,0.7725072604065828,0.7792836398838335,0.7792836398838335,0.7831558567279767,0.7831558567279767,0.7879961277831559,0.7879961277831559,0.7889641819941917,0.7889641819941917,0.797676669893514,0.797676669893514,0.7986447241045499,0.7986447241045499,0.7996127783155856,0.7996127783155856,0.8121974830590513,0.8121974830590513,0.8228460793804453,0.8228460793804453,0.8247821878025169,0.8247821878025169,0.8267182962245886,0.8267182962245886,0.8276863504356244,0.8276863504356244,0.8286544046466602,0.8286544046466602,0.8315585672797676,0.8315585672797676,0.8334946757018393,0.8334946757018393,0.8373668925459826,0.8373668925459826,0.8402710551790901,0.8402710551790901,0.8451113262342691,0.8451113262342691,0.8586640851887706,0.8586640851887706,0.8596321393998064,0.8596321393998064,0.8625363020329139,0.8625363020329139,0.8644724104549855,0.8644724104549855,0.8741529525653436,0.8741529525653436,0.8751210067763795,0.8751210067763795,0.8760890609874153,0.8760890609874153,0.8770571151984511,0.8770571151984511,0.8789932236205228,0.8789932236205228,0.8838334946757018,0.8838334946757018,0.8857696030977735,0.8857696030977735,0.8877057115198451,0.8877057115198451,0.888673765730881,0.888673765730881,0.8906098741529526,0.8906098741529526,0.89351403678606,0.89351403678606,0.8954501452081317,0.8954501452081317,0.8964181994191674,0.8964181994191674,0.9031945788964182,0.9031945788964182,0.9051306873184899,0.9051306873184899,0.9060987415295256,0.9060987415295256,0.9138431752178122,0.9138431752178122,0.9177153920619555,0.9177153920619555,0.9186834462729913,0.9186834462729913,0.9215876089060987,0.9215876089060987,0.9225556631171346,0.9225556631171346,0.925459825750242,0.925459825750242,0.9264278799612778,0.9264278799612778,0.9283639883833494,0.9283639883833494,0.9303000968054211,0.9303000968054211,0.9322362052274927,0.9322362052274927,0.9341723136495643,0.9341723136495643,0.9351403678606002,0.9351403678606002,0.936108422071636,0.936108422071636,0.9370764762826719,0.9370764762826719,0.9390125847047435,0.9390125847047435,0.9399806389157793,0.9399806389157793,0.9409486931268151,0.9409486931268151,0.9428848015488868,0.9428848015488868,0.9438528557599225,0.9438528557599225,0.9486931268151017,0.9486931268151017,0.9496611810261375,0.9496611810261375,0.9506292352371732,0.9506292352371732,0.9515972894482091,0.9515972894482091,0.9564375605033882,0.9564375605033882,0.957405614714424,0.957405614714424,0.9583736689254598,0.9583736689254598,0.9603097773475314,0.9603097773475314,0.9612778315585673,0.9612778315585673,0.9622458857696031,0.9622458857696031,0.9641819941916747,0.9641819941916747,0.9651500484027106,0.9651500484027106,0.9661181026137464,0.9661181026137464,0.9670861568247822,0.9670861568247822,0.968054211035818,0.968054211035818,0.9690222652468539,0.9690222652468539,0.9699903194578896,0.9699903194578896,0.9709583736689255,0.9709583736689255,0.9738625363020329,0.9738625363020329,0.9748305905130688,0.9748305905130688,0.9767666989351403,0.9767666989351403,0.9777347531461762,0.9777347531461762,0.9796708615682478,0.9796708615682478,0.9806389157792836,0.9806389157792836,0.9816069699903195,0.9816069699903195,0.9825750242013552,0.9825750242013552,0.9835430784123911,0.9835430784123911,0.9845111326234269,0.9845111326234269,0.9854791868344628,0.9854791868344628,0.9864472410454985,0.9864472410454985,0.9874152952565344,0.9874152952565344,0.9883833494675702,0.9883833494675702,0.989351403678606,0.989351403678606,0.9903194578896418,0.9903194578896418,0.9922555663117134,0.9922555663117134,0.9932236205227493,0.9932236205227493,0.9941916747337851,0.9941916747337851,0.995159728944821,0.995159728944821,0.9961277831558567,0.9961277831558567,0.9970958373668926,0.9970958373668926,0.9980638915779284,0.9980638915779284,0.9990319457889641,0.9990319457889641,1,1],"yaxis":"y"}],"layout":{"height":600,"legend":{"tracegroupgap":0},"shapes":[{"line":{"dash":"dash"},"type":"line","x0":0,"x1":1,"y0":0,"y1":1}],"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"title":{"text":"ROC Curve (AUC=0.8819)"},"width":800,"xaxis":{"anchor":"y","constrain":"domain","domain":[0,1],"title":{"text":"False Positive Rate"}},"yaxis":{"anchor":"x","domain":[0,1],"scaleanchor":"x","scaleratio":1,"title":{"text":"True Positive Rate"}}}},"text/html":["<div>                            <div id=\"2c66af7b-0c60-45ac-b4b8-a15f49a21c75\" class=\"plotly-graph-div\" style=\"height:600px; width:800px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"2c66af7b-0c60-45ac-b4b8-a15f49a21c75\")) {                    Plotly.newPlot(                        \"2c66af7b-0c60-45ac-b4b8-a15f49a21c75\",                        [{\"fillpattern\":{\"shape\":\"\"},\"hovertemplate\":\"False Positive Rate=%{x}\\u003cbr\\u003eTrue Positive Rate=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"stackgroup\":\"1\",\"x\":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.00267379679144385,0.00267379679144385,0.0053475935828877,0.0053475935828877,0.008021390374331552,0.008021390374331552,0.0106951871657754,0.0106951871657754,0.013368983957219251,0.013368983957219251,0.016042780748663103,0.016042780748663103,0.01871657754010695,0.01871657754010695,0.0213903743315508,0.0213903743315508,0.02406417112299465,0.02406417112299465,0.026737967914438502,0.026737967914438502,0.026737967914438502,0.026737967914438502,0.029411764705882353,0.029411764705882353,0.03208556149732621,0.03208556149732621,0.034759358288770054,0.034759358288770054,0.0374331550802139,0.0374331550802139,0.040106951871657755,0.040106951871657755,0.0427807486631016,0.0427807486631016,0.045454545454545456,0.045454545454545456,0.0481283422459893,0.0481283422459893,0.05080213903743316,0.05080213903743316,0.053475935828877004,0.053475935828877004,0.05614973262032086,0.05614973262032086,0.058823529411764705,0.058823529411764705,0.06149732620320856,0.06149732620320856,0.06417112299465241,0.06417112299465241,0.06684491978609626,0.06684491978609626,0.06951871657754011,0.06951871657754011,0.07219251336898395,0.07219251336898395,0.0748663101604278,0.0748663101604278,0.07754010695187166,0.07754010695187166,0.08288770053475936,0.08288770053475936,0.0855614973262032,0.0855614973262032,0.08823529411764706,0.08823529411764706,0.09090909090909091,0.09090909090909091,0.09358288770053476,0.09358288770053476,0.0962566844919786,0.0962566844919786,0.09893048128342247,0.09893048128342247,0.10160427807486631,0.10160427807486631,0.10427807486631016,0.10427807486631016,0.10695187165775401,0.10695187165775401,0.11229946524064172,0.11229946524064172,0.11764705882352941,0.11764705882352941,0.12032085561497326,0.12032085561497326,0.12299465240641712,0.12299465240641712,0.12566844919786097,0.12566844919786097,0.12834224598930483,0.12834224598930483,0.13101604278074866,0.13101604278074866,0.13368983957219252,0.13368983957219252,0.13636363636363635,0.13636363636363635,0.13903743315508021,0.13903743315508021,0.14171122994652408,0.14171122994652408,0.1443850267379679,0.1443850267379679,0.14705882352941177,0.14705882352941177,0.1497326203208556,0.1497326203208556,0.15240641711229946,0.15240641711229946,0.15775401069518716,0.15775401069518716,0.16042780748663102,0.16042780748663102,0.16310160427807488,0.16310160427807488,0.1657754010695187,0.1657754010695187,0.16844919786096257,0.16844919786096257,0.1711229946524064,0.1711229946524064,0.17379679144385027,0.17379679144385027,0.17647058823529413,0.17647058823529413,0.18181818181818182,0.18181818181818182,0.18449197860962566,0.18449197860962566,0.18716577540106952,0.18716577540106952,0.1925133689839572,0.1925133689839572,0.19518716577540107,0.19518716577540107,0.19786096256684493,0.19786096256684493,0.20320855614973263,0.20320855614973263,0.20588235294117646,0.20588235294117646,0.20855614973262032,0.20855614973262032,0.21122994652406418,0.21122994652406418,0.21390374331550802,0.21390374331550802,0.21657754010695188,0.21657754010695188,0.22727272727272727,0.22727272727272727,0.22994652406417113,0.22994652406417113,0.232620320855615,0.232620320855615,0.23796791443850268,0.23796791443850268,0.24064171122994651,0.24064171122994651,0.24331550802139038,0.24331550802139038,0.24598930481283424,0.24598930481283424,0.25133689839572193,0.25133689839572193,0.25668449197860965,0.25668449197860965,0.25935828877005346,0.25935828877005346,0.2620320855614973,0.2620320855614973,0.2647058823529412,0.2647058823529412,0.26737967914438504,0.26737967914438504,0.2700534759358289,0.2700534759358289,0.27807486631016043,0.27807486631016043,0.28609625668449196,0.28609625668449196,0.2914438502673797,0.2914438502673797,0.29411764705882354,0.29411764705882354,0.2967914438502674,0.2967914438502674,0.2994652406417112,0.2994652406417112,0.30213903743315507,0.30213903743315507,0.3074866310160428,0.3074866310160428,0.31016042780748665,0.31016042780748665,0.3155080213903743,0.3155080213903743,0.32620320855614976,0.32620320855614976,0.3342245989304813,0.3342245989304813,0.33689839572192515,0.33689839572192515,0.34759358288770054,0.34759358288770054,0.3502673796791444,0.3502673796791444,0.35294117647058826,0.35294117647058826,0.3582887700534759,0.3582887700534759,0.36363636363636365,0.36363636363636365,0.3663101604278075,0.3663101604278075,0.3716577540106952,0.3716577540106952,0.37433155080213903,0.37433155080213903,0.38235294117647056,0.38235294117647056,0.3877005347593583,0.3877005347593583,0.393048128342246,0.393048128342246,0.3983957219251337,0.3983957219251337,0.4037433155080214,0.4037433155080214,0.41711229946524064,0.41711229946524064,0.42245989304812837,0.42245989304812837,0.42513368983957217,0.42513368983957217,0.42780748663101603,0.42780748663101603,0.4304812834224599,0.4304812834224599,0.4358288770053476,0.4358288770053476,0.4411764705882353,0.4411764705882353,0.44919786096256686,0.44919786096256686,0.45454545454545453,0.45454545454545453,0.45989304812834225,0.45989304812834225,0.4625668449197861,0.4625668449197861,0.4786096256684492,0.4786096256684492,0.48128342245989303,0.48128342245989303,0.4839572192513369,0.4839572192513369,0.49732620320855614,0.49732620320855614,0.5213903743315508,0.5213903743315508,0.5240641711229946,0.5240641711229946,0.5294117647058824,0.5294117647058824,0.5347593582887701,0.5347593582887701,0.5374331550802139,0.5374331550802139,0.5427807486631016,0.5427807486631016,0.5481283422459893,0.5481283422459893,0.553475935828877,0.553475935828877,0.5561497326203209,0.5561497326203209,0.5588235294117647,0.5588235294117647,0.5614973262032086,0.5614973262032086,0.5641711229946524,0.5641711229946524,0.5855614973262032,0.5855614973262032,0.5962566844919787,0.5962566844919787,0.6042780748663101,0.6042780748663101,0.6363636363636364,0.6363636363636364,0.6390374331550802,0.6390374331550802,0.660427807486631,0.660427807486631,0.6657754010695187,0.6657754010695187,0.6871657754010695,0.6871657754010695,0.6925133689839572,0.6925133689839572,0.6978609625668449,0.6978609625668449,0.7005347593582888,0.7005347593582888,0.7085561497326203,0.7085561497326203,0.7219251336898396,0.7219251336898396,0.7406417112299465,0.7406417112299465,0.7700534759358288,0.7700534759358288,0.7834224598930482,0.7834224598930482,0.786096256684492,0.786096256684492,0.8021390374331551,0.8021390374331551,0.8315508021390374,0.8315508021390374,0.8342245989304813,0.8342245989304813,0.8663101604278075,0.8663101604278075,0.8850267379679144,0.8850267379679144,0.9064171122994652,0.9064171122994652,1.0],\"xaxis\":\"x\",\"y\":[0.0,0.021297192642787996,0.022265246853823813,0.02904162633107454,0.03291384317521781,0.03388189738625363,0.03581800580832527,0.036786060019361085,0.03872216844143272,0.04065827686350436,0.044530493707647625,0.061955469506292354,0.06389157792836399,0.07163601161665054,0.07357212003872217,0.08712487899322362,0.08906098741529525,0.09970958373668926,0.10164569215876089,0.13165537270087124,0.1335914811229429,0.13746369796708616,0.13746369796708616,0.1713455953533398,0.1713455953533398,0.17618586640851888,0.17618586640851888,0.20038722168441434,0.20038722168441434,0.24878993223620524,0.24878993223620524,0.2749273959341723,0.2749273959341723,0.2787996127783156,0.2787996127783156,0.3020329138431752,0.3020329138431752,0.33688286544046464,0.33688286544046464,0.34075508228460794,0.34075508228460794,0.34462729912875123,0.3465634075508228,0.3543078412391094,0.3543078412391094,0.4075508228460794,0.4075508228460794,0.42400774443368827,0.42400774443368827,0.43852855759922554,0.43852855759922554,0.4617618586640852,0.4617618586640852,0.4791868344627299,0.4791868344627299,0.4888673765730881,0.4888673765730881,0.5072604065827686,0.5072604065827686,0.510164569215876,0.510164569215876,0.5188770571151985,0.5188770571151985,0.5256534365924492,0.5256534365924492,0.5285575992255567,0.5285575992255567,0.5324298160696999,0.5324298160696999,0.5401742497579864,0.5401742497579864,0.5508228460793805,0.5508228460793805,0.5517909002904162,0.5517909002904162,0.5595353339787028,0.5595353339787028,0.5605033881897387,0.5605033881897387,0.5614714424007744,0.5614714424007744,0.5769603097773476,0.5769603097773476,0.5818005808325266,0.5818005808325266,0.5934172313649564,0.5934172313649564,0.6001936108422071,0.6001936108422071,0.6127783155856728,0.6127783155856728,0.6205227492739593,0.6205227492739593,0.6243949661181026,0.6243949661181026,0.6263310745401742,0.6263310745401742,0.6311713455953534,0.6311713455953534,0.6379477250726041,0.6379477250726041,0.6495643756050339,0.6495643756050339,0.6524685382381413,0.6524685382381413,0.6592449177153921,0.6592449177153921,0.6698935140367861,0.6698935140367861,0.6718296224588577,0.6718296224588577,0.7057115198451114,0.7057115198451114,0.7095837366892546,0.7095837366892546,0.7105517909002904,0.7105517909002904,0.712487899322362,0.712487899322362,0.7144240077444337,0.7144240077444337,0.7212003872216844,0.7212003872216844,0.723136495643756,0.723136495643756,0.7270087124878993,0.7270087124878993,0.7279767666989352,0.7279767666989352,0.7308809293320426,0.7308809293320426,0.7454017424975798,0.7454017424975798,0.7463697967086157,0.7463697967086157,0.7483059051306873,0.7483059051306873,0.755082284607938,0.755082284607938,0.7560503388189739,0.7560503388189739,0.7579864472410455,0.7579864472410455,0.7666989351403679,0.7666989351403679,0.7686350435624395,0.7686350435624395,0.7705711519845111,0.7705711519845111,0.771539206195547,0.771539206195547,0.7725072604065828,0.7725072604065828,0.7792836398838335,0.7792836398838335,0.7831558567279767,0.7831558567279767,0.7879961277831559,0.7879961277831559,0.7889641819941917,0.7889641819941917,0.797676669893514,0.797676669893514,0.7986447241045499,0.7986447241045499,0.7996127783155856,0.7996127783155856,0.8121974830590513,0.8121974830590513,0.8228460793804453,0.8228460793804453,0.8247821878025169,0.8247821878025169,0.8267182962245886,0.8267182962245886,0.8276863504356244,0.8276863504356244,0.8286544046466602,0.8286544046466602,0.8315585672797676,0.8315585672797676,0.8334946757018393,0.8334946757018393,0.8373668925459826,0.8373668925459826,0.8402710551790901,0.8402710551790901,0.8451113262342691,0.8451113262342691,0.8586640851887706,0.8586640851887706,0.8596321393998064,0.8596321393998064,0.8625363020329139,0.8625363020329139,0.8644724104549855,0.8644724104549855,0.8741529525653436,0.8741529525653436,0.8751210067763795,0.8751210067763795,0.8760890609874153,0.8760890609874153,0.8770571151984511,0.8770571151984511,0.8789932236205228,0.8789932236205228,0.8838334946757018,0.8838334946757018,0.8857696030977735,0.8857696030977735,0.8877057115198451,0.8877057115198451,0.888673765730881,0.888673765730881,0.8906098741529526,0.8906098741529526,0.89351403678606,0.89351403678606,0.8954501452081317,0.8954501452081317,0.8964181994191674,0.8964181994191674,0.9031945788964182,0.9031945788964182,0.9051306873184899,0.9051306873184899,0.9060987415295256,0.9060987415295256,0.9138431752178122,0.9138431752178122,0.9177153920619555,0.9177153920619555,0.9186834462729913,0.9186834462729913,0.9215876089060987,0.9215876089060987,0.9225556631171346,0.9225556631171346,0.925459825750242,0.925459825750242,0.9264278799612778,0.9264278799612778,0.9283639883833494,0.9283639883833494,0.9303000968054211,0.9303000968054211,0.9322362052274927,0.9322362052274927,0.9341723136495643,0.9341723136495643,0.9351403678606002,0.9351403678606002,0.936108422071636,0.936108422071636,0.9370764762826719,0.9370764762826719,0.9390125847047435,0.9390125847047435,0.9399806389157793,0.9399806389157793,0.9409486931268151,0.9409486931268151,0.9428848015488868,0.9428848015488868,0.9438528557599225,0.9438528557599225,0.9486931268151017,0.9486931268151017,0.9496611810261375,0.9496611810261375,0.9506292352371732,0.9506292352371732,0.9515972894482091,0.9515972894482091,0.9564375605033882,0.9564375605033882,0.957405614714424,0.957405614714424,0.9583736689254598,0.9583736689254598,0.9603097773475314,0.9603097773475314,0.9612778315585673,0.9612778315585673,0.9622458857696031,0.9622458857696031,0.9641819941916747,0.9641819941916747,0.9651500484027106,0.9651500484027106,0.9661181026137464,0.9661181026137464,0.9670861568247822,0.9670861568247822,0.968054211035818,0.968054211035818,0.9690222652468539,0.9690222652468539,0.9699903194578896,0.9699903194578896,0.9709583736689255,0.9709583736689255,0.9738625363020329,0.9738625363020329,0.9748305905130688,0.9748305905130688,0.9767666989351403,0.9767666989351403,0.9777347531461762,0.9777347531461762,0.9796708615682478,0.9796708615682478,0.9806389157792836,0.9806389157792836,0.9816069699903195,0.9816069699903195,0.9825750242013552,0.9825750242013552,0.9835430784123911,0.9835430784123911,0.9845111326234269,0.9845111326234269,0.9854791868344628,0.9854791868344628,0.9864472410454985,0.9864472410454985,0.9874152952565344,0.9874152952565344,0.9883833494675702,0.9883833494675702,0.989351403678606,0.989351403678606,0.9903194578896418,0.9903194578896418,0.9922555663117134,0.9922555663117134,0.9932236205227493,0.9932236205227493,0.9941916747337851,0.9941916747337851,0.995159728944821,0.995159728944821,0.9961277831558567,0.9961277831558567,0.9970958373668926,0.9970958373668926,0.9980638915779284,0.9980638915779284,0.9990319457889641,0.9990319457889641,1.0,1.0],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"False Positive Rate\"},\"constrain\":\"domain\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"True Positive Rate\"},\"scaleanchor\":\"x\",\"scaleratio\":1},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"ROC Curve (AUC=0.8819)\"},\"height\":600,\"width\":800,\"shapes\":[{\"line\":{\"dash\":\"dash\"},\"type\":\"line\",\"x0\":0,\"x1\":1,\"y0\":0,\"y1\":1}],\"showlegend\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('2c66af7b-0c60-45ac-b4b8-a15f49a21c75');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"fillpattern":{"shape":""},"hovertemplate":"Recall=%{x}<br>Precision=%{y}<extra></extra>","legendgroup":"","line":{"color":"#636efa"},"marker":{"symbol":"circle"},"mode":"lines","name":"","orientation":"v","showlegend":false,"stackgroup":"1","type":"scatter","x":[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9961277831558567,0.9961277831558567,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9932236205227493,0.9932236205227493,0.9922555663117134,0.9922555663117134,0.9922555663117134,0.9922555663117134,0.9922555663117134,0.9922555663117134,0.9912875121006777,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.989351403678606,0.989351403678606,0.989351403678606,0.989351403678606,0.989351403678606,0.989351403678606,0.989351403678606,0.989351403678606,0.9883833494675702,0.9883833494675702,0.9883833494675702,0.9883833494675702,0.9883833494675702,0.9883833494675702,0.9874152952565344,0.9874152952565344,0.9874152952565344,0.9874152952565344,0.9864472410454985,0.9864472410454985,0.9854791868344628,0.9854791868344628,0.9854791868344628,0.9845111326234269,0.9845111326234269,0.9845111326234269,0.9835430784123911,0.9835430784123911,0.9835430784123911,0.9835430784123911,0.9835430784123911,0.9835430784123911,0.9835430784123911,0.9835430784123911,0.9835430784123911,0.9825750242013552,0.9825750242013552,0.9825750242013552,0.9816069699903195,0.9816069699903195,0.9816069699903195,0.9816069699903195,0.9816069699903195,0.9816069699903195,0.9816069699903195,0.9816069699903195,0.9816069699903195,0.9806389157792836,0.9806389157792836,0.9796708615682478,0.9796708615682478,0.9796708615682478,0.9796708615682478,0.9796708615682478,0.9796708615682478,0.9796708615682478,0.9796708615682478,0.9796708615682478,0.9796708615682478,0.9796708615682478,0.9796708615682478,0.9796708615682478,0.978702807357212,0.9777347531461762,0.9777347531461762,0.9777347531461762,0.9777347531461762,0.9767666989351403,0.9767666989351403,0.9767666989351403,0.9767666989351403,0.9767666989351403,0.9757986447241046,0.9748305905130688,0.9748305905130688,0.9748305905130688,0.9748305905130688,0.9748305905130688,0.9748305905130688,0.9748305905130688,0.9748305905130688,0.9748305905130688,0.9738625363020329,0.9738625363020329,0.972894482090997,0.9719264278799613,0.9709583736689255,0.9709583736689255,0.9699903194578896,0.9699903194578896,0.9690222652468539,0.9690222652468539,0.968054211035818,0.968054211035818,0.968054211035818,0.9670861568247822,0.9670861568247822,0.9670861568247822,0.9661181026137464,0.9661181026137464,0.9661181026137464,0.9651500484027106,0.9651500484027106,0.9641819941916747,0.9641819941916747,0.9641819941916747,0.9632139399806389,0.9622458857696031,0.9622458857696031,0.9622458857696031,0.9612778315585673,0.9612778315585673,0.9603097773475314,0.9603097773475314,0.9603097773475314,0.9603097773475314,0.9603097773475314,0.9603097773475314,0.9603097773475314,0.9603097773475314,0.9603097773475314,0.9603097773475314,0.9593417231364957,0.9583736689254598,0.9583736689254598,0.9583736689254598,0.9583736689254598,0.9583736689254598,0.9583736689254598,0.957405614714424,0.957405614714424,0.9564375605033882,0.9564375605033882,0.9554695062923524,0.9545014520813165,0.9535333978702807,0.952565343659245,0.9515972894482091,0.9515972894482091,0.9515972894482091,0.9515972894482091,0.9515972894482091,0.9515972894482091,0.9515972894482091,0.9506292352371732,0.9506292352371732,0.9496611810261375,0.9496611810261375,0.9496611810261375,0.9486931268151017,0.9486931268151017,0.9486931268151017,0.9477250726040658,0.9467570183930301,0.9457889641819942,0.9448209099709584,0.9438528557599225,0.9438528557599225,0.9438528557599225,0.9438528557599225,0.9428848015488868,0.9428848015488868,0.9428848015488868,0.9419167473378509,0.9409486931268151,0.9409486931268151,0.9409486931268151,0.9399806389157793,0.9399806389157793,0.9390125847047435,0.9390125847047435,0.9380445304937076,0.9370764762826719,0.9370764762826719,0.936108422071636,0.936108422071636,0.936108422071636,0.9351403678606002,0.9351403678606002,0.9351403678606002,0.9351403678606002,0.9351403678606002,0.9351403678606002,0.9341723136495643,0.9341723136495643,0.9341723136495643,0.9332042594385286,0.9322362052274927,0.9322362052274927,0.9322362052274927,0.9312681510164569,0.9303000968054211,0.9303000968054211,0.9303000968054211,0.9293320425943853,0.9283639883833494,0.9283639883833494,0.9283639883833494,0.9273959341723137,0.9264278799612778,0.9264278799612778,0.9264278799612778,0.9264278799612778,0.925459825750242,0.925459825750242,0.9244917715392061,0.9235237173281704,0.9225556631171346,0.9225556631171346,0.9225556631171346,0.9215876089060987,0.9215876089060987,0.920619554695063,0.9196515004840271,0.9186834462729913,0.9186834462729913,0.9186834462729913,0.9177153920619555,0.9177153920619555,0.9177153920619555,0.9167473378509197,0.9157792836398838,0.914811229428848,0.9138431752178122,0.9138431752178122,0.9128751210067764,0.9119070667957405,0.9109390125847048,0.9099709583736689,0.9090029041626331,0.9080348499515973,0.9070667957405615,0.9060987415295256,0.9060987415295256,0.9051306873184899,0.9051306873184899,0.9051306873184899,0.9051306873184899,0.9051306873184899,0.904162633107454,0.9031945788964182,0.9031945788964182,0.9022265246853823,0.9012584704743466,0.9002904162633107,0.8993223620522749,0.8983543078412392,0.8973862536302033,0.8964181994191674,0.8964181994191674,0.8964181994191674,0.8964181994191674,0.8954501452081317,0.8954501452081317,0.8954501452081317,0.8954501452081317,0.8954501452081317,0.8944820909970959,0.89351403678606,0.89351403678606,0.89351403678606,0.8925459825750242,0.8915779283639884,0.8906098741529526,0.8906098741529526,0.8896418199419167,0.888673765730881,0.888673765730881,0.888673765730881,0.8877057115198451,0.8877057115198451,0.8867376573088093,0.8857696030977735,0.8857696030977735,0.8848015488867377,0.8838334946757018,0.8838334946757018,0.882865440464666,0.8818973862536302,0.8809293320425944,0.8799612778315585,0.8789932236205228,0.8789932236205228,0.8780251694094869,0.8770571151984511,0.8770571151984511,0.8770571151984511,0.8760890609874153,0.8760890609874153,0.8760890609874153,0.8760890609874153,0.8751210067763795,0.8751210067763795,0.8751210067763795,0.8751210067763795,0.8741529525653436,0.8741529525653436,0.8731848983543078,0.872216844143272,0.8712487899322362,0.8702807357212003,0.8693126815101646,0.8683446272991288,0.8673765730880929,0.8664085188770572,0.8654404646660213,0.8644724104549855,0.8644724104549855,0.8635043562439496,0.8625363020329139,0.8625363020329139,0.861568247821878,0.8606001936108422,0.8596321393998064,0.8596321393998064,0.8586640851887706,0.8586640851887706,0.8576960309777347,0.856727976766699,0.8557599225556631,0.8547918683446273,0.8538238141335914,0.8528557599225557,0.8518877057115198,0.850919651500484,0.8499515972894482,0.8489835430784124,0.8480154888673765,0.8470474346563408,0.846079380445305,0.8451113262342691,0.8451113262342691,0.8451113262342691,0.8441432720232332,0.8431752178121975,0.8422071636011617,0.8412391093901258,0.8402710551790901,0.8402710551790901,0.8402710551790901,0.8393030009680542,0.8383349467570184,0.8373668925459826,0.8373668925459826,0.8363988383349468,0.8354307841239109,0.8344627299128751,0.8334946757018393,0.8334946757018393,0.8325266214908035,0.8315585672797676,0.8315585672797676,0.8305905130687319,0.829622458857696,0.8286544046466602,0.8286544046466602,0.8286544046466602,0.8276863504356244,0.8276863504356244,0.8267182962245886,0.8267182962245886,0.8257502420135527,0.8247821878025169,0.8247821878025169,0.8247821878025169,0.8247821878025169,0.8247821878025169,0.8238141335914811,0.8228460793804453,0.8228460793804453,0.8218780251694094,0.8209099709583737,0.8199419167473379,0.818973862536302,0.8180058083252663,0.8170377541142304,0.8160696999031946,0.8151016456921588,0.814133591481123,0.8131655372700871,0.8121974830590513,0.8121974830590513,0.8112294288480155,0.8102613746369797,0.8092933204259438,0.8083252662149081,0.8073572120038722,0.8063891577928364,0.8054211035818006,0.8044530493707648,0.8034849951597289,0.8025169409486931,0.8015488867376573,0.8005808325266215,0.7996127783155856,0.7996127783155856,0.7986447241045499,0.7986447241045499,0.797676669893514,0.797676669893514,0.7967086156824782,0.7957405614714425,0.7947725072604066,0.7938044530493708,0.7928363988383349,0.7918683446272992,0.7909002904162633,0.7899322362052275,0.7889641819941917,0.7889641819941917,0.7889641819941917,0.7879961277831559,0.7879961277831559,0.78702807357212,0.7860600193610843,0.7850919651500484,0.7841239109390126,0.7831558567279767,0.7831558567279767,0.782187802516941,0.7812197483059051,0.7802516940948693,0.7792836398838335,0.7792836398838335,0.7792836398838335,0.7783155856727977,0.7773475314617618,0.7763794772507261,0.7754114230396902,0.7744433688286544,0.7734753146176185,0.7725072604065828,0.7725072604065828,0.771539206195547,0.771539206195547,0.7705711519845111,0.7705711519845111,0.7705711519845111,0.7696030977734754,0.7686350435624395,0.7686350435624395,0.7676669893514037,0.7666989351403679,0.7666989351403679,0.7657308809293321,0.7647628267182962,0.7637947725072604,0.7628267182962246,0.7618586640851888,0.7608906098741529,0.7599225556631172,0.7589545014520813,0.7579864472410455,0.7579864472410455,0.7570183930300097,0.7560503388189739,0.7560503388189739,0.755082284607938,0.755082284607938,0.7541142303969022,0.7531461761858664,0.7521781219748306,0.7512100677637947,0.750242013552759,0.7492739593417231,0.7483059051306873,0.7483059051306873,0.7473378509196515,0.7463697967086157,0.7463697967086157,0.7454017424975798,0.7454017424975798,0.7454017424975798,0.744433688286544,0.7434656340755083,0.7424975798644724,0.7415295256534365,0.7405614714424008,0.739593417231365,0.7386253630203291,0.7376573088092934,0.7366892545982575,0.7357212003872217,0.7347531461761858,0.7337850919651501,0.7328170377541142,0.7318489835430784,0.7308809293320426,0.7308809293320426,0.7299128751210068,0.7289448209099709,0.7279767666989352,0.7279767666989352,0.7270087124878993,0.7270087124878993,0.7260406582768635,0.7250726040658277,0.7241045498547919,0.723136495643756,0.723136495643756,0.7221684414327202,0.7212003872216844,0.7212003872216844,0.7202323330106486,0.7192642787996127,0.718296224588577,0.7173281703775412,0.7163601161665053,0.7153920619554696,0.7144240077444337,0.7144240077444337,0.7134559535333979,0.712487899322362,0.712487899322362,0.7115198451113263,0.7105517909002904,0.7105517909002904,0.7095837366892546,0.7095837366892546,0.7086156824782188,0.707647628267183,0.7066795740561471,0.7057115198451114,0.7057115198451114,0.7047434656340755,0.7037754114230397,0.7028073572120038,0.7018393030009681,0.7008712487899322,0.6999031945788964,0.6989351403678606,0.6979670861568248,0.6969990319457889,0.6960309777347532,0.6950629235237173,0.6940948693126815,0.6931268151016456,0.6921587608906099,0.691190706679574,0.6902226524685382,0.6892545982575025,0.6882865440464666,0.6873184898354308,0.686350435624395,0.6853823814133592,0.6844143272023233,0.6834462729912875,0.6824782187802517,0.6815101645692159,0.68054211035818,0.6795740561471443,0.6786060019361084,0.6776379477250726,0.6766698935140368,0.675701839303001,0.6747337850919651,0.6737657308809293,0.6727976766698935,0.6718296224588577,0.6718296224588577,0.6708615682478218,0.6698935140367861,0.6698935140367861,0.6689254598257502,0.6679574056147144,0.6669893514036787,0.6660212971926428,0.665053242981607,0.6640851887705711,0.6631171345595354,0.6621490803484995,0.6611810261374637,0.6602129719264279,0.6592449177153921,0.6592449177153921,0.6582768635043562,0.6573088092933205,0.6563407550822846,0.6553727008712488,0.6544046466602129,0.6534365924491772,0.6524685382381413,0.6524685382381413,0.6524685382381413,0.6515004840271055,0.6505324298160697,0.6495643756050339,0.6495643756050339,0.6495643756050339,0.648596321393998,0.6476282671829623,0.6466602129719264,0.6456921587608906,0.6447241045498547,0.643756050338819,0.6427879961277831,0.6418199419167473,0.6408518877057116,0.6398838334946757,0.6389157792836399,0.6379477250726041,0.6379477250726041,0.6369796708615683,0.6360116166505324,0.6350435624394967,0.6340755082284608,0.633107454017425,0.6321393998063891,0.6311713455953534,0.6311713455953534,0.6302032913843175,0.6292352371732817,0.6282671829622459,0.6272991287512101,0.6263310745401742,0.6263310745401742,0.6253630203291385,0.6243949661181026,0.6243949661181026,0.6234269119070668,0.6224588576960309,0.6214908034849952,0.6205227492739593,0.6205227492739593,0.6195546950629235,0.6185866408518877,0.6176185866408519,0.616650532429816,0.6156824782187803,0.6147144240077445,0.6137463697967086,0.6127783155856728,0.6127783155856728,0.611810261374637,0.6108422071636012,0.6098741529525653,0.6089060987415296,0.6079380445304937,0.6069699903194579,0.6060019361084221,0.6050338818973863,0.6040658276863504,0.6030977734753146,0.6021297192642788,0.601161665053243,0.6001936108422071,0.6001936108422071,0.5992255566311714,0.5982575024201355,0.5972894482090997,0.5963213939980639,0.5953533397870281,0.5943852855759922,0.5934172313649564,0.5934172313649564,0.5924491771539206,0.5914811229428848,0.590513068731849,0.5895450145208132,0.5885769603097774,0.5876089060987415,0.5866408518877058,0.5856727976766699,0.5847047434656341,0.5837366892545982,0.5827686350435625,0.5818005808325266,0.5818005808325266,0.5808325266214908,0.579864472410455,0.5788964181994192,0.5779283639883833,0.5769603097773476,0.5769603097773476,0.5769603097773476,0.5759922555663117,0.5750242013552759,0.57405614714424,0.5730880929332043,0.5721200387221684,0.5711519845111326,0.5701839303000968,0.569215876089061,0.5682478218780251,0.5672797676669894,0.5663117134559535,0.5653436592449177,0.5643756050338818,0.5634075508228461,0.5624394966118103,0.5614714424007744,0.5614714424007744,0.5605033881897387,0.5605033881897387,0.5595353339787028,0.5595353339787028,0.558567279767667,0.5575992255566312,0.5566311713455954,0.5556631171345595,0.5546950629235237,0.5537270087124879,0.5527589545014521,0.5517909002904162,0.5517909002904162,0.5508228460793805,0.5508228460793805,0.5498547918683446,0.5488867376573088,0.547918683446273,0.5469506292352372,0.5459825750242013,0.5450145208131656,0.5440464666021297,0.5430784123910939,0.542110358180058,0.5411423039690223,0.5401742497579864,0.5401742497579864,0.5392061955469506,0.5382381413359149,0.537270087124879,0.5363020329138432,0.5353339787028074,0.5343659244917716,0.5333978702807357,0.5324298160696999,0.5324298160696999,0.5314617618586641,0.5304937076476283,0.5295256534365924,0.5285575992255567,0.5285575992255567,0.5275895450145208,0.526621490803485,0.5256534365924492,0.5256534365924492,0.5246853823814134,0.5237173281703775,0.5227492739593417,0.5217812197483059,0.5208131655372701,0.5198451113262342,0.5188770571151985,0.5188770571151985,0.5179090029041626,0.5169409486931268,0.515972894482091,0.5150048402710552,0.5140367860600193,0.5130687318489835,0.5121006776379478,0.5111326234269119,0.510164569215876,0.510164569215876,0.5091965150048403,0.5082284607938045,0.5072604065827686,0.5072604065827686,0.5062923523717329,0.505324298160697,0.5043562439496612,0.5033881897386253,0.5024201355275896,0.5014520813165537,0.5004840271055179,0.4995159728944821,0.4985479186834463,0.4975798644724105,0.49661181026137463,0.49564375605033884,0.494675701839303,0.4937076476282672,0.4927395934172314,0.49177153920619554,0.49080348499515974,0.4898354307841239,0.4888673765730881,0.4888673765730881,0.4878993223620523,0.48693126815101645,0.48596321393998065,0.4849951597289448,0.484027105517909,0.4830590513068732,0.48209099709583736,0.48112294288480156,0.4801548886737657,0.4791868344627299,0.4791868344627299,0.4782187802516941,0.47725072604065827,0.4762826718296225,0.4753146176185866,0.4743465634075508,0.47337850919651503,0.4724104549854792,0.4714424007744434,0.47047434656340753,0.46950629235237173,0.46853823814133594,0.4675701839303001,0.4666021297192643,0.46563407550822844,0.46466602129719264,0.46369796708615685,0.462729912875121,0.4617618586640852,0.4617618586640852,0.46079380445304935,0.45982575024201355,0.45885769603097776,0.4578896418199419,0.4569215876089061,0.45595353339787026,0.45498547918683446,0.45401742497579867,0.4530493707647628,0.452081316553727,0.45111326234269117,0.45014520813165537,0.4491771539206196,0.4482090997095837,0.44724104549854793,0.4462729912875121,0.4453049370764763,0.4443368828654405,0.44336882865440463,0.44240077444336884,0.441432720232333,0.4404646660212972,0.4394966118102614,0.43852855759922554,0.43852855759922554,0.43756050338818975,0.4365924491771539,0.4356243949661181,0.4346563407550823,0.43368828654404645,0.43272023233301066,0.4317521781219748,0.430784123910939,0.4298160696999032,0.42884801548886736,0.42787996127783157,0.4269119070667957,0.4259438528557599,0.4249757986447241,0.42400774443368827,0.42400774443368827,0.4230396902226525,0.4220716360116166,0.42110358180058083,0.42013552758954503,0.4191674733785092,0.4181994191674734,0.41723136495643753,0.41626331074540174,0.41529525653436594,0.4143272023233301,0.4133591481122943,0.41239109390125844,0.41142303969022265,0.41045498547918685,0.409486931268151,0.4085188770571152,0.4075508228460794,0.4075508228460794,0.40658276863504356,0.40561471442400776,0.4046466602129719,0.4036786060019361,0.4027105517909003,0.40174249757986447,0.40077444336882867,0.3998063891577928,0.398838334946757,0.3978702807357212,0.3969022265246854,0.3959341723136496,0.39496611810261373,0.39399806389157793,0.39303000968054214,0.3920619554695063,0.3910939012584705,0.39012584704743464,0.38915779283639884,0.38818973862536305,0.3872216844143272,0.3862536302032914,0.38528557599225555,0.38431752178121975,0.38334946757018395,0.3823814133591481,0.3814133591481123,0.38044530493707646,0.37947725072604066,0.37850919651500486,0.377541142303969,0.3765730880929332,0.37560503388189737,0.37463697967086157,0.3736689254598258,0.3727008712487899,0.3717328170377541,0.3707647628267183,0.3697967086156825,0.3688286544046467,0.36786060019361083,0.36689254598257504,0.3659244917715392,0.3649564375605034,0.3639883833494676,0.36302032913843174,0.36205227492739595,0.3610842207163601,0.3601161665053243,0.3591481122942885,0.35818005808325265,0.35721200387221685,0.356243949661181,0.3552758954501452,0.3543078412391094,0.3543078412391094,0.35333978702807356,0.35237173281703776,0.3514036786060019,0.3504356243949661,0.3494675701839303,0.34849951597289447,0.3475314617618587,0.3465634075508228,0.34462729912875123,0.3436592449177154,0.3426911907066796,0.34172313649564373,0.34075508228460794,0.34075508228460794,0.33978702807357214,0.3388189738625363,0.3378509196515005,0.33688286544046464,0.33688286544046464,0.33591481122942884,0.33494675701839305,0.3339787028073572,0.3330106485963214,0.33204259438528555,0.33107454017424975,0.33010648596321396,0.3291384317521781,0.3281703775411423,0.32720232333010646,0.32623426911907066,0.32526621490803487,0.324298160696999,0.3233301064859632,0.32236205227492737,0.3213939980638916,0.3204259438528558,0.3194578896418199,0.31848983543078413,0.31752178121974833,0.3165537270087125,0.3155856727976767,0.31461761858664083,0.31364956437560504,0.31268151016456924,0.3117134559535334,0.3107454017424976,0.30977734753146174,0.30880929332042595,0.30784123910939015,0.3068731848983543,0.3059051306873185,0.30493707647628265,0.30396902226524686,0.30300096805421106,0.3020329138431752,0.3020329138431752,0.3010648596321394,0.30009680542110356,0.29912875121006777,0.29816069699903197,0.2971926427879961,0.2962245885769603,0.2952565343659245,0.2942884801548887,0.2933204259438529,0.29235237173281703,0.29138431752178123,0.2904162633107454,0.2894482090997096,0.2884801548886738,0.28751210067763794,0.28654404646660214,0.2855759922555663,0.2846079380445305,0.2836398838334947,0.28267182962245885,0.28170377541142305,0.2807357212003872,0.2797676669893514,0.2787996127783156,0.2787996127783156,0.27783155856727976,0.27686350435624396,0.2758954501452081,0.2749273959341723,0.2749273959341723,0.2739593417231365,0.27299128751210067,0.27202323330106487,0.271055179090029,0.2700871248789932,0.2691190706679574,0.2681510164569216,0.2671829622458858,0.26621490803484993,0.26524685382381413,0.26427879961277834,0.2633107454017425,0.2623426911907067,0.26137463697967084,0.26040658276863504,0.25943852855759925,0.2584704743465634,0.2575024201355276,0.25653436592449175,0.25556631171345595,0.25459825750242016,0.2536302032913843,0.2526621490803485,0.25169409486931266,0.25072604065827686,0.24975798644724104,0.24878993223620524,0.24878993223620524,0.24782187802516942,0.2468538238141336,0.24588576960309777,0.24491771539206195,0.24394966118102615,0.24298160696999033,0.2420135527589545,0.24104549854791868,0.24007744433688286,0.23910939012584706,0.23814133591481124,0.2371732817037754,0.2362052274927396,0.23523717328170377,0.23426911907066797,0.23330106485963215,0.23233301064859632,0.2313649564375605,0.23039690222652467,0.22942884801548888,0.22846079380445306,0.22749273959341723,0.2265246853823814,0.22555663117134558,0.2245885769603098,0.22362052274927396,0.22265246853823814,0.22168441432720232,0.2207163601161665,0.2197483059051307,0.21878025169409487,0.21781219748305905,0.21684414327202323,0.2158760890609874,0.2149080348499516,0.21393998063891578,0.21297192642787996,0.21200387221684414,0.2110358180058083,0.21006776379477252,0.2090997095837367,0.20813165537270087,0.20716360116166505,0.20619554695062922,0.20522749273959343,0.2042594385285576,0.20329138431752178,0.20232333010648595,0.20135527589545016,0.20038722168441434,0.20038722168441434,0.1994191674733785,0.1984511132623427,0.19748305905130686,0.19651500484027107,0.19554695062923524,0.19457889641819942,0.1936108422071636,0.19264278799612777,0.19167473378509198,0.19070667957405615,0.18973862536302033,0.1887705711519845,0.18780251694094868,0.1868344627299129,0.18586640851887706,0.18489835430784124,0.18393030009680542,0.1829622458857696,0.1819941916747338,0.18102613746369797,0.18005808325266215,0.17909002904162633,0.1781219748305905,0.1771539206195547,0.17618586640851888,0.17618586640851888,0.17521781219748306,0.17424975798644723,0.1732817037754114,0.17231364956437561,0.1713455953533398,0.1713455953533398,0.17037754114230397,0.16940948693126814,0.16844143272023232,0.16747337850919652,0.1665053242981607,0.16553727008712488,0.16456921587608905,0.16360116166505323,0.16263310745401743,0.1616650532429816,0.1606969990319458,0.15972894482090996,0.15876089060987417,0.15779283639883834,0.15682478218780252,0.1558567279767667,0.15488867376573087,0.15392061955469508,0.15295256534365925,0.15198451113262343,0.1510164569215876,0.15004840271055178,0.14908034849951599,0.14811229428848016,0.14714424007744434,0.14617618586640851,0.1452081316553727,0.1442400774443369,0.14327202323330107,0.14230396902226525,0.14133591481122942,0.1403678606001936,0.1393998063891578,0.13843175217812198,0.13746369796708616,0.13746369796708616,0.13649564375605033,0.1355275895450145,0.1345595353339787,0.1335914811229429,0.13165537270087124,0.13068731848983542,0.12971926427879962,0.1287512100677638,0.12778315585672798,0.12681510164569215,0.12584704743465633,0.12487899322362052,0.12391093901258471,0.12294288480154889,0.12197483059051308,0.12100677637947725,0.12003872216844143,0.11907066795740562,0.1181026137463698,0.11713455953533398,0.11616650532429816,0.11519845111326234,0.11423039690222653,0.1132623426911907,0.1122942884801549,0.11132623426911907,0.11035818005808325,0.10939012584704744,0.10842207163601161,0.1074540174249758,0.10648596321393998,0.10551790900290416,0.10454985479186835,0.10358180058083252,0.10261374636979671,0.10164569215876089,0.09970958373668926,0.09874152952565343,0.09777347531461762,0.0968054211035818,0.09583736689254599,0.09486931268151017,0.09390125847047434,0.09293320425943853,0.09196515004840271,0.0909970958373669,0.09002904162633107,0.08906098741529525,0.08712487899322362,0.08615682478218781,0.08518877057115198,0.08422071636011616,0.08325266214908035,0.08228460793804453,0.08131655372700872,0.0803484995159729,0.07938044530493708,0.07841239109390126,0.07744433688286544,0.07647628267182963,0.0755082284607938,0.07454017424975799,0.07357212003872217,0.07163601161665054,0.07066795740561471,0.0696999031945789,0.06873184898354308,0.06776379477250725,0.06679574056147145,0.06582768635043562,0.06485963213939981,0.06389157792836399,0.061955469506292354,0.06098741529525654,0.060019361084220714,0.0590513068731849,0.05808325266214908,0.057115198451113264,0.05614714424007745,0.05517909002904162,0.05421103581800581,0.05324298160696999,0.05227492739593417,0.051306873184898356,0.05033881897386254,0.049370764762826716,0.0484027105517909,0.04743465634075508,0.046466602129719266,0.04549854791868345,0.044530493707647625,0.04259438528557599,0.04065827686350436,0.03969022265246854,0.03872216844143272,0.036786060019361085,0.03581800580832527,0.03388189738625363,0.03291384317521781,0.02904162633107454,0.022265246853823813,0.021297192642787996,0],"xaxis":"x","y":[0.7341862117981521,0.7347083926031295,0.7352313167259786,0.7357549857549858,0.7362794012829651,0.7368045649072753,0.7373304782298359,0.7378571428571429,0.7383845604002859,0.7389127324749643,0.7394416607015032,0.7399713467048711,0.7405017921146954,0.7410329985652798,0.741564967695621,0.7420977011494253,0.7426312005751258,0.7431654676258993,0.7437005039596832,0.7442363112391931,0.7447728911319395,0.7453102453102453,0.7458483754512636,0.7463872832369942,0.7469269703543022,0.7474674384949349,0.7480086893555394,0.7485507246376811,0.7490935460478607,0.7496371552975326,0.7501815541031227,0.7507267441860465,0.7512727272727273,0.7518195050946143,0.752367079388201,0.7529154518950437,0.7527352297592997,0.7532846715328467,0.7538349159970782,0.7543859649122807,0.7549378200438918,0.7554904831625183,0.756043956043956,0.7565982404692082,0.7571533382245048,0.7569750367107195,0.7575312270389419,0.7580882352941176,0.7586460632818248,0.7592047128129602,0.7597641857037583,0.7603244837758112,0.7608856088560886,0.7607090103397341,0.7612712490761271,0.7618343195266272,0.7623982235381199,0.762962962962963,0.7635285396590067,0.7640949554896143,0.7646622123236823,0.7652303120356612,0.7657992565055762,0.7663690476190477,0.766939687267312,0.767511177347243,0.767337807606264,0.767910447761194,0.7677371172516804,0.7683109118086696,0.768885564697083,0.7694610778443114,0.7700374531835206,0.7706146926536732,0.7711927981995499,0.7717717717717718,0.772351615326822,0.7729323308270677,0.7735139202407826,0.7740963855421686,0.7739261492087415,0.7745098039215687,0.7750943396226415,0.775679758308157,0.7762660619803476,0.7768532526475038,0.7774413323239969,0.7772727272727272,0.7778620166793025,0.7776934749620638,0.7782839787395596,0.7788753799392097,0.779467680608365,0.7800608828006088,0.7806549885757806,0.7804878048780488,0.7803203661327232,0.7809160305343511,0.7815126050420168,0.7821100917431193,0.782708492731446,0.7833078101071975,0.7839080459770115,0.7845092024539877,0.7851112816577129,0.7857142857142857,0.7863182167563413,0.786923076923077,0.7867590454195535,0.7873651771956857,0.7879722436391673,0.7885802469135802,0.7891891891891892,0.7897990726429676,0.7904098994586234,0.7910216718266254,0.790859798605732,0.7914728682170543,0.7920868890612878,0.7927018633540373,0.7933177933177933,0.7939346811819595,0.7937743190661478,0.794392523364486,0.7950116913484022,0.7956318252730109,0.795472287275566,0.79609375,0.7959343236903831,0.7965571205007824,0.7971808927173062,0.7970219435736677,0.7976470588235294,0.7982731554160125,0.798114689709348,0.7987421383647799,0.7993705743509048,0.8,0.8006304176516943,0.8012618296529969,0.8018942383583267,0.8025276461295419,0.8031620553359684,0.803006329113924,0.8036421219319082,0.8042789223454834,0.8041237113402062,0.8047619047619048,0.8054011119936457,0.8060413354531002,0.8066825775656324,0.8073248407643312,0.8079681274900399,0.8086124401913876,0.8092577813248204,0.8091054313099042,0.8097521982414069,0.8096,0.8102481985588471,0.8108974358974359,0.8115477145148356,0.812199036918138,0.8128514056224899,0.8135048231511254,0.8141592920353983,0.8148148148148148,0.8154713940370669,0.8161290322580645,0.8167877320419693,0.8174474959612278,0.8172999191592563,0.8171521035598706,0.8178137651821862,0.8184764991896273,0.819140308191403,0.8189935064935064,0.8196588139723802,0.8203252032520325,0.8209926769731489,0.8216612377850163,0.8215158924205379,0.8213703099510603,0.8220408163265306,0.8227124183006536,0.8233851185609158,0.8240589198036007,0.8247338247338247,0.8254098360655737,0.8260869565217391,0.8267651888341544,0.8266228430566968,0.8273026315789473,0.8271604938271605,0.8270181219110379,0.8268755152514426,0.8275577557755776,0.8274153592072667,0.828099173553719,0.8279569892473119,0.8286423841059603,0.8285004142502072,0.8291873963515755,0.8298755186721992,0.829734219269103,0.830423940149626,0.8311148086522463,0.8309741881765196,0.8316666666666667,0.8323603002502085,0.832220367278798,0.8329156223893066,0.8327759197324415,0.8334728033472804,0.8341708542713567,0.8340318524727578,0.8338926174496645,0.834592779177162,0.8352941176470589,0.8351555929352397,0.8358585858585859,0.8357203032855939,0.836424957841484,0.8371308016877637,0.8378378378378378,0.8385460693153001,0.8392554991539763,0.8399661303979679,0.8406779661016949,0.8413910093299406,0.8421052631578947,0.8419711129991504,0.8418367346938775,0.8425531914893617,0.8432708688245315,0.8439897698209718,0.8447098976109215,0.8454312553373186,0.8452991452991453,0.8460222412318221,0.8458904109589042,0.8466152527849186,0.8464837049742711,0.8463519313304722,0.8462199312714777,0.8460877042132416,0.8459552495697074,0.8466838931955211,0.8474137931034482,0.8481449525452976,0.8488773747841105,0.8496110630942092,0.8503460207612457,0.8502164502164502,0.8509532062391681,0.8508239375542064,0.8515625,0.8523023457862728,0.8521739130434782,0.8529155787641427,0.8536585365853658,0.8535309503051438,0.8534031413612565,0.8532751091703057,0.8531468531468531,0.8530183727034121,0.8537653239929948,0.8545135845749343,0.8552631578947368,0.8551360842844601,0.8558875219683656,0.8566402814423922,0.8565140845070423,0.8563876651982378,0.8571428571428571,0.8578993821712269,0.857773851590106,0.8585322723253758,0.8584070796460177,0.8591674047829938,0.8590425531914894,0.8589174800354925,0.8596802841918295,0.8595555555555555,0.8603202846975089,0.8610863757791629,0.8609625668449198,0.8617305976806423,0.8625,0.8632707774798928,0.8640429338103757,0.864816472694718,0.8646953405017921,0.8654708520179372,0.8662477558348295,0.8661275831087152,0.8660071942446043,0.8667866786678667,0.8675675675675676,0.8674481514878268,0.8673285198555957,0.8681120144534779,0.8688969258589512,0.8687782805429864,0.8686594202898551,0.8694469628286491,0.8702359346642469,0.8701180744777475,0.87,0.8707916287534122,0.8715846994535519,0.8723792160437557,0.8722627737226277,0.8730593607305936,0.8729433272394881,0.8728270814272644,0.8727106227106227,0.8735105407882676,0.8743119266055046,0.8741965105601469,0.875,0.874885004599816,0.8747697974217311,0.8746543778801843,0.8754612546125461,0.876269621421976,0.8761552680221811,0.8769657724329325,0.8777777777777778,0.8776645041705282,0.8775510204081632,0.8774373259052924,0.8773234200743495,0.878139534883721,0.8780260707635009,0.8779123951537745,0.8777985074626866,0.8776844070961718,0.8775700934579439,0.8774555659494855,0.8773408239700374,0.8772258669165885,0.8780487804878049,0.8779342723004695,0.8787593984962406,0.8795860771401693,0.8804143126177024,0.88124410933082,0.8811320754716981,0.8810198300283286,0.8818525519848771,0.8817407757805109,0.8816287878787878,0.8815165876777251,0.881404174573055,0.8812915479582146,0.8811787072243346,0.8810656517602283,0.8819047619047619,0.882745471877979,0.8835877862595419,0.8834765998089781,0.884321223709369,0.8851674641148325,0.8860153256704981,0.8868648130393096,0.8867562380038387,0.8866474543707973,0.8875,0.888354186717998,0.8882466281310212,0.8881388621022179,0.888030888030888,0.8888888888888888,0.8887814313346228,0.888673765730881,0.8895348837209303,0.8903976721629486,0.8902912621359224,0.891156462585034,0.8910505836575876,0.8909444985394352,0.8918128654970761,0.8917073170731707,0.8916015625,0.8924731182795699,0.8923679060665362,0.8922624877571009,0.8921568627450981,0.8920510304219823,0.8919449901768173,0.8928220255653884,0.8927165354330708,0.8926108374384236,0.893491124260355,0.8943731490621916,0.8942687747035574,0.8951533135509396,0.8960396039603961,0.8969276511397423,0.8968253968253969,0.8977159880834161,0.8986083499005965,0.8995024875621891,0.899402390438247,0.9002991026919243,0.9001996007984032,0.9000999000999002,0.9,0.8998998998998999,0.8997995991983968,0.8996990972918756,0.8995983935742972,0.8994974874371859,0.8993963782696177,0.8992950654582075,0.9002016129032258,0.900100908173562,0.9,0.9009100101112234,0.9008097165991903,0.900709219858156,0.9006085192697769,0.9015228426395939,0.9014227642276422,0.9023397761953205,0.9022403258655805,0.9021406727828746,0.9020408163265307,0.9019407558733401,0.901840490797546,0.901740020470829,0.9016393442622951,0.9015384615384615,0.9014373716632443,0.9013360739979445,0.9012345679012346,0.9011328527291452,0.9010309278350516,0.9009287925696594,0.9018595041322314,0.9027921406411582,0.9026915113871635,0.9025906735751296,0.9024896265560166,0.9023883696780893,0.9022869022869023,0.9032258064516129,0.9041666666666667,0.9040667361835245,0.9039665970772442,0.9038662486938349,0.9048117154811716,0.9047120418848168,0.9046121593291404,0.9045120671563484,0.9044117647058824,0.9053627760252366,0.9052631578947369,0.9051633298208641,0.9061181434599156,0.9060190073917634,0.9059196617336153,0.9058201058201059,0.9067796610169492,0.9077412513255567,0.9076433121019108,0.9086078639744952,0.9085106382978724,0.9094781682641108,0.9093816631130064,0.9092849519743863,0.9102564102564102,0.9112299465240642,0.9122055674518201,0.9131832797427653,0.9130901287553648,0.9129967776584318,0.9139784946236559,0.9138858988159311,0.9137931034482759,0.9137001078748651,0.9136069114470843,0.9135135135135135,0.9134199134199135,0.9133261105092091,0.913232104121475,0.9131378935939196,0.9130434782608695,0.9129488574537541,0.9139433551198257,0.9138495092693566,0.9137554585152838,0.9136612021857924,0.9135667396061269,0.9134720700985761,0.9133771929824561,0.9132821075740944,0.9131868131868132,0.9130913091309131,0.9129955947136564,0.9128996692392503,0.91280353200883,0.912707182320442,0.9137168141592921,0.9136212624584718,0.9146341463414634,0.9145394006659268,0.9155555555555556,0.9154616240266963,0.9153674832962138,0.915273132664437,0.9151785714285714,0.9150837988826815,0.9149888143176734,0.9148936170212766,0.9147982062780269,0.9147025813692481,0.9157303370786517,0.9167604049493814,0.9166666666666666,0.9177001127395716,0.917607223476298,0.9175141242937853,0.917420814479638,0.9173272933182333,0.9172335600907029,0.9182746878547106,0.9181818181818182,0.9180887372013652,0.9179954441913439,0.9179019384264538,0.9189497716894978,0.92,0.919908466819222,0.9198167239404352,0.9197247706422018,0.9196326061997704,0.9195402298850575,0.9194476409666283,0.9193548387096774,0.9204152249134948,0.9203233256351039,0.9213872832369943,0.9212962962962963,0.9223638470451911,0.9234338747099768,0.9233449477351916,0.9232558139534883,0.9243306169965075,0.9242424242424242,0.9241540256709452,0.9252336448598131,0.9251461988304094,0.9250585480093677,0.9249706916764361,0.9248826291079812,0.9247943595769683,0.9247058823529412,0.9246171967020024,0.9245283018867925,0.9244391971664699,0.925531914893617,0.9254437869822485,0.9253554502369669,0.9264531435349941,0.9263657957244655,0.9274673008323424,0.9273809523809524,0.9272943980929678,0.9272076372315036,0.927120669056153,0.9270334928229665,0.9269461077844311,0.9268585131894485,0.9279711884753902,0.9278846153846154,0.927797833935018,0.9289156626506024,0.9288299155609168,0.9299516908212561,0.9310761789600968,0.9309927360774818,0.9309090909090909,0.9308252427184466,0.9307411907654921,0.9306569343065694,0.9305724725943971,0.9304878048780488,0.9304029304029304,0.9303178484107579,0.9302325581395349,0.9301470588235294,0.9300613496932515,0.9299754299754299,0.9298892988929889,0.9298029556650246,0.9309494451294698,0.9308641975308642,0.930778739184178,0.9306930693069307,0.9318463444857497,0.9317617866004962,0.9329192546583851,0.9328358208955224,0.9327521793275217,0.9326683291770573,0.9325842696629213,0.93375,0.9336670838548186,0.9335839598997494,0.9347553324968633,0.9346733668341709,0.9345911949685535,0.9345088161209067,0.9344262295081968,0.9343434343434344,0.934260429835651,0.9341772151898734,0.935361216730038,0.9352791878172588,0.9351969504447268,0.9363867684478372,0.9363057324840764,0.9362244897959183,0.9374201787994891,0.9373401534526854,0.93854033290653,0.9384615384615385,0.938382541720154,0.9383033419023136,0.9382239382239382,0.9394329896907216,0.9393548387096774,0.9392764857881137,0.9391979301423027,0.939119170984456,0.9390402075226978,0.938961038961039,0.9388816644993498,0.9388020833333334,0.9387222946544981,0.9386422976501305,0.938562091503268,0.9384816753926701,0.9384010484927916,0.9383202099737533,0.938239159001314,0.9381578947368421,0.9380764163372859,0.9379947229551451,0.9379128137384413,0.9378306878306878,0.937748344370861,0.9376657824933687,0.9375830013280213,0.9375,0.9374167776298269,0.9373333333333334,0.9372496662216289,0.9371657754010695,0.9370816599732262,0.9369973190348525,0.9369127516778524,0.9368279569892473,0.9367429340511441,0.9366576819407008,0.9365721997300944,0.9378378378378378,0.9377537212449256,0.9376693766937669,0.9389416553595658,0.938858695652174,0.9387755102040817,0.9386920980926431,0.9386084583901774,0.9385245901639344,0.9384404924760602,0.9383561643835616,0.9382716049382716,0.9381868131868132,0.938101788170564,0.9380165289256198,0.9393103448275862,0.9392265193370166,0.9391424619640387,0.9390581717451524,0.9389736477115118,0.9388888888888889,0.9388038942976356,0.9387186629526463,0.9400278940027894,0.9413407821229051,0.9412587412587412,0.9411764705882353,0.94109396914446,0.9424157303370787,0.9437412095639943,0.9436619718309859,0.9435825105782792,0.943502824858757,0.9434229137199435,0.943342776203966,0.9432624113475178,0.9431818181818182,0.9431009957325747,0.9430199430199431,0.9429386590584878,0.9428571428571428,0.9427753934191703,0.9441260744985673,0.9440459110473458,0.9439655172413793,0.943884892086331,0.9438040345821326,0.9437229437229437,0.9436416184971098,0.9435600578871202,0.9449275362318841,0.9448476052249637,0.9447674418604651,0.9446870451237264,0.9446064139941691,0.9445255474452555,0.945906432748538,0.9458272327964861,0.9457478005865103,0.947136563876652,0.9470588235294117,0.946980854197349,0.9469026548672567,0.946824224519941,0.9482248520710059,0.9481481481481482,0.9480712166172107,0.9479940564635958,0.9479166666666666,0.9478390461997019,0.9477611940298507,0.9476831091180867,0.9476047904191617,0.9490254872563718,0.948948948948949,0.9488721804511279,0.9487951807228916,0.9487179487179487,0.9486404833836858,0.9485627836611196,0.9484848484848485,0.9484066767830045,0.9483282674772037,0.9482496194824962,0.948170731707317,0.9480916030534351,0.9480122324159022,0.9494640122511485,0.9493865030674846,0.9493087557603687,0.9492307692307692,0.9491525423728814,0.9490740740740741,0.9489953632148377,0.9489164086687306,0.9503875968992248,0.9503105590062112,0.9502332814930016,0.9501557632398754,0.9500780031201248,0.95,0.9499217527386542,0.9498432601880877,0.9497645211930926,0.949685534591195,0.9496062992125984,0.9495268138801262,0.9494470774091627,0.9509493670886076,0.9508716323296355,0.9507936507936507,0.9507154213036566,0.9506369426751592,0.9505582137161085,0.952076677316294,0.9536,0.9535256410256411,0.9534510433386838,0.9533762057877814,0.9533011272141707,0.9532258064516129,0.9531502423263328,0.9530744336569579,0.9529983792544571,0.952922077922078,0.9528455284552846,0.9527687296416938,0.9526916802610114,0.9526143790849673,0.9525368248772504,0.9524590163934427,0.9523809523809523,0.9539473684210527,0.9538714991762768,0.9554455445544554,0.9553719008264463,0.956953642384106,0.956882255389718,0.9568106312292359,0.956738768718802,0.9566666666666667,0.9565943238731218,0.9565217391304348,0.9564489112227805,0.9563758389261745,0.957983193277311,0.9579124579124579,0.9595278246205734,0.9594594594594594,0.9593908629441624,0.9593220338983051,0.9592529711375212,0.9591836734693877,0.959114139693356,0.9590443686006825,0.958974358974359,0.958904109589041,0.9588336192109777,0.9587628865979382,0.9604130808950087,0.9603448275862069,0.9602763385146805,0.9602076124567474,0.9601386481802426,0.9600694444444444,0.96,0.9599303135888502,0.9598603839441536,0.9615384615384616,0.9614711033274956,0.9614035087719298,0.961335676625659,0.9612676056338029,0.9629629629629629,0.9628975265017667,0.9628318584070796,0.9627659574468085,0.9644760213143873,0.9644128113879004,0.964349376114082,0.9642857142857143,0.964221824686941,0.96415770609319,0.9640933572710951,0.9640287769784173,0.9657657657657658,0.9657039711191335,0.9656419529837251,0.9655797101449275,0.9655172413793104,0.9654545454545455,0.9653916211293261,0.9653284671532847,0.9652650822669104,0.9652014652014652,0.9669724770642202,0.9669117647058824,0.9668508287292817,0.966789667896679,0.9685767097966729,0.9685185185185186,0.9684601113172542,0.9684014869888475,0.9683426443202979,0.9682835820895522,0.9682242990654205,0.9681647940074907,0.9681050656660413,0.9680451127819549,0.967984934086629,0.9679245283018868,0.9678638941398866,0.9678030303030303,0.967741935483871,0.967680608365019,0.9676190476190476,0.9675572519083969,0.9674952198852772,0.9674329501915708,0.9692898272552783,0.9692307692307692,0.9691714836223507,0.9691119691119691,0.9690522243713733,0.9689922480620154,0.9689320388349515,0.9688715953307393,0.9688109161793372,0.96875,0.9686888454011742,0.9705882352941176,0.9705304518664047,0.9704724409448819,0.9704142011834319,0.9703557312252964,0.9702970297029703,0.9702380952380952,0.9701789264413518,0.9701195219123506,0.9700598802395209,0.97,0.969939879759519,0.9698795180722891,0.9698189134808853,0.969758064516129,0.9696969696969697,0.9696356275303644,0.9695740365111561,0.9695121951219512,0.9714867617107943,0.9714285714285714,0.9713701431492843,0.9713114754098361,0.971252566735113,0.9711934156378601,0.9711340206185567,0.9710743801652892,0.9710144927536232,0.970954356846473,0.9708939708939709,0.9708333333333333,0.9707724425887265,0.9707112970711297,0.9706498951781971,0.9705882352941176,0.9705263157894737,0.9704641350210971,0.9704016913319239,0.9703389830508474,0.970276008492569,0.9702127659574468,0.9701492537313433,0.9700854700854701,0.9700214132762313,0.9721030042918455,0.9720430107526882,0.9719827586206896,0.9719222462203023,0.9718614718614719,0.9718004338394793,0.9717391304347827,0.971677559912854,0.9716157205240175,0.9715536105032823,0.9714912280701754,0.9714285714285714,0.9713656387665198,0.9713024282560706,0.9712389380530974,0.9711751662971175,0.9733333333333334,0.9732739420935412,0.9732142857142857,0.9731543624161074,0.9730941704035875,0.9730337078651685,0.972972972972973,0.9729119638826185,0.9728506787330317,0.9727891156462585,0.9727272727272728,0.9726651480637813,0.9726027397260274,0.9725400457665904,0.9724770642201835,0.9724137931034482,0.9723502304147466,0.9722863741339491,0.9745370370370371,0.974477958236659,0.9744186046511628,0.9743589743589743,0.9742990654205608,0.9742388758782201,0.9741784037558685,0.9741176470588235,0.9740566037735849,0.9739952718676123,0.9739336492890995,0.9738717339667459,0.9738095238095238,0.9737470167064439,0.9736842105263158,0.973621103117506,0.9735576923076923,0.9734939759036144,0.9734299516908212,0.9733656174334141,0.9733009708737864,0.9732360097323601,0.973170731707317,0.9731051344743277,0.9730392156862745,0.972972972972973,0.9729064039408867,0.9728395061728395,0.9727722772277227,0.9727047146401985,0.972636815920398,0.972568578553616,0.9725,0.9724310776942355,0.9723618090452262,0.9722921914357683,0.9722222222222222,0.9721518987341772,0.9720812182741116,0.9720101781170484,0.9719387755102041,0.9718670076726342,0.9717948717948718,0.9717223650385605,0.9716494845360825,0.9715762273901809,0.9715025906735751,0.9714285714285714,0.9713541666666666,0.9712793733681462,0.9712041884816754,0.9711286089238845,0.9710526315789474,0.9709762532981531,0.9708994708994709,0.9708222811671088,0.973404255319149,0.9733333333333334,0.9732620320855615,0.9731903485254692,0.9731182795698925,0.9730458221024259,0.972972972972973,0.9728997289972899,0.9728260869565217,0.9726775956284153,0.9726027397260274,0.9725274725274725,0.9724517906336089,0.9723756906077348,0.9750692520775623,0.975,0.9749303621169917,0.9748603351955307,0.9747899159663865,0.9775280898876404,0.9774647887323944,0.9774011299435028,0.9773371104815864,0.9772727272727273,0.9772079772079773,0.9771428571428571,0.9770773638968482,0.9770114942528736,0.9769452449567724,0.976878612716763,0.9768115942028985,0.9767441860465116,0.9766763848396501,0.9766081871345029,0.9765395894428153,0.9764705882352941,0.976401179941003,0.9763313609467456,0.9762611275964391,0.9761904761904762,0.9761194029850746,0.9760479041916168,0.975975975975976,0.9759036144578314,0.9758308157099698,0.9757575757575757,0.9756838905775076,0.975609756097561,0.9755351681957186,0.9754601226993865,0.9753846153846154,0.9753086419753086,0.9752321981424149,0.9751552795031055,0.9750778816199377,0.975,0.9780564263322884,0.9779874213836478,0.9779179810725552,0.9778481012658228,0.9777777777777777,0.9777070063694268,0.9776357827476039,0.9775641025641025,0.977491961414791,0.9774193548387097,0.9773462783171522,0.9772727272727273,0.9771986970684039,0.9771241830065359,0.9770491803278688,0.9769736842105263,0.976897689768977,0.9768211920529801,0.9767441860465116,0.9766666666666667,0.9765886287625418,0.9765100671140939,0.9764309764309764,0.9763513513513513,0.976271186440678,0.9795918367346939,0.9795221843003413,0.9794520547945206,0.979381443298969,0.9793103448275862,0.9826989619377162,0.9826388888888888,0.9825783972125436,0.9825174825174825,0.9824561403508771,0.9823943661971831,0.9823321554770318,0.9822695035460993,0.9822064056939501,0.9821428571428571,0.982078853046595,0.9820143884892086,0.9819494584837545,0.9818840579710145,0.9818181818181818,0.9817518248175182,0.9816849816849816,0.9816176470588235,0.981549815498155,0.9814814814814815,0.9814126394052045,0.9813432835820896,0.9812734082397003,0.981203007518797,0.9811320754716981,0.9810606060606061,0.9809885931558935,0.9809160305343512,0.9846743295019157,0.9846153846153847,0.9845559845559846,0.9844961240310077,0.9844357976653697,0.984375,0.984313725490196,0.984251968503937,0.9841897233201581,0.9841269841269841,0.9840637450199203,0.984,0.9839357429718876,0.9838709677419355,0.9838056680161943,0.983739837398374,0.9836734693877551,0.9836065573770492,0.9835390946502057,0.9834710743801653,0.983402489626556,0.9833333333333333,0.9832635983263598,0.9831932773109243,0.9831223628691983,0.9830508474576272,0.9829787234042553,0.9829059829059829,0.9828326180257511,0.9827586206896551,0.9826839826839827,0.9826086956521739,0.982532751091703,0.9824561403508771,0.9823788546255506,0.9823008849557522,0.9822222222222222,0.9821428571428571,0.9820627802690582,0.9819819819819819,0.9819004524886877,0.9818181818181818,0.9817351598173516,0.981651376146789,0.9815668202764977,0.9814814814814815,0.9813953488372092,0.9813084112149533,0.9812206572769953,0.9811320754716981,0.981042654028436,0.9857142857142858,0.9856459330143541,0.9855769230769231,0.9855072463768116,0.9854368932038835,0.9853658536585366,0.9852941176470589,0.9852216748768473,0.9851485148514851,0.9850746268656716,0.985,0.9849246231155779,0.9848484848484849,0.9847715736040609,0.9846938775510204,0.9846153846153847,0.9845360824742269,0.9844559585492227,0.984375,0.9842931937172775,0.9842105263157894,0.9841269841269841,0.9840425531914894,0.983957219251337,0.9838709677419355,0.9837837837837838,0.9891304347826086,0.9890710382513661,0.989010989010989,0.988950276243094,0.9888888888888889,0.9888268156424581,0.9943820224719101,0.9943502824858758,0.9943181818181818,0.9942857142857143,0.9942528735632183,0.9942196531791907,0.9941860465116279,0.9941520467836257,0.9941176470588236,0.9940828402366864,0.9940476190476191,0.9940119760479041,0.9939759036144579,0.9939393939393939,0.9939024390243902,0.9938650306748467,0.9938271604938271,0.9937888198757764,0.99375,0.9937106918238994,0.9936708860759493,0.9936305732484076,0.9935897435897436,0.9935483870967742,0.9935064935064936,0.9934640522875817,0.993421052631579,0.9933774834437086,0.9933333333333333,0.9932885906040269,0.9932432432432432,0.9931972789115646,0.9931506849315068,0.993103448275862,0.9930555555555556,0.993006993006993,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],"yaxis":"y"}],"layout":{"height":600,"legend":{"tracegroupgap":0},"shapes":[{"line":{"dash":"dash"},"type":"line","x0":0,"x1":1,"y0":1,"y1":0}],"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"title":{"text":"Precision-Recall Curve (AUC=0.8819)"},"width":800,"xaxis":{"anchor":"y","constrain":"domain","domain":[0,1],"title":{"text":"Recall"}},"yaxis":{"anchor":"x","domain":[0,1],"scaleanchor":"x","scaleratio":1,"title":{"text":"Precision"}}}},"text/html":["<div>                            <div id=\"6e58aa77-1a57-4aa8-8911-bf6da2a0146b\" class=\"plotly-graph-div\" style=\"height:600px; width:800px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"6e58aa77-1a57-4aa8-8911-bf6da2a0146b\")) {                    Plotly.newPlot(                        \"6e58aa77-1a57-4aa8-8911-bf6da2a0146b\",                        [{\"fillpattern\":{\"shape\":\"\"},\"hovertemplate\":\"Recall=%{x}\\u003cbr\\u003ePrecision=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"stackgroup\":\"1\",\"x\":[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9961277831558567,0.9961277831558567,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9932236205227493,0.9932236205227493,0.9922555663117134,0.9922555663117134,0.9922555663117134,0.9922555663117134,0.9922555663117134,0.9922555663117134,0.9912875121006777,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.989351403678606,0.989351403678606,0.989351403678606,0.989351403678606,0.989351403678606,0.989351403678606,0.989351403678606,0.989351403678606,0.9883833494675702,0.9883833494675702,0.9883833494675702,0.9883833494675702,0.9883833494675702,0.9883833494675702,0.9874152952565344,0.9874152952565344,0.9874152952565344,0.9874152952565344,0.9864472410454985,0.9864472410454985,0.9854791868344628,0.9854791868344628,0.9854791868344628,0.9845111326234269,0.9845111326234269,0.9845111326234269,0.9835430784123911,0.9835430784123911,0.9835430784123911,0.9835430784123911,0.9835430784123911,0.9835430784123911,0.9835430784123911,0.9835430784123911,0.9835430784123911,0.9825750242013552,0.9825750242013552,0.9825750242013552,0.9816069699903195,0.9816069699903195,0.9816069699903195,0.9816069699903195,0.9816069699903195,0.9816069699903195,0.9816069699903195,0.9816069699903195,0.9816069699903195,0.9806389157792836,0.9806389157792836,0.9796708615682478,0.9796708615682478,0.9796708615682478,0.9796708615682478,0.9796708615682478,0.9796708615682478,0.9796708615682478,0.9796708615682478,0.9796708615682478,0.9796708615682478,0.9796708615682478,0.9796708615682478,0.9796708615682478,0.978702807357212,0.9777347531461762,0.9777347531461762,0.9777347531461762,0.9777347531461762,0.9767666989351403,0.9767666989351403,0.9767666989351403,0.9767666989351403,0.9767666989351403,0.9757986447241046,0.9748305905130688,0.9748305905130688,0.9748305905130688,0.9748305905130688,0.9748305905130688,0.9748305905130688,0.9748305905130688,0.9748305905130688,0.9748305905130688,0.9738625363020329,0.9738625363020329,0.972894482090997,0.9719264278799613,0.9709583736689255,0.9709583736689255,0.9699903194578896,0.9699903194578896,0.9690222652468539,0.9690222652468539,0.968054211035818,0.968054211035818,0.968054211035818,0.9670861568247822,0.9670861568247822,0.9670861568247822,0.9661181026137464,0.9661181026137464,0.9661181026137464,0.9651500484027106,0.9651500484027106,0.9641819941916747,0.9641819941916747,0.9641819941916747,0.9632139399806389,0.9622458857696031,0.9622458857696031,0.9622458857696031,0.9612778315585673,0.9612778315585673,0.9603097773475314,0.9603097773475314,0.9603097773475314,0.9603097773475314,0.9603097773475314,0.9603097773475314,0.9603097773475314,0.9603097773475314,0.9603097773475314,0.9603097773475314,0.9593417231364957,0.9583736689254598,0.9583736689254598,0.9583736689254598,0.9583736689254598,0.9583736689254598,0.9583736689254598,0.957405614714424,0.957405614714424,0.9564375605033882,0.9564375605033882,0.9554695062923524,0.9545014520813165,0.9535333978702807,0.952565343659245,0.9515972894482091,0.9515972894482091,0.9515972894482091,0.9515972894482091,0.9515972894482091,0.9515972894482091,0.9515972894482091,0.9506292352371732,0.9506292352371732,0.9496611810261375,0.9496611810261375,0.9496611810261375,0.9486931268151017,0.9486931268151017,0.9486931268151017,0.9477250726040658,0.9467570183930301,0.9457889641819942,0.9448209099709584,0.9438528557599225,0.9438528557599225,0.9438528557599225,0.9438528557599225,0.9428848015488868,0.9428848015488868,0.9428848015488868,0.9419167473378509,0.9409486931268151,0.9409486931268151,0.9409486931268151,0.9399806389157793,0.9399806389157793,0.9390125847047435,0.9390125847047435,0.9380445304937076,0.9370764762826719,0.9370764762826719,0.936108422071636,0.936108422071636,0.936108422071636,0.9351403678606002,0.9351403678606002,0.9351403678606002,0.9351403678606002,0.9351403678606002,0.9351403678606002,0.9341723136495643,0.9341723136495643,0.9341723136495643,0.9332042594385286,0.9322362052274927,0.9322362052274927,0.9322362052274927,0.9312681510164569,0.9303000968054211,0.9303000968054211,0.9303000968054211,0.9293320425943853,0.9283639883833494,0.9283639883833494,0.9283639883833494,0.9273959341723137,0.9264278799612778,0.9264278799612778,0.9264278799612778,0.9264278799612778,0.925459825750242,0.925459825750242,0.9244917715392061,0.9235237173281704,0.9225556631171346,0.9225556631171346,0.9225556631171346,0.9215876089060987,0.9215876089060987,0.920619554695063,0.9196515004840271,0.9186834462729913,0.9186834462729913,0.9186834462729913,0.9177153920619555,0.9177153920619555,0.9177153920619555,0.9167473378509197,0.9157792836398838,0.914811229428848,0.9138431752178122,0.9138431752178122,0.9128751210067764,0.9119070667957405,0.9109390125847048,0.9099709583736689,0.9090029041626331,0.9080348499515973,0.9070667957405615,0.9060987415295256,0.9060987415295256,0.9051306873184899,0.9051306873184899,0.9051306873184899,0.9051306873184899,0.9051306873184899,0.904162633107454,0.9031945788964182,0.9031945788964182,0.9022265246853823,0.9012584704743466,0.9002904162633107,0.8993223620522749,0.8983543078412392,0.8973862536302033,0.8964181994191674,0.8964181994191674,0.8964181994191674,0.8964181994191674,0.8954501452081317,0.8954501452081317,0.8954501452081317,0.8954501452081317,0.8954501452081317,0.8944820909970959,0.89351403678606,0.89351403678606,0.89351403678606,0.8925459825750242,0.8915779283639884,0.8906098741529526,0.8906098741529526,0.8896418199419167,0.888673765730881,0.888673765730881,0.888673765730881,0.8877057115198451,0.8877057115198451,0.8867376573088093,0.8857696030977735,0.8857696030977735,0.8848015488867377,0.8838334946757018,0.8838334946757018,0.882865440464666,0.8818973862536302,0.8809293320425944,0.8799612778315585,0.8789932236205228,0.8789932236205228,0.8780251694094869,0.8770571151984511,0.8770571151984511,0.8770571151984511,0.8760890609874153,0.8760890609874153,0.8760890609874153,0.8760890609874153,0.8751210067763795,0.8751210067763795,0.8751210067763795,0.8751210067763795,0.8741529525653436,0.8741529525653436,0.8731848983543078,0.872216844143272,0.8712487899322362,0.8702807357212003,0.8693126815101646,0.8683446272991288,0.8673765730880929,0.8664085188770572,0.8654404646660213,0.8644724104549855,0.8644724104549855,0.8635043562439496,0.8625363020329139,0.8625363020329139,0.861568247821878,0.8606001936108422,0.8596321393998064,0.8596321393998064,0.8586640851887706,0.8586640851887706,0.8576960309777347,0.856727976766699,0.8557599225556631,0.8547918683446273,0.8538238141335914,0.8528557599225557,0.8518877057115198,0.850919651500484,0.8499515972894482,0.8489835430784124,0.8480154888673765,0.8470474346563408,0.846079380445305,0.8451113262342691,0.8451113262342691,0.8451113262342691,0.8441432720232332,0.8431752178121975,0.8422071636011617,0.8412391093901258,0.8402710551790901,0.8402710551790901,0.8402710551790901,0.8393030009680542,0.8383349467570184,0.8373668925459826,0.8373668925459826,0.8363988383349468,0.8354307841239109,0.8344627299128751,0.8334946757018393,0.8334946757018393,0.8325266214908035,0.8315585672797676,0.8315585672797676,0.8305905130687319,0.829622458857696,0.8286544046466602,0.8286544046466602,0.8286544046466602,0.8276863504356244,0.8276863504356244,0.8267182962245886,0.8267182962245886,0.8257502420135527,0.8247821878025169,0.8247821878025169,0.8247821878025169,0.8247821878025169,0.8247821878025169,0.8238141335914811,0.8228460793804453,0.8228460793804453,0.8218780251694094,0.8209099709583737,0.8199419167473379,0.818973862536302,0.8180058083252663,0.8170377541142304,0.8160696999031946,0.8151016456921588,0.814133591481123,0.8131655372700871,0.8121974830590513,0.8121974830590513,0.8112294288480155,0.8102613746369797,0.8092933204259438,0.8083252662149081,0.8073572120038722,0.8063891577928364,0.8054211035818006,0.8044530493707648,0.8034849951597289,0.8025169409486931,0.8015488867376573,0.8005808325266215,0.7996127783155856,0.7996127783155856,0.7986447241045499,0.7986447241045499,0.797676669893514,0.797676669893514,0.7967086156824782,0.7957405614714425,0.7947725072604066,0.7938044530493708,0.7928363988383349,0.7918683446272992,0.7909002904162633,0.7899322362052275,0.7889641819941917,0.7889641819941917,0.7889641819941917,0.7879961277831559,0.7879961277831559,0.78702807357212,0.7860600193610843,0.7850919651500484,0.7841239109390126,0.7831558567279767,0.7831558567279767,0.782187802516941,0.7812197483059051,0.7802516940948693,0.7792836398838335,0.7792836398838335,0.7792836398838335,0.7783155856727977,0.7773475314617618,0.7763794772507261,0.7754114230396902,0.7744433688286544,0.7734753146176185,0.7725072604065828,0.7725072604065828,0.771539206195547,0.771539206195547,0.7705711519845111,0.7705711519845111,0.7705711519845111,0.7696030977734754,0.7686350435624395,0.7686350435624395,0.7676669893514037,0.7666989351403679,0.7666989351403679,0.7657308809293321,0.7647628267182962,0.7637947725072604,0.7628267182962246,0.7618586640851888,0.7608906098741529,0.7599225556631172,0.7589545014520813,0.7579864472410455,0.7579864472410455,0.7570183930300097,0.7560503388189739,0.7560503388189739,0.755082284607938,0.755082284607938,0.7541142303969022,0.7531461761858664,0.7521781219748306,0.7512100677637947,0.750242013552759,0.7492739593417231,0.7483059051306873,0.7483059051306873,0.7473378509196515,0.7463697967086157,0.7463697967086157,0.7454017424975798,0.7454017424975798,0.7454017424975798,0.744433688286544,0.7434656340755083,0.7424975798644724,0.7415295256534365,0.7405614714424008,0.739593417231365,0.7386253630203291,0.7376573088092934,0.7366892545982575,0.7357212003872217,0.7347531461761858,0.7337850919651501,0.7328170377541142,0.7318489835430784,0.7308809293320426,0.7308809293320426,0.7299128751210068,0.7289448209099709,0.7279767666989352,0.7279767666989352,0.7270087124878993,0.7270087124878993,0.7260406582768635,0.7250726040658277,0.7241045498547919,0.723136495643756,0.723136495643756,0.7221684414327202,0.7212003872216844,0.7212003872216844,0.7202323330106486,0.7192642787996127,0.718296224588577,0.7173281703775412,0.7163601161665053,0.7153920619554696,0.7144240077444337,0.7144240077444337,0.7134559535333979,0.712487899322362,0.712487899322362,0.7115198451113263,0.7105517909002904,0.7105517909002904,0.7095837366892546,0.7095837366892546,0.7086156824782188,0.707647628267183,0.7066795740561471,0.7057115198451114,0.7057115198451114,0.7047434656340755,0.7037754114230397,0.7028073572120038,0.7018393030009681,0.7008712487899322,0.6999031945788964,0.6989351403678606,0.6979670861568248,0.6969990319457889,0.6960309777347532,0.6950629235237173,0.6940948693126815,0.6931268151016456,0.6921587608906099,0.691190706679574,0.6902226524685382,0.6892545982575025,0.6882865440464666,0.6873184898354308,0.686350435624395,0.6853823814133592,0.6844143272023233,0.6834462729912875,0.6824782187802517,0.6815101645692159,0.68054211035818,0.6795740561471443,0.6786060019361084,0.6776379477250726,0.6766698935140368,0.675701839303001,0.6747337850919651,0.6737657308809293,0.6727976766698935,0.6718296224588577,0.6718296224588577,0.6708615682478218,0.6698935140367861,0.6698935140367861,0.6689254598257502,0.6679574056147144,0.6669893514036787,0.6660212971926428,0.665053242981607,0.6640851887705711,0.6631171345595354,0.6621490803484995,0.6611810261374637,0.6602129719264279,0.6592449177153921,0.6592449177153921,0.6582768635043562,0.6573088092933205,0.6563407550822846,0.6553727008712488,0.6544046466602129,0.6534365924491772,0.6524685382381413,0.6524685382381413,0.6524685382381413,0.6515004840271055,0.6505324298160697,0.6495643756050339,0.6495643756050339,0.6495643756050339,0.648596321393998,0.6476282671829623,0.6466602129719264,0.6456921587608906,0.6447241045498547,0.643756050338819,0.6427879961277831,0.6418199419167473,0.6408518877057116,0.6398838334946757,0.6389157792836399,0.6379477250726041,0.6379477250726041,0.6369796708615683,0.6360116166505324,0.6350435624394967,0.6340755082284608,0.633107454017425,0.6321393998063891,0.6311713455953534,0.6311713455953534,0.6302032913843175,0.6292352371732817,0.6282671829622459,0.6272991287512101,0.6263310745401742,0.6263310745401742,0.6253630203291385,0.6243949661181026,0.6243949661181026,0.6234269119070668,0.6224588576960309,0.6214908034849952,0.6205227492739593,0.6205227492739593,0.6195546950629235,0.6185866408518877,0.6176185866408519,0.616650532429816,0.6156824782187803,0.6147144240077445,0.6137463697967086,0.6127783155856728,0.6127783155856728,0.611810261374637,0.6108422071636012,0.6098741529525653,0.6089060987415296,0.6079380445304937,0.6069699903194579,0.6060019361084221,0.6050338818973863,0.6040658276863504,0.6030977734753146,0.6021297192642788,0.601161665053243,0.6001936108422071,0.6001936108422071,0.5992255566311714,0.5982575024201355,0.5972894482090997,0.5963213939980639,0.5953533397870281,0.5943852855759922,0.5934172313649564,0.5934172313649564,0.5924491771539206,0.5914811229428848,0.590513068731849,0.5895450145208132,0.5885769603097774,0.5876089060987415,0.5866408518877058,0.5856727976766699,0.5847047434656341,0.5837366892545982,0.5827686350435625,0.5818005808325266,0.5818005808325266,0.5808325266214908,0.579864472410455,0.5788964181994192,0.5779283639883833,0.5769603097773476,0.5769603097773476,0.5769603097773476,0.5759922555663117,0.5750242013552759,0.57405614714424,0.5730880929332043,0.5721200387221684,0.5711519845111326,0.5701839303000968,0.569215876089061,0.5682478218780251,0.5672797676669894,0.5663117134559535,0.5653436592449177,0.5643756050338818,0.5634075508228461,0.5624394966118103,0.5614714424007744,0.5614714424007744,0.5605033881897387,0.5605033881897387,0.5595353339787028,0.5595353339787028,0.558567279767667,0.5575992255566312,0.5566311713455954,0.5556631171345595,0.5546950629235237,0.5537270087124879,0.5527589545014521,0.5517909002904162,0.5517909002904162,0.5508228460793805,0.5508228460793805,0.5498547918683446,0.5488867376573088,0.547918683446273,0.5469506292352372,0.5459825750242013,0.5450145208131656,0.5440464666021297,0.5430784123910939,0.542110358180058,0.5411423039690223,0.5401742497579864,0.5401742497579864,0.5392061955469506,0.5382381413359149,0.537270087124879,0.5363020329138432,0.5353339787028074,0.5343659244917716,0.5333978702807357,0.5324298160696999,0.5324298160696999,0.5314617618586641,0.5304937076476283,0.5295256534365924,0.5285575992255567,0.5285575992255567,0.5275895450145208,0.526621490803485,0.5256534365924492,0.5256534365924492,0.5246853823814134,0.5237173281703775,0.5227492739593417,0.5217812197483059,0.5208131655372701,0.5198451113262342,0.5188770571151985,0.5188770571151985,0.5179090029041626,0.5169409486931268,0.515972894482091,0.5150048402710552,0.5140367860600193,0.5130687318489835,0.5121006776379478,0.5111326234269119,0.510164569215876,0.510164569215876,0.5091965150048403,0.5082284607938045,0.5072604065827686,0.5072604065827686,0.5062923523717329,0.505324298160697,0.5043562439496612,0.5033881897386253,0.5024201355275896,0.5014520813165537,0.5004840271055179,0.4995159728944821,0.4985479186834463,0.4975798644724105,0.49661181026137463,0.49564375605033884,0.494675701839303,0.4937076476282672,0.4927395934172314,0.49177153920619554,0.49080348499515974,0.4898354307841239,0.4888673765730881,0.4888673765730881,0.4878993223620523,0.48693126815101645,0.48596321393998065,0.4849951597289448,0.484027105517909,0.4830590513068732,0.48209099709583736,0.48112294288480156,0.4801548886737657,0.4791868344627299,0.4791868344627299,0.4782187802516941,0.47725072604065827,0.4762826718296225,0.4753146176185866,0.4743465634075508,0.47337850919651503,0.4724104549854792,0.4714424007744434,0.47047434656340753,0.46950629235237173,0.46853823814133594,0.4675701839303001,0.4666021297192643,0.46563407550822844,0.46466602129719264,0.46369796708615685,0.462729912875121,0.4617618586640852,0.4617618586640852,0.46079380445304935,0.45982575024201355,0.45885769603097776,0.4578896418199419,0.4569215876089061,0.45595353339787026,0.45498547918683446,0.45401742497579867,0.4530493707647628,0.452081316553727,0.45111326234269117,0.45014520813165537,0.4491771539206196,0.4482090997095837,0.44724104549854793,0.4462729912875121,0.4453049370764763,0.4443368828654405,0.44336882865440463,0.44240077444336884,0.441432720232333,0.4404646660212972,0.4394966118102614,0.43852855759922554,0.43852855759922554,0.43756050338818975,0.4365924491771539,0.4356243949661181,0.4346563407550823,0.43368828654404645,0.43272023233301066,0.4317521781219748,0.430784123910939,0.4298160696999032,0.42884801548886736,0.42787996127783157,0.4269119070667957,0.4259438528557599,0.4249757986447241,0.42400774443368827,0.42400774443368827,0.4230396902226525,0.4220716360116166,0.42110358180058083,0.42013552758954503,0.4191674733785092,0.4181994191674734,0.41723136495643753,0.41626331074540174,0.41529525653436594,0.4143272023233301,0.4133591481122943,0.41239109390125844,0.41142303969022265,0.41045498547918685,0.409486931268151,0.4085188770571152,0.4075508228460794,0.4075508228460794,0.40658276863504356,0.40561471442400776,0.4046466602129719,0.4036786060019361,0.4027105517909003,0.40174249757986447,0.40077444336882867,0.3998063891577928,0.398838334946757,0.3978702807357212,0.3969022265246854,0.3959341723136496,0.39496611810261373,0.39399806389157793,0.39303000968054214,0.3920619554695063,0.3910939012584705,0.39012584704743464,0.38915779283639884,0.38818973862536305,0.3872216844143272,0.3862536302032914,0.38528557599225555,0.38431752178121975,0.38334946757018395,0.3823814133591481,0.3814133591481123,0.38044530493707646,0.37947725072604066,0.37850919651500486,0.377541142303969,0.3765730880929332,0.37560503388189737,0.37463697967086157,0.3736689254598258,0.3727008712487899,0.3717328170377541,0.3707647628267183,0.3697967086156825,0.3688286544046467,0.36786060019361083,0.36689254598257504,0.3659244917715392,0.3649564375605034,0.3639883833494676,0.36302032913843174,0.36205227492739595,0.3610842207163601,0.3601161665053243,0.3591481122942885,0.35818005808325265,0.35721200387221685,0.356243949661181,0.3552758954501452,0.3543078412391094,0.3543078412391094,0.35333978702807356,0.35237173281703776,0.3514036786060019,0.3504356243949661,0.3494675701839303,0.34849951597289447,0.3475314617618587,0.3465634075508228,0.34462729912875123,0.3436592449177154,0.3426911907066796,0.34172313649564373,0.34075508228460794,0.34075508228460794,0.33978702807357214,0.3388189738625363,0.3378509196515005,0.33688286544046464,0.33688286544046464,0.33591481122942884,0.33494675701839305,0.3339787028073572,0.3330106485963214,0.33204259438528555,0.33107454017424975,0.33010648596321396,0.3291384317521781,0.3281703775411423,0.32720232333010646,0.32623426911907066,0.32526621490803487,0.324298160696999,0.3233301064859632,0.32236205227492737,0.3213939980638916,0.3204259438528558,0.3194578896418199,0.31848983543078413,0.31752178121974833,0.3165537270087125,0.3155856727976767,0.31461761858664083,0.31364956437560504,0.31268151016456924,0.3117134559535334,0.3107454017424976,0.30977734753146174,0.30880929332042595,0.30784123910939015,0.3068731848983543,0.3059051306873185,0.30493707647628265,0.30396902226524686,0.30300096805421106,0.3020329138431752,0.3020329138431752,0.3010648596321394,0.30009680542110356,0.29912875121006777,0.29816069699903197,0.2971926427879961,0.2962245885769603,0.2952565343659245,0.2942884801548887,0.2933204259438529,0.29235237173281703,0.29138431752178123,0.2904162633107454,0.2894482090997096,0.2884801548886738,0.28751210067763794,0.28654404646660214,0.2855759922555663,0.2846079380445305,0.2836398838334947,0.28267182962245885,0.28170377541142305,0.2807357212003872,0.2797676669893514,0.2787996127783156,0.2787996127783156,0.27783155856727976,0.27686350435624396,0.2758954501452081,0.2749273959341723,0.2749273959341723,0.2739593417231365,0.27299128751210067,0.27202323330106487,0.271055179090029,0.2700871248789932,0.2691190706679574,0.2681510164569216,0.2671829622458858,0.26621490803484993,0.26524685382381413,0.26427879961277834,0.2633107454017425,0.2623426911907067,0.26137463697967084,0.26040658276863504,0.25943852855759925,0.2584704743465634,0.2575024201355276,0.25653436592449175,0.25556631171345595,0.25459825750242016,0.2536302032913843,0.2526621490803485,0.25169409486931266,0.25072604065827686,0.24975798644724104,0.24878993223620524,0.24878993223620524,0.24782187802516942,0.2468538238141336,0.24588576960309777,0.24491771539206195,0.24394966118102615,0.24298160696999033,0.2420135527589545,0.24104549854791868,0.24007744433688286,0.23910939012584706,0.23814133591481124,0.2371732817037754,0.2362052274927396,0.23523717328170377,0.23426911907066797,0.23330106485963215,0.23233301064859632,0.2313649564375605,0.23039690222652467,0.22942884801548888,0.22846079380445306,0.22749273959341723,0.2265246853823814,0.22555663117134558,0.2245885769603098,0.22362052274927396,0.22265246853823814,0.22168441432720232,0.2207163601161665,0.2197483059051307,0.21878025169409487,0.21781219748305905,0.21684414327202323,0.2158760890609874,0.2149080348499516,0.21393998063891578,0.21297192642787996,0.21200387221684414,0.2110358180058083,0.21006776379477252,0.2090997095837367,0.20813165537270087,0.20716360116166505,0.20619554695062922,0.20522749273959343,0.2042594385285576,0.20329138431752178,0.20232333010648595,0.20135527589545016,0.20038722168441434,0.20038722168441434,0.1994191674733785,0.1984511132623427,0.19748305905130686,0.19651500484027107,0.19554695062923524,0.19457889641819942,0.1936108422071636,0.19264278799612777,0.19167473378509198,0.19070667957405615,0.18973862536302033,0.1887705711519845,0.18780251694094868,0.1868344627299129,0.18586640851887706,0.18489835430784124,0.18393030009680542,0.1829622458857696,0.1819941916747338,0.18102613746369797,0.18005808325266215,0.17909002904162633,0.1781219748305905,0.1771539206195547,0.17618586640851888,0.17618586640851888,0.17521781219748306,0.17424975798644723,0.1732817037754114,0.17231364956437561,0.1713455953533398,0.1713455953533398,0.17037754114230397,0.16940948693126814,0.16844143272023232,0.16747337850919652,0.1665053242981607,0.16553727008712488,0.16456921587608905,0.16360116166505323,0.16263310745401743,0.1616650532429816,0.1606969990319458,0.15972894482090996,0.15876089060987417,0.15779283639883834,0.15682478218780252,0.1558567279767667,0.15488867376573087,0.15392061955469508,0.15295256534365925,0.15198451113262343,0.1510164569215876,0.15004840271055178,0.14908034849951599,0.14811229428848016,0.14714424007744434,0.14617618586640851,0.1452081316553727,0.1442400774443369,0.14327202323330107,0.14230396902226525,0.14133591481122942,0.1403678606001936,0.1393998063891578,0.13843175217812198,0.13746369796708616,0.13746369796708616,0.13649564375605033,0.1355275895450145,0.1345595353339787,0.1335914811229429,0.13165537270087124,0.13068731848983542,0.12971926427879962,0.1287512100677638,0.12778315585672798,0.12681510164569215,0.12584704743465633,0.12487899322362052,0.12391093901258471,0.12294288480154889,0.12197483059051308,0.12100677637947725,0.12003872216844143,0.11907066795740562,0.1181026137463698,0.11713455953533398,0.11616650532429816,0.11519845111326234,0.11423039690222653,0.1132623426911907,0.1122942884801549,0.11132623426911907,0.11035818005808325,0.10939012584704744,0.10842207163601161,0.1074540174249758,0.10648596321393998,0.10551790900290416,0.10454985479186835,0.10358180058083252,0.10261374636979671,0.10164569215876089,0.09970958373668926,0.09874152952565343,0.09777347531461762,0.0968054211035818,0.09583736689254599,0.09486931268151017,0.09390125847047434,0.09293320425943853,0.09196515004840271,0.0909970958373669,0.09002904162633107,0.08906098741529525,0.08712487899322362,0.08615682478218781,0.08518877057115198,0.08422071636011616,0.08325266214908035,0.08228460793804453,0.08131655372700872,0.0803484995159729,0.07938044530493708,0.07841239109390126,0.07744433688286544,0.07647628267182963,0.0755082284607938,0.07454017424975799,0.07357212003872217,0.07163601161665054,0.07066795740561471,0.0696999031945789,0.06873184898354308,0.06776379477250725,0.06679574056147145,0.06582768635043562,0.06485963213939981,0.06389157792836399,0.061955469506292354,0.06098741529525654,0.060019361084220714,0.0590513068731849,0.05808325266214908,0.057115198451113264,0.05614714424007745,0.05517909002904162,0.05421103581800581,0.05324298160696999,0.05227492739593417,0.051306873184898356,0.05033881897386254,0.049370764762826716,0.0484027105517909,0.04743465634075508,0.046466602129719266,0.04549854791868345,0.044530493707647625,0.04259438528557599,0.04065827686350436,0.03969022265246854,0.03872216844143272,0.036786060019361085,0.03581800580832527,0.03388189738625363,0.03291384317521781,0.02904162633107454,0.022265246853823813,0.021297192642787996,0.0],\"xaxis\":\"x\",\"y\":[0.7341862117981521,0.7347083926031295,0.7352313167259786,0.7357549857549858,0.7362794012829651,0.7368045649072753,0.7373304782298359,0.7378571428571429,0.7383845604002859,0.7389127324749643,0.7394416607015032,0.7399713467048711,0.7405017921146954,0.7410329985652798,0.741564967695621,0.7420977011494253,0.7426312005751258,0.7431654676258993,0.7437005039596832,0.7442363112391931,0.7447728911319395,0.7453102453102453,0.7458483754512636,0.7463872832369942,0.7469269703543022,0.7474674384949349,0.7480086893555394,0.7485507246376811,0.7490935460478607,0.7496371552975326,0.7501815541031227,0.7507267441860465,0.7512727272727273,0.7518195050946143,0.752367079388201,0.7529154518950437,0.7527352297592997,0.7532846715328467,0.7538349159970782,0.7543859649122807,0.7549378200438918,0.7554904831625183,0.756043956043956,0.7565982404692082,0.7571533382245048,0.7569750367107195,0.7575312270389419,0.7580882352941176,0.7586460632818248,0.7592047128129602,0.7597641857037583,0.7603244837758112,0.7608856088560886,0.7607090103397341,0.7612712490761271,0.7618343195266272,0.7623982235381199,0.762962962962963,0.7635285396590067,0.7640949554896143,0.7646622123236823,0.7652303120356612,0.7657992565055762,0.7663690476190477,0.766939687267312,0.767511177347243,0.767337807606264,0.767910447761194,0.7677371172516804,0.7683109118086696,0.768885564697083,0.7694610778443114,0.7700374531835206,0.7706146926536732,0.7711927981995499,0.7717717717717718,0.772351615326822,0.7729323308270677,0.7735139202407826,0.7740963855421686,0.7739261492087415,0.7745098039215687,0.7750943396226415,0.775679758308157,0.7762660619803476,0.7768532526475038,0.7774413323239969,0.7772727272727272,0.7778620166793025,0.7776934749620638,0.7782839787395596,0.7788753799392097,0.779467680608365,0.7800608828006088,0.7806549885757806,0.7804878048780488,0.7803203661327232,0.7809160305343511,0.7815126050420168,0.7821100917431193,0.782708492731446,0.7833078101071975,0.7839080459770115,0.7845092024539877,0.7851112816577129,0.7857142857142857,0.7863182167563413,0.786923076923077,0.7867590454195535,0.7873651771956857,0.7879722436391673,0.7885802469135802,0.7891891891891892,0.7897990726429676,0.7904098994586234,0.7910216718266254,0.790859798605732,0.7914728682170543,0.7920868890612878,0.7927018633540373,0.7933177933177933,0.7939346811819595,0.7937743190661478,0.794392523364486,0.7950116913484022,0.7956318252730109,0.795472287275566,0.79609375,0.7959343236903831,0.7965571205007824,0.7971808927173062,0.7970219435736677,0.7976470588235294,0.7982731554160125,0.798114689709348,0.7987421383647799,0.7993705743509048,0.8,0.8006304176516943,0.8012618296529969,0.8018942383583267,0.8025276461295419,0.8031620553359684,0.803006329113924,0.8036421219319082,0.8042789223454834,0.8041237113402062,0.8047619047619048,0.8054011119936457,0.8060413354531002,0.8066825775656324,0.8073248407643312,0.8079681274900399,0.8086124401913876,0.8092577813248204,0.8091054313099042,0.8097521982414069,0.8096,0.8102481985588471,0.8108974358974359,0.8115477145148356,0.812199036918138,0.8128514056224899,0.8135048231511254,0.8141592920353983,0.8148148148148148,0.8154713940370669,0.8161290322580645,0.8167877320419693,0.8174474959612278,0.8172999191592563,0.8171521035598706,0.8178137651821862,0.8184764991896273,0.819140308191403,0.8189935064935064,0.8196588139723802,0.8203252032520325,0.8209926769731489,0.8216612377850163,0.8215158924205379,0.8213703099510603,0.8220408163265306,0.8227124183006536,0.8233851185609158,0.8240589198036007,0.8247338247338247,0.8254098360655737,0.8260869565217391,0.8267651888341544,0.8266228430566968,0.8273026315789473,0.8271604938271605,0.8270181219110379,0.8268755152514426,0.8275577557755776,0.8274153592072667,0.828099173553719,0.8279569892473119,0.8286423841059603,0.8285004142502072,0.8291873963515755,0.8298755186721992,0.829734219269103,0.830423940149626,0.8311148086522463,0.8309741881765196,0.8316666666666667,0.8323603002502085,0.832220367278798,0.8329156223893066,0.8327759197324415,0.8334728033472804,0.8341708542713567,0.8340318524727578,0.8338926174496645,0.834592779177162,0.8352941176470589,0.8351555929352397,0.8358585858585859,0.8357203032855939,0.836424957841484,0.8371308016877637,0.8378378378378378,0.8385460693153001,0.8392554991539763,0.8399661303979679,0.8406779661016949,0.8413910093299406,0.8421052631578947,0.8419711129991504,0.8418367346938775,0.8425531914893617,0.8432708688245315,0.8439897698209718,0.8447098976109215,0.8454312553373186,0.8452991452991453,0.8460222412318221,0.8458904109589042,0.8466152527849186,0.8464837049742711,0.8463519313304722,0.8462199312714777,0.8460877042132416,0.8459552495697074,0.8466838931955211,0.8474137931034482,0.8481449525452976,0.8488773747841105,0.8496110630942092,0.8503460207612457,0.8502164502164502,0.8509532062391681,0.8508239375542064,0.8515625,0.8523023457862728,0.8521739130434782,0.8529155787641427,0.8536585365853658,0.8535309503051438,0.8534031413612565,0.8532751091703057,0.8531468531468531,0.8530183727034121,0.8537653239929948,0.8545135845749343,0.8552631578947368,0.8551360842844601,0.8558875219683656,0.8566402814423922,0.8565140845070423,0.8563876651982378,0.8571428571428571,0.8578993821712269,0.857773851590106,0.8585322723253758,0.8584070796460177,0.8591674047829938,0.8590425531914894,0.8589174800354925,0.8596802841918295,0.8595555555555555,0.8603202846975089,0.8610863757791629,0.8609625668449198,0.8617305976806423,0.8625,0.8632707774798928,0.8640429338103757,0.864816472694718,0.8646953405017921,0.8654708520179372,0.8662477558348295,0.8661275831087152,0.8660071942446043,0.8667866786678667,0.8675675675675676,0.8674481514878268,0.8673285198555957,0.8681120144534779,0.8688969258589512,0.8687782805429864,0.8686594202898551,0.8694469628286491,0.8702359346642469,0.8701180744777475,0.87,0.8707916287534122,0.8715846994535519,0.8723792160437557,0.8722627737226277,0.8730593607305936,0.8729433272394881,0.8728270814272644,0.8727106227106227,0.8735105407882676,0.8743119266055046,0.8741965105601469,0.875,0.874885004599816,0.8747697974217311,0.8746543778801843,0.8754612546125461,0.876269621421976,0.8761552680221811,0.8769657724329325,0.8777777777777778,0.8776645041705282,0.8775510204081632,0.8774373259052924,0.8773234200743495,0.878139534883721,0.8780260707635009,0.8779123951537745,0.8777985074626866,0.8776844070961718,0.8775700934579439,0.8774555659494855,0.8773408239700374,0.8772258669165885,0.8780487804878049,0.8779342723004695,0.8787593984962406,0.8795860771401693,0.8804143126177024,0.88124410933082,0.8811320754716981,0.8810198300283286,0.8818525519848771,0.8817407757805109,0.8816287878787878,0.8815165876777251,0.881404174573055,0.8812915479582146,0.8811787072243346,0.8810656517602283,0.8819047619047619,0.882745471877979,0.8835877862595419,0.8834765998089781,0.884321223709369,0.8851674641148325,0.8860153256704981,0.8868648130393096,0.8867562380038387,0.8866474543707973,0.8875,0.888354186717998,0.8882466281310212,0.8881388621022179,0.888030888030888,0.8888888888888888,0.8887814313346228,0.888673765730881,0.8895348837209303,0.8903976721629486,0.8902912621359224,0.891156462585034,0.8910505836575876,0.8909444985394352,0.8918128654970761,0.8917073170731707,0.8916015625,0.8924731182795699,0.8923679060665362,0.8922624877571009,0.8921568627450981,0.8920510304219823,0.8919449901768173,0.8928220255653884,0.8927165354330708,0.8926108374384236,0.893491124260355,0.8943731490621916,0.8942687747035574,0.8951533135509396,0.8960396039603961,0.8969276511397423,0.8968253968253969,0.8977159880834161,0.8986083499005965,0.8995024875621891,0.899402390438247,0.9002991026919243,0.9001996007984032,0.9000999000999002,0.9,0.8998998998998999,0.8997995991983968,0.8996990972918756,0.8995983935742972,0.8994974874371859,0.8993963782696177,0.8992950654582075,0.9002016129032258,0.900100908173562,0.9,0.9009100101112234,0.9008097165991903,0.900709219858156,0.9006085192697769,0.9015228426395939,0.9014227642276422,0.9023397761953205,0.9022403258655805,0.9021406727828746,0.9020408163265307,0.9019407558733401,0.901840490797546,0.901740020470829,0.9016393442622951,0.9015384615384615,0.9014373716632443,0.9013360739979445,0.9012345679012346,0.9011328527291452,0.9010309278350516,0.9009287925696594,0.9018595041322314,0.9027921406411582,0.9026915113871635,0.9025906735751296,0.9024896265560166,0.9023883696780893,0.9022869022869023,0.9032258064516129,0.9041666666666667,0.9040667361835245,0.9039665970772442,0.9038662486938349,0.9048117154811716,0.9047120418848168,0.9046121593291404,0.9045120671563484,0.9044117647058824,0.9053627760252366,0.9052631578947369,0.9051633298208641,0.9061181434599156,0.9060190073917634,0.9059196617336153,0.9058201058201059,0.9067796610169492,0.9077412513255567,0.9076433121019108,0.9086078639744952,0.9085106382978724,0.9094781682641108,0.9093816631130064,0.9092849519743863,0.9102564102564102,0.9112299465240642,0.9122055674518201,0.9131832797427653,0.9130901287553648,0.9129967776584318,0.9139784946236559,0.9138858988159311,0.9137931034482759,0.9137001078748651,0.9136069114470843,0.9135135135135135,0.9134199134199135,0.9133261105092091,0.913232104121475,0.9131378935939196,0.9130434782608695,0.9129488574537541,0.9139433551198257,0.9138495092693566,0.9137554585152838,0.9136612021857924,0.9135667396061269,0.9134720700985761,0.9133771929824561,0.9132821075740944,0.9131868131868132,0.9130913091309131,0.9129955947136564,0.9128996692392503,0.91280353200883,0.912707182320442,0.9137168141592921,0.9136212624584718,0.9146341463414634,0.9145394006659268,0.9155555555555556,0.9154616240266963,0.9153674832962138,0.915273132664437,0.9151785714285714,0.9150837988826815,0.9149888143176734,0.9148936170212766,0.9147982062780269,0.9147025813692481,0.9157303370786517,0.9167604049493814,0.9166666666666666,0.9177001127395716,0.917607223476298,0.9175141242937853,0.917420814479638,0.9173272933182333,0.9172335600907029,0.9182746878547106,0.9181818181818182,0.9180887372013652,0.9179954441913439,0.9179019384264538,0.9189497716894978,0.92,0.919908466819222,0.9198167239404352,0.9197247706422018,0.9196326061997704,0.9195402298850575,0.9194476409666283,0.9193548387096774,0.9204152249134948,0.9203233256351039,0.9213872832369943,0.9212962962962963,0.9223638470451911,0.9234338747099768,0.9233449477351916,0.9232558139534883,0.9243306169965075,0.9242424242424242,0.9241540256709452,0.9252336448598131,0.9251461988304094,0.9250585480093677,0.9249706916764361,0.9248826291079812,0.9247943595769683,0.9247058823529412,0.9246171967020024,0.9245283018867925,0.9244391971664699,0.925531914893617,0.9254437869822485,0.9253554502369669,0.9264531435349941,0.9263657957244655,0.9274673008323424,0.9273809523809524,0.9272943980929678,0.9272076372315036,0.927120669056153,0.9270334928229665,0.9269461077844311,0.9268585131894485,0.9279711884753902,0.9278846153846154,0.927797833935018,0.9289156626506024,0.9288299155609168,0.9299516908212561,0.9310761789600968,0.9309927360774818,0.9309090909090909,0.9308252427184466,0.9307411907654921,0.9306569343065694,0.9305724725943971,0.9304878048780488,0.9304029304029304,0.9303178484107579,0.9302325581395349,0.9301470588235294,0.9300613496932515,0.9299754299754299,0.9298892988929889,0.9298029556650246,0.9309494451294698,0.9308641975308642,0.930778739184178,0.9306930693069307,0.9318463444857497,0.9317617866004962,0.9329192546583851,0.9328358208955224,0.9327521793275217,0.9326683291770573,0.9325842696629213,0.93375,0.9336670838548186,0.9335839598997494,0.9347553324968633,0.9346733668341709,0.9345911949685535,0.9345088161209067,0.9344262295081968,0.9343434343434344,0.934260429835651,0.9341772151898734,0.935361216730038,0.9352791878172588,0.9351969504447268,0.9363867684478372,0.9363057324840764,0.9362244897959183,0.9374201787994891,0.9373401534526854,0.93854033290653,0.9384615384615385,0.938382541720154,0.9383033419023136,0.9382239382239382,0.9394329896907216,0.9393548387096774,0.9392764857881137,0.9391979301423027,0.939119170984456,0.9390402075226978,0.938961038961039,0.9388816644993498,0.9388020833333334,0.9387222946544981,0.9386422976501305,0.938562091503268,0.9384816753926701,0.9384010484927916,0.9383202099737533,0.938239159001314,0.9381578947368421,0.9380764163372859,0.9379947229551451,0.9379128137384413,0.9378306878306878,0.937748344370861,0.9376657824933687,0.9375830013280213,0.9375,0.9374167776298269,0.9373333333333334,0.9372496662216289,0.9371657754010695,0.9370816599732262,0.9369973190348525,0.9369127516778524,0.9368279569892473,0.9367429340511441,0.9366576819407008,0.9365721997300944,0.9378378378378378,0.9377537212449256,0.9376693766937669,0.9389416553595658,0.938858695652174,0.9387755102040817,0.9386920980926431,0.9386084583901774,0.9385245901639344,0.9384404924760602,0.9383561643835616,0.9382716049382716,0.9381868131868132,0.938101788170564,0.9380165289256198,0.9393103448275862,0.9392265193370166,0.9391424619640387,0.9390581717451524,0.9389736477115118,0.9388888888888889,0.9388038942976356,0.9387186629526463,0.9400278940027894,0.9413407821229051,0.9412587412587412,0.9411764705882353,0.94109396914446,0.9424157303370787,0.9437412095639943,0.9436619718309859,0.9435825105782792,0.943502824858757,0.9434229137199435,0.943342776203966,0.9432624113475178,0.9431818181818182,0.9431009957325747,0.9430199430199431,0.9429386590584878,0.9428571428571428,0.9427753934191703,0.9441260744985673,0.9440459110473458,0.9439655172413793,0.943884892086331,0.9438040345821326,0.9437229437229437,0.9436416184971098,0.9435600578871202,0.9449275362318841,0.9448476052249637,0.9447674418604651,0.9446870451237264,0.9446064139941691,0.9445255474452555,0.945906432748538,0.9458272327964861,0.9457478005865103,0.947136563876652,0.9470588235294117,0.946980854197349,0.9469026548672567,0.946824224519941,0.9482248520710059,0.9481481481481482,0.9480712166172107,0.9479940564635958,0.9479166666666666,0.9478390461997019,0.9477611940298507,0.9476831091180867,0.9476047904191617,0.9490254872563718,0.948948948948949,0.9488721804511279,0.9487951807228916,0.9487179487179487,0.9486404833836858,0.9485627836611196,0.9484848484848485,0.9484066767830045,0.9483282674772037,0.9482496194824962,0.948170731707317,0.9480916030534351,0.9480122324159022,0.9494640122511485,0.9493865030674846,0.9493087557603687,0.9492307692307692,0.9491525423728814,0.9490740740740741,0.9489953632148377,0.9489164086687306,0.9503875968992248,0.9503105590062112,0.9502332814930016,0.9501557632398754,0.9500780031201248,0.95,0.9499217527386542,0.9498432601880877,0.9497645211930926,0.949685534591195,0.9496062992125984,0.9495268138801262,0.9494470774091627,0.9509493670886076,0.9508716323296355,0.9507936507936507,0.9507154213036566,0.9506369426751592,0.9505582137161085,0.952076677316294,0.9536,0.9535256410256411,0.9534510433386838,0.9533762057877814,0.9533011272141707,0.9532258064516129,0.9531502423263328,0.9530744336569579,0.9529983792544571,0.952922077922078,0.9528455284552846,0.9527687296416938,0.9526916802610114,0.9526143790849673,0.9525368248772504,0.9524590163934427,0.9523809523809523,0.9539473684210527,0.9538714991762768,0.9554455445544554,0.9553719008264463,0.956953642384106,0.956882255389718,0.9568106312292359,0.956738768718802,0.9566666666666667,0.9565943238731218,0.9565217391304348,0.9564489112227805,0.9563758389261745,0.957983193277311,0.9579124579124579,0.9595278246205734,0.9594594594594594,0.9593908629441624,0.9593220338983051,0.9592529711375212,0.9591836734693877,0.959114139693356,0.9590443686006825,0.958974358974359,0.958904109589041,0.9588336192109777,0.9587628865979382,0.9604130808950087,0.9603448275862069,0.9602763385146805,0.9602076124567474,0.9601386481802426,0.9600694444444444,0.96,0.9599303135888502,0.9598603839441536,0.9615384615384616,0.9614711033274956,0.9614035087719298,0.961335676625659,0.9612676056338029,0.9629629629629629,0.9628975265017667,0.9628318584070796,0.9627659574468085,0.9644760213143873,0.9644128113879004,0.964349376114082,0.9642857142857143,0.964221824686941,0.96415770609319,0.9640933572710951,0.9640287769784173,0.9657657657657658,0.9657039711191335,0.9656419529837251,0.9655797101449275,0.9655172413793104,0.9654545454545455,0.9653916211293261,0.9653284671532847,0.9652650822669104,0.9652014652014652,0.9669724770642202,0.9669117647058824,0.9668508287292817,0.966789667896679,0.9685767097966729,0.9685185185185186,0.9684601113172542,0.9684014869888475,0.9683426443202979,0.9682835820895522,0.9682242990654205,0.9681647940074907,0.9681050656660413,0.9680451127819549,0.967984934086629,0.9679245283018868,0.9678638941398866,0.9678030303030303,0.967741935483871,0.967680608365019,0.9676190476190476,0.9675572519083969,0.9674952198852772,0.9674329501915708,0.9692898272552783,0.9692307692307692,0.9691714836223507,0.9691119691119691,0.9690522243713733,0.9689922480620154,0.9689320388349515,0.9688715953307393,0.9688109161793372,0.96875,0.9686888454011742,0.9705882352941176,0.9705304518664047,0.9704724409448819,0.9704142011834319,0.9703557312252964,0.9702970297029703,0.9702380952380952,0.9701789264413518,0.9701195219123506,0.9700598802395209,0.97,0.969939879759519,0.9698795180722891,0.9698189134808853,0.969758064516129,0.9696969696969697,0.9696356275303644,0.9695740365111561,0.9695121951219512,0.9714867617107943,0.9714285714285714,0.9713701431492843,0.9713114754098361,0.971252566735113,0.9711934156378601,0.9711340206185567,0.9710743801652892,0.9710144927536232,0.970954356846473,0.9708939708939709,0.9708333333333333,0.9707724425887265,0.9707112970711297,0.9706498951781971,0.9705882352941176,0.9705263157894737,0.9704641350210971,0.9704016913319239,0.9703389830508474,0.970276008492569,0.9702127659574468,0.9701492537313433,0.9700854700854701,0.9700214132762313,0.9721030042918455,0.9720430107526882,0.9719827586206896,0.9719222462203023,0.9718614718614719,0.9718004338394793,0.9717391304347827,0.971677559912854,0.9716157205240175,0.9715536105032823,0.9714912280701754,0.9714285714285714,0.9713656387665198,0.9713024282560706,0.9712389380530974,0.9711751662971175,0.9733333333333334,0.9732739420935412,0.9732142857142857,0.9731543624161074,0.9730941704035875,0.9730337078651685,0.972972972972973,0.9729119638826185,0.9728506787330317,0.9727891156462585,0.9727272727272728,0.9726651480637813,0.9726027397260274,0.9725400457665904,0.9724770642201835,0.9724137931034482,0.9723502304147466,0.9722863741339491,0.9745370370370371,0.974477958236659,0.9744186046511628,0.9743589743589743,0.9742990654205608,0.9742388758782201,0.9741784037558685,0.9741176470588235,0.9740566037735849,0.9739952718676123,0.9739336492890995,0.9738717339667459,0.9738095238095238,0.9737470167064439,0.9736842105263158,0.973621103117506,0.9735576923076923,0.9734939759036144,0.9734299516908212,0.9733656174334141,0.9733009708737864,0.9732360097323601,0.973170731707317,0.9731051344743277,0.9730392156862745,0.972972972972973,0.9729064039408867,0.9728395061728395,0.9727722772277227,0.9727047146401985,0.972636815920398,0.972568578553616,0.9725,0.9724310776942355,0.9723618090452262,0.9722921914357683,0.9722222222222222,0.9721518987341772,0.9720812182741116,0.9720101781170484,0.9719387755102041,0.9718670076726342,0.9717948717948718,0.9717223650385605,0.9716494845360825,0.9715762273901809,0.9715025906735751,0.9714285714285714,0.9713541666666666,0.9712793733681462,0.9712041884816754,0.9711286089238845,0.9710526315789474,0.9709762532981531,0.9708994708994709,0.9708222811671088,0.973404255319149,0.9733333333333334,0.9732620320855615,0.9731903485254692,0.9731182795698925,0.9730458221024259,0.972972972972973,0.9728997289972899,0.9728260869565217,0.9726775956284153,0.9726027397260274,0.9725274725274725,0.9724517906336089,0.9723756906077348,0.9750692520775623,0.975,0.9749303621169917,0.9748603351955307,0.9747899159663865,0.9775280898876404,0.9774647887323944,0.9774011299435028,0.9773371104815864,0.9772727272727273,0.9772079772079773,0.9771428571428571,0.9770773638968482,0.9770114942528736,0.9769452449567724,0.976878612716763,0.9768115942028985,0.9767441860465116,0.9766763848396501,0.9766081871345029,0.9765395894428153,0.9764705882352941,0.976401179941003,0.9763313609467456,0.9762611275964391,0.9761904761904762,0.9761194029850746,0.9760479041916168,0.975975975975976,0.9759036144578314,0.9758308157099698,0.9757575757575757,0.9756838905775076,0.975609756097561,0.9755351681957186,0.9754601226993865,0.9753846153846154,0.9753086419753086,0.9752321981424149,0.9751552795031055,0.9750778816199377,0.975,0.9780564263322884,0.9779874213836478,0.9779179810725552,0.9778481012658228,0.9777777777777777,0.9777070063694268,0.9776357827476039,0.9775641025641025,0.977491961414791,0.9774193548387097,0.9773462783171522,0.9772727272727273,0.9771986970684039,0.9771241830065359,0.9770491803278688,0.9769736842105263,0.976897689768977,0.9768211920529801,0.9767441860465116,0.9766666666666667,0.9765886287625418,0.9765100671140939,0.9764309764309764,0.9763513513513513,0.976271186440678,0.9795918367346939,0.9795221843003413,0.9794520547945206,0.979381443298969,0.9793103448275862,0.9826989619377162,0.9826388888888888,0.9825783972125436,0.9825174825174825,0.9824561403508771,0.9823943661971831,0.9823321554770318,0.9822695035460993,0.9822064056939501,0.9821428571428571,0.982078853046595,0.9820143884892086,0.9819494584837545,0.9818840579710145,0.9818181818181818,0.9817518248175182,0.9816849816849816,0.9816176470588235,0.981549815498155,0.9814814814814815,0.9814126394052045,0.9813432835820896,0.9812734082397003,0.981203007518797,0.9811320754716981,0.9810606060606061,0.9809885931558935,0.9809160305343512,0.9846743295019157,0.9846153846153847,0.9845559845559846,0.9844961240310077,0.9844357976653697,0.984375,0.984313725490196,0.984251968503937,0.9841897233201581,0.9841269841269841,0.9840637450199203,0.984,0.9839357429718876,0.9838709677419355,0.9838056680161943,0.983739837398374,0.9836734693877551,0.9836065573770492,0.9835390946502057,0.9834710743801653,0.983402489626556,0.9833333333333333,0.9832635983263598,0.9831932773109243,0.9831223628691983,0.9830508474576272,0.9829787234042553,0.9829059829059829,0.9828326180257511,0.9827586206896551,0.9826839826839827,0.9826086956521739,0.982532751091703,0.9824561403508771,0.9823788546255506,0.9823008849557522,0.9822222222222222,0.9821428571428571,0.9820627802690582,0.9819819819819819,0.9819004524886877,0.9818181818181818,0.9817351598173516,0.981651376146789,0.9815668202764977,0.9814814814814815,0.9813953488372092,0.9813084112149533,0.9812206572769953,0.9811320754716981,0.981042654028436,0.9857142857142858,0.9856459330143541,0.9855769230769231,0.9855072463768116,0.9854368932038835,0.9853658536585366,0.9852941176470589,0.9852216748768473,0.9851485148514851,0.9850746268656716,0.985,0.9849246231155779,0.9848484848484849,0.9847715736040609,0.9846938775510204,0.9846153846153847,0.9845360824742269,0.9844559585492227,0.984375,0.9842931937172775,0.9842105263157894,0.9841269841269841,0.9840425531914894,0.983957219251337,0.9838709677419355,0.9837837837837838,0.9891304347826086,0.9890710382513661,0.989010989010989,0.988950276243094,0.9888888888888889,0.9888268156424581,0.9943820224719101,0.9943502824858758,0.9943181818181818,0.9942857142857143,0.9942528735632183,0.9942196531791907,0.9941860465116279,0.9941520467836257,0.9941176470588236,0.9940828402366864,0.9940476190476191,0.9940119760479041,0.9939759036144579,0.9939393939393939,0.9939024390243902,0.9938650306748467,0.9938271604938271,0.9937888198757764,0.99375,0.9937106918238994,0.9936708860759493,0.9936305732484076,0.9935897435897436,0.9935483870967742,0.9935064935064936,0.9934640522875817,0.993421052631579,0.9933774834437086,0.9933333333333333,0.9932885906040269,0.9932432432432432,0.9931972789115646,0.9931506849315068,0.993103448275862,0.9930555555555556,0.993006993006993,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Recall\"},\"constrain\":\"domain\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Precision\"},\"scaleanchor\":\"x\",\"scaleratio\":1},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Precision-Recall Curve (AUC=0.8819)\"},\"height\":600,\"width\":800,\"shapes\":[{\"line\":{\"dash\":\"dash\"},\"type\":\"line\",\"x0\":0,\"x1\":1,\"y0\":1,\"y1\":0}],\"showlegend\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('6e58aa77-1a57-4aa8-8911-bf6da2a0146b');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"}],"source":["target_score = extra_trees_clf.predict_proba(features_valid)[:, 1]\n","\n","fpr, tpr, thresholds = roc_curve(target_valid, target_score)\n","\n","fig = px.area(\n","    x=fpr, y=tpr,\n","    title=f'ROC Curve (AUC={auc(fpr, tpr):.4f})',\n","    labels=dict(x='False Positive Rate', y='True Positive Rate'),\n","    width=800, height=600\n",")\n","fig.add_shape(\n","    type='line', line=dict(dash='dash'),\n","    x0=0, x1=1, y0=0, y1=1\n",")\n","\n","fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n","fig.update_xaxes(constrain='domain')\n","fig.update_layout(showlegend=False)\n","fig.show()\n","\n","precision, recall, thresholds = precision_recall_curve(target_valid, target_score)\n","\n","fig = px.area(\n","    x=recall, y=precision,\n","    title=f'Precision-Recall Curve (AUC={auc(fpr, tpr):.4f})',\n","    labels=dict(x='Recall', y='Precision'),\n","    width=800, height=600\n",")\n","fig.add_shape(\n","    type='line', line=dict(dash='dash'),\n","    x0=0, x1=1, y0=1, y1=0\n",")\n","fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n","fig.update_xaxes(constrain='domain')\n","fig.update_layout(showlegend=False)\n","fig.show()"]},{"cell_type":"markdown","metadata":{},"source":["--------"]},{"cell_type":"markdown","metadata":{},"source":["# Logistic Regression"]},{"cell_type":"code","execution_count":79,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T16:53:23.562118Z","iopub.status.busy":"2023-11-30T16:53:23.561856Z","iopub.status.idle":"2023-11-30T16:53:41.358165Z","shell.execute_reply":"2023-11-30T16:53:41.356738Z","shell.execute_reply.started":"2023-11-30T16:53:23.562094Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Runtime:\n","CPU times: user 260 ms, sys: 106 ms, total: 366 ms\n","Wall time: 2.82 s\n"]}],"source":["%%time\n","log_model = LogisticRegression()\n","log_parameters = [{\"solver\": ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'],\n","                      \"fit_intercept\": [True, False],\n","                       \"penalty\": ['l1', 'l2', 'elasticnet'],\n","                      \"n_jobs\": list(range(1,200))}]\n","\n","log_clf = RandomizedSearchCV(log_model, log_parameters, scoring='roc_auc', n_jobs=-1, cv=cv)\n","log_clf.fit(features_train, target_train)\n","# create a variable for the best model\n","best_log = log_clf.best_estimator_\n","log_pred = best_log.predict(features_valid)\n","print('Runtime:')"]},{"cell_type":"code","execution_count":80,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 1000x500 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["sns.set(style=\"white\", color_codes=True)\n","plt.rcParams['axes.linewidth'] = 0.1\n","\n","fig, ax = plt.subplots(figsize = (10,5))\n","disp = CalibrationDisplay.from_estimator(log_clf, features_valid, target_valid, ax=ax)\n","plt.title('Calibration Chart - Logistic Regression', fontsize=10)\n","ax.set_xlabel('Mean predicted probability (Positive class: 1)', fontsize=10)\n","ax.set_ylabel('Fraction of positives (Positive class: 1)',fontsize=10)\n","\n","ax.tick_params(color='gray', labelcolor='gray')\n","for spine in ax.spines.values():\n","    spine.set_edgecolor('gray')\n","\n","\n","fig.tight_layout()\n","plt.legend(fontsize=8)\n","plt.show()"]},{"cell_type":"code","execution_count":81,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T16:53:41.367003Z","iopub.status.busy":"2023-11-30T16:53:41.363014Z","iopub.status.idle":"2023-11-30T16:53:45.451418Z","shell.execute_reply":"2023-11-30T16:53:45.450399Z","shell.execute_reply.started":"2023-11-30T16:53:41.366952Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Cross Validation Scores: [0.85124724 0.8327765  0.85178571 0.78652074 0.81972926 0.8421947\n"," 0.80411866 0.80244816 0.8662159  0.83342002 0.81100896 0.81016705\n"," 0.83533986 0.82379032 0.84467166 0.81984447 0.8406682  0.80745968\n"," 0.84688511 0.83786986 0.78523355 0.84017857 0.85815092 0.8328341\n"," 0.83398618 0.85092166 0.84161866 0.8296659  0.82209316 0.79449838\n"," 0.82300885 0.81800115 0.82263825 0.8344182  0.85351382 0.85711406\n"," 0.81486175 0.81431452 0.83685853 0.82714979 0.82764842 0.82730415\n"," 0.81641705 0.80270737 0.83554147 0.82926267 0.85374424 0.83767281\n"," 0.83240869 0.83619394]\n"]}],"source":["log_scores = cross_val_score(log_model, features_train, target_train, cv=cv, scoring='roc_auc')\n","print('Cross Validation Scores: {}'.format(log_scores))"]},{"cell_type":"code","execution_count":82,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T16:53:45.453259Z","iopub.status.busy":"2023-11-30T16:53:45.452705Z","iopub.status.idle":"2023-11-30T16:53:45.479560Z","shell.execute_reply":"2023-11-30T16:53:45.478438Z","shell.execute_reply.started":"2023-11-30T16:53:45.453224Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Best hyperparameters: {'solver': 'saga', 'penalty': 'l1', 'n_jobs': 106, 'fit_intercept': False}\n","\n","Best score: 0.8293790749861191\n","\n","Average Cross Validation Score: 0.829162458233739\n","\n","ROC AUC Score - Validation Dataset: 0.8545847979251544\n"]}],"source":["# summary\n","print('Best hyperparameters:',  log_clf.best_params_)\n","print()\n","print('Best score:',  log_clf.best_score_)\n","print()\n","print('Average Cross Validation Score: {}'.format(log_scores.mean()))\n","print()\n","print('ROC AUC Score - Validation Dataset:',  roc_auc_score(target_valid, log_clf.predict_proba(features_valid)[:, 1]))"]},{"cell_type":"markdown","metadata":{},"source":["# ROC AUC Curve - LogisticRegression"]},{"cell_type":"code","execution_count":83,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T16:53:45.489716Z","iopub.status.busy":"2023-11-30T16:53:45.485889Z","iopub.status.idle":"2023-11-30T16:53:45.726171Z","shell.execute_reply":"2023-11-30T16:53:45.725272Z","shell.execute_reply.started":"2023-11-30T16:53:45.489647Z"},"trusted":true},"outputs":[{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"fillpattern":{"shape":""},"hovertemplate":"False Positive Rate=%{x}<br>True Positive Rate=%{y}<extra></extra>","legendgroup":"","line":{"color":"#636efa"},"marker":{"symbol":"circle"},"mode":"lines","name":"","orientation":"v","showlegend":false,"stackgroup":"1","type":"scatter","x":[0,0,0,0.00267379679144385,0.00267379679144385,0.0053475935828877,0.0053475935828877,0.008021390374331552,0.008021390374331552,0.0106951871657754,0.0106951871657754,0.013368983957219251,0.013368983957219251,0.016042780748663103,0.016042780748663103,0.01871657754010695,0.01871657754010695,0.0213903743315508,0.0213903743315508,0.02406417112299465,0.02406417112299465,0.026737967914438502,0.026737967914438502,0.029411764705882353,0.029411764705882353,0.03208556149732621,0.03208556149732621,0.034759358288770054,0.034759358288770054,0.0374331550802139,0.0374331550802139,0.040106951871657755,0.040106951871657755,0.0427807486631016,0.0427807486631016,0.045454545454545456,0.045454545454545456,0.0481283422459893,0.0481283422459893,0.05080213903743316,0.05080213903743316,0.053475935828877004,0.053475935828877004,0.05614973262032086,0.05614973262032086,0.058823529411764705,0.058823529411764705,0.06149732620320856,0.06149732620320856,0.06417112299465241,0.06417112299465241,0.06684491978609626,0.06684491978609626,0.06951871657754011,0.06951871657754011,0.07219251336898395,0.07219251336898395,0.07219251336898395,0.07219251336898395,0.0748663101604278,0.0748663101604278,0.07754010695187166,0.07754010695187166,0.08021390374331551,0.08021390374331551,0.08288770053475936,0.08288770053475936,0.0855614973262032,0.0855614973262032,0.09358288770053476,0.09358288770053476,0.0962566844919786,0.0962566844919786,0.10160427807486631,0.10160427807486631,0.10427807486631016,0.10427807486631016,0.10695187165775401,0.10695187165775401,0.10962566844919786,0.10962566844919786,0.11497326203208556,0.11497326203208556,0.11764705882352941,0.11764705882352941,0.12032085561497326,0.12032085561497326,0.12299465240641712,0.12299465240641712,0.12566844919786097,0.12566844919786097,0.12834224598930483,0.12834224598930483,0.13101604278074866,0.13101604278074866,0.13368983957219252,0.13368983957219252,0.13636363636363635,0.13636363636363635,0.13903743315508021,0.13903743315508021,0.1443850267379679,0.1443850267379679,0.1497326203208556,0.1497326203208556,0.15240641711229946,0.15240641711229946,0.15508021390374332,0.15508021390374332,0.16310160427807488,0.16310160427807488,0.1657754010695187,0.1657754010695187,0.16844919786096257,0.16844919786096257,0.17379679144385027,0.17379679144385027,0.17647058823529413,0.17647058823529413,0.17914438502673796,0.17914438502673796,0.18449197860962566,0.18449197860962566,0.18716577540106952,0.18716577540106952,0.18983957219251338,0.18983957219251338,0.1925133689839572,0.1925133689839572,0.19518716577540107,0.19518716577540107,0.19786096256684493,0.19786096256684493,0.20053475935828877,0.20053475935828877,0.20588235294117646,0.20588235294117646,0.20855614973262032,0.20855614973262032,0.21122994652406418,0.21122994652406418,0.21657754010695188,0.21657754010695188,0.2192513368983957,0.2192513368983957,0.22192513368983957,0.22192513368983957,0.22459893048128343,0.22459893048128343,0.22994652406417113,0.22994652406417113,0.232620320855615,0.232620320855615,0.23529411764705882,0.23529411764705882,0.23796791443850268,0.23796791443850268,0.24598930481283424,0.24598930481283424,0.24866310160427807,0.24866310160427807,0.25133689839572193,0.25133689839572193,0.25668449197860965,0.25668449197860965,0.25935828877005346,0.25935828877005346,0.2620320855614973,0.2620320855614973,0.2647058823529412,0.2647058823529412,0.26737967914438504,0.26737967914438504,0.2700534759358289,0.2700534759358289,0.2727272727272727,0.2727272727272727,0.27540106951871657,0.27540106951871657,0.2807486631016043,0.2807486631016043,0.2914438502673797,0.2914438502673797,0.29411764705882354,0.29411764705882354,0.2994652406417112,0.2994652406417112,0.3048128342245989,0.3048128342245989,0.3074866310160428,0.3074866310160428,0.31283422459893045,0.31283422459893045,0.32085561497326204,0.32085561497326204,0.32887700534759357,0.32887700534759357,0.3315508021390374,0.3315508021390374,0.3342245989304813,0.3342245989304813,0.33689839572192515,0.33689839572192515,0.339572192513369,0.339572192513369,0.3422459893048128,0.3422459893048128,0.3449197860962567,0.3449197860962567,0.34759358288770054,0.34759358288770054,0.3502673796791444,0.3502673796791444,0.35561497326203206,0.35561497326203206,0.3609625668449198,0.3609625668449198,0.36363636363636365,0.36363636363636365,0.37433155080213903,0.37433155080213903,0.3770053475935829,0.3770053475935829,0.37967914438502676,0.37967914438502676,0.38235294117647056,0.38235294117647056,0.3850267379679144,0.3850267379679144,0.3877005347593583,0.3877005347593583,0.393048128342246,0.393048128342246,0.39572192513368987,0.39572192513368987,0.3983957219251337,0.3983957219251337,0.40106951871657753,0.40106951871657753,0.40641711229946526,0.40641711229946526,0.4090909090909091,0.4090909090909091,0.4144385026737968,0.4144385026737968,0.42245989304812837,0.42245989304812837,0.43315508021390375,0.43315508021390375,0.4358288770053476,0.4358288770053476,0.44385026737967914,0.44385026737967914,0.446524064171123,0.446524064171123,0.44919786096256686,0.44919786096256686,0.45187165775401067,0.45187165775401067,0.45989304812834225,0.45989304812834225,0.4625668449197861,0.4625668449197861,0.46524064171123,0.46524064171123,0.47058823529411764,0.47058823529411764,0.4732620320855615,0.4732620320855615,0.47593582887700536,0.47593582887700536,0.4786096256684492,0.4786096256684492,0.48128342245989303,0.48128342245989303,0.48663101604278075,0.48663101604278075,0.4919786096256685,0.4919786096256685,0.4946524064171123,0.4946524064171123,0.49732620320855614,0.49732620320855614,0.5133689839572193,0.5133689839572193,0.5213903743315508,0.5213903743315508,0.5240641711229946,0.5240641711229946,0.5267379679144385,0.5267379679144385,0.5294117647058824,0.5294117647058824,0.5320855614973262,0.5320855614973262,0.5481283422459893,0.5481283422459893,0.553475935828877,0.553475935828877,0.5561497326203209,0.5561497326203209,0.5641711229946524,0.5641711229946524,0.5721925133689839,0.5721925133689839,0.5802139037433155,0.5802139037433155,0.5909090909090909,0.5909090909090909,0.606951871657754,0.606951871657754,0.6149732620320856,0.6149732620320856,0.6176470588235294,0.6176470588235294,0.6283422459893048,0.6283422459893048,0.6336898395721925,0.6336898395721925,0.6417112299465241,0.6417112299465241,0.6443850267379679,0.6443850267379679,0.6764705882352942,0.6764705882352942,0.679144385026738,0.679144385026738,0.6844919786096256,0.6844919786096256,0.6871657754010695,0.6871657754010695,0.6925133689839572,0.6925133689839572,0.6951871657754011,0.6951871657754011,0.7005347593582888,0.7005347593582888,0.7058823529411765,0.7058823529411765,0.732620320855615,0.732620320855615,0.7620320855614974,0.7620320855614974,0.7807486631016043,0.7807486631016043,0.786096256684492,0.786096256684492,0.7941176470588235,0.7941176470588235,0.8101604278074866,0.8101604278074866,0.8155080213903744,0.8155080213903744,0.839572192513369,0.839572192513369,0.8502673796791443,0.8502673796791443,0.8689839572192514,0.8689839572192514,0.8716577540106952,0.8716577540106952,0.8770053475935828,0.8770053475935828,0.893048128342246,0.893048128342246,0.9064171122994652,0.9064171122994652,0.9358288770053476,0.9358288770053476,0.983957219251337,0.983957219251337,1],"xaxis":"x","y":[0,0.000968054211035818,0.04065827686350436,0.04065827686350436,0.06389157792836399,0.06389157792836399,0.08325266214908035,0.08325266214908035,0.11519845111326234,0.11519845111326234,0.14811229428848016,0.14811229428848016,0.16456921587608905,0.16456921587608905,0.16844143272023232,0.16844143272023232,0.22749273959341723,0.22749273959341723,0.24394966118102615,0.24394966118102615,0.2739593417231365,0.2739593417231365,0.30784123910939015,0.30784123910939015,0.31752178121974833,0.31752178121974833,0.31848983543078413,0.31848983543078413,0.3330106485963214,0.3330106485963214,0.33978702807357214,0.33978702807357214,0.3601161665053243,0.3601161665053243,0.36689254598257504,0.36689254598257504,0.3717328170377541,0.3717328170377541,0.37560503388189737,0.37560503388189737,0.3814133591481123,0.3814133591481123,0.4569215876089061,0.4569215876089061,0.4791868344627299,0.4791868344627299,0.4849951597289448,0.4849951597289448,0.5062923523717329,0.5062923523717329,0.5343659244917716,0.5343659244917716,0.5556631171345595,0.5556631171345595,0.5575992255566312,0.5575992255566312,0.5634075508228461,0.5653436592449177,0.5808325266214908,0.5808325266214908,0.5818005808325266,0.5818005808325266,0.5837366892545982,0.5837366892545982,0.5847047434656341,0.5847047434656341,0.5953533397870281,0.5953533397870281,0.5982575024201355,0.5982575024201355,0.6089060987415296,0.6089060987415296,0.6098741529525653,0.6098741529525653,0.6224588576960309,0.6224588576960309,0.6243949661181026,0.6243949661181026,0.6282671829622459,0.6282671829622459,0.6389157792836399,0.6389157792836399,0.6466602129719264,0.6466602129719264,0.6505324298160697,0.6505324298160697,0.6534365924491772,0.6534365924491772,0.6544046466602129,0.6544046466602129,0.6573088092933205,0.6573088092933205,0.6669893514036787,0.6669893514036787,0.6689254598257502,0.6689254598257502,0.6718296224588577,0.6718296224588577,0.6834462729912875,0.6834462729912875,0.6844143272023233,0.6844143272023233,0.686350435624395,0.686350435624395,0.7057115198451114,0.7057115198451114,0.707647628267183,0.707647628267183,0.7115198451113263,0.7115198451113263,0.7192642787996127,0.7192642787996127,0.723136495643756,0.723136495643756,0.7347531461761858,0.7347531461761858,0.7386253630203291,0.7386253630203291,0.7434656340755083,0.7434656340755083,0.7599225556631172,0.7599225556631172,0.7608906098741529,0.7608906098741529,0.7618586640851888,0.7618586640851888,0.7647628267182962,0.7647628267182962,0.7657308809293321,0.7657308809293321,0.7676669893514037,0.7676669893514037,0.7696030977734754,0.7696030977734754,0.7705711519845111,0.7705711519845111,0.7812197483059051,0.7812197483059051,0.7831558567279767,0.7831558567279767,0.7860600193610843,0.7860600193610843,0.7889641819941917,0.7889641819941917,0.7899322362052275,0.7899322362052275,0.7918683446272992,0.7918683446272992,0.7947725072604066,0.7947725072604066,0.7957405614714425,0.7957405614714425,0.7967086156824782,0.7967086156824782,0.7996127783155856,0.7996127783155856,0.8015488867376573,0.8015488867376573,0.8044530493707648,0.8044530493707648,0.8054211035818006,0.8054211035818006,0.8073572120038722,0.8073572120038722,0.8083252662149081,0.8083252662149081,0.8092933204259438,0.8092933204259438,0.8112294288480155,0.8112294288480155,0.8170377541142304,0.8170377541142304,0.8180058083252663,0.8180058083252663,0.818973862536302,0.818973862536302,0.8209099709583737,0.8209099709583737,0.8238141335914811,0.8238141335914811,0.8247821878025169,0.8247821878025169,0.8257502420135527,0.8257502420135527,0.829622458857696,0.829622458857696,0.8315585672797676,0.8315585672797676,0.8325266214908035,0.8325266214908035,0.8334946757018393,0.8334946757018393,0.8363988383349468,0.8363988383349468,0.8402710551790901,0.8402710551790901,0.8431752178121975,0.8431752178121975,0.846079380445305,0.846079380445305,0.8470474346563408,0.8470474346563408,0.8489835430784124,0.8489835430784124,0.8499515972894482,0.8499515972894482,0.850919651500484,0.850919651500484,0.8518877057115198,0.8518877057115198,0.8538238141335914,0.8538238141335914,0.8557599225556631,0.8557599225556631,0.856727976766699,0.856727976766699,0.8576960309777347,0.8576960309777347,0.8606001936108422,0.8606001936108422,0.8635043562439496,0.8635043562439496,0.8654404646660213,0.8654404646660213,0.8664085188770572,0.8664085188770572,0.8702807357212003,0.8702807357212003,0.872216844143272,0.872216844143272,0.8741529525653436,0.8741529525653436,0.8751210067763795,0.8751210067763795,0.8770571151984511,0.8770571151984511,0.8780251694094869,0.8780251694094869,0.8789932236205228,0.8789932236205228,0.8818973862536302,0.8818973862536302,0.8848015488867377,0.8848015488867377,0.8896418199419167,0.8896418199419167,0.8906098741529526,0.8906098741529526,0.89351403678606,0.89351403678606,0.8954501452081317,0.8954501452081317,0.8964181994191674,0.8964181994191674,0.8993223620522749,0.8993223620522749,0.9012584704743466,0.9012584704743466,0.9138431752178122,0.9138431752178122,0.9177153920619555,0.9177153920619555,0.9186834462729913,0.9186834462729913,0.920619554695063,0.920619554695063,0.9244917715392061,0.9244917715392061,0.925459825750242,0.925459825750242,0.9264278799612778,0.9264278799612778,0.9273959341723137,0.9273959341723137,0.9283639883833494,0.9283639883833494,0.9293320425943853,0.9293320425943853,0.9322362052274927,0.9322362052274927,0.9341723136495643,0.9341723136495643,0.9370764762826719,0.9370764762826719,0.9390125847047435,0.9390125847047435,0.9399806389157793,0.9399806389157793,0.9409486931268151,0.9409486931268151,0.9419167473378509,0.9419167473378509,0.9428848015488868,0.9428848015488868,0.9448209099709584,0.9448209099709584,0.9457889641819942,0.9457889641819942,0.9477250726040658,0.9477250726040658,0.9486931268151017,0.9486931268151017,0.9545014520813165,0.9545014520813165,0.9554695062923524,0.9554695062923524,0.957405614714424,0.957405614714424,0.9593417231364957,0.9593417231364957,0.9603097773475314,0.9603097773475314,0.9612778315585673,0.9612778315585673,0.9622458857696031,0.9622458857696031,0.9632139399806389,0.9632139399806389,0.9641819941916747,0.9641819941916747,0.9651500484027106,0.9651500484027106,0.9661181026137464,0.9661181026137464,0.9690222652468539,0.9690222652468539,0.9719264278799613,0.9719264278799613,0.972894482090997,0.972894482090997,0.9748305905130688,0.9748305905130688,0.9757986447241046,0.9757986447241046,0.9777347531461762,0.9777347531461762,0.978702807357212,0.978702807357212,0.9796708615682478,0.9796708615682478,0.9825750242013552,0.9825750242013552,0.9854791868344628,0.9854791868344628,0.9864472410454985,0.9864472410454985,0.9874152952565344,0.9874152952565344,0.9883833494675702,0.9883833494675702,0.989351403678606,0.989351403678606,0.9903194578896418,0.9903194578896418,0.9912875121006777,0.9912875121006777,0.9922555663117134,0.9922555663117134,0.9932236205227493,0.9932236205227493,0.9941916747337851,0.9941916747337851,0.9961277831558567,0.9961277831558567,0.9970958373668926,0.9970958373668926,0.9980638915779284,0.9980638915779284,0.9990319457889641,0.9990319457889641,1,1],"yaxis":"y"}],"layout":{"height":600,"legend":{"tracegroupgap":0},"shapes":[{"line":{"dash":"dash"},"type":"line","x0":0,"x1":1,"y0":0,"y1":1}],"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"title":{"text":"ROC Curve (AUC=0.8546)"},"width":800,"xaxis":{"anchor":"y","constrain":"domain","domain":[0,1],"title":{"text":"False Positive Rate"}},"yaxis":{"anchor":"x","domain":[0,1],"scaleanchor":"x","scaleratio":1,"title":{"text":"True Positive Rate"}}}},"text/html":["<div>                            <div id=\"7ed2e858-5bd6-46c8-b98d-4a7404079e93\" class=\"plotly-graph-div\" style=\"height:600px; width:800px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"7ed2e858-5bd6-46c8-b98d-4a7404079e93\")) {                    Plotly.newPlot(                        \"7ed2e858-5bd6-46c8-b98d-4a7404079e93\",                        [{\"fillpattern\":{\"shape\":\"\"},\"hovertemplate\":\"False Positive Rate=%{x}\\u003cbr\\u003eTrue Positive Rate=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"stackgroup\":\"1\",\"x\":[0.0,0.0,0.0,0.00267379679144385,0.00267379679144385,0.0053475935828877,0.0053475935828877,0.008021390374331552,0.008021390374331552,0.0106951871657754,0.0106951871657754,0.013368983957219251,0.013368983957219251,0.016042780748663103,0.016042780748663103,0.01871657754010695,0.01871657754010695,0.0213903743315508,0.0213903743315508,0.02406417112299465,0.02406417112299465,0.026737967914438502,0.026737967914438502,0.029411764705882353,0.029411764705882353,0.03208556149732621,0.03208556149732621,0.034759358288770054,0.034759358288770054,0.0374331550802139,0.0374331550802139,0.040106951871657755,0.040106951871657755,0.0427807486631016,0.0427807486631016,0.045454545454545456,0.045454545454545456,0.0481283422459893,0.0481283422459893,0.05080213903743316,0.05080213903743316,0.053475935828877004,0.053475935828877004,0.05614973262032086,0.05614973262032086,0.058823529411764705,0.058823529411764705,0.06149732620320856,0.06149732620320856,0.06417112299465241,0.06417112299465241,0.06684491978609626,0.06684491978609626,0.06951871657754011,0.06951871657754011,0.07219251336898395,0.07219251336898395,0.07219251336898395,0.07219251336898395,0.0748663101604278,0.0748663101604278,0.07754010695187166,0.07754010695187166,0.08021390374331551,0.08021390374331551,0.08288770053475936,0.08288770053475936,0.0855614973262032,0.0855614973262032,0.09358288770053476,0.09358288770053476,0.0962566844919786,0.0962566844919786,0.10160427807486631,0.10160427807486631,0.10427807486631016,0.10427807486631016,0.10695187165775401,0.10695187165775401,0.10962566844919786,0.10962566844919786,0.11497326203208556,0.11497326203208556,0.11764705882352941,0.11764705882352941,0.12032085561497326,0.12032085561497326,0.12299465240641712,0.12299465240641712,0.12566844919786097,0.12566844919786097,0.12834224598930483,0.12834224598930483,0.13101604278074866,0.13101604278074866,0.13368983957219252,0.13368983957219252,0.13636363636363635,0.13636363636363635,0.13903743315508021,0.13903743315508021,0.1443850267379679,0.1443850267379679,0.1497326203208556,0.1497326203208556,0.15240641711229946,0.15240641711229946,0.15508021390374332,0.15508021390374332,0.16310160427807488,0.16310160427807488,0.1657754010695187,0.1657754010695187,0.16844919786096257,0.16844919786096257,0.17379679144385027,0.17379679144385027,0.17647058823529413,0.17647058823529413,0.17914438502673796,0.17914438502673796,0.18449197860962566,0.18449197860962566,0.18716577540106952,0.18716577540106952,0.18983957219251338,0.18983957219251338,0.1925133689839572,0.1925133689839572,0.19518716577540107,0.19518716577540107,0.19786096256684493,0.19786096256684493,0.20053475935828877,0.20053475935828877,0.20588235294117646,0.20588235294117646,0.20855614973262032,0.20855614973262032,0.21122994652406418,0.21122994652406418,0.21657754010695188,0.21657754010695188,0.2192513368983957,0.2192513368983957,0.22192513368983957,0.22192513368983957,0.22459893048128343,0.22459893048128343,0.22994652406417113,0.22994652406417113,0.232620320855615,0.232620320855615,0.23529411764705882,0.23529411764705882,0.23796791443850268,0.23796791443850268,0.24598930481283424,0.24598930481283424,0.24866310160427807,0.24866310160427807,0.25133689839572193,0.25133689839572193,0.25668449197860965,0.25668449197860965,0.25935828877005346,0.25935828877005346,0.2620320855614973,0.2620320855614973,0.2647058823529412,0.2647058823529412,0.26737967914438504,0.26737967914438504,0.2700534759358289,0.2700534759358289,0.2727272727272727,0.2727272727272727,0.27540106951871657,0.27540106951871657,0.2807486631016043,0.2807486631016043,0.2914438502673797,0.2914438502673797,0.29411764705882354,0.29411764705882354,0.2994652406417112,0.2994652406417112,0.3048128342245989,0.3048128342245989,0.3074866310160428,0.3074866310160428,0.31283422459893045,0.31283422459893045,0.32085561497326204,0.32085561497326204,0.32887700534759357,0.32887700534759357,0.3315508021390374,0.3315508021390374,0.3342245989304813,0.3342245989304813,0.33689839572192515,0.33689839572192515,0.339572192513369,0.339572192513369,0.3422459893048128,0.3422459893048128,0.3449197860962567,0.3449197860962567,0.34759358288770054,0.34759358288770054,0.3502673796791444,0.3502673796791444,0.35561497326203206,0.35561497326203206,0.3609625668449198,0.3609625668449198,0.36363636363636365,0.36363636363636365,0.37433155080213903,0.37433155080213903,0.3770053475935829,0.3770053475935829,0.37967914438502676,0.37967914438502676,0.38235294117647056,0.38235294117647056,0.3850267379679144,0.3850267379679144,0.3877005347593583,0.3877005347593583,0.393048128342246,0.393048128342246,0.39572192513368987,0.39572192513368987,0.3983957219251337,0.3983957219251337,0.40106951871657753,0.40106951871657753,0.40641711229946526,0.40641711229946526,0.4090909090909091,0.4090909090909091,0.4144385026737968,0.4144385026737968,0.42245989304812837,0.42245989304812837,0.43315508021390375,0.43315508021390375,0.4358288770053476,0.4358288770053476,0.44385026737967914,0.44385026737967914,0.446524064171123,0.446524064171123,0.44919786096256686,0.44919786096256686,0.45187165775401067,0.45187165775401067,0.45989304812834225,0.45989304812834225,0.4625668449197861,0.4625668449197861,0.46524064171123,0.46524064171123,0.47058823529411764,0.47058823529411764,0.4732620320855615,0.4732620320855615,0.47593582887700536,0.47593582887700536,0.4786096256684492,0.4786096256684492,0.48128342245989303,0.48128342245989303,0.48663101604278075,0.48663101604278075,0.4919786096256685,0.4919786096256685,0.4946524064171123,0.4946524064171123,0.49732620320855614,0.49732620320855614,0.5133689839572193,0.5133689839572193,0.5213903743315508,0.5213903743315508,0.5240641711229946,0.5240641711229946,0.5267379679144385,0.5267379679144385,0.5294117647058824,0.5294117647058824,0.5320855614973262,0.5320855614973262,0.5481283422459893,0.5481283422459893,0.553475935828877,0.553475935828877,0.5561497326203209,0.5561497326203209,0.5641711229946524,0.5641711229946524,0.5721925133689839,0.5721925133689839,0.5802139037433155,0.5802139037433155,0.5909090909090909,0.5909090909090909,0.606951871657754,0.606951871657754,0.6149732620320856,0.6149732620320856,0.6176470588235294,0.6176470588235294,0.6283422459893048,0.6283422459893048,0.6336898395721925,0.6336898395721925,0.6417112299465241,0.6417112299465241,0.6443850267379679,0.6443850267379679,0.6764705882352942,0.6764705882352942,0.679144385026738,0.679144385026738,0.6844919786096256,0.6844919786096256,0.6871657754010695,0.6871657754010695,0.6925133689839572,0.6925133689839572,0.6951871657754011,0.6951871657754011,0.7005347593582888,0.7005347593582888,0.7058823529411765,0.7058823529411765,0.732620320855615,0.732620320855615,0.7620320855614974,0.7620320855614974,0.7807486631016043,0.7807486631016043,0.786096256684492,0.786096256684492,0.7941176470588235,0.7941176470588235,0.8101604278074866,0.8101604278074866,0.8155080213903744,0.8155080213903744,0.839572192513369,0.839572192513369,0.8502673796791443,0.8502673796791443,0.8689839572192514,0.8689839572192514,0.8716577540106952,0.8716577540106952,0.8770053475935828,0.8770053475935828,0.893048128342246,0.893048128342246,0.9064171122994652,0.9064171122994652,0.9358288770053476,0.9358288770053476,0.983957219251337,0.983957219251337,1.0],\"xaxis\":\"x\",\"y\":[0.0,0.000968054211035818,0.04065827686350436,0.04065827686350436,0.06389157792836399,0.06389157792836399,0.08325266214908035,0.08325266214908035,0.11519845111326234,0.11519845111326234,0.14811229428848016,0.14811229428848016,0.16456921587608905,0.16456921587608905,0.16844143272023232,0.16844143272023232,0.22749273959341723,0.22749273959341723,0.24394966118102615,0.24394966118102615,0.2739593417231365,0.2739593417231365,0.30784123910939015,0.30784123910939015,0.31752178121974833,0.31752178121974833,0.31848983543078413,0.31848983543078413,0.3330106485963214,0.3330106485963214,0.33978702807357214,0.33978702807357214,0.3601161665053243,0.3601161665053243,0.36689254598257504,0.36689254598257504,0.3717328170377541,0.3717328170377541,0.37560503388189737,0.37560503388189737,0.3814133591481123,0.3814133591481123,0.4569215876089061,0.4569215876089061,0.4791868344627299,0.4791868344627299,0.4849951597289448,0.4849951597289448,0.5062923523717329,0.5062923523717329,0.5343659244917716,0.5343659244917716,0.5556631171345595,0.5556631171345595,0.5575992255566312,0.5575992255566312,0.5634075508228461,0.5653436592449177,0.5808325266214908,0.5808325266214908,0.5818005808325266,0.5818005808325266,0.5837366892545982,0.5837366892545982,0.5847047434656341,0.5847047434656341,0.5953533397870281,0.5953533397870281,0.5982575024201355,0.5982575024201355,0.6089060987415296,0.6089060987415296,0.6098741529525653,0.6098741529525653,0.6224588576960309,0.6224588576960309,0.6243949661181026,0.6243949661181026,0.6282671829622459,0.6282671829622459,0.6389157792836399,0.6389157792836399,0.6466602129719264,0.6466602129719264,0.6505324298160697,0.6505324298160697,0.6534365924491772,0.6534365924491772,0.6544046466602129,0.6544046466602129,0.6573088092933205,0.6573088092933205,0.6669893514036787,0.6669893514036787,0.6689254598257502,0.6689254598257502,0.6718296224588577,0.6718296224588577,0.6834462729912875,0.6834462729912875,0.6844143272023233,0.6844143272023233,0.686350435624395,0.686350435624395,0.7057115198451114,0.7057115198451114,0.707647628267183,0.707647628267183,0.7115198451113263,0.7115198451113263,0.7192642787996127,0.7192642787996127,0.723136495643756,0.723136495643756,0.7347531461761858,0.7347531461761858,0.7386253630203291,0.7386253630203291,0.7434656340755083,0.7434656340755083,0.7599225556631172,0.7599225556631172,0.7608906098741529,0.7608906098741529,0.7618586640851888,0.7618586640851888,0.7647628267182962,0.7647628267182962,0.7657308809293321,0.7657308809293321,0.7676669893514037,0.7676669893514037,0.7696030977734754,0.7696030977734754,0.7705711519845111,0.7705711519845111,0.7812197483059051,0.7812197483059051,0.7831558567279767,0.7831558567279767,0.7860600193610843,0.7860600193610843,0.7889641819941917,0.7889641819941917,0.7899322362052275,0.7899322362052275,0.7918683446272992,0.7918683446272992,0.7947725072604066,0.7947725072604066,0.7957405614714425,0.7957405614714425,0.7967086156824782,0.7967086156824782,0.7996127783155856,0.7996127783155856,0.8015488867376573,0.8015488867376573,0.8044530493707648,0.8044530493707648,0.8054211035818006,0.8054211035818006,0.8073572120038722,0.8073572120038722,0.8083252662149081,0.8083252662149081,0.8092933204259438,0.8092933204259438,0.8112294288480155,0.8112294288480155,0.8170377541142304,0.8170377541142304,0.8180058083252663,0.8180058083252663,0.818973862536302,0.818973862536302,0.8209099709583737,0.8209099709583737,0.8238141335914811,0.8238141335914811,0.8247821878025169,0.8247821878025169,0.8257502420135527,0.8257502420135527,0.829622458857696,0.829622458857696,0.8315585672797676,0.8315585672797676,0.8325266214908035,0.8325266214908035,0.8334946757018393,0.8334946757018393,0.8363988383349468,0.8363988383349468,0.8402710551790901,0.8402710551790901,0.8431752178121975,0.8431752178121975,0.846079380445305,0.846079380445305,0.8470474346563408,0.8470474346563408,0.8489835430784124,0.8489835430784124,0.8499515972894482,0.8499515972894482,0.850919651500484,0.850919651500484,0.8518877057115198,0.8518877057115198,0.8538238141335914,0.8538238141335914,0.8557599225556631,0.8557599225556631,0.856727976766699,0.856727976766699,0.8576960309777347,0.8576960309777347,0.8606001936108422,0.8606001936108422,0.8635043562439496,0.8635043562439496,0.8654404646660213,0.8654404646660213,0.8664085188770572,0.8664085188770572,0.8702807357212003,0.8702807357212003,0.872216844143272,0.872216844143272,0.8741529525653436,0.8741529525653436,0.8751210067763795,0.8751210067763795,0.8770571151984511,0.8770571151984511,0.8780251694094869,0.8780251694094869,0.8789932236205228,0.8789932236205228,0.8818973862536302,0.8818973862536302,0.8848015488867377,0.8848015488867377,0.8896418199419167,0.8896418199419167,0.8906098741529526,0.8906098741529526,0.89351403678606,0.89351403678606,0.8954501452081317,0.8954501452081317,0.8964181994191674,0.8964181994191674,0.8993223620522749,0.8993223620522749,0.9012584704743466,0.9012584704743466,0.9138431752178122,0.9138431752178122,0.9177153920619555,0.9177153920619555,0.9186834462729913,0.9186834462729913,0.920619554695063,0.920619554695063,0.9244917715392061,0.9244917715392061,0.925459825750242,0.925459825750242,0.9264278799612778,0.9264278799612778,0.9273959341723137,0.9273959341723137,0.9283639883833494,0.9283639883833494,0.9293320425943853,0.9293320425943853,0.9322362052274927,0.9322362052274927,0.9341723136495643,0.9341723136495643,0.9370764762826719,0.9370764762826719,0.9390125847047435,0.9390125847047435,0.9399806389157793,0.9399806389157793,0.9409486931268151,0.9409486931268151,0.9419167473378509,0.9419167473378509,0.9428848015488868,0.9428848015488868,0.9448209099709584,0.9448209099709584,0.9457889641819942,0.9457889641819942,0.9477250726040658,0.9477250726040658,0.9486931268151017,0.9486931268151017,0.9545014520813165,0.9545014520813165,0.9554695062923524,0.9554695062923524,0.957405614714424,0.957405614714424,0.9593417231364957,0.9593417231364957,0.9603097773475314,0.9603097773475314,0.9612778315585673,0.9612778315585673,0.9622458857696031,0.9622458857696031,0.9632139399806389,0.9632139399806389,0.9641819941916747,0.9641819941916747,0.9651500484027106,0.9651500484027106,0.9661181026137464,0.9661181026137464,0.9690222652468539,0.9690222652468539,0.9719264278799613,0.9719264278799613,0.972894482090997,0.972894482090997,0.9748305905130688,0.9748305905130688,0.9757986447241046,0.9757986447241046,0.9777347531461762,0.9777347531461762,0.978702807357212,0.978702807357212,0.9796708615682478,0.9796708615682478,0.9825750242013552,0.9825750242013552,0.9854791868344628,0.9854791868344628,0.9864472410454985,0.9864472410454985,0.9874152952565344,0.9874152952565344,0.9883833494675702,0.9883833494675702,0.989351403678606,0.989351403678606,0.9903194578896418,0.9903194578896418,0.9912875121006777,0.9912875121006777,0.9922555663117134,0.9922555663117134,0.9932236205227493,0.9932236205227493,0.9941916747337851,0.9941916747337851,0.9961277831558567,0.9961277831558567,0.9970958373668926,0.9970958373668926,0.9980638915779284,0.9980638915779284,0.9990319457889641,0.9990319457889641,1.0,1.0],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"False Positive Rate\"},\"constrain\":\"domain\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"True Positive Rate\"},\"scaleanchor\":\"x\",\"scaleratio\":1},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"ROC Curve (AUC=0.8546)\"},\"height\":600,\"width\":800,\"shapes\":[{\"line\":{\"dash\":\"dash\"},\"type\":\"line\",\"x0\":0,\"x1\":1,\"y0\":0,\"y1\":1}],\"showlegend\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('7ed2e858-5bd6-46c8-b98d-4a7404079e93');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"fillpattern":{"shape":""},"hovertemplate":"Recall=%{x}<br>Precision=%{y}<extra></extra>","legendgroup":"","line":{"color":"#636efa"},"marker":{"symbol":"circle"},"mode":"lines","name":"","orientation":"v","showlegend":false,"stackgroup":"1","type":"scatter","x":[1,1,1,1,1,1,1,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.995159728944821,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9932236205227493,0.9932236205227493,0.9922555663117134,0.9922555663117134,0.9922555663117134,0.9922555663117134,0.9922555663117134,0.9922555663117134,0.9922555663117134,0.9922555663117134,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.989351403678606,0.989351403678606,0.989351403678606,0.9883833494675702,0.9883833494675702,0.9883833494675702,0.9883833494675702,0.9883833494675702,0.9883833494675702,0.9883833494675702,0.9874152952565344,0.9874152952565344,0.9874152952565344,0.9874152952565344,0.9864472410454985,0.9864472410454985,0.9864472410454985,0.9854791868344628,0.9854791868344628,0.9854791868344628,0.9854791868344628,0.9854791868344628,0.9854791868344628,0.9854791868344628,0.9854791868344628,0.9845111326234269,0.9835430784123911,0.9825750242013552,0.9825750242013552,0.9825750242013552,0.9825750242013552,0.9825750242013552,0.9825750242013552,0.9825750242013552,0.9825750242013552,0.9825750242013552,0.9825750242013552,0.9825750242013552,0.9825750242013552,0.9816069699903195,0.9806389157792836,0.9796708615682478,0.9796708615682478,0.9796708615682478,0.9796708615682478,0.9796708615682478,0.9796708615682478,0.9796708615682478,0.9796708615682478,0.9796708615682478,0.9796708615682478,0.9796708615682478,0.978702807357212,0.978702807357212,0.978702807357212,0.9777347531461762,0.9777347531461762,0.9777347531461762,0.9767666989351403,0.9757986447241046,0.9757986447241046,0.9748305905130688,0.9748305905130688,0.9748305905130688,0.9738625363020329,0.972894482090997,0.972894482090997,0.9719264278799613,0.9719264278799613,0.9719264278799613,0.9709583736689255,0.9699903194578896,0.9690222652468539,0.9690222652468539,0.968054211035818,0.9670861568247822,0.9661181026137464,0.9661181026137464,0.9661181026137464,0.9661181026137464,0.9661181026137464,0.9661181026137464,0.9661181026137464,0.9661181026137464,0.9661181026137464,0.9661181026137464,0.9661181026137464,0.9661181026137464,0.9661181026137464,0.9651500484027106,0.9651500484027106,0.9641819941916747,0.9641819941916747,0.9641819941916747,0.9641819941916747,0.9632139399806389,0.9632139399806389,0.9632139399806389,0.9622458857696031,0.9622458857696031,0.9622458857696031,0.9622458857696031,0.9622458857696031,0.9612778315585673,0.9612778315585673,0.9603097773475314,0.9603097773475314,0.9603097773475314,0.9603097773475314,0.9593417231364957,0.9593417231364957,0.9593417231364957,0.9593417231364957,0.9593417231364957,0.9593417231364957,0.9593417231364957,0.9583736689254598,0.957405614714424,0.957405614714424,0.957405614714424,0.957405614714424,0.957405614714424,0.9564375605033882,0.9554695062923524,0.9554695062923524,0.9554695062923524,0.9554695062923524,0.9545014520813165,0.9545014520813165,0.9545014520813165,0.9545014520813165,0.9535333978702807,0.952565343659245,0.9515972894482091,0.9506292352371732,0.9496611810261375,0.9486931268151017,0.9486931268151017,0.9486931268151017,0.9486931268151017,0.9477250726040658,0.9477250726040658,0.9467570183930301,0.9457889641819942,0.9457889641819942,0.9457889641819942,0.9448209099709584,0.9448209099709584,0.9448209099709584,0.9448209099709584,0.9448209099709584,0.9448209099709584,0.9448209099709584,0.9438528557599225,0.9428848015488868,0.9428848015488868,0.9419167473378509,0.9419167473378509,0.9409486931268151,0.9409486931268151,0.9399806389157793,0.9399806389157793,0.9390125847047435,0.9390125847047435,0.9390125847047435,0.9390125847047435,0.9380445304937076,0.9370764762826719,0.9370764762826719,0.9370764762826719,0.9370764762826719,0.9370764762826719,0.9370764762826719,0.9370764762826719,0.936108422071636,0.9351403678606002,0.9341723136495643,0.9341723136495643,0.9332042594385286,0.9322362052274927,0.9322362052274927,0.9312681510164569,0.9303000968054211,0.9293320425943853,0.9293320425943853,0.9293320425943853,0.9283639883833494,0.9283639883833494,0.9283639883833494,0.9273959341723137,0.9273959341723137,0.9264278799612778,0.9264278799612778,0.925459825750242,0.925459825750242,0.9244917715392061,0.9244917715392061,0.9235237173281704,0.9225556631171346,0.9215876089060987,0.920619554695063,0.920619554695063,0.920619554695063,0.9196515004840271,0.9186834462729913,0.9186834462729913,0.9177153920619555,0.9177153920619555,0.9167473378509197,0.9157792836398838,0.914811229428848,0.9138431752178122,0.9138431752178122,0.9138431752178122,0.9138431752178122,0.9128751210067764,0.9119070667957405,0.9109390125847048,0.9099709583736689,0.9090029041626331,0.9080348499515973,0.9070667957405615,0.9060987415295256,0.9051306873184899,0.904162633107454,0.9031945788964182,0.9022265246853823,0.9012584704743466,0.9012584704743466,0.9002904162633107,0.8993223620522749,0.8993223620522749,0.8983543078412392,0.8973862536302033,0.8964181994191674,0.8964181994191674,0.8954501452081317,0.8954501452081317,0.8954501452081317,0.8954501452081317,0.8944820909970959,0.89351403678606,0.89351403678606,0.8925459825750242,0.8915779283639884,0.8906098741529526,0.8906098741529526,0.8906098741529526,0.8906098741529526,0.8906098741529526,0.8896418199419167,0.8896418199419167,0.8896418199419167,0.8896418199419167,0.888673765730881,0.8877057115198451,0.8867376573088093,0.8857696030977735,0.8848015488867377,0.8848015488867377,0.8848015488867377,0.8838334946757018,0.882865440464666,0.8818973862536302,0.8818973862536302,0.8809293320425944,0.8799612778315585,0.8789932236205228,0.8789932236205228,0.8789932236205228,0.8780251694094869,0.8780251694094869,0.8770571151984511,0.8770571151984511,0.8760890609874153,0.8751210067763795,0.8751210067763795,0.8741529525653436,0.8741529525653436,0.8741529525653436,0.8731848983543078,0.872216844143272,0.872216844143272,0.8712487899322362,0.8702807357212003,0.8702807357212003,0.8693126815101646,0.8683446272991288,0.8673765730880929,0.8664085188770572,0.8664085188770572,0.8654404646660213,0.8654404646660213,0.8644724104549855,0.8635043562439496,0.8635043562439496,0.8625363020329139,0.861568247821878,0.8606001936108422,0.8606001936108422,0.8606001936108422,0.8606001936108422,0.8606001936108422,0.8596321393998064,0.8586640851887706,0.8576960309777347,0.8576960309777347,0.856727976766699,0.856727976766699,0.856727976766699,0.8557599225556631,0.8557599225556631,0.8557599225556631,0.8547918683446273,0.8538238141335914,0.8538238141335914,0.8528557599225557,0.8518877057115198,0.8518877057115198,0.850919651500484,0.850919651500484,0.8499515972894482,0.8499515972894482,0.8489835430784124,0.8489835430784124,0.8480154888673765,0.8470474346563408,0.8470474346563408,0.846079380445305,0.846079380445305,0.8451113262342691,0.8441432720232332,0.8431752178121975,0.8431752178121975,0.8422071636011617,0.8412391093901258,0.8402710551790901,0.8402710551790901,0.8402710551790901,0.8402710551790901,0.8393030009680542,0.8383349467570184,0.8373668925459826,0.8363988383349468,0.8363988383349468,0.8363988383349468,0.8363988383349468,0.8354307841239109,0.8344627299128751,0.8334946757018393,0.8334946757018393,0.8334946757018393,0.8325266214908035,0.8325266214908035,0.8315585672797676,0.8315585672797676,0.8315585672797676,0.8305905130687319,0.829622458857696,0.829622458857696,0.829622458857696,0.8286544046466602,0.8276863504356244,0.8267182962245886,0.8257502420135527,0.8257502420135527,0.8247821878025169,0.8247821878025169,0.8247821878025169,0.8247821878025169,0.8247821878025169,0.8238141335914811,0.8238141335914811,0.8238141335914811,0.8228460793804453,0.8218780251694094,0.8209099709583737,0.8209099709583737,0.8199419167473379,0.818973862536302,0.818973862536302,0.8180058083252663,0.8180058083252663,0.8170377541142304,0.8170377541142304,0.8160696999031946,0.8151016456921588,0.814133591481123,0.8131655372700871,0.8121974830590513,0.8112294288480155,0.8112294288480155,0.8102613746369797,0.8092933204259438,0.8092933204259438,0.8083252662149081,0.8083252662149081,0.8073572120038722,0.8073572120038722,0.8073572120038722,0.8063891577928364,0.8054211035818006,0.8054211035818006,0.8044530493707648,0.8044530493707648,0.8034849951597289,0.8025169409486931,0.8015488867376573,0.8015488867376573,0.8015488867376573,0.8015488867376573,0.8005808325266215,0.7996127783155856,0.7996127783155856,0.7986447241045499,0.797676669893514,0.7967086156824782,0.7967086156824782,0.7957405614714425,0.7957405614714425,0.7947725072604066,0.7947725072604066,0.7947725072604066,0.7938044530493708,0.7928363988383349,0.7918683446272992,0.7918683446272992,0.7909002904162633,0.7899322362052275,0.7899322362052275,0.7889641819941917,0.7889641819941917,0.7879961277831559,0.78702807357212,0.7860600193610843,0.7860600193610843,0.7860600193610843,0.7850919651500484,0.7841239109390126,0.7831558567279767,0.7831558567279767,0.782187802516941,0.7812197483059051,0.7812197483059051,0.7802516940948693,0.7792836398838335,0.7783155856727977,0.7773475314617618,0.7763794772507261,0.7754114230396902,0.7744433688286544,0.7734753146176185,0.7725072604065828,0.771539206195547,0.7705711519845111,0.7705711519845111,0.7705711519845111,0.7696030977734754,0.7696030977734754,0.7686350435624395,0.7676669893514037,0.7676669893514037,0.7666989351403679,0.7657308809293321,0.7657308809293321,0.7647628267182962,0.7647628267182962,0.7637947725072604,0.7628267182962246,0.7618586640851888,0.7618586640851888,0.7608906098741529,0.7608906098741529,0.7599225556631172,0.7599225556631172,0.7599225556631172,0.7589545014520813,0.7579864472410455,0.7570183930300097,0.7560503388189739,0.755082284607938,0.7541142303969022,0.7531461761858664,0.7521781219748306,0.7512100677637947,0.750242013552759,0.7492739593417231,0.7483059051306873,0.7473378509196515,0.7463697967086157,0.7454017424975798,0.744433688286544,0.7434656340755083,0.7434656340755083,0.7424975798644724,0.7415295256534365,0.7405614714424008,0.739593417231365,0.7386253630203291,0.7386253630203291,0.7376573088092934,0.7366892545982575,0.7357212003872217,0.7347531461761858,0.7347531461761858,0.7347531461761858,0.7337850919651501,0.7328170377541142,0.7318489835430784,0.7308809293320426,0.7299128751210068,0.7289448209099709,0.7279767666989352,0.7270087124878993,0.7260406582768635,0.7250726040658277,0.7241045498547919,0.723136495643756,0.723136495643756,0.7221684414327202,0.7212003872216844,0.7202323330106486,0.7192642787996127,0.7192642787996127,0.718296224588577,0.7173281703775412,0.7163601161665053,0.7153920619554696,0.7144240077444337,0.7134559535333979,0.712487899322362,0.7115198451113263,0.7115198451113263,0.7115198451113263,0.7115198451113263,0.7105517909002904,0.7095837366892546,0.7086156824782188,0.707647628267183,0.707647628267183,0.7066795740561471,0.7057115198451114,0.7057115198451114,0.7047434656340755,0.7037754114230397,0.7028073572120038,0.7018393030009681,0.7008712487899322,0.6999031945788964,0.6989351403678606,0.6979670861568248,0.6969990319457889,0.6960309777347532,0.6950629235237173,0.6940948693126815,0.6931268151016456,0.6921587608906099,0.691190706679574,0.6902226524685382,0.6892545982575025,0.6882865440464666,0.6873184898354308,0.686350435624395,0.686350435624395,0.686350435624395,0.6853823814133592,0.6844143272023233,0.6844143272023233,0.6844143272023233,0.6834462729912875,0.6834462729912875,0.6824782187802517,0.6815101645692159,0.68054211035818,0.6795740561471443,0.6786060019361084,0.6776379477250726,0.6766698935140368,0.675701839303001,0.6747337850919651,0.6737657308809293,0.6727976766698935,0.6718296224588577,0.6718296224588577,0.6708615682478218,0.6698935140367861,0.6689254598257502,0.6689254598257502,0.6679574056147144,0.6669893514036787,0.6669893514036787,0.6660212971926428,0.665053242981607,0.6640851887705711,0.6631171345595354,0.6621490803484995,0.6611810261374637,0.6602129719264279,0.6592449177153921,0.6582768635043562,0.6573088092933205,0.6573088092933205,0.6563407550822846,0.6553727008712488,0.6544046466602129,0.6544046466602129,0.6534365924491772,0.6534365924491772,0.6524685382381413,0.6515004840271055,0.6505324298160697,0.6505324298160697,0.6495643756050339,0.648596321393998,0.6476282671829623,0.6466602129719264,0.6466602129719264,0.6456921587608906,0.6447241045498547,0.643756050338819,0.6427879961277831,0.6418199419167473,0.6408518877057116,0.6398838334946757,0.6389157792836399,0.6389157792836399,0.6389157792836399,0.6379477250726041,0.6369796708615683,0.6360116166505324,0.6350435624394967,0.6340755082284608,0.633107454017425,0.6321393998063891,0.6311713455953534,0.6302032913843175,0.6292352371732817,0.6282671829622459,0.6282671829622459,0.6272991287512101,0.6263310745401742,0.6253630203291385,0.6243949661181026,0.6243949661181026,0.6234269119070668,0.6224588576960309,0.6224588576960309,0.6214908034849952,0.6205227492739593,0.6195546950629235,0.6185866408518877,0.6176185866408519,0.616650532429816,0.6156824782187803,0.6147144240077445,0.6137463697967086,0.6127783155856728,0.611810261374637,0.6108422071636012,0.6098741529525653,0.6098741529525653,0.6098741529525653,0.6089060987415296,0.6089060987415296,0.6079380445304937,0.6069699903194579,0.6060019361084221,0.6050338818973863,0.6040658276863504,0.6030977734753146,0.6021297192642788,0.601161665053243,0.6001936108422071,0.5992255566311714,0.5982575024201355,0.5982575024201355,0.5982575024201355,0.5982575024201355,0.5972894482090997,0.5963213939980639,0.5953533397870281,0.5953533397870281,0.5943852855759922,0.5934172313649564,0.5924491771539206,0.5914811229428848,0.590513068731849,0.5895450145208132,0.5885769603097774,0.5876089060987415,0.5866408518877058,0.5856727976766699,0.5847047434656341,0.5847047434656341,0.5837366892545982,0.5837366892545982,0.5827686350435625,0.5818005808325266,0.5818005808325266,0.5808325266214908,0.5808325266214908,0.579864472410455,0.5788964181994192,0.5779283639883833,0.5769603097773476,0.5759922555663117,0.5750242013552759,0.57405614714424,0.5730880929332043,0.5721200387221684,0.5711519845111326,0.5701839303000968,0.569215876089061,0.5682478218780251,0.5672797676669894,0.5663117134559535,0.5653436592449177,0.5634075508228461,0.5624394966118103,0.5614714424007744,0.5605033881897387,0.5595353339787028,0.558567279767667,0.5575992255566312,0.5575992255566312,0.5566311713455954,0.5556631171345595,0.5556631171345595,0.5546950629235237,0.5537270087124879,0.5527589545014521,0.5517909002904162,0.5508228460793805,0.5498547918683446,0.5488867376573088,0.547918683446273,0.5469506292352372,0.5459825750242013,0.5450145208131656,0.5440464666021297,0.5430784123910939,0.542110358180058,0.5411423039690223,0.5401742497579864,0.5392061955469506,0.5382381413359149,0.537270087124879,0.5363020329138432,0.5353339787028074,0.5343659244917716,0.5343659244917716,0.5333978702807357,0.5324298160696999,0.5314617618586641,0.5304937076476283,0.5295256534365924,0.5285575992255567,0.5275895450145208,0.526621490803485,0.5256534365924492,0.5246853823814134,0.5237173281703775,0.5227492739593417,0.5217812197483059,0.5208131655372701,0.5198451113262342,0.5188770571151985,0.5179090029041626,0.5169409486931268,0.515972894482091,0.5150048402710552,0.5140367860600193,0.5130687318489835,0.5121006776379478,0.5111326234269119,0.510164569215876,0.5091965150048403,0.5082284607938045,0.5072604065827686,0.5062923523717329,0.5062923523717329,0.505324298160697,0.5043562439496612,0.5033881897386253,0.5024201355275896,0.5014520813165537,0.5004840271055179,0.4995159728944821,0.4985479186834463,0.4975798644724105,0.49661181026137463,0.49564375605033884,0.494675701839303,0.4937076476282672,0.4927395934172314,0.49177153920619554,0.49080348499515974,0.4898354307841239,0.4888673765730881,0.4878993223620523,0.48693126815101645,0.48596321393998065,0.4849951597289448,0.4849951597289448,0.484027105517909,0.4830590513068732,0.48209099709583736,0.48112294288480156,0.4801548886737657,0.4791868344627299,0.4791868344627299,0.4782187802516941,0.47725072604065827,0.4762826718296225,0.4753146176185866,0.4743465634075508,0.47337850919651503,0.4724104549854792,0.4714424007744434,0.47047434656340753,0.46950629235237173,0.46853823814133594,0.4675701839303001,0.4666021297192643,0.46563407550822844,0.46466602129719264,0.46369796708615685,0.462729912875121,0.4617618586640852,0.46079380445304935,0.45982575024201355,0.45885769603097776,0.4578896418199419,0.4569215876089061,0.4569215876089061,0.45595353339787026,0.45498547918683446,0.45401742497579867,0.4530493707647628,0.452081316553727,0.45111326234269117,0.45014520813165537,0.4491771539206196,0.4482090997095837,0.44724104549854793,0.4462729912875121,0.4453049370764763,0.4443368828654405,0.44336882865440463,0.44240077444336884,0.441432720232333,0.4404646660212972,0.4394966118102614,0.43852855759922554,0.43756050338818975,0.4365924491771539,0.4356243949661181,0.4346563407550823,0.43368828654404645,0.43272023233301066,0.4317521781219748,0.430784123910939,0.4298160696999032,0.42884801548886736,0.42787996127783157,0.4269119070667957,0.4259438528557599,0.4249757986447241,0.42400774443368827,0.4230396902226525,0.4220716360116166,0.42110358180058083,0.42013552758954503,0.4191674733785092,0.4181994191674734,0.41723136495643753,0.41626331074540174,0.41529525653436594,0.4143272023233301,0.4133591481122943,0.41239109390125844,0.41142303969022265,0.41045498547918685,0.409486931268151,0.4085188770571152,0.4075508228460794,0.40658276863504356,0.40561471442400776,0.4046466602129719,0.4036786060019361,0.4027105517909003,0.40174249757986447,0.40077444336882867,0.3998063891577928,0.398838334946757,0.3978702807357212,0.3969022265246854,0.3959341723136496,0.39496611810261373,0.39399806389157793,0.39303000968054214,0.3920619554695063,0.3910939012584705,0.39012584704743464,0.38915779283639884,0.38818973862536305,0.3872216844143272,0.3862536302032914,0.38528557599225555,0.38431752178121975,0.38334946757018395,0.3823814133591481,0.3814133591481123,0.3814133591481123,0.38044530493707646,0.37947725072604066,0.37850919651500486,0.377541142303969,0.3765730880929332,0.37560503388189737,0.37560503388189737,0.37463697967086157,0.3736689254598258,0.3727008712487899,0.3717328170377541,0.3717328170377541,0.3707647628267183,0.3697967086156825,0.3688286544046467,0.36786060019361083,0.36689254598257504,0.36689254598257504,0.3659244917715392,0.3649564375605034,0.3639883833494676,0.36302032913843174,0.36205227492739595,0.3610842207163601,0.3601161665053243,0.3601161665053243,0.3591481122942885,0.35818005808325265,0.35721200387221685,0.356243949661181,0.3552758954501452,0.3543078412391094,0.35333978702807356,0.35237173281703776,0.3514036786060019,0.3504356243949661,0.3494675701839303,0.34849951597289447,0.3475314617618587,0.3465634075508228,0.345595353339787,0.34462729912875123,0.3436592449177154,0.3426911907066796,0.34172313649564373,0.34075508228460794,0.33978702807357214,0.33978702807357214,0.3388189738625363,0.3378509196515005,0.33688286544046464,0.33591481122942884,0.33494675701839305,0.3339787028073572,0.3330106485963214,0.3330106485963214,0.33204259438528555,0.33107454017424975,0.33010648596321396,0.3291384317521781,0.3281703775411423,0.32720232333010646,0.32623426911907066,0.32526621490803487,0.324298160696999,0.3233301064859632,0.32236205227492737,0.3213939980638916,0.3204259438528558,0.3194578896418199,0.31848983543078413,0.31848983543078413,0.31752178121974833,0.31752178121974833,0.3165537270087125,0.3155856727976767,0.31461761858664083,0.31364956437560504,0.31268151016456924,0.3117134559535334,0.3107454017424976,0.30977734753146174,0.30880929332042595,0.30784123910939015,0.30784123910939015,0.3068731848983543,0.3059051306873185,0.30493707647628265,0.30396902226524686,0.30300096805421106,0.3020329138431752,0.3010648596321394,0.30009680542110356,0.29912875121006777,0.29816069699903197,0.2971926427879961,0.2962245885769603,0.2952565343659245,0.2942884801548887,0.2933204259438529,0.29235237173281703,0.29138431752178123,0.2904162633107454,0.2894482090997096,0.2884801548886738,0.28751210067763794,0.28654404646660214,0.2855759922555663,0.2846079380445305,0.2836398838334947,0.28267182962245885,0.28170377541142305,0.2807357212003872,0.2797676669893514,0.2787996127783156,0.27783155856727976,0.27686350435624396,0.2758954501452081,0.2749273959341723,0.2739593417231365,0.2739593417231365,0.27299128751210067,0.27202323330106487,0.271055179090029,0.2700871248789932,0.2691190706679574,0.2681510164569216,0.2671829622458858,0.26621490803484993,0.26524685382381413,0.26427879961277834,0.2633107454017425,0.2623426911907067,0.26137463697967084,0.26040658276863504,0.25943852855759925,0.2584704743465634,0.2575024201355276,0.25653436592449175,0.25556631171345595,0.25459825750242016,0.2536302032913843,0.2526621490803485,0.25169409486931266,0.25072604065827686,0.24975798644724104,0.24878993223620524,0.24782187802516942,0.2468538238141336,0.24588576960309777,0.24491771539206195,0.24394966118102615,0.24394966118102615,0.24298160696999033,0.2420135527589545,0.24104549854791868,0.24007744433688286,0.23910939012584706,0.23814133591481124,0.2371732817037754,0.2362052274927396,0.23523717328170377,0.23426911907066797,0.23330106485963215,0.23233301064859632,0.2313649564375605,0.23039690222652467,0.22942884801548888,0.22846079380445306,0.22749273959341723,0.22749273959341723,0.2265246853823814,0.22555663117134558,0.2245885769603098,0.22362052274927396,0.22265246853823814,0.22168441432720232,0.2207163601161665,0.2197483059051307,0.21878025169409487,0.21781219748305905,0.21684414327202323,0.2158760890609874,0.2149080348499516,0.21393998063891578,0.21297192642787996,0.21200387221684414,0.2110358180058083,0.21006776379477252,0.2090997095837367,0.20813165537270087,0.20716360116166505,0.20619554695062922,0.20522749273959343,0.2042594385285576,0.20329138431752178,0.20232333010648595,0.20135527589545016,0.20038722168441434,0.1994191674733785,0.1984511132623427,0.19748305905130686,0.19651500484027107,0.19554695062923524,0.19457889641819942,0.1936108422071636,0.19264278799612777,0.19167473378509198,0.19070667957405615,0.18973862536302033,0.1887705711519845,0.18780251694094868,0.1868344627299129,0.18586640851887706,0.18489835430784124,0.18393030009680542,0.1829622458857696,0.1819941916747338,0.18102613746369797,0.18005808325266215,0.17909002904162633,0.1781219748305905,0.1771539206195547,0.17618586640851888,0.17521781219748306,0.17424975798644723,0.1732817037754114,0.17231364956437561,0.1713455953533398,0.17037754114230397,0.16940948693126814,0.16844143272023232,0.16844143272023232,0.16747337850919652,0.1665053242981607,0.16553727008712488,0.16456921587608905,0.16456921587608905,0.16360116166505323,0.16263310745401743,0.1616650532429816,0.1606969990319458,0.15972894482090996,0.15876089060987417,0.15779283639883834,0.15682478218780252,0.1558567279767667,0.15488867376573087,0.15392061955469508,0.15295256534365925,0.15198451113262343,0.1510164569215876,0.15004840271055178,0.14908034849951599,0.14811229428848016,0.14811229428848016,0.14714424007744434,0.14617618586640851,0.1452081316553727,0.1442400774443369,0.14327202323330107,0.14230396902226525,0.14133591481122942,0.1403678606001936,0.1393998063891578,0.13843175217812198,0.13746369796708616,0.13649564375605033,0.1355275895450145,0.1345595353339787,0.1335914811229429,0.13262342691190707,0.13165537270087124,0.13068731848983542,0.12971926427879962,0.1287512100677638,0.12778315585672798,0.12681510164569215,0.12584704743465633,0.12487899322362052,0.12391093901258471,0.12294288480154889,0.12197483059051308,0.12100677637947725,0.12003872216844143,0.11907066795740562,0.1181026137463698,0.11713455953533398,0.11616650532429816,0.11519845111326234,0.11519845111326234,0.11423039690222653,0.1132623426911907,0.1122942884801549,0.11132623426911907,0.11035818005808325,0.10939012584704744,0.10842207163601161,0.1074540174249758,0.10648596321393998,0.10551790900290416,0.10454985479186835,0.10358180058083252,0.10261374636979671,0.10164569215876089,0.10067763794772508,0.09970958373668926,0.09874152952565343,0.09777347531461762,0.0968054211035818,0.09583736689254599,0.09486931268151017,0.09390125847047434,0.09293320425943853,0.09196515004840271,0.0909970958373669,0.09002904162633107,0.08906098741529525,0.08809293320425944,0.08712487899322362,0.08615682478218781,0.08518877057115198,0.08422071636011616,0.08325266214908035,0.08325266214908035,0.08228460793804453,0.08131655372700872,0.0803484995159729,0.07938044530493708,0.07841239109390126,0.07744433688286544,0.07647628267182963,0.0755082284607938,0.07454017424975799,0.07357212003872217,0.07260406582768635,0.07163601161665054,0.07066795740561471,0.0696999031945789,0.06873184898354308,0.06776379477250725,0.06679574056147145,0.06582768635043562,0.06485963213939981,0.06389157792836399,0.06389157792836399,0.06292352371732816,0.061955469506292354,0.06098741529525654,0.060019361084220714,0.0590513068731849,0.05808325266214908,0.057115198451113264,0.05614714424007745,0.05517909002904162,0.05421103581800581,0.05324298160696999,0.05227492739593417,0.051306873184898356,0.05033881897386254,0.049370764762826716,0.0484027105517909,0.04743465634075508,0.046466602129719266,0.04549854791868345,0.044530493707647625,0.04356243949661181,0.04259438528557599,0.041626331074540175,0.04065827686350436,0.04065827686350436,0.03969022265246854,0.03872216844143272,0.0377541142303969,0.036786060019361085,0.03581800580832527,0.03484995159728945,0.03388189738625363,0.03291384317521781,0.031945788964181994,0.030977734753146177,0.030009680542110357,0.02904162633107454,0.028073572120038724,0.027105517909002903,0.026137463697967087,0.02516940948693127,0.02420135527589545,0.023233301064859633,0.022265246853823813,0.021297192642787996,0.02032913843175218,0.01936108422071636,0.018393030009680542,0.017424975798644726,0.016456921587608905,0.015488867376573089,0.01452081316553727,0.013552758954501452,0.012584704743465635,0.011616650532429816,0.010648596321393998,0.00968054211035818,0.008712487899322363,0.007744433688286544,0.006776379477250726,0.005808325266214908,0.00484027105517909,0.003872216844143272,0.002904162633107454,0.001936108422071636,0.000968054211035818,0],"xaxis":"x","y":[0.7341862117981521,0.7347083926031295,0.7352313167259786,0.7357549857549858,0.7362794012829651,0.7368045649072753,0.7373304782298359,0.7371428571428571,0.7376697641172266,0.7381974248927039,0.7387258410880458,0.7392550143266475,0.7397849462365591,0.7403156384505022,0.7408470926058865,0.7413793103448276,0.7419122933141624,0.7424460431654676,0.7429805615550756,0.7435158501440923,0.7440519105984138,0.7445887445887446,0.7451263537906138,0.7456647398843931,0.7462039045553145,0.7467438494934877,0.7465604634322954,0.7471014492753624,0.747643219724438,0.7481857764876633,0.7487291212781408,0.7492732558139535,0.7498181818181818,0.7503639010189228,0.7509104151493081,0.7514577259475219,0.7520058351568198,0.7525547445255475,0.7523739956172388,0.7529239766081871,0.7534747622531089,0.7540263543191801,0.7545787545787546,0.7551319648093842,0.7549523110785032,0.7555066079295154,0.7560617193240264,0.7566176470588235,0.7571743929359823,0.7577319587628866,0.7582903463522476,0.7581120943952803,0.7579335793357933,0.758493353028065,0.7590539541759054,0.7588757396449705,0.7594374537379719,0.7592592592592593,0.759822090437361,0.7603857566765578,0.7609502598366741,0.7615156017830609,0.7620817843866171,0.7626488095238095,0.763216679076694,0.7630402384500745,0.7636092468307233,0.764179104477612,0.7647498132935027,0.7653213751868461,0.7651458489154824,0.7657185628742516,0.7662921348314606,0.7668665667166417,0.7674418604651163,0.7680180180180181,0.768595041322314,0.7691729323308271,0.7697516930022573,0.7703313253012049,0.7701582516955539,0.770739064856712,0.7713207547169811,0.7711480362537765,0.7717309145880574,0.7723146747352496,0.7728993186979561,0.7734848484848484,0.7740712661106899,0.7746585735963581,0.7744874715261959,0.7750759878419453,0.7756653992395437,0.776255707762557,0.776085300837776,0.7766768292682927,0.7772692601067888,0.7770992366412214,0.7776928953399541,0.7782874617737003,0.7788829380260138,0.77947932618683,0.7800766283524905,0.7806748466257669,0.7812739831158864,0.7811059907834101,0.7809377401998463,0.7807692307692308,0.7813702848344881,0.7819722650231125,0.7825751734772552,0.783179012345679,0.7837837837837838,0.7843894899536321,0.7849961330239753,0.7856037151702786,0.7862122385747483,0.7868217054263565,0.7874321179208689,0.7872670807453416,0.7871017871017871,0.7869362363919129,0.7875486381322957,0.7881619937694704,0.7887763055339049,0.7893915756630265,0.790007806401249,0.790625,0.7912431587177482,0.7918622848200313,0.7924823805794832,0.7931034482758621,0.7929411764705883,0.793563579277865,0.7941869599371564,0.7940251572327044,0.7946498819826908,0.7952755905511811,0.7951142631993696,0.7949526813880127,0.7955801104972375,0.7954186413902053,0.7960474308300395,0.7966772151898734,0.7965162311955661,0.7963549920760697,0.7969865186360032,0.7968253968253968,0.7974583002382843,0.7980922098569158,0.7979315831344471,0.7977707006369427,0.797609561752988,0.7982456140350878,0.7980845969672785,0.797923322683706,0.7977617905675459,0.7984,0.7990392313851081,0.7996794871794872,0.8003207698476343,0.8009630818619583,0.8016064257028113,0.8022508038585209,0.8028962188254224,0.8035426731078905,0.8041901692183723,0.8048387096774193,0.8054882970137207,0.8053311793214862,0.8059822150363783,0.8058252427184466,0.8064777327935223,0.807131280388979,0.8077858880778589,0.8076298701298701,0.8082859463850528,0.8089430894308943,0.8087876322213181,0.8094462540716613,0.8101059494702526,0.8107667210440457,0.8114285714285714,0.8112745098039216,0.8119378577269011,0.8117839607201309,0.8124488124488124,0.8131147540983606,0.8137817883511075,0.8136288998357963,0.8142974527526705,0.8149671052631579,0.8156378600823045,0.8163097199341022,0.8169826875515251,0.8176567656765676,0.8175061932287366,0.8173553719008264,0.8180314309346567,0.8187086092715232,0.8193869096934548,0.8200663349917081,0.8199170124481328,0.8197674418604651,0.8204488778054863,0.8211314475873545,0.8218151540383014,0.8216666666666667,0.8223519599666389,0.8230383973288815,0.8237259816207184,0.8235785953177257,0.8234309623430962,0.8232830820770519,0.8231349538977368,0.822986577181208,0.8228379513014273,0.8235294117647058,0.8242220353238016,0.8249158249158249,0.8247683235046336,0.8254637436762225,0.8253164556962025,0.825168918918919,0.8258664412510567,0.8265651438240271,0.8264182895850973,0.8271186440677966,0.8278201865988125,0.8285229202037352,0.8292268479184367,0.8299319727891157,0.8306382978723404,0.8304940374787053,0.8303495311167945,0.8310580204778157,0.8309137489325363,0.8316239316239317,0.8314798973481609,0.8321917808219178,0.8320479862896315,0.8327615780445969,0.8326180257510729,0.8333333333333334,0.8340498710232158,0.8347676419965576,0.834625322997416,0.8344827586206897,0.8352027610008628,0.8359240069084629,0.8366464995678479,0.8373702422145328,0.8380952380952381,0.8388214904679376,0.8386816999132697,0.8385416666666666,0.838401390095569,0.8391304347826087,0.8389904264577894,0.8388501742160279,0.8395815170008718,0.8394415357766143,0.8393013100436681,0.8391608391608392,0.8398950131233596,0.840630472854641,0.8404907975460123,0.8412280701754385,0.8419666374012291,0.8418277680140598,0.8425681618293756,0.8424295774647887,0.8431718061674008,0.8430335097001763,0.8437775816416593,0.8436395759717314,0.8443854995579133,0.8442477876106195,0.8441098317094774,0.8439716312056738,0.8438331854480923,0.844582593250444,0.8453333333333334,0.8451957295373665,0.8450578806767587,0.8458110516934046,0.8456735057983943,0.8464285714285714,0.8462913315460232,0.8461538461538461,0.8460161145926589,0.8458781362007168,0.8466367713004485,0.8473967684021544,0.8481581311769991,0.8480215827338129,0.8478847884788479,0.8477477477477477,0.8476104598737602,0.8474729241877257,0.8473351400180669,0.8471971066907775,0.8470588235294118,0.8469202898550725,0.8467815049864007,0.8466424682395645,0.846503178928247,0.8463636363636363,0.8471337579617835,0.8469945355191257,0.8468550592525068,0.8476277372262774,0.8474885844748858,0.8473491773308958,0.8472095150960659,0.847985347985348,0.847846012832264,0.8486238532110092,0.8494031221303948,0.8501838235294118,0.8500459981600736,0.8499079189686924,0.8506912442396314,0.8505535055350554,0.850415512465374,0.8502772643253235,0.851063829787234,0.8518518518518519,0.8526413345690455,0.8534322820037106,0.8532961931290622,0.854089219330855,0.8548837209302326,0.8556797020484171,0.8555452003727866,0.855410447761194,0.8552754435107376,0.8551401869158879,0.8550046772684752,0.8558052434456929,0.8566073102155577,0.8564727954971857,0.856338028169014,0.856203007518797,0.8570084666039511,0.8568738229755178,0.8567389255419415,0.8566037735849057,0.8574126534466477,0.8582230623818525,0.8580889309366131,0.8589015151515151,0.8587677725118483,0.8595825426944972,0.8594491927825261,0.8593155893536122,0.8601332064700286,0.86,0.8608198284080076,0.8616412213740458,0.8615090735434575,0.861376673040153,0.8622009569377991,0.8620689655172413,0.8619367209971237,0.8627639155470249,0.8626320845341018,0.8625,0.8623676612127045,0.8622350674373795,0.863066538090646,0.862934362934363,0.863768115942029,0.8636363636363636,0.8635043562439496,0.8643410852713178,0.8642095053346266,0.8640776699029126,0.8639455782312925,0.8647859922178989,0.8656280428432327,0.8664717348927875,0.8673170731707317,0.8671875,0.8670576735092864,0.8669275929549902,0.8677766895200784,0.8676470588235294,0.8684985279685966,0.869351669941061,0.8692232055063913,0.8700787401574803,0.870935960591133,0.8708086785009862,0.8706811451135242,0.8715415019762845,0.8714144411473789,0.8712871287128713,0.8721506442021804,0.8720238095238095,0.8728897715988083,0.8727634194831014,0.8736318407960199,0.8735059760956175,0.8743768693918246,0.874251497005988,0.8741258741258742,0.875,0.8748748748748749,0.875751503006012,0.8756268806419257,0.8755020080321285,0.8753768844221106,0.8762575452716298,0.8761329305135952,0.876008064516129,0.875882946518668,0.8767676767676768,0.8776541961577351,0.8785425101214575,0.878419452887538,0.8782961460446247,0.8781725888324873,0.8780487804878049,0.8789420142421159,0.879837067209776,0.8807339449541285,0.8806122448979592,0.8804902962206334,0.8803680981595092,0.8812691914022518,0.882172131147541,0.882051282051282,0.8829568788501027,0.8828365878725591,0.8837448559670782,0.8846549948506695,0.8845360824742268,0.8844169246646026,0.8853305785123967,0.8862461220268872,0.8861283643892339,0.8860103626943006,0.8858921161825726,0.885773624091381,0.8866943866943867,0.886576482830385,0.8875,0.8884254431699687,0.8893528183716075,0.890282131661442,0.8901673640167364,0.8910994764397906,0.8920335429769392,0.8919202518363064,0.8918067226890757,0.8916929547844374,0.8926315789473684,0.8925184404636459,0.8924050632911392,0.8933474128827877,0.8932346723044398,0.8941798941798942,0.8940677966101694,0.8950159066808059,0.8949044585987261,0.8947927736450585,0.8946808510638298,0.8945686900958466,0.894456289978678,0.8943436499466382,0.8952991452991453,0.895187165775401,0.8950749464668094,0.8960342979635584,0.8959227467811158,0.8968850698174007,0.896774193548387,0.8977395048439182,0.8987068965517241,0.8985976267529665,0.8984881209503239,0.8994594594594595,0.8993506493506493,0.9003250270855905,0.9002169197396963,0.9001085776330076,0.9,0.9009793253536452,0.9019607843137255,0.9029443838604144,0.9028384279475983,0.9027322404371585,0.9037199124726477,0.9036144578313253,0.9035087719298246,0.9034028540065862,0.9043956043956044,0.9042904290429042,0.9052863436123348,0.9051819184123484,0.9061810154525386,0.907182320441989,0.9070796460176991,0.9069767441860465,0.9068736141906873,0.9078801331853497,0.9077777777777778,0.9076751946607341,0.9086859688195991,0.9085841694537347,0.9095982142857143,0.9094972067039107,0.9093959731543624,0.9092945128779395,0.9103139013452914,0.9113355780022446,0.9112359550561798,0.9111361079865017,0.911036036036036,0.9120631341600902,0.9119638826185101,0.911864406779661,0.9128959276018099,0.912797281993205,0.9126984126984127,0.9125993189557321,0.9125,0.9124004550625711,0.9123006833712984,0.9122006841505131,0.9121004566210046,0.912,0.9118993135011442,0.9117983963344788,0.9128440366972477,0.9138920780711826,0.9137931034482759,0.9148446490218642,0.9147465437788018,0.9146482122260668,0.9157043879907621,0.915606936416185,0.9155092592592593,0.9165701042873696,0.9164733178654292,0.9175377468060395,0.9174418604651163,0.9173457508731082,0.9172494172494172,0.9183197199533255,0.9182242990654206,0.9192982456140351,0.9192037470725996,0.9202813599062134,0.9213615023474179,0.9212690951821386,0.9211764705882353,0.9210836277974087,0.9209905660377359,0.9208972845336482,0.9208037825059102,0.9207100591715977,0.9206161137440758,0.9205219454329775,0.9204275534441805,0.920332936979786,0.9202380952380952,0.9201430274135876,0.9200477326968973,0.9199522102747909,0.9198564593301436,0.9197604790419162,0.920863309352518,0.9207683073229291,0.9206730769230769,0.9205776173285198,0.9204819277108434,0.9203860072376358,0.9214975845410628,0.9214026602176542,0.9213075060532687,0.9212121212121213,0.9211165048543689,0.9222357229647631,0.9233576642335767,0.9232643118148599,0.9231707317073171,0.9230769230769231,0.9229828850855746,0.9228886168910648,0.9227941176470589,0.9226993865030675,0.9226044226044227,0.922509225092251,0.9224137931034483,0.9223181257706535,0.9222222222222223,0.92336217552534,0.9232673267326733,0.9231722428748451,0.9230769230769231,0.9229813664596274,0.9241293532338308,0.9240348692403487,0.9239401496259352,0.9238451935081149,0.92375,0.9236545682102628,0.9235588972431078,0.9234629861982434,0.9233668341708543,0.9245283018867925,0.9256926952141058,0.926860025220681,0.9267676767676768,0.9266750948166877,0.9265822784810127,0.926489226869455,0.9276649746192893,0.9275730622617535,0.9274809160305344,0.9286624203821656,0.9285714285714286,0.9284802043422733,0.928388746803069,0.9282970550576184,0.9282051282051282,0.9281129653401797,0.9280205655526992,0.9279279279279279,0.9278350515463918,0.927741935483871,0.9276485788113695,0.9275549805950841,0.927461139896373,0.9273670557717251,0.9272727272727272,0.9271781534460338,0.9270833333333334,0.9269882659713168,0.9268929503916449,0.9267973856209151,0.9280104712041884,0.9292267365661862,0.9291338582677166,0.9290407358738502,0.9302631578947368,0.9314888010540184,0.9313984168865436,0.9326287978863936,0.9325396825396826,0.9324503311258279,0.9323607427055703,0.9322709163346613,0.9321808510638298,0.9320905459387483,0.932,0.931909212283044,0.9318181818181818,0.9317269076305221,0.9316353887399463,0.9315436241610738,0.9327956989247311,0.9327052489905787,0.9326145552560647,0.9325236167341431,0.9337837837837838,0.9336941813261164,0.9336043360433605,0.9348710990502035,0.9347826086956522,0.9346938775510204,0.9346049046321526,0.9345156889495225,0.9344262295081968,0.9343365253077975,0.9342465753424658,0.934156378600823,0.9340659340659341,0.9339752407152683,0.9352617079889807,0.9351724137931035,0.9350828729281768,0.9349930843706777,0.9362880886426593,0.9361997226074896,0.9375,0.9374130737134909,0.9373259052924791,0.9372384937238494,0.9385474860335196,0.9384615384615385,0.938375350140056,0.938288920056101,0.9382022471910112,0.939521800281294,0.9394366197183098,0.9393511988716502,0.9392655367231638,0.9391796322489392,0.9390934844192634,0.9390070921985816,0.9389204545454546,0.9388335704125178,0.9401709401709402,0.9415121255349501,0.9414285714285714,0.9413447782546495,0.9412607449856734,0.9411764705882353,0.9410919540229885,0.9410071942446043,0.9409221902017291,0.9408369408369408,0.9407514450867052,0.9406657018813314,0.9405797101449276,0.941944847605225,0.9418604651162791,0.9417758369723436,0.9416909620991254,0.9416058394160584,0.9429824561403509,0.9428989751098097,0.9428152492668622,0.9441997063142438,0.9441176470588235,0.9440353460972017,0.943952802359882,0.9438700147710487,0.9437869822485208,0.9437037037037037,0.9436201780415431,0.9435364041604755,0.9434523809523809,0.9433681073025335,0.9432835820895522,0.9431988041853513,0.9431137724550899,0.9445277361319341,0.9459459459459459,0.9458646616541353,0.947289156626506,0.947209653092006,0.947129909365559,0.9470499243570348,0.946969696969697,0.9468892261001517,0.9468085106382979,0.9467275494672754,0.9466463414634146,0.9465648854961832,0.9464831804281345,0.9464012251148545,0.9478527607361963,0.9493087557603687,0.9507692307692308,0.9506933744221879,0.9506172839506173,0.9505409582689336,0.9520123839009288,0.951937984496124,0.9518633540372671,0.9517884914463453,0.9517133956386293,0.9516380655226209,0.9515625,0.9514866979655712,0.95141065830721,0.9513343799058085,0.9512578616352201,0.9511811023622048,0.9526813880126183,0.95260663507109,0.9541139240506329,0.9540412044374009,0.953968253968254,0.9554848966613673,0.9554140127388535,0.9569377990430622,0.9568690095846646,0.9568,0.9567307692307693,0.956661316211878,0.9565916398713826,0.9565217391304348,0.9564516129032258,0.9563812600969306,0.9563106796116505,0.9562398703403565,0.9561688311688312,0.9560975609756097,0.9560260586319218,0.9559543230016313,0.9558823529411765,0.955810147299509,0.9556650246305419,0.9555921052631579,0.9555189456342669,0.9554455445544554,0.9553719008264463,0.9552980132450332,0.9552238805970149,0.9568106312292359,0.956738768718802,0.9566666666666667,0.9582637729549248,0.9581939799331104,0.9581239530988275,0.9580536912751678,0.957983193277311,0.9579124579124579,0.9578414839797639,0.9577702702702703,0.9576988155668359,0.9576271186440678,0.9575551782682513,0.9574829931972789,0.9574105621805792,0.9573378839590444,0.9572649572649573,0.9571917808219178,0.9571183533447685,0.9570446735395189,0.9569707401032702,0.9568965517241379,0.9568221070811744,0.9567474048442907,0.9566724436741768,0.9583333333333334,0.9582608695652174,0.9581881533101045,0.9581151832460733,0.958041958041958,0.957968476357268,0.9578947368421052,0.9578207381370826,0.9577464788732394,0.9576719576719577,0.9575971731448764,0.9575221238938053,0.9574468085106383,0.9573712255772646,0.9572953736654805,0.9572192513368984,0.9571428571428572,0.9570661896243292,0.956989247311828,0.9569120287253142,0.9568345323741008,0.9567567567567568,0.9566787003610109,0.9566003616636528,0.9565217391304348,0.956442831215971,0.9563636363636364,0.9562841530054644,0.9562043795620438,0.9561243144424132,0.9578754578754579,0.9577981651376147,0.9577205882352942,0.9576427255985267,0.9575645756457565,0.9574861367837338,0.9574074074074074,0.9573283858998145,0.9572490706319703,0.957169459962756,0.957089552238806,0.9570093457943926,0.9569288389513109,0.9568480300187617,0.956766917293233,0.9566854990583804,0.9566037735849057,0.9565217391304348,0.9564393939393939,0.9563567362428842,0.9562737642585551,0.9561904761904761,0.9561068702290076,0.9579349904397706,0.9578544061302682,0.9577735124760077,0.9576923076923077,0.9576107899807321,0.9575289575289575,0.9574468085106383,0.9593023255813954,0.9592233009708738,0.9591439688715954,0.9590643274853801,0.958984375,0.958904109589041,0.9588235294117647,0.9587426326129665,0.9586614173228346,0.9585798816568047,0.958498023715415,0.9584158415841584,0.9583333333333334,0.9582504970178927,0.9581673306772909,0.9580838323353293,0.958,0.9579158316633266,0.9578313253012049,0.9577464788732394,0.9576612903225806,0.9575757575757575,0.9574898785425101,0.9574036511156186,0.959349593495935,0.9592668024439919,0.9591836734693877,0.9591002044989775,0.9590163934426229,0.9589322381930184,0.9588477366255144,0.9587628865979382,0.9586776859504132,0.9585921325051759,0.9585062240663901,0.9584199584199584,0.9583333333333334,0.9582463465553236,0.9581589958158996,0.9580712788259959,0.957983193277311,0.9578947368421052,0.9578059071729957,0.9577167019027484,0.9576271186440678,0.9575371549893843,0.9574468085106383,0.9573560767590619,0.9572649572649573,0.9571734475374732,0.9570815450643777,0.956989247311828,0.9568965517241379,0.9568034557235421,0.9567099567099567,0.9566160520607375,0.9565217391304348,0.9564270152505446,0.9563318777292577,0.9562363238512035,0.956140350877193,0.9560439560439561,0.9559471365638766,0.9558498896247241,0.9557522123893806,0.9556541019955654,0.9555555555555556,0.955456570155902,0.9553571428571429,0.9552572706935123,0.9551569506726457,0.9550561797752809,0.954954954954955,0.9548532731376975,0.9547511312217195,0.9546485260770975,0.9545454545454546,0.9544419134396356,0.954337899543379,0.954233409610984,0.9541284403669725,0.9540229885057471,0.9539170506912442,0.953810623556582,0.9537037037037037,0.9535962877030162,0.9534883720930233,0.9533799533799534,0.9532710280373832,0.9531615925058547,0.9530516431924883,0.9529411764705882,0.9528301886792453,0.9527186761229315,0.95260663507109,0.9524940617577197,0.9523809523809523,0.9522673031026253,0.9521531100478469,0.9520383693045563,0.9519230769230769,0.9518072289156626,0.9516908212560387,0.9539951573849879,0.9538834951456311,0.9537712895377128,0.9536585365853658,0.9535452322738386,0.9534313725490197,0.9533169533169533,0.9556650246305419,0.9555555555555556,0.9554455445544554,0.9553349875930521,0.9552238805970149,0.9576059850374065,0.9575,0.9573934837092731,0.957286432160804,0.9571788413098237,0.9570707070707071,0.959493670886076,0.9593908629441624,0.9592875318066157,0.9591836734693877,0.959079283887468,0.958974358974359,0.9588688946015425,0.9587628865979382,0.9612403100775194,0.961139896373057,0.961038961038961,0.9609375,0.9608355091383812,0.9607329842931938,0.9606299212598425,0.9605263157894737,0.9604221635883905,0.9603174603174603,0.9602122015915119,0.9601063829787234,0.96,0.9598930481283422,0.9597855227882037,0.9596774193548387,0.9595687331536388,0.9594594594594594,0.959349593495935,0.9592391304347826,0.9591280653950953,0.9590163934426229,0.9616438356164384,0.9615384615384616,0.9614325068870524,0.9613259668508287,0.961218836565097,0.9611111111111111,0.9610027855153204,0.9608938547486033,0.9635854341736695,0.9634831460674157,0.9633802816901409,0.963276836158192,0.9631728045325779,0.9630681818181818,0.9629629629629629,0.9628571428571429,0.9627507163323782,0.9626436781609196,0.962536023054755,0.9624277456647399,0.9623188405797102,0.9622093023255814,0.9620991253644315,0.9619883040935673,0.9648093841642229,0.9647058823529412,0.967551622418879,0.9674556213017751,0.9673590504451038,0.9672619047619048,0.9671641791044776,0.9670658682634731,0.9669669669669669,0.9668674698795181,0.9667673716012085,0.9666666666666667,0.9665653495440729,0.9695121951219512,0.9694189602446484,0.9693251533742331,0.9692307692307692,0.9691358024691358,0.9690402476780186,0.968944099378882,0.9688473520249221,0.96875,0.9686520376175548,0.9685534591194969,0.9684542586750788,0.9683544303797469,0.9682539682539683,0.9681528662420382,0.9680511182108626,0.967948717948718,0.9678456591639871,0.967741935483871,0.9676375404530745,0.9675324675324676,0.9674267100977199,0.9673202614379085,0.9672131147540983,0.9671052631578947,0.966996699669967,0.9668874172185431,0.9667774086378738,0.9666666666666667,0.9665551839464883,0.9664429530201343,0.9663299663299664,0.9662162162162162,0.9661016949152542,0.9659863945578231,0.9658703071672355,0.9691780821917808,0.9690721649484536,0.9689655172413794,0.9688581314878892,0.96875,0.9686411149825784,0.9685314685314685,0.968421052631579,0.9683098591549296,0.9681978798586572,0.9680851063829787,0.9679715302491103,0.9678571428571429,0.967741935483871,0.9676258992805755,0.9675090252707581,0.967391304347826,0.9672727272727273,0.9671532846715328,0.967032967032967,0.9669117647058824,0.966789667896679,0.9666666666666667,0.966542750929368,0.9664179104477612,0.9662921348314607,0.9661654135338346,0.9660377358490566,0.9659090909090909,0.9657794676806084,0.9656488549618321,0.9655172413793104,0.9692307692307692,0.9691119691119691,0.9689922480620154,0.9688715953307393,0.96875,0.9686274509803922,0.968503937007874,0.9683794466403162,0.9682539682539683,0.9681274900398407,0.968,0.9678714859437751,0.967741935483871,0.9676113360323887,0.967479674796748,0.9673469387755103,0.9672131147540983,0.9670781893004116,0.9710743801652892,0.970954356846473,0.9708333333333333,0.9707112970711297,0.9705882352941176,0.9704641350210971,0.9703389830508474,0.9702127659574468,0.9700854700854701,0.9699570815450643,0.9698275862068966,0.9696969696969697,0.9695652173913043,0.9694323144104804,0.9692982456140351,0.9691629955947136,0.9690265486725663,0.9688888888888889,0.96875,0.968609865470852,0.9684684684684685,0.9683257918552036,0.9681818181818181,0.9680365296803652,0.9678899082568807,0.967741935483871,0.9675925925925926,0.9674418604651163,0.9672897196261683,0.9671361502347418,0.9669811320754716,0.966824644549763,0.9666666666666667,0.9665071770334929,0.9663461538461539,0.966183574879227,0.9660194174757282,0.9658536585365853,0.9656862745098039,0.9655172413793104,0.9653465346534653,0.9651741293532339,0.965,0.964824120603015,0.9646464646464646,0.9644670050761421,0.9642857142857143,0.9641025641025641,0.9639175257731959,0.9637305699481865,0.9635416666666666,0.9633507853403142,0.9631578947368421,0.9629629629629629,0.9627659574468085,0.9625668449197861,0.9623655913978495,0.9621621621621622,0.9619565217391305,0.9617486338797814,0.9615384615384616,0.9613259668508287,0.9666666666666667,0.9664804469273743,0.9662921348314607,0.9661016949152542,0.9659090909090909,0.9714285714285714,0.9712643678160919,0.9710982658959537,0.9709302325581395,0.9707602339181286,0.9705882352941176,0.9704142011834319,0.9702380952380952,0.9700598802395209,0.9698795180722891,0.9696969696969697,0.9695121951219512,0.9693251533742331,0.9691358024691358,0.968944099378882,0.96875,0.9685534591194969,0.9683544303797469,0.9745222929936306,0.9743589743589743,0.9741935483870968,0.974025974025974,0.9738562091503268,0.9736842105263158,0.9735099337748344,0.9733333333333334,0.9731543624161074,0.972972972972973,0.9727891156462585,0.9726027397260274,0.9724137931034482,0.9722222222222222,0.972027972027972,0.971830985915493,0.9716312056737588,0.9714285714285714,0.9712230215827338,0.9710144927536232,0.9708029197080292,0.9705882352941176,0.9703703703703703,0.9701492537313433,0.9699248120300752,0.9696969696969697,0.9694656488549618,0.9692307692307692,0.9689922480620154,0.96875,0.968503937007874,0.9682539682539683,0.968,0.967741935483871,0.967479674796748,0.9754098360655737,0.9752066115702479,0.975,0.9747899159663865,0.9745762711864406,0.9743589743589743,0.9741379310344828,0.9739130434782609,0.9736842105263158,0.9734513274336283,0.9732142857142857,0.972972972972973,0.9727272727272728,0.9724770642201835,0.9722222222222222,0.9719626168224299,0.9716981132075472,0.9714285714285714,0.9711538461538461,0.970873786407767,0.9705882352941176,0.9702970297029703,0.97,0.9696969696969697,0.9693877551020408,0.9690721649484536,0.96875,0.968421052631579,0.9680851063829787,0.967741935483871,0.967391304347826,0.967032967032967,0.9666666666666667,0.9662921348314607,0.9772727272727273,0.9770114942528736,0.9767441860465116,0.9764705882352941,0.9761904761904762,0.9759036144578314,0.975609756097561,0.9753086419753086,0.975,0.9746835443037974,0.9743589743589743,0.974025974025974,0.9736842105263158,0.9733333333333334,0.972972972972973,0.9726027397260274,0.9722222222222222,0.971830985915493,0.9714285714285714,0.9710144927536232,0.9705882352941176,0.9850746268656716,0.9848484848484849,0.9846153846153847,0.984375,0.9841269841269841,0.9838709677419355,0.9836065573770492,0.9833333333333333,0.9830508474576272,0.9827586206896551,0.9824561403508771,0.9821428571428571,0.9818181818181818,0.9814814814814815,0.9811320754716981,0.9807692307692307,0.9803921568627451,0.98,0.9795918367346939,0.9791666666666666,0.9787234042553191,0.9782608695652174,0.9777777777777777,0.9772727272727273,0.9767441860465116,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],"yaxis":"y"}],"layout":{"height":600,"legend":{"tracegroupgap":0},"shapes":[{"line":{"dash":"dash"},"type":"line","x0":0,"x1":1,"y0":1,"y1":0}],"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"title":{"text":"Precision-Recall Curve (AUC=0.8546)"},"width":800,"xaxis":{"anchor":"y","constrain":"domain","domain":[0,1],"title":{"text":"Recall"}},"yaxis":{"anchor":"x","domain":[0,1],"scaleanchor":"x","scaleratio":1,"title":{"text":"Precision"}}}},"text/html":["<div>                            <div id=\"97eb69af-7e17-4db5-85e5-4f09e0f9cc0a\" class=\"plotly-graph-div\" style=\"height:600px; width:800px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"97eb69af-7e17-4db5-85e5-4f09e0f9cc0a\")) {                    Plotly.newPlot(                        \"97eb69af-7e17-4db5-85e5-4f09e0f9cc0a\",                        [{\"fillpattern\":{\"shape\":\"\"},\"hovertemplate\":\"Recall=%{x}\\u003cbr\\u003ePrecision=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"stackgroup\":\"1\",\"x\":[1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.995159728944821,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9932236205227493,0.9932236205227493,0.9922555663117134,0.9922555663117134,0.9922555663117134,0.9922555663117134,0.9922555663117134,0.9922555663117134,0.9922555663117134,0.9922555663117134,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.989351403678606,0.989351403678606,0.989351403678606,0.9883833494675702,0.9883833494675702,0.9883833494675702,0.9883833494675702,0.9883833494675702,0.9883833494675702,0.9883833494675702,0.9874152952565344,0.9874152952565344,0.9874152952565344,0.9874152952565344,0.9864472410454985,0.9864472410454985,0.9864472410454985,0.9854791868344628,0.9854791868344628,0.9854791868344628,0.9854791868344628,0.9854791868344628,0.9854791868344628,0.9854791868344628,0.9854791868344628,0.9845111326234269,0.9835430784123911,0.9825750242013552,0.9825750242013552,0.9825750242013552,0.9825750242013552,0.9825750242013552,0.9825750242013552,0.9825750242013552,0.9825750242013552,0.9825750242013552,0.9825750242013552,0.9825750242013552,0.9825750242013552,0.9816069699903195,0.9806389157792836,0.9796708615682478,0.9796708615682478,0.9796708615682478,0.9796708615682478,0.9796708615682478,0.9796708615682478,0.9796708615682478,0.9796708615682478,0.9796708615682478,0.9796708615682478,0.9796708615682478,0.978702807357212,0.978702807357212,0.978702807357212,0.9777347531461762,0.9777347531461762,0.9777347531461762,0.9767666989351403,0.9757986447241046,0.9757986447241046,0.9748305905130688,0.9748305905130688,0.9748305905130688,0.9738625363020329,0.972894482090997,0.972894482090997,0.9719264278799613,0.9719264278799613,0.9719264278799613,0.9709583736689255,0.9699903194578896,0.9690222652468539,0.9690222652468539,0.968054211035818,0.9670861568247822,0.9661181026137464,0.9661181026137464,0.9661181026137464,0.9661181026137464,0.9661181026137464,0.9661181026137464,0.9661181026137464,0.9661181026137464,0.9661181026137464,0.9661181026137464,0.9661181026137464,0.9661181026137464,0.9661181026137464,0.9651500484027106,0.9651500484027106,0.9641819941916747,0.9641819941916747,0.9641819941916747,0.9641819941916747,0.9632139399806389,0.9632139399806389,0.9632139399806389,0.9622458857696031,0.9622458857696031,0.9622458857696031,0.9622458857696031,0.9622458857696031,0.9612778315585673,0.9612778315585673,0.9603097773475314,0.9603097773475314,0.9603097773475314,0.9603097773475314,0.9593417231364957,0.9593417231364957,0.9593417231364957,0.9593417231364957,0.9593417231364957,0.9593417231364957,0.9593417231364957,0.9583736689254598,0.957405614714424,0.957405614714424,0.957405614714424,0.957405614714424,0.957405614714424,0.9564375605033882,0.9554695062923524,0.9554695062923524,0.9554695062923524,0.9554695062923524,0.9545014520813165,0.9545014520813165,0.9545014520813165,0.9545014520813165,0.9535333978702807,0.952565343659245,0.9515972894482091,0.9506292352371732,0.9496611810261375,0.9486931268151017,0.9486931268151017,0.9486931268151017,0.9486931268151017,0.9477250726040658,0.9477250726040658,0.9467570183930301,0.9457889641819942,0.9457889641819942,0.9457889641819942,0.9448209099709584,0.9448209099709584,0.9448209099709584,0.9448209099709584,0.9448209099709584,0.9448209099709584,0.9448209099709584,0.9438528557599225,0.9428848015488868,0.9428848015488868,0.9419167473378509,0.9419167473378509,0.9409486931268151,0.9409486931268151,0.9399806389157793,0.9399806389157793,0.9390125847047435,0.9390125847047435,0.9390125847047435,0.9390125847047435,0.9380445304937076,0.9370764762826719,0.9370764762826719,0.9370764762826719,0.9370764762826719,0.9370764762826719,0.9370764762826719,0.9370764762826719,0.936108422071636,0.9351403678606002,0.9341723136495643,0.9341723136495643,0.9332042594385286,0.9322362052274927,0.9322362052274927,0.9312681510164569,0.9303000968054211,0.9293320425943853,0.9293320425943853,0.9293320425943853,0.9283639883833494,0.9283639883833494,0.9283639883833494,0.9273959341723137,0.9273959341723137,0.9264278799612778,0.9264278799612778,0.925459825750242,0.925459825750242,0.9244917715392061,0.9244917715392061,0.9235237173281704,0.9225556631171346,0.9215876089060987,0.920619554695063,0.920619554695063,0.920619554695063,0.9196515004840271,0.9186834462729913,0.9186834462729913,0.9177153920619555,0.9177153920619555,0.9167473378509197,0.9157792836398838,0.914811229428848,0.9138431752178122,0.9138431752178122,0.9138431752178122,0.9138431752178122,0.9128751210067764,0.9119070667957405,0.9109390125847048,0.9099709583736689,0.9090029041626331,0.9080348499515973,0.9070667957405615,0.9060987415295256,0.9051306873184899,0.904162633107454,0.9031945788964182,0.9022265246853823,0.9012584704743466,0.9012584704743466,0.9002904162633107,0.8993223620522749,0.8993223620522749,0.8983543078412392,0.8973862536302033,0.8964181994191674,0.8964181994191674,0.8954501452081317,0.8954501452081317,0.8954501452081317,0.8954501452081317,0.8944820909970959,0.89351403678606,0.89351403678606,0.8925459825750242,0.8915779283639884,0.8906098741529526,0.8906098741529526,0.8906098741529526,0.8906098741529526,0.8906098741529526,0.8896418199419167,0.8896418199419167,0.8896418199419167,0.8896418199419167,0.888673765730881,0.8877057115198451,0.8867376573088093,0.8857696030977735,0.8848015488867377,0.8848015488867377,0.8848015488867377,0.8838334946757018,0.882865440464666,0.8818973862536302,0.8818973862536302,0.8809293320425944,0.8799612778315585,0.8789932236205228,0.8789932236205228,0.8789932236205228,0.8780251694094869,0.8780251694094869,0.8770571151984511,0.8770571151984511,0.8760890609874153,0.8751210067763795,0.8751210067763795,0.8741529525653436,0.8741529525653436,0.8741529525653436,0.8731848983543078,0.872216844143272,0.872216844143272,0.8712487899322362,0.8702807357212003,0.8702807357212003,0.8693126815101646,0.8683446272991288,0.8673765730880929,0.8664085188770572,0.8664085188770572,0.8654404646660213,0.8654404646660213,0.8644724104549855,0.8635043562439496,0.8635043562439496,0.8625363020329139,0.861568247821878,0.8606001936108422,0.8606001936108422,0.8606001936108422,0.8606001936108422,0.8606001936108422,0.8596321393998064,0.8586640851887706,0.8576960309777347,0.8576960309777347,0.856727976766699,0.856727976766699,0.856727976766699,0.8557599225556631,0.8557599225556631,0.8557599225556631,0.8547918683446273,0.8538238141335914,0.8538238141335914,0.8528557599225557,0.8518877057115198,0.8518877057115198,0.850919651500484,0.850919651500484,0.8499515972894482,0.8499515972894482,0.8489835430784124,0.8489835430784124,0.8480154888673765,0.8470474346563408,0.8470474346563408,0.846079380445305,0.846079380445305,0.8451113262342691,0.8441432720232332,0.8431752178121975,0.8431752178121975,0.8422071636011617,0.8412391093901258,0.8402710551790901,0.8402710551790901,0.8402710551790901,0.8402710551790901,0.8393030009680542,0.8383349467570184,0.8373668925459826,0.8363988383349468,0.8363988383349468,0.8363988383349468,0.8363988383349468,0.8354307841239109,0.8344627299128751,0.8334946757018393,0.8334946757018393,0.8334946757018393,0.8325266214908035,0.8325266214908035,0.8315585672797676,0.8315585672797676,0.8315585672797676,0.8305905130687319,0.829622458857696,0.829622458857696,0.829622458857696,0.8286544046466602,0.8276863504356244,0.8267182962245886,0.8257502420135527,0.8257502420135527,0.8247821878025169,0.8247821878025169,0.8247821878025169,0.8247821878025169,0.8247821878025169,0.8238141335914811,0.8238141335914811,0.8238141335914811,0.8228460793804453,0.8218780251694094,0.8209099709583737,0.8209099709583737,0.8199419167473379,0.818973862536302,0.818973862536302,0.8180058083252663,0.8180058083252663,0.8170377541142304,0.8170377541142304,0.8160696999031946,0.8151016456921588,0.814133591481123,0.8131655372700871,0.8121974830590513,0.8112294288480155,0.8112294288480155,0.8102613746369797,0.8092933204259438,0.8092933204259438,0.8083252662149081,0.8083252662149081,0.8073572120038722,0.8073572120038722,0.8073572120038722,0.8063891577928364,0.8054211035818006,0.8054211035818006,0.8044530493707648,0.8044530493707648,0.8034849951597289,0.8025169409486931,0.8015488867376573,0.8015488867376573,0.8015488867376573,0.8015488867376573,0.8005808325266215,0.7996127783155856,0.7996127783155856,0.7986447241045499,0.797676669893514,0.7967086156824782,0.7967086156824782,0.7957405614714425,0.7957405614714425,0.7947725072604066,0.7947725072604066,0.7947725072604066,0.7938044530493708,0.7928363988383349,0.7918683446272992,0.7918683446272992,0.7909002904162633,0.7899322362052275,0.7899322362052275,0.7889641819941917,0.7889641819941917,0.7879961277831559,0.78702807357212,0.7860600193610843,0.7860600193610843,0.7860600193610843,0.7850919651500484,0.7841239109390126,0.7831558567279767,0.7831558567279767,0.782187802516941,0.7812197483059051,0.7812197483059051,0.7802516940948693,0.7792836398838335,0.7783155856727977,0.7773475314617618,0.7763794772507261,0.7754114230396902,0.7744433688286544,0.7734753146176185,0.7725072604065828,0.771539206195547,0.7705711519845111,0.7705711519845111,0.7705711519845111,0.7696030977734754,0.7696030977734754,0.7686350435624395,0.7676669893514037,0.7676669893514037,0.7666989351403679,0.7657308809293321,0.7657308809293321,0.7647628267182962,0.7647628267182962,0.7637947725072604,0.7628267182962246,0.7618586640851888,0.7618586640851888,0.7608906098741529,0.7608906098741529,0.7599225556631172,0.7599225556631172,0.7599225556631172,0.7589545014520813,0.7579864472410455,0.7570183930300097,0.7560503388189739,0.755082284607938,0.7541142303969022,0.7531461761858664,0.7521781219748306,0.7512100677637947,0.750242013552759,0.7492739593417231,0.7483059051306873,0.7473378509196515,0.7463697967086157,0.7454017424975798,0.744433688286544,0.7434656340755083,0.7434656340755083,0.7424975798644724,0.7415295256534365,0.7405614714424008,0.739593417231365,0.7386253630203291,0.7386253630203291,0.7376573088092934,0.7366892545982575,0.7357212003872217,0.7347531461761858,0.7347531461761858,0.7347531461761858,0.7337850919651501,0.7328170377541142,0.7318489835430784,0.7308809293320426,0.7299128751210068,0.7289448209099709,0.7279767666989352,0.7270087124878993,0.7260406582768635,0.7250726040658277,0.7241045498547919,0.723136495643756,0.723136495643756,0.7221684414327202,0.7212003872216844,0.7202323330106486,0.7192642787996127,0.7192642787996127,0.718296224588577,0.7173281703775412,0.7163601161665053,0.7153920619554696,0.7144240077444337,0.7134559535333979,0.712487899322362,0.7115198451113263,0.7115198451113263,0.7115198451113263,0.7115198451113263,0.7105517909002904,0.7095837366892546,0.7086156824782188,0.707647628267183,0.707647628267183,0.7066795740561471,0.7057115198451114,0.7057115198451114,0.7047434656340755,0.7037754114230397,0.7028073572120038,0.7018393030009681,0.7008712487899322,0.6999031945788964,0.6989351403678606,0.6979670861568248,0.6969990319457889,0.6960309777347532,0.6950629235237173,0.6940948693126815,0.6931268151016456,0.6921587608906099,0.691190706679574,0.6902226524685382,0.6892545982575025,0.6882865440464666,0.6873184898354308,0.686350435624395,0.686350435624395,0.686350435624395,0.6853823814133592,0.6844143272023233,0.6844143272023233,0.6844143272023233,0.6834462729912875,0.6834462729912875,0.6824782187802517,0.6815101645692159,0.68054211035818,0.6795740561471443,0.6786060019361084,0.6776379477250726,0.6766698935140368,0.675701839303001,0.6747337850919651,0.6737657308809293,0.6727976766698935,0.6718296224588577,0.6718296224588577,0.6708615682478218,0.6698935140367861,0.6689254598257502,0.6689254598257502,0.6679574056147144,0.6669893514036787,0.6669893514036787,0.6660212971926428,0.665053242981607,0.6640851887705711,0.6631171345595354,0.6621490803484995,0.6611810261374637,0.6602129719264279,0.6592449177153921,0.6582768635043562,0.6573088092933205,0.6573088092933205,0.6563407550822846,0.6553727008712488,0.6544046466602129,0.6544046466602129,0.6534365924491772,0.6534365924491772,0.6524685382381413,0.6515004840271055,0.6505324298160697,0.6505324298160697,0.6495643756050339,0.648596321393998,0.6476282671829623,0.6466602129719264,0.6466602129719264,0.6456921587608906,0.6447241045498547,0.643756050338819,0.6427879961277831,0.6418199419167473,0.6408518877057116,0.6398838334946757,0.6389157792836399,0.6389157792836399,0.6389157792836399,0.6379477250726041,0.6369796708615683,0.6360116166505324,0.6350435624394967,0.6340755082284608,0.633107454017425,0.6321393998063891,0.6311713455953534,0.6302032913843175,0.6292352371732817,0.6282671829622459,0.6282671829622459,0.6272991287512101,0.6263310745401742,0.6253630203291385,0.6243949661181026,0.6243949661181026,0.6234269119070668,0.6224588576960309,0.6224588576960309,0.6214908034849952,0.6205227492739593,0.6195546950629235,0.6185866408518877,0.6176185866408519,0.616650532429816,0.6156824782187803,0.6147144240077445,0.6137463697967086,0.6127783155856728,0.611810261374637,0.6108422071636012,0.6098741529525653,0.6098741529525653,0.6098741529525653,0.6089060987415296,0.6089060987415296,0.6079380445304937,0.6069699903194579,0.6060019361084221,0.6050338818973863,0.6040658276863504,0.6030977734753146,0.6021297192642788,0.601161665053243,0.6001936108422071,0.5992255566311714,0.5982575024201355,0.5982575024201355,0.5982575024201355,0.5982575024201355,0.5972894482090997,0.5963213939980639,0.5953533397870281,0.5953533397870281,0.5943852855759922,0.5934172313649564,0.5924491771539206,0.5914811229428848,0.590513068731849,0.5895450145208132,0.5885769603097774,0.5876089060987415,0.5866408518877058,0.5856727976766699,0.5847047434656341,0.5847047434656341,0.5837366892545982,0.5837366892545982,0.5827686350435625,0.5818005808325266,0.5818005808325266,0.5808325266214908,0.5808325266214908,0.579864472410455,0.5788964181994192,0.5779283639883833,0.5769603097773476,0.5759922555663117,0.5750242013552759,0.57405614714424,0.5730880929332043,0.5721200387221684,0.5711519845111326,0.5701839303000968,0.569215876089061,0.5682478218780251,0.5672797676669894,0.5663117134559535,0.5653436592449177,0.5634075508228461,0.5624394966118103,0.5614714424007744,0.5605033881897387,0.5595353339787028,0.558567279767667,0.5575992255566312,0.5575992255566312,0.5566311713455954,0.5556631171345595,0.5556631171345595,0.5546950629235237,0.5537270087124879,0.5527589545014521,0.5517909002904162,0.5508228460793805,0.5498547918683446,0.5488867376573088,0.547918683446273,0.5469506292352372,0.5459825750242013,0.5450145208131656,0.5440464666021297,0.5430784123910939,0.542110358180058,0.5411423039690223,0.5401742497579864,0.5392061955469506,0.5382381413359149,0.537270087124879,0.5363020329138432,0.5353339787028074,0.5343659244917716,0.5343659244917716,0.5333978702807357,0.5324298160696999,0.5314617618586641,0.5304937076476283,0.5295256534365924,0.5285575992255567,0.5275895450145208,0.526621490803485,0.5256534365924492,0.5246853823814134,0.5237173281703775,0.5227492739593417,0.5217812197483059,0.5208131655372701,0.5198451113262342,0.5188770571151985,0.5179090029041626,0.5169409486931268,0.515972894482091,0.5150048402710552,0.5140367860600193,0.5130687318489835,0.5121006776379478,0.5111326234269119,0.510164569215876,0.5091965150048403,0.5082284607938045,0.5072604065827686,0.5062923523717329,0.5062923523717329,0.505324298160697,0.5043562439496612,0.5033881897386253,0.5024201355275896,0.5014520813165537,0.5004840271055179,0.4995159728944821,0.4985479186834463,0.4975798644724105,0.49661181026137463,0.49564375605033884,0.494675701839303,0.4937076476282672,0.4927395934172314,0.49177153920619554,0.49080348499515974,0.4898354307841239,0.4888673765730881,0.4878993223620523,0.48693126815101645,0.48596321393998065,0.4849951597289448,0.4849951597289448,0.484027105517909,0.4830590513068732,0.48209099709583736,0.48112294288480156,0.4801548886737657,0.4791868344627299,0.4791868344627299,0.4782187802516941,0.47725072604065827,0.4762826718296225,0.4753146176185866,0.4743465634075508,0.47337850919651503,0.4724104549854792,0.4714424007744434,0.47047434656340753,0.46950629235237173,0.46853823814133594,0.4675701839303001,0.4666021297192643,0.46563407550822844,0.46466602129719264,0.46369796708615685,0.462729912875121,0.4617618586640852,0.46079380445304935,0.45982575024201355,0.45885769603097776,0.4578896418199419,0.4569215876089061,0.4569215876089061,0.45595353339787026,0.45498547918683446,0.45401742497579867,0.4530493707647628,0.452081316553727,0.45111326234269117,0.45014520813165537,0.4491771539206196,0.4482090997095837,0.44724104549854793,0.4462729912875121,0.4453049370764763,0.4443368828654405,0.44336882865440463,0.44240077444336884,0.441432720232333,0.4404646660212972,0.4394966118102614,0.43852855759922554,0.43756050338818975,0.4365924491771539,0.4356243949661181,0.4346563407550823,0.43368828654404645,0.43272023233301066,0.4317521781219748,0.430784123910939,0.4298160696999032,0.42884801548886736,0.42787996127783157,0.4269119070667957,0.4259438528557599,0.4249757986447241,0.42400774443368827,0.4230396902226525,0.4220716360116166,0.42110358180058083,0.42013552758954503,0.4191674733785092,0.4181994191674734,0.41723136495643753,0.41626331074540174,0.41529525653436594,0.4143272023233301,0.4133591481122943,0.41239109390125844,0.41142303969022265,0.41045498547918685,0.409486931268151,0.4085188770571152,0.4075508228460794,0.40658276863504356,0.40561471442400776,0.4046466602129719,0.4036786060019361,0.4027105517909003,0.40174249757986447,0.40077444336882867,0.3998063891577928,0.398838334946757,0.3978702807357212,0.3969022265246854,0.3959341723136496,0.39496611810261373,0.39399806389157793,0.39303000968054214,0.3920619554695063,0.3910939012584705,0.39012584704743464,0.38915779283639884,0.38818973862536305,0.3872216844143272,0.3862536302032914,0.38528557599225555,0.38431752178121975,0.38334946757018395,0.3823814133591481,0.3814133591481123,0.3814133591481123,0.38044530493707646,0.37947725072604066,0.37850919651500486,0.377541142303969,0.3765730880929332,0.37560503388189737,0.37560503388189737,0.37463697967086157,0.3736689254598258,0.3727008712487899,0.3717328170377541,0.3717328170377541,0.3707647628267183,0.3697967086156825,0.3688286544046467,0.36786060019361083,0.36689254598257504,0.36689254598257504,0.3659244917715392,0.3649564375605034,0.3639883833494676,0.36302032913843174,0.36205227492739595,0.3610842207163601,0.3601161665053243,0.3601161665053243,0.3591481122942885,0.35818005808325265,0.35721200387221685,0.356243949661181,0.3552758954501452,0.3543078412391094,0.35333978702807356,0.35237173281703776,0.3514036786060019,0.3504356243949661,0.3494675701839303,0.34849951597289447,0.3475314617618587,0.3465634075508228,0.345595353339787,0.34462729912875123,0.3436592449177154,0.3426911907066796,0.34172313649564373,0.34075508228460794,0.33978702807357214,0.33978702807357214,0.3388189738625363,0.3378509196515005,0.33688286544046464,0.33591481122942884,0.33494675701839305,0.3339787028073572,0.3330106485963214,0.3330106485963214,0.33204259438528555,0.33107454017424975,0.33010648596321396,0.3291384317521781,0.3281703775411423,0.32720232333010646,0.32623426911907066,0.32526621490803487,0.324298160696999,0.3233301064859632,0.32236205227492737,0.3213939980638916,0.3204259438528558,0.3194578896418199,0.31848983543078413,0.31848983543078413,0.31752178121974833,0.31752178121974833,0.3165537270087125,0.3155856727976767,0.31461761858664083,0.31364956437560504,0.31268151016456924,0.3117134559535334,0.3107454017424976,0.30977734753146174,0.30880929332042595,0.30784123910939015,0.30784123910939015,0.3068731848983543,0.3059051306873185,0.30493707647628265,0.30396902226524686,0.30300096805421106,0.3020329138431752,0.3010648596321394,0.30009680542110356,0.29912875121006777,0.29816069699903197,0.2971926427879961,0.2962245885769603,0.2952565343659245,0.2942884801548887,0.2933204259438529,0.29235237173281703,0.29138431752178123,0.2904162633107454,0.2894482090997096,0.2884801548886738,0.28751210067763794,0.28654404646660214,0.2855759922555663,0.2846079380445305,0.2836398838334947,0.28267182962245885,0.28170377541142305,0.2807357212003872,0.2797676669893514,0.2787996127783156,0.27783155856727976,0.27686350435624396,0.2758954501452081,0.2749273959341723,0.2739593417231365,0.2739593417231365,0.27299128751210067,0.27202323330106487,0.271055179090029,0.2700871248789932,0.2691190706679574,0.2681510164569216,0.2671829622458858,0.26621490803484993,0.26524685382381413,0.26427879961277834,0.2633107454017425,0.2623426911907067,0.26137463697967084,0.26040658276863504,0.25943852855759925,0.2584704743465634,0.2575024201355276,0.25653436592449175,0.25556631171345595,0.25459825750242016,0.2536302032913843,0.2526621490803485,0.25169409486931266,0.25072604065827686,0.24975798644724104,0.24878993223620524,0.24782187802516942,0.2468538238141336,0.24588576960309777,0.24491771539206195,0.24394966118102615,0.24394966118102615,0.24298160696999033,0.2420135527589545,0.24104549854791868,0.24007744433688286,0.23910939012584706,0.23814133591481124,0.2371732817037754,0.2362052274927396,0.23523717328170377,0.23426911907066797,0.23330106485963215,0.23233301064859632,0.2313649564375605,0.23039690222652467,0.22942884801548888,0.22846079380445306,0.22749273959341723,0.22749273959341723,0.2265246853823814,0.22555663117134558,0.2245885769603098,0.22362052274927396,0.22265246853823814,0.22168441432720232,0.2207163601161665,0.2197483059051307,0.21878025169409487,0.21781219748305905,0.21684414327202323,0.2158760890609874,0.2149080348499516,0.21393998063891578,0.21297192642787996,0.21200387221684414,0.2110358180058083,0.21006776379477252,0.2090997095837367,0.20813165537270087,0.20716360116166505,0.20619554695062922,0.20522749273959343,0.2042594385285576,0.20329138431752178,0.20232333010648595,0.20135527589545016,0.20038722168441434,0.1994191674733785,0.1984511132623427,0.19748305905130686,0.19651500484027107,0.19554695062923524,0.19457889641819942,0.1936108422071636,0.19264278799612777,0.19167473378509198,0.19070667957405615,0.18973862536302033,0.1887705711519845,0.18780251694094868,0.1868344627299129,0.18586640851887706,0.18489835430784124,0.18393030009680542,0.1829622458857696,0.1819941916747338,0.18102613746369797,0.18005808325266215,0.17909002904162633,0.1781219748305905,0.1771539206195547,0.17618586640851888,0.17521781219748306,0.17424975798644723,0.1732817037754114,0.17231364956437561,0.1713455953533398,0.17037754114230397,0.16940948693126814,0.16844143272023232,0.16844143272023232,0.16747337850919652,0.1665053242981607,0.16553727008712488,0.16456921587608905,0.16456921587608905,0.16360116166505323,0.16263310745401743,0.1616650532429816,0.1606969990319458,0.15972894482090996,0.15876089060987417,0.15779283639883834,0.15682478218780252,0.1558567279767667,0.15488867376573087,0.15392061955469508,0.15295256534365925,0.15198451113262343,0.1510164569215876,0.15004840271055178,0.14908034849951599,0.14811229428848016,0.14811229428848016,0.14714424007744434,0.14617618586640851,0.1452081316553727,0.1442400774443369,0.14327202323330107,0.14230396902226525,0.14133591481122942,0.1403678606001936,0.1393998063891578,0.13843175217812198,0.13746369796708616,0.13649564375605033,0.1355275895450145,0.1345595353339787,0.1335914811229429,0.13262342691190707,0.13165537270087124,0.13068731848983542,0.12971926427879962,0.1287512100677638,0.12778315585672798,0.12681510164569215,0.12584704743465633,0.12487899322362052,0.12391093901258471,0.12294288480154889,0.12197483059051308,0.12100677637947725,0.12003872216844143,0.11907066795740562,0.1181026137463698,0.11713455953533398,0.11616650532429816,0.11519845111326234,0.11519845111326234,0.11423039690222653,0.1132623426911907,0.1122942884801549,0.11132623426911907,0.11035818005808325,0.10939012584704744,0.10842207163601161,0.1074540174249758,0.10648596321393998,0.10551790900290416,0.10454985479186835,0.10358180058083252,0.10261374636979671,0.10164569215876089,0.10067763794772508,0.09970958373668926,0.09874152952565343,0.09777347531461762,0.0968054211035818,0.09583736689254599,0.09486931268151017,0.09390125847047434,0.09293320425943853,0.09196515004840271,0.0909970958373669,0.09002904162633107,0.08906098741529525,0.08809293320425944,0.08712487899322362,0.08615682478218781,0.08518877057115198,0.08422071636011616,0.08325266214908035,0.08325266214908035,0.08228460793804453,0.08131655372700872,0.0803484995159729,0.07938044530493708,0.07841239109390126,0.07744433688286544,0.07647628267182963,0.0755082284607938,0.07454017424975799,0.07357212003872217,0.07260406582768635,0.07163601161665054,0.07066795740561471,0.0696999031945789,0.06873184898354308,0.06776379477250725,0.06679574056147145,0.06582768635043562,0.06485963213939981,0.06389157792836399,0.06389157792836399,0.06292352371732816,0.061955469506292354,0.06098741529525654,0.060019361084220714,0.0590513068731849,0.05808325266214908,0.057115198451113264,0.05614714424007745,0.05517909002904162,0.05421103581800581,0.05324298160696999,0.05227492739593417,0.051306873184898356,0.05033881897386254,0.049370764762826716,0.0484027105517909,0.04743465634075508,0.046466602129719266,0.04549854791868345,0.044530493707647625,0.04356243949661181,0.04259438528557599,0.041626331074540175,0.04065827686350436,0.04065827686350436,0.03969022265246854,0.03872216844143272,0.0377541142303969,0.036786060019361085,0.03581800580832527,0.03484995159728945,0.03388189738625363,0.03291384317521781,0.031945788964181994,0.030977734753146177,0.030009680542110357,0.02904162633107454,0.028073572120038724,0.027105517909002903,0.026137463697967087,0.02516940948693127,0.02420135527589545,0.023233301064859633,0.022265246853823813,0.021297192642787996,0.02032913843175218,0.01936108422071636,0.018393030009680542,0.017424975798644726,0.016456921587608905,0.015488867376573089,0.01452081316553727,0.013552758954501452,0.012584704743465635,0.011616650532429816,0.010648596321393998,0.00968054211035818,0.008712487899322363,0.007744433688286544,0.006776379477250726,0.005808325266214908,0.00484027105517909,0.003872216844143272,0.002904162633107454,0.001936108422071636,0.000968054211035818,0.0],\"xaxis\":\"x\",\"y\":[0.7341862117981521,0.7347083926031295,0.7352313167259786,0.7357549857549858,0.7362794012829651,0.7368045649072753,0.7373304782298359,0.7371428571428571,0.7376697641172266,0.7381974248927039,0.7387258410880458,0.7392550143266475,0.7397849462365591,0.7403156384505022,0.7408470926058865,0.7413793103448276,0.7419122933141624,0.7424460431654676,0.7429805615550756,0.7435158501440923,0.7440519105984138,0.7445887445887446,0.7451263537906138,0.7456647398843931,0.7462039045553145,0.7467438494934877,0.7465604634322954,0.7471014492753624,0.747643219724438,0.7481857764876633,0.7487291212781408,0.7492732558139535,0.7498181818181818,0.7503639010189228,0.7509104151493081,0.7514577259475219,0.7520058351568198,0.7525547445255475,0.7523739956172388,0.7529239766081871,0.7534747622531089,0.7540263543191801,0.7545787545787546,0.7551319648093842,0.7549523110785032,0.7555066079295154,0.7560617193240264,0.7566176470588235,0.7571743929359823,0.7577319587628866,0.7582903463522476,0.7581120943952803,0.7579335793357933,0.758493353028065,0.7590539541759054,0.7588757396449705,0.7594374537379719,0.7592592592592593,0.759822090437361,0.7603857566765578,0.7609502598366741,0.7615156017830609,0.7620817843866171,0.7626488095238095,0.763216679076694,0.7630402384500745,0.7636092468307233,0.764179104477612,0.7647498132935027,0.7653213751868461,0.7651458489154824,0.7657185628742516,0.7662921348314606,0.7668665667166417,0.7674418604651163,0.7680180180180181,0.768595041322314,0.7691729323308271,0.7697516930022573,0.7703313253012049,0.7701582516955539,0.770739064856712,0.7713207547169811,0.7711480362537765,0.7717309145880574,0.7723146747352496,0.7728993186979561,0.7734848484848484,0.7740712661106899,0.7746585735963581,0.7744874715261959,0.7750759878419453,0.7756653992395437,0.776255707762557,0.776085300837776,0.7766768292682927,0.7772692601067888,0.7770992366412214,0.7776928953399541,0.7782874617737003,0.7788829380260138,0.77947932618683,0.7800766283524905,0.7806748466257669,0.7812739831158864,0.7811059907834101,0.7809377401998463,0.7807692307692308,0.7813702848344881,0.7819722650231125,0.7825751734772552,0.783179012345679,0.7837837837837838,0.7843894899536321,0.7849961330239753,0.7856037151702786,0.7862122385747483,0.7868217054263565,0.7874321179208689,0.7872670807453416,0.7871017871017871,0.7869362363919129,0.7875486381322957,0.7881619937694704,0.7887763055339049,0.7893915756630265,0.790007806401249,0.790625,0.7912431587177482,0.7918622848200313,0.7924823805794832,0.7931034482758621,0.7929411764705883,0.793563579277865,0.7941869599371564,0.7940251572327044,0.7946498819826908,0.7952755905511811,0.7951142631993696,0.7949526813880127,0.7955801104972375,0.7954186413902053,0.7960474308300395,0.7966772151898734,0.7965162311955661,0.7963549920760697,0.7969865186360032,0.7968253968253968,0.7974583002382843,0.7980922098569158,0.7979315831344471,0.7977707006369427,0.797609561752988,0.7982456140350878,0.7980845969672785,0.797923322683706,0.7977617905675459,0.7984,0.7990392313851081,0.7996794871794872,0.8003207698476343,0.8009630818619583,0.8016064257028113,0.8022508038585209,0.8028962188254224,0.8035426731078905,0.8041901692183723,0.8048387096774193,0.8054882970137207,0.8053311793214862,0.8059822150363783,0.8058252427184466,0.8064777327935223,0.807131280388979,0.8077858880778589,0.8076298701298701,0.8082859463850528,0.8089430894308943,0.8087876322213181,0.8094462540716613,0.8101059494702526,0.8107667210440457,0.8114285714285714,0.8112745098039216,0.8119378577269011,0.8117839607201309,0.8124488124488124,0.8131147540983606,0.8137817883511075,0.8136288998357963,0.8142974527526705,0.8149671052631579,0.8156378600823045,0.8163097199341022,0.8169826875515251,0.8176567656765676,0.8175061932287366,0.8173553719008264,0.8180314309346567,0.8187086092715232,0.8193869096934548,0.8200663349917081,0.8199170124481328,0.8197674418604651,0.8204488778054863,0.8211314475873545,0.8218151540383014,0.8216666666666667,0.8223519599666389,0.8230383973288815,0.8237259816207184,0.8235785953177257,0.8234309623430962,0.8232830820770519,0.8231349538977368,0.822986577181208,0.8228379513014273,0.8235294117647058,0.8242220353238016,0.8249158249158249,0.8247683235046336,0.8254637436762225,0.8253164556962025,0.825168918918919,0.8258664412510567,0.8265651438240271,0.8264182895850973,0.8271186440677966,0.8278201865988125,0.8285229202037352,0.8292268479184367,0.8299319727891157,0.8306382978723404,0.8304940374787053,0.8303495311167945,0.8310580204778157,0.8309137489325363,0.8316239316239317,0.8314798973481609,0.8321917808219178,0.8320479862896315,0.8327615780445969,0.8326180257510729,0.8333333333333334,0.8340498710232158,0.8347676419965576,0.834625322997416,0.8344827586206897,0.8352027610008628,0.8359240069084629,0.8366464995678479,0.8373702422145328,0.8380952380952381,0.8388214904679376,0.8386816999132697,0.8385416666666666,0.838401390095569,0.8391304347826087,0.8389904264577894,0.8388501742160279,0.8395815170008718,0.8394415357766143,0.8393013100436681,0.8391608391608392,0.8398950131233596,0.840630472854641,0.8404907975460123,0.8412280701754385,0.8419666374012291,0.8418277680140598,0.8425681618293756,0.8424295774647887,0.8431718061674008,0.8430335097001763,0.8437775816416593,0.8436395759717314,0.8443854995579133,0.8442477876106195,0.8441098317094774,0.8439716312056738,0.8438331854480923,0.844582593250444,0.8453333333333334,0.8451957295373665,0.8450578806767587,0.8458110516934046,0.8456735057983943,0.8464285714285714,0.8462913315460232,0.8461538461538461,0.8460161145926589,0.8458781362007168,0.8466367713004485,0.8473967684021544,0.8481581311769991,0.8480215827338129,0.8478847884788479,0.8477477477477477,0.8476104598737602,0.8474729241877257,0.8473351400180669,0.8471971066907775,0.8470588235294118,0.8469202898550725,0.8467815049864007,0.8466424682395645,0.846503178928247,0.8463636363636363,0.8471337579617835,0.8469945355191257,0.8468550592525068,0.8476277372262774,0.8474885844748858,0.8473491773308958,0.8472095150960659,0.847985347985348,0.847846012832264,0.8486238532110092,0.8494031221303948,0.8501838235294118,0.8500459981600736,0.8499079189686924,0.8506912442396314,0.8505535055350554,0.850415512465374,0.8502772643253235,0.851063829787234,0.8518518518518519,0.8526413345690455,0.8534322820037106,0.8532961931290622,0.854089219330855,0.8548837209302326,0.8556797020484171,0.8555452003727866,0.855410447761194,0.8552754435107376,0.8551401869158879,0.8550046772684752,0.8558052434456929,0.8566073102155577,0.8564727954971857,0.856338028169014,0.856203007518797,0.8570084666039511,0.8568738229755178,0.8567389255419415,0.8566037735849057,0.8574126534466477,0.8582230623818525,0.8580889309366131,0.8589015151515151,0.8587677725118483,0.8595825426944972,0.8594491927825261,0.8593155893536122,0.8601332064700286,0.86,0.8608198284080076,0.8616412213740458,0.8615090735434575,0.861376673040153,0.8622009569377991,0.8620689655172413,0.8619367209971237,0.8627639155470249,0.8626320845341018,0.8625,0.8623676612127045,0.8622350674373795,0.863066538090646,0.862934362934363,0.863768115942029,0.8636363636363636,0.8635043562439496,0.8643410852713178,0.8642095053346266,0.8640776699029126,0.8639455782312925,0.8647859922178989,0.8656280428432327,0.8664717348927875,0.8673170731707317,0.8671875,0.8670576735092864,0.8669275929549902,0.8677766895200784,0.8676470588235294,0.8684985279685966,0.869351669941061,0.8692232055063913,0.8700787401574803,0.870935960591133,0.8708086785009862,0.8706811451135242,0.8715415019762845,0.8714144411473789,0.8712871287128713,0.8721506442021804,0.8720238095238095,0.8728897715988083,0.8727634194831014,0.8736318407960199,0.8735059760956175,0.8743768693918246,0.874251497005988,0.8741258741258742,0.875,0.8748748748748749,0.875751503006012,0.8756268806419257,0.8755020080321285,0.8753768844221106,0.8762575452716298,0.8761329305135952,0.876008064516129,0.875882946518668,0.8767676767676768,0.8776541961577351,0.8785425101214575,0.878419452887538,0.8782961460446247,0.8781725888324873,0.8780487804878049,0.8789420142421159,0.879837067209776,0.8807339449541285,0.8806122448979592,0.8804902962206334,0.8803680981595092,0.8812691914022518,0.882172131147541,0.882051282051282,0.8829568788501027,0.8828365878725591,0.8837448559670782,0.8846549948506695,0.8845360824742268,0.8844169246646026,0.8853305785123967,0.8862461220268872,0.8861283643892339,0.8860103626943006,0.8858921161825726,0.885773624091381,0.8866943866943867,0.886576482830385,0.8875,0.8884254431699687,0.8893528183716075,0.890282131661442,0.8901673640167364,0.8910994764397906,0.8920335429769392,0.8919202518363064,0.8918067226890757,0.8916929547844374,0.8926315789473684,0.8925184404636459,0.8924050632911392,0.8933474128827877,0.8932346723044398,0.8941798941798942,0.8940677966101694,0.8950159066808059,0.8949044585987261,0.8947927736450585,0.8946808510638298,0.8945686900958466,0.894456289978678,0.8943436499466382,0.8952991452991453,0.895187165775401,0.8950749464668094,0.8960342979635584,0.8959227467811158,0.8968850698174007,0.896774193548387,0.8977395048439182,0.8987068965517241,0.8985976267529665,0.8984881209503239,0.8994594594594595,0.8993506493506493,0.9003250270855905,0.9002169197396963,0.9001085776330076,0.9,0.9009793253536452,0.9019607843137255,0.9029443838604144,0.9028384279475983,0.9027322404371585,0.9037199124726477,0.9036144578313253,0.9035087719298246,0.9034028540065862,0.9043956043956044,0.9042904290429042,0.9052863436123348,0.9051819184123484,0.9061810154525386,0.907182320441989,0.9070796460176991,0.9069767441860465,0.9068736141906873,0.9078801331853497,0.9077777777777778,0.9076751946607341,0.9086859688195991,0.9085841694537347,0.9095982142857143,0.9094972067039107,0.9093959731543624,0.9092945128779395,0.9103139013452914,0.9113355780022446,0.9112359550561798,0.9111361079865017,0.911036036036036,0.9120631341600902,0.9119638826185101,0.911864406779661,0.9128959276018099,0.912797281993205,0.9126984126984127,0.9125993189557321,0.9125,0.9124004550625711,0.9123006833712984,0.9122006841505131,0.9121004566210046,0.912,0.9118993135011442,0.9117983963344788,0.9128440366972477,0.9138920780711826,0.9137931034482759,0.9148446490218642,0.9147465437788018,0.9146482122260668,0.9157043879907621,0.915606936416185,0.9155092592592593,0.9165701042873696,0.9164733178654292,0.9175377468060395,0.9174418604651163,0.9173457508731082,0.9172494172494172,0.9183197199533255,0.9182242990654206,0.9192982456140351,0.9192037470725996,0.9202813599062134,0.9213615023474179,0.9212690951821386,0.9211764705882353,0.9210836277974087,0.9209905660377359,0.9208972845336482,0.9208037825059102,0.9207100591715977,0.9206161137440758,0.9205219454329775,0.9204275534441805,0.920332936979786,0.9202380952380952,0.9201430274135876,0.9200477326968973,0.9199522102747909,0.9198564593301436,0.9197604790419162,0.920863309352518,0.9207683073229291,0.9206730769230769,0.9205776173285198,0.9204819277108434,0.9203860072376358,0.9214975845410628,0.9214026602176542,0.9213075060532687,0.9212121212121213,0.9211165048543689,0.9222357229647631,0.9233576642335767,0.9232643118148599,0.9231707317073171,0.9230769230769231,0.9229828850855746,0.9228886168910648,0.9227941176470589,0.9226993865030675,0.9226044226044227,0.922509225092251,0.9224137931034483,0.9223181257706535,0.9222222222222223,0.92336217552534,0.9232673267326733,0.9231722428748451,0.9230769230769231,0.9229813664596274,0.9241293532338308,0.9240348692403487,0.9239401496259352,0.9238451935081149,0.92375,0.9236545682102628,0.9235588972431078,0.9234629861982434,0.9233668341708543,0.9245283018867925,0.9256926952141058,0.926860025220681,0.9267676767676768,0.9266750948166877,0.9265822784810127,0.926489226869455,0.9276649746192893,0.9275730622617535,0.9274809160305344,0.9286624203821656,0.9285714285714286,0.9284802043422733,0.928388746803069,0.9282970550576184,0.9282051282051282,0.9281129653401797,0.9280205655526992,0.9279279279279279,0.9278350515463918,0.927741935483871,0.9276485788113695,0.9275549805950841,0.927461139896373,0.9273670557717251,0.9272727272727272,0.9271781534460338,0.9270833333333334,0.9269882659713168,0.9268929503916449,0.9267973856209151,0.9280104712041884,0.9292267365661862,0.9291338582677166,0.9290407358738502,0.9302631578947368,0.9314888010540184,0.9313984168865436,0.9326287978863936,0.9325396825396826,0.9324503311258279,0.9323607427055703,0.9322709163346613,0.9321808510638298,0.9320905459387483,0.932,0.931909212283044,0.9318181818181818,0.9317269076305221,0.9316353887399463,0.9315436241610738,0.9327956989247311,0.9327052489905787,0.9326145552560647,0.9325236167341431,0.9337837837837838,0.9336941813261164,0.9336043360433605,0.9348710990502035,0.9347826086956522,0.9346938775510204,0.9346049046321526,0.9345156889495225,0.9344262295081968,0.9343365253077975,0.9342465753424658,0.934156378600823,0.9340659340659341,0.9339752407152683,0.9352617079889807,0.9351724137931035,0.9350828729281768,0.9349930843706777,0.9362880886426593,0.9361997226074896,0.9375,0.9374130737134909,0.9373259052924791,0.9372384937238494,0.9385474860335196,0.9384615384615385,0.938375350140056,0.938288920056101,0.9382022471910112,0.939521800281294,0.9394366197183098,0.9393511988716502,0.9392655367231638,0.9391796322489392,0.9390934844192634,0.9390070921985816,0.9389204545454546,0.9388335704125178,0.9401709401709402,0.9415121255349501,0.9414285714285714,0.9413447782546495,0.9412607449856734,0.9411764705882353,0.9410919540229885,0.9410071942446043,0.9409221902017291,0.9408369408369408,0.9407514450867052,0.9406657018813314,0.9405797101449276,0.941944847605225,0.9418604651162791,0.9417758369723436,0.9416909620991254,0.9416058394160584,0.9429824561403509,0.9428989751098097,0.9428152492668622,0.9441997063142438,0.9441176470588235,0.9440353460972017,0.943952802359882,0.9438700147710487,0.9437869822485208,0.9437037037037037,0.9436201780415431,0.9435364041604755,0.9434523809523809,0.9433681073025335,0.9432835820895522,0.9431988041853513,0.9431137724550899,0.9445277361319341,0.9459459459459459,0.9458646616541353,0.947289156626506,0.947209653092006,0.947129909365559,0.9470499243570348,0.946969696969697,0.9468892261001517,0.9468085106382979,0.9467275494672754,0.9466463414634146,0.9465648854961832,0.9464831804281345,0.9464012251148545,0.9478527607361963,0.9493087557603687,0.9507692307692308,0.9506933744221879,0.9506172839506173,0.9505409582689336,0.9520123839009288,0.951937984496124,0.9518633540372671,0.9517884914463453,0.9517133956386293,0.9516380655226209,0.9515625,0.9514866979655712,0.95141065830721,0.9513343799058085,0.9512578616352201,0.9511811023622048,0.9526813880126183,0.95260663507109,0.9541139240506329,0.9540412044374009,0.953968253968254,0.9554848966613673,0.9554140127388535,0.9569377990430622,0.9568690095846646,0.9568,0.9567307692307693,0.956661316211878,0.9565916398713826,0.9565217391304348,0.9564516129032258,0.9563812600969306,0.9563106796116505,0.9562398703403565,0.9561688311688312,0.9560975609756097,0.9560260586319218,0.9559543230016313,0.9558823529411765,0.955810147299509,0.9556650246305419,0.9555921052631579,0.9555189456342669,0.9554455445544554,0.9553719008264463,0.9552980132450332,0.9552238805970149,0.9568106312292359,0.956738768718802,0.9566666666666667,0.9582637729549248,0.9581939799331104,0.9581239530988275,0.9580536912751678,0.957983193277311,0.9579124579124579,0.9578414839797639,0.9577702702702703,0.9576988155668359,0.9576271186440678,0.9575551782682513,0.9574829931972789,0.9574105621805792,0.9573378839590444,0.9572649572649573,0.9571917808219178,0.9571183533447685,0.9570446735395189,0.9569707401032702,0.9568965517241379,0.9568221070811744,0.9567474048442907,0.9566724436741768,0.9583333333333334,0.9582608695652174,0.9581881533101045,0.9581151832460733,0.958041958041958,0.957968476357268,0.9578947368421052,0.9578207381370826,0.9577464788732394,0.9576719576719577,0.9575971731448764,0.9575221238938053,0.9574468085106383,0.9573712255772646,0.9572953736654805,0.9572192513368984,0.9571428571428572,0.9570661896243292,0.956989247311828,0.9569120287253142,0.9568345323741008,0.9567567567567568,0.9566787003610109,0.9566003616636528,0.9565217391304348,0.956442831215971,0.9563636363636364,0.9562841530054644,0.9562043795620438,0.9561243144424132,0.9578754578754579,0.9577981651376147,0.9577205882352942,0.9576427255985267,0.9575645756457565,0.9574861367837338,0.9574074074074074,0.9573283858998145,0.9572490706319703,0.957169459962756,0.957089552238806,0.9570093457943926,0.9569288389513109,0.9568480300187617,0.956766917293233,0.9566854990583804,0.9566037735849057,0.9565217391304348,0.9564393939393939,0.9563567362428842,0.9562737642585551,0.9561904761904761,0.9561068702290076,0.9579349904397706,0.9578544061302682,0.9577735124760077,0.9576923076923077,0.9576107899807321,0.9575289575289575,0.9574468085106383,0.9593023255813954,0.9592233009708738,0.9591439688715954,0.9590643274853801,0.958984375,0.958904109589041,0.9588235294117647,0.9587426326129665,0.9586614173228346,0.9585798816568047,0.958498023715415,0.9584158415841584,0.9583333333333334,0.9582504970178927,0.9581673306772909,0.9580838323353293,0.958,0.9579158316633266,0.9578313253012049,0.9577464788732394,0.9576612903225806,0.9575757575757575,0.9574898785425101,0.9574036511156186,0.959349593495935,0.9592668024439919,0.9591836734693877,0.9591002044989775,0.9590163934426229,0.9589322381930184,0.9588477366255144,0.9587628865979382,0.9586776859504132,0.9585921325051759,0.9585062240663901,0.9584199584199584,0.9583333333333334,0.9582463465553236,0.9581589958158996,0.9580712788259959,0.957983193277311,0.9578947368421052,0.9578059071729957,0.9577167019027484,0.9576271186440678,0.9575371549893843,0.9574468085106383,0.9573560767590619,0.9572649572649573,0.9571734475374732,0.9570815450643777,0.956989247311828,0.9568965517241379,0.9568034557235421,0.9567099567099567,0.9566160520607375,0.9565217391304348,0.9564270152505446,0.9563318777292577,0.9562363238512035,0.956140350877193,0.9560439560439561,0.9559471365638766,0.9558498896247241,0.9557522123893806,0.9556541019955654,0.9555555555555556,0.955456570155902,0.9553571428571429,0.9552572706935123,0.9551569506726457,0.9550561797752809,0.954954954954955,0.9548532731376975,0.9547511312217195,0.9546485260770975,0.9545454545454546,0.9544419134396356,0.954337899543379,0.954233409610984,0.9541284403669725,0.9540229885057471,0.9539170506912442,0.953810623556582,0.9537037037037037,0.9535962877030162,0.9534883720930233,0.9533799533799534,0.9532710280373832,0.9531615925058547,0.9530516431924883,0.9529411764705882,0.9528301886792453,0.9527186761229315,0.95260663507109,0.9524940617577197,0.9523809523809523,0.9522673031026253,0.9521531100478469,0.9520383693045563,0.9519230769230769,0.9518072289156626,0.9516908212560387,0.9539951573849879,0.9538834951456311,0.9537712895377128,0.9536585365853658,0.9535452322738386,0.9534313725490197,0.9533169533169533,0.9556650246305419,0.9555555555555556,0.9554455445544554,0.9553349875930521,0.9552238805970149,0.9576059850374065,0.9575,0.9573934837092731,0.957286432160804,0.9571788413098237,0.9570707070707071,0.959493670886076,0.9593908629441624,0.9592875318066157,0.9591836734693877,0.959079283887468,0.958974358974359,0.9588688946015425,0.9587628865979382,0.9612403100775194,0.961139896373057,0.961038961038961,0.9609375,0.9608355091383812,0.9607329842931938,0.9606299212598425,0.9605263157894737,0.9604221635883905,0.9603174603174603,0.9602122015915119,0.9601063829787234,0.96,0.9598930481283422,0.9597855227882037,0.9596774193548387,0.9595687331536388,0.9594594594594594,0.959349593495935,0.9592391304347826,0.9591280653950953,0.9590163934426229,0.9616438356164384,0.9615384615384616,0.9614325068870524,0.9613259668508287,0.961218836565097,0.9611111111111111,0.9610027855153204,0.9608938547486033,0.9635854341736695,0.9634831460674157,0.9633802816901409,0.963276836158192,0.9631728045325779,0.9630681818181818,0.9629629629629629,0.9628571428571429,0.9627507163323782,0.9626436781609196,0.962536023054755,0.9624277456647399,0.9623188405797102,0.9622093023255814,0.9620991253644315,0.9619883040935673,0.9648093841642229,0.9647058823529412,0.967551622418879,0.9674556213017751,0.9673590504451038,0.9672619047619048,0.9671641791044776,0.9670658682634731,0.9669669669669669,0.9668674698795181,0.9667673716012085,0.9666666666666667,0.9665653495440729,0.9695121951219512,0.9694189602446484,0.9693251533742331,0.9692307692307692,0.9691358024691358,0.9690402476780186,0.968944099378882,0.9688473520249221,0.96875,0.9686520376175548,0.9685534591194969,0.9684542586750788,0.9683544303797469,0.9682539682539683,0.9681528662420382,0.9680511182108626,0.967948717948718,0.9678456591639871,0.967741935483871,0.9676375404530745,0.9675324675324676,0.9674267100977199,0.9673202614379085,0.9672131147540983,0.9671052631578947,0.966996699669967,0.9668874172185431,0.9667774086378738,0.9666666666666667,0.9665551839464883,0.9664429530201343,0.9663299663299664,0.9662162162162162,0.9661016949152542,0.9659863945578231,0.9658703071672355,0.9691780821917808,0.9690721649484536,0.9689655172413794,0.9688581314878892,0.96875,0.9686411149825784,0.9685314685314685,0.968421052631579,0.9683098591549296,0.9681978798586572,0.9680851063829787,0.9679715302491103,0.9678571428571429,0.967741935483871,0.9676258992805755,0.9675090252707581,0.967391304347826,0.9672727272727273,0.9671532846715328,0.967032967032967,0.9669117647058824,0.966789667896679,0.9666666666666667,0.966542750929368,0.9664179104477612,0.9662921348314607,0.9661654135338346,0.9660377358490566,0.9659090909090909,0.9657794676806084,0.9656488549618321,0.9655172413793104,0.9692307692307692,0.9691119691119691,0.9689922480620154,0.9688715953307393,0.96875,0.9686274509803922,0.968503937007874,0.9683794466403162,0.9682539682539683,0.9681274900398407,0.968,0.9678714859437751,0.967741935483871,0.9676113360323887,0.967479674796748,0.9673469387755103,0.9672131147540983,0.9670781893004116,0.9710743801652892,0.970954356846473,0.9708333333333333,0.9707112970711297,0.9705882352941176,0.9704641350210971,0.9703389830508474,0.9702127659574468,0.9700854700854701,0.9699570815450643,0.9698275862068966,0.9696969696969697,0.9695652173913043,0.9694323144104804,0.9692982456140351,0.9691629955947136,0.9690265486725663,0.9688888888888889,0.96875,0.968609865470852,0.9684684684684685,0.9683257918552036,0.9681818181818181,0.9680365296803652,0.9678899082568807,0.967741935483871,0.9675925925925926,0.9674418604651163,0.9672897196261683,0.9671361502347418,0.9669811320754716,0.966824644549763,0.9666666666666667,0.9665071770334929,0.9663461538461539,0.966183574879227,0.9660194174757282,0.9658536585365853,0.9656862745098039,0.9655172413793104,0.9653465346534653,0.9651741293532339,0.965,0.964824120603015,0.9646464646464646,0.9644670050761421,0.9642857142857143,0.9641025641025641,0.9639175257731959,0.9637305699481865,0.9635416666666666,0.9633507853403142,0.9631578947368421,0.9629629629629629,0.9627659574468085,0.9625668449197861,0.9623655913978495,0.9621621621621622,0.9619565217391305,0.9617486338797814,0.9615384615384616,0.9613259668508287,0.9666666666666667,0.9664804469273743,0.9662921348314607,0.9661016949152542,0.9659090909090909,0.9714285714285714,0.9712643678160919,0.9710982658959537,0.9709302325581395,0.9707602339181286,0.9705882352941176,0.9704142011834319,0.9702380952380952,0.9700598802395209,0.9698795180722891,0.9696969696969697,0.9695121951219512,0.9693251533742331,0.9691358024691358,0.968944099378882,0.96875,0.9685534591194969,0.9683544303797469,0.9745222929936306,0.9743589743589743,0.9741935483870968,0.974025974025974,0.9738562091503268,0.9736842105263158,0.9735099337748344,0.9733333333333334,0.9731543624161074,0.972972972972973,0.9727891156462585,0.9726027397260274,0.9724137931034482,0.9722222222222222,0.972027972027972,0.971830985915493,0.9716312056737588,0.9714285714285714,0.9712230215827338,0.9710144927536232,0.9708029197080292,0.9705882352941176,0.9703703703703703,0.9701492537313433,0.9699248120300752,0.9696969696969697,0.9694656488549618,0.9692307692307692,0.9689922480620154,0.96875,0.968503937007874,0.9682539682539683,0.968,0.967741935483871,0.967479674796748,0.9754098360655737,0.9752066115702479,0.975,0.9747899159663865,0.9745762711864406,0.9743589743589743,0.9741379310344828,0.9739130434782609,0.9736842105263158,0.9734513274336283,0.9732142857142857,0.972972972972973,0.9727272727272728,0.9724770642201835,0.9722222222222222,0.9719626168224299,0.9716981132075472,0.9714285714285714,0.9711538461538461,0.970873786407767,0.9705882352941176,0.9702970297029703,0.97,0.9696969696969697,0.9693877551020408,0.9690721649484536,0.96875,0.968421052631579,0.9680851063829787,0.967741935483871,0.967391304347826,0.967032967032967,0.9666666666666667,0.9662921348314607,0.9772727272727273,0.9770114942528736,0.9767441860465116,0.9764705882352941,0.9761904761904762,0.9759036144578314,0.975609756097561,0.9753086419753086,0.975,0.9746835443037974,0.9743589743589743,0.974025974025974,0.9736842105263158,0.9733333333333334,0.972972972972973,0.9726027397260274,0.9722222222222222,0.971830985915493,0.9714285714285714,0.9710144927536232,0.9705882352941176,0.9850746268656716,0.9848484848484849,0.9846153846153847,0.984375,0.9841269841269841,0.9838709677419355,0.9836065573770492,0.9833333333333333,0.9830508474576272,0.9827586206896551,0.9824561403508771,0.9821428571428571,0.9818181818181818,0.9814814814814815,0.9811320754716981,0.9807692307692307,0.9803921568627451,0.98,0.9795918367346939,0.9791666666666666,0.9787234042553191,0.9782608695652174,0.9777777777777777,0.9772727272727273,0.9767441860465116,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Recall\"},\"constrain\":\"domain\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Precision\"},\"scaleanchor\":\"x\",\"scaleratio\":1},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Precision-Recall Curve (AUC=0.8546)\"},\"height\":600,\"width\":800,\"shapes\":[{\"line\":{\"dash\":\"dash\"},\"type\":\"line\",\"x0\":0,\"x1\":1,\"y0\":1,\"y1\":0}],\"showlegend\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('97eb69af-7e17-4db5-85e5-4f09e0f9cc0a');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"}],"source":["target_score = log_clf.predict_proba(features_valid)[:, 1]\n","\n","fpr, tpr, thresholds = roc_curve(target_valid, target_score)\n","\n","fig = px.area(\n","    x=fpr, y=tpr,\n","    title=f'ROC Curve (AUC={auc(fpr, tpr):.4f})',\n","    labels=dict(x='False Positive Rate', y='True Positive Rate'),\n","    width=800, height=600\n",")\n","fig.add_shape(\n","    type='line', line=dict(dash='dash'),\n","    x0=0, x1=1, y0=0, y1=1\n",")\n","\n","fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n","fig.update_xaxes(constrain='domain')\n","fig.update_layout(showlegend=False)\n","fig.show()\n","\n","precision, recall, thresholds = precision_recall_curve(target_valid, target_score)\n","\n","fig = px.area(\n","    x=recall, y=precision,\n","    title=f'Precision-Recall Curve (AUC={auc(fpr, tpr):.4f})',\n","    labels=dict(x='Recall', y='Precision'),\n","    width=800, height=600\n",")\n","fig.add_shape(\n","    type='line', line=dict(dash='dash'),\n","    x0=0, x1=1, y0=1, y1=0\n",")\n","fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n","fig.update_xaxes(constrain='domain')\n","fig.update_layout(showlegend=False)\n","fig.show()"]},{"cell_type":"markdown","metadata":{},"source":["-------"]},{"cell_type":"markdown","metadata":{},"source":["# Ridge Classification"]},{"cell_type":"code","execution_count":84,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T16:53:45.727614Z","iopub.status.busy":"2023-11-30T16:53:45.727326Z","iopub.status.idle":"2023-11-30T16:53:53.993580Z","shell.execute_reply":"2023-11-30T16:53:53.992668Z","shell.execute_reply.started":"2023-11-30T16:53:45.727589Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Runtime:\n"]}],"source":["ridge_model = RidgeClassifier(random_state=random_state)\n","ridge_parameters = [{\"alpha\": list(range(0,1000)), \n","                     \"fit_intercept\": [True, False], \n","                     \"solver\": ['svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']}]\n","\n","ridge_clf = RandomizedSearchCV(ridge_model, ridge_parameters, scoring='roc_auc', n_jobs=-1, cv=cv)\n","ridge_clf.fit(features_train, target_train)\n","# create a variable for the best model\n","best_ridge = ridge_clf.best_estimator_\n","ridge_pred = best_ridge.predict(features_valid)\n","print('Runtime:')"]},{"cell_type":"code","execution_count":85,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T16:53:53.995997Z","iopub.status.busy":"2023-11-30T16:53:53.995322Z","iopub.status.idle":"2023-11-30T16:53:55.327974Z","shell.execute_reply":"2023-11-30T16:53:55.326745Z","shell.execute_reply.started":"2023-11-30T16:53:53.995962Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Cross Validation Scores: [0.84617808 0.83467742 0.85218894 0.77952189 0.81604263 0.84153226\n"," 0.8        0.80063364 0.85821197 0.83434466 0.8157631  0.80884217\n"," 0.82825461 0.81782834 0.85132488 0.81730991 0.83090438 0.80095046\n"," 0.841684   0.83287101 0.78468941 0.83548387 0.85538594 0.83084677\n"," 0.82272465 0.84720622 0.83977535 0.82825461 0.82033056 0.78730351\n"," 0.82587278 0.8155818  0.81201037 0.83666475 0.84881912 0.85192972\n"," 0.80815092 0.80918779 0.83434466 0.82350902 0.81942893 0.82675691\n"," 0.81466014 0.79795507 0.83372696 0.8249712  0.85567396 0.83231567\n"," 0.83394013 0.831773  ]\n"]}],"source":["ridge_scores = cross_val_score(ridge_model, features_train, target_train, cv=cv, scoring='roc_auc')\n","print('Cross Validation Scores: {}'.format(ridge_scores))"]},{"cell_type":"code","execution_count":86,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T16:53:55.330829Z","iopub.status.busy":"2023-11-30T16:53:55.329727Z","iopub.status.idle":"2023-11-30T16:53:55.339315Z","shell.execute_reply":"2023-11-30T16:53:55.338321Z","shell.execute_reply.started":"2023-11-30T16:53:55.330795Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Best hyperparameters: {'solver': 'sag', 'fit_intercept': True, 'alpha': 26}\n","\n","Best score: 0.8268434390131754\n","\n","Average Cross Validation Score: 0.8259667628691291\n"]}],"source":["# summary\n","print('Best hyperparameters:',  ridge_clf.best_params_)\n","print()\n","print('Best score:',  ridge_clf.best_score_)\n","print()\n","print('Average Cross Validation Score: {}'.format(ridge_scores.mean()))"]},{"cell_type":"markdown","metadata":{},"source":["-------"]},{"cell_type":"markdown","metadata":{},"source":["# LightGBM"]},{"cell_type":"code","execution_count":87,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T16:53:55.342580Z","iopub.status.busy":"2023-11-30T16:53:55.341944Z","iopub.status.idle":"2023-11-30T16:54:28.984603Z","shell.execute_reply":"2023-11-30T16:54:28.983717Z","shell.execute_reply.started":"2023-11-30T16:53:55.342548Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008088 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006528 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007345 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007635 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006744 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005982 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008392 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004136 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n"]},{"name":"stdout","output_type":"stream","text":["[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016365 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000958 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000879 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002636 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002036 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001724 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002214 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009766 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005354 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000613 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002413 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013245 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.036657 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001719 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001676 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003056 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002837 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001827 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009424 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039129 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001920 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001444 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001866 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001714 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003210 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007887 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001896 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002993 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001980 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002753 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004682 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003277 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003232 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001551 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003772 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015064 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015265 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010375 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006736 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002076 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001772 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001867 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002202 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002065 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002826 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001945 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003111 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001927 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002165 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001892 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003184 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001821 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001963 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001760 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001413 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002755 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002106 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000985 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002668 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002493 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002224 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002730 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028357 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006841 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001978 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002265 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002280 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002179 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002012 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002053 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003528 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003447 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002422 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014656 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001148 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001794 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002784 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001970 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001804 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002169 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 570\n","\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002579 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001850 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001839 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001927 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005603 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002457 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001990 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002843 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.127527 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002629 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002860 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002314 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001905 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001971 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001600 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001529 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002968 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004680 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001887 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001926 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002022 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001865 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001482 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001859 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001134 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001433 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002003 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.035399 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004616 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001923 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002843 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001747 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001946 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002676 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001572 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001934 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001729 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004410 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.[LightGBM] [Info] Start training from score 1.016006\n","\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003123 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001816 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001706 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001439 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015531 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002277 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001731 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001795 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002059 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003292 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002575 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001341 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001690 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001975 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001995 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002479 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001919 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001971 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001255 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002688 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002812 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002705 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005567 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002111 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003170 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002097 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001676 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002274 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001900 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002106 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003908 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002161 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001848 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002101 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002015 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002325 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001532 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002952 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002825 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001708 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003142 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001778 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002697 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001976 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002477 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004010 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002445 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002430 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002392 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006270 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002557 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003377 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002357 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006904 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001482 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004663 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001720 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003343 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002104 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003453 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002308 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002721 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002529 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001451 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002914 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001443 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011485 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004735 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002048 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002048 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002294 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002776 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001965 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002034 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025900 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003196 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033504 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002264 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001367 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013808 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002133 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005299 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004446 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002040 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001933 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002071 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002403 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002214 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012552 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002127 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031903 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007969 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001746 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002127 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022100 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001685 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001820 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002296 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001567 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002195 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001830 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001694 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001917 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010062 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002273 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017543 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005073 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002593 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001762 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002958 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001688 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001861 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002467 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001563 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001699 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003031 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002053 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005665 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001807 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002128 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002600 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001750 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002012 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002015 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002115 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002026 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002853 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002771 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001996 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002009 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002688 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002723 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007419 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001739 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002088 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001726 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001985 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001746 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002119 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001606 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002327 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034138 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001930 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036247 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009839 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003928 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002716 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003240 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003824 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002765 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002332 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003078 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001011 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044855 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002413 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002701 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003221 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001867 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003464 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032661 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001887 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001909 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001959 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002143 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001662 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005984 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001749 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042343 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002190 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002165 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002221 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001935 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008702 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002826 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001709 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001967 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001673 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002018 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023167 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001537 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002106 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001158 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001714 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001554 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001156 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001838 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001929 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001424 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001713 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001980 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001561 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001438 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001715 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002117 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003622 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.126606 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001577 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003360 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001457 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001521 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001572 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001838 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001440 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001909 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001648 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001957 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001997 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020439 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001423 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001328 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.114742 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001471 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002579 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002025 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001877 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002561 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002285 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001983 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002138 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001210 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002329 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002450 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003703 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001696 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004755 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001458 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002491 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004918 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003351 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003369 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001678 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002974 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002603 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001182 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002082 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023177 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001948 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001852 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002753 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002158 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002332 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001969 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001620 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001674 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001838 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002175 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002078 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001587 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001843 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002599 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002218 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001658 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004427 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002085 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003280 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001634 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002260 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002187 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002119 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002006 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001750 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005759 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003182 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004054 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003224 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002167 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002069 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005918 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002607 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001962 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001492 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005862 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001955 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001838 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002306 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001119 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001977 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002359 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004620 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002125 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002239 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003258 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019770 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033145 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001481 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001828 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003577 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001895 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001841 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002975 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002033 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001449 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002539 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002314 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001933 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002345 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012755 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001733 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001665 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003811 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001852 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005161 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008183 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004945 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002767 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004096 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002162 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002633 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001860 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001808 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001757 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000643 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003734 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017567 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002161 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002691 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002263 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002000 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001832 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001980 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001754 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001521 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002542 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001875 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002101 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.127352 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002466 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002857 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002704 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002575 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003507 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002743 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001831 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002053 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002180 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014284 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001699 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001970 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002237 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002152 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001835 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002743 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002663 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001818 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013381 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002233 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001445 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001971 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003099 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002092 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004414 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002726 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002075 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002555 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003746 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005728 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002146 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.127255 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003022 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001683 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002092 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002104 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001640 seconds.\n","You can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029908 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] Total Bins 570[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002097 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005916 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002198 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011928 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001671 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002145 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001730 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002319 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002212 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002000 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 3097, number of negative: 1121\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000654 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 4218, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734234 -> initscore=1.016213\n","[LightGBM] [Info] Start training from score 1.016213\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","Runtime:\n","CPU times: user 915 ms, sys: 735 ms, total: 1.65 s\n","Wall time: 1min 6s\n"]}],"source":["%%time\n","\n","lgb_model = lgb.LGBMClassifier(random_state=random_state)\n","\n","lgb_params = {\n","#'objective': ['binary'],\n","'boosting_type': ['gbdt', 'dart', 'rf'],\n","'num_leaves': [1,6,8,12,22,26,28,31,35,40],\n","'learning_rate': [0.001,0.01, 0.05, 0.08, 0.09, 0.1, 0.11, 0.15, 0.2, 0.3, 0.5, 0.7, 0.8, 0.9, 1],\n","'feature_fraction': [0.1, 0.2, 0.5, 0.6, 0.8, 0.9, 1],\n","'max_depth': [1,6,8,12,15,18,22,25,30],\n","'min_data_in_leaf': [20,25,30],\n","'bagging_fraction': [0.1,0.3,0.5,0.7,1],\n","#'num_iterations': [1,6,8,12,20,22,30,35]\n","}\n","\n","lgb_clf = RandomizedSearchCV(lgb_model, lgb_params, scoring='roc_auc', n_jobs=10, cv=cv)\n","lgb_clf.fit(features_train, target_train)\n","# create a variable for the best model\n","best_lgb = lgb_clf.best_estimator_\n","lgb_pred = best_lgb.predict(features_valid)\n","print('Runtime:')"]},{"cell_type":"code","execution_count":88,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 1000x500 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["sns.set(style=\"white\", color_codes=True)\n","plt.rcParams['axes.linewidth'] = 0.1\n","\n","fig, ax = plt.subplots(figsize = (10,5))\n","disp = CalibrationDisplay.from_estimator(lgb_clf, features_valid, target_valid, ax=ax)\n","plt.title('Calibration Chart - LGBM Classifier', fontsize=10)\n","ax.set_xlabel('Mean predicted probability (Positive class: 1)', fontsize=10)\n","ax.set_ylabel('Fraction of positives (Positive class: 1)',fontsize=10)\n","\n","ax.tick_params(color='gray', labelcolor='gray')\n","for spine in ax.spines.values():\n","    spine.set_edgecolor('gray')\n","\n","\n","fig.tight_layout()\n","plt.legend(fontsize=8)\n","plt.show()"]},{"cell_type":"code","execution_count":89,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T16:54:28.989434Z","iopub.status.busy":"2023-11-30T16:54:28.988544Z","iopub.status.idle":"2023-11-30T16:54:34.691369Z","shell.execute_reply":"2023-11-30T16:54:34.690609Z","shell.execute_reply.started":"2023-11-30T16:54:28.989397Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001315 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000545 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000647 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000630 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000620 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000709 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000708 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000614 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000647 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000614 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000885 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000994 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000701 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000764 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000563 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000554 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000537 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000614 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000874 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000524 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000583 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000509 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000708 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000494 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000687 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000549 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000560 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000759 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000550 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000613 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000545 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000531 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000638 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000607 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000722 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000721 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000542 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000755 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000676 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000588 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000620 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000738 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000678 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000581 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000675 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000580 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000644 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000649 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000549 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000524 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","Cross Validation Scores: [0.92287424 0.89749424 0.92220622 0.87747696 0.92615207 0.90812212\n"," 0.89979839 0.89285714 0.92400601 0.90895169 0.87453103 0.88315092\n"," 0.90913018 0.89386521 0.9280818  0.91129032 0.93047235 0.88773041\n"," 0.92782016 0.91452843 0.88936621 0.90967742 0.91998848 0.90691244\n"," 0.896803   0.92540323 0.9203629  0.91627304 0.90531091 0.87956542\n"," 0.90652118 0.88513825 0.91071429 0.92404954 0.92315668 0.93585829\n"," 0.90374424 0.89331797 0.89820273 0.89901179 0.93034911 0.91826037\n"," 0.89017857 0.88680876 0.91751152 0.89363479 0.91687788 0.92707373\n"," 0.90406842 0.91874711]\n"]}],"source":["lgb_scores = cross_val_score(lgb_model, features_train, target_train, cv=cv, scoring='roc_auc')\n","print('Cross Validation Scores: {}'.format(lgb_scores))"]},{"cell_type":"code","execution_count":90,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T16:54:34.697463Z","iopub.status.busy":"2023-11-30T16:54:34.695161Z","iopub.status.idle":"2023-11-30T16:54:34.712956Z","shell.execute_reply":"2023-11-30T16:54:34.712295Z","shell.execute_reply.started":"2023-11-30T16:54:34.697431Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Best hyperparameters: {'num_leaves': 8, 'min_data_in_leaf': 30, 'max_depth': 22, 'learning_rate': 0.3, 'feature_fraction': 0.9, 'boosting_type': 'dart', 'bagging_fraction': 0.7}\n","\n","Best score: 0.8921367493406681\n","\n","Average Cross Validation Score: 0.9078685635877259\n","\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","ROC AUC Score - Validation Dataset: 0.9106982932220673\n"]}],"source":["# summary\n","print('Best hyperparameters:',  lgb_clf.best_params_)\n","print()\n","print('Best score:',  lgb_clf.best_score_)\n","print()\n","print('Average Cross Validation Score: {}'.format(lgb_scores.mean()))\n","print()\n","print('ROC AUC Score - Validation Dataset:',  roc_auc_score(target_valid, lgb_clf.predict_proba(features_valid)[:, 1]))"]},{"cell_type":"markdown","metadata":{},"source":["# ROC AUC Curve - LightGBM"]},{"cell_type":"code","execution_count":91,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T16:54:34.716893Z","iopub.status.busy":"2023-11-30T16:54:34.716406Z","iopub.status.idle":"2023-11-30T16:54:34.854502Z","shell.execute_reply":"2023-11-30T16:54:34.853716Z","shell.execute_reply.started":"2023-11-30T16:54:34.716859Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n"]},{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"fillpattern":{"shape":""},"hovertemplate":"False Positive Rate=%{x}<br>True Positive Rate=%{y}<extra></extra>","legendgroup":"","line":{"color":"#636efa"},"marker":{"symbol":"circle"},"mode":"lines","name":"","orientation":"v","showlegend":false,"stackgroup":"1","type":"scatter","x":[0,0,0.00267379679144385,0.00267379679144385,0.00267379679144385,0.00267379679144385,0.00267379679144385,0.00267379679144385,0.00267379679144385,0.00267379679144385,0.00267379679144385,0.00267379679144385,0.00267379679144385,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.008021390374331552,0.008021390374331552,0.0106951871657754,0.0106951871657754,0.0106951871657754,0.0106951871657754,0.0106951871657754,0.0106951871657754,0.0106951871657754,0.0106951871657754,0.0106951871657754,0.0106951871657754,0.0106951871657754,0.0106951871657754,0.013368983957219251,0.013368983957219251,0.013368983957219251,0.013368983957219251,0.016042780748663103,0.016042780748663103,0.01871657754010695,0.01871657754010695,0.01871657754010695,0.01871657754010695,0.01871657754010695,0.01871657754010695,0.01871657754010695,0.01871657754010695,0.01871657754010695,0.01871657754010695,0.01871657754010695,0.01871657754010695,0.01871657754010695,0.01871657754010695,0.01871657754010695,0.01871657754010695,0.0213903743315508,0.0213903743315508,0.02406417112299465,0.02406417112299465,0.02406417112299465,0.02406417112299465,0.02406417112299465,0.026737967914438502,0.026737967914438502,0.029411764705882353,0.029411764705882353,0.03208556149732621,0.03208556149732621,0.0374331550802139,0.0374331550802139,0.040106951871657755,0.040106951871657755,0.040106951871657755,0.040106951871657755,0.0427807486631016,0.0427807486631016,0.045454545454545456,0.045454545454545456,0.0481283422459893,0.0481283422459893,0.0481283422459893,0.0481283422459893,0.05080213903743316,0.05080213903743316,0.05080213903743316,0.053475935828877004,0.053475935828877004,0.05614973262032086,0.05614973262032086,0.05614973262032086,0.05614973262032086,0.05614973262032086,0.05614973262032086,0.058823529411764705,0.058823529411764705,0.06149732620320856,0.06149732620320856,0.06417112299465241,0.06417112299465241,0.06417112299465241,0.06417112299465241,0.06684491978609626,0.06684491978609626,0.06951871657754011,0.06951871657754011,0.07219251336898395,0.07219251336898395,0.0748663101604278,0.0748663101604278,0.07754010695187166,0.07754010695187166,0.08021390374331551,0.08021390374331551,0.0855614973262032,0.0855614973262032,0.08823529411764706,0.08823529411764706,0.09090909090909091,0.09090909090909091,0.09358288770053476,0.09358288770053476,0.0962566844919786,0.0962566844919786,0.0962566844919786,0.0962566844919786,0.10160427807486631,0.10160427807486631,0.10427807486631016,0.10427807486631016,0.10695187165775401,0.10695187165775401,0.10962566844919786,0.10962566844919786,0.11229946524064172,0.11229946524064172,0.11497326203208556,0.11497326203208556,0.11764705882352941,0.11764705882352941,0.12032085561497326,0.12032085561497326,0.12299465240641712,0.12299465240641712,0.12566844919786097,0.12566844919786097,0.12834224598930483,0.12834224598930483,0.13101604278074866,0.13101604278074866,0.13368983957219252,0.13368983957219252,0.13636363636363635,0.13636363636363635,0.13903743315508021,0.13903743315508021,0.14171122994652408,0.14171122994652408,0.14705882352941177,0.14705882352941177,0.1497326203208556,0.1497326203208556,0.15240641711229946,0.15240641711229946,0.15508021390374332,0.15508021390374332,0.15775401069518716,0.15775401069518716,0.16042780748663102,0.16042780748663102,0.16310160427807488,0.16310160427807488,0.1657754010695187,0.1657754010695187,0.16844919786096257,0.16844919786096257,0.1711229946524064,0.1711229946524064,0.17379679144385027,0.17379679144385027,0.17647058823529413,0.17647058823529413,0.18449197860962566,0.18449197860962566,0.1925133689839572,0.1925133689839572,0.19518716577540107,0.19518716577540107,0.20320855614973263,0.20320855614973263,0.20588235294117646,0.20588235294117646,0.21122994652406418,0.21122994652406418,0.21390374331550802,0.21390374331550802,0.21657754010695188,0.21657754010695188,0.2192513368983957,0.2192513368983957,0.22192513368983957,0.22192513368983957,0.22459893048128343,0.22459893048128343,0.22727272727272727,0.22727272727272727,0.22994652406417113,0.22994652406417113,0.232620320855615,0.232620320855615,0.23529411764705882,0.23529411764705882,0.24331550802139038,0.24331550802139038,0.24866310160427807,0.24866310160427807,0.25133689839572193,0.25133689839572193,0.2540106951871658,0.2540106951871658,0.25935828877005346,0.25935828877005346,0.2647058823529412,0.2647058823529412,0.26737967914438504,0.26737967914438504,0.2700534759358289,0.2700534759358289,0.2727272727272727,0.2727272727272727,0.2727272727272727,0.2727272727272727,0.27540106951871657,0.27540106951871657,0.2807486631016043,0.2807486631016043,0.28342245989304815,0.28342245989304815,0.2914438502673797,0.2914438502673797,0.29411764705882354,0.29411764705882354,0.2967914438502674,0.2967914438502674,0.2994652406417112,0.2994652406417112,0.30213903743315507,0.30213903743315507,0.3048128342245989,0.3048128342245989,0.3074866310160428,0.3074866310160428,0.31283422459893045,0.31283422459893045,0.3155080213903743,0.3155080213903743,0.3181818181818182,0.3181818181818182,0.32085561497326204,0.32085561497326204,0.3235294117647059,0.3235294117647059,0.32887700534759357,0.32887700534759357,0.3315508021390374,0.3315508021390374,0.339572192513369,0.339572192513369,0.3422459893048128,0.3422459893048128,0.35294117647058826,0.35294117647058826,0.3582887700534759,0.3582887700534759,0.3609625668449198,0.3609625668449198,0.36363636363636365,0.36363636363636365,0.3689839572192513,0.3689839572192513,0.3770053475935829,0.3770053475935829,0.38235294117647056,0.38235294117647056,0.3877005347593583,0.3877005347593583,0.3983957219251337,0.3983957219251337,0.4037433155080214,0.4037433155080214,0.40641711229946526,0.40641711229946526,0.4090909090909091,0.4090909090909091,0.4117647058823529,0.4117647058823529,0.4144385026737968,0.4144385026737968,0.41711229946524064,0.41711229946524064,0.43315508021390375,0.43315508021390375,0.4385026737967914,0.4411764705882353,0.4411764705882353,0.45187165775401067,0.45187165775401067,0.45454545454545453,0.45454545454545453,0.46524064171123,0.46524064171123,0.4893048128342246,0.4893048128342246,0.4919786096256685,0.4919786096256685,0.4946524064171123,0.4946524064171123,0.5213903743315508,0.5267379679144385,0.5588235294117647,0.5588235294117647,0.5614973262032086,0.5614973262032086,0.5641711229946524,0.5641711229946524,0.6203208556149733,0.6229946524064172,0.6497326203208557,0.6550802139037433,0.7032085561497327,0.7032085561497327,0.7486631016042781,0.7566844919786097,0.767379679144385,0.7727272727272727,0.8048128342245989,0.8155080213903744,0.9010695187165776,0.9064171122994652,0.9652406417112299,0.9705882352941176,0.9866310160427807,0.9919786096256684,0.9946524064171123,1],"xaxis":"x","y":[0,0.000968054211035818,0.000968054211035818,0.006776379477250726,0.01452081316553727,0.01936108422071636,0.022265246853823813,0.027105517909002903,0.030009680542110357,0.031945788964181994,0.03484995159728945,0.036786060019361085,0.04743465634075508,0.04743465634075508,0.0484027105517909,0.05033881897386254,0.05227492739593417,0.05421103581800581,0.05517909002904162,0.057115198451113264,0.060019361084220714,0.06292352371732816,0.06582768635043562,0.06776379477250725,0.07066795740561471,0.07260406582768635,0.07647628267182963,0.07744433688286544,0.0803484995159729,0.08131655372700872,0.08325266214908035,0.08615682478218781,0.08906098741529525,0.0968054211035818,0.10067763794772508,0.10261374636979671,0.10551790900290416,0.10842207163601161,0.10939012584704744,0.11132623426911907,0.1122942884801549,0.11423039690222653,0.12391093901258471,0.12391093901258471,0.12487899322362052,0.12487899322362052,0.14133591481122942,0.14327202323330107,0.17521781219748306,0.1771539206195547,0.20135527589545016,0.2042594385285576,0.21200387221684414,0.21393998063891578,0.24007744433688286,0.2420135527589545,0.26427879961277834,0.26427879961277834,0.26524685382381413,0.2700871248789932,0.2758954501452081,0.2758954501452081,0.27783155856727976,0.27783155856727976,0.2807357212003872,0.28267182962245885,0.3165537270087125,0.3194578896418199,0.3233301064859632,0.32526621490803487,0.3281703775411423,0.33010648596321396,0.34849951597289447,0.35333978702807356,0.3552758954501452,0.35721200387221685,0.36205227492739595,0.3639883833494676,0.3649564375605034,0.3649564375605034,0.3659244917715392,0.3659244917715392,0.3688286544046467,0.38915779283639884,0.3910939012584705,0.4085188770571152,0.4085188770571152,0.41626331074540174,0.41626331074540174,0.4298160696999032,0.4298160696999032,0.46466602129719264,0.46466602129719264,0.4985479186834463,0.4985479186834463,0.5014520813165537,0.5033881897386253,0.5217812197483059,0.5217812197483059,0.5333978702807357,0.5333978702807357,0.5450145208131656,0.5450145208131656,0.5469506292352372,0.5488867376573088,0.5498547918683446,0.5498547918683446,0.5517909002904162,0.5527589545014521,0.5527589545014521,0.5575992255566312,0.5575992255566312,0.558567279767667,0.5605033881897387,0.5672797676669894,0.569215876089061,0.5847047434656341,0.5847047434656341,0.5866408518877058,0.5866408518877058,0.5943852855759922,0.5943852855759922,0.6060019361084221,0.6079380445304937,0.611810261374637,0.611810261374637,0.6263310745401742,0.6263310745401742,0.6302032913843175,0.6302032913843175,0.6389157792836399,0.6389157792836399,0.6398838334946757,0.6398838334946757,0.648596321393998,0.648596321393998,0.6505324298160697,0.6505324298160697,0.6553727008712488,0.6553727008712488,0.6631171345595354,0.6631171345595354,0.665053242981607,0.6660212971926428,0.6698935140367861,0.6698935140367861,0.6747337850919651,0.6766698935140368,0.6882865440464666,0.6882865440464666,0.6960309777347532,0.6960309777347532,0.6989351403678606,0.6999031945788964,0.7028073572120038,0.7028073572120038,0.7086156824782188,0.7095837366892546,0.7250726040658277,0.7250726040658277,0.7299128751210068,0.7299128751210068,0.7318489835430784,0.7318489835430784,0.7337850919651501,0.7337850919651501,0.7366892545982575,0.7366892545982575,0.7424975798644724,0.7424975798644724,0.7666989351403679,0.7666989351403679,0.7686350435624395,0.7686350435624395,0.7705711519845111,0.7705711519845111,0.7841239109390126,0.7841239109390126,0.7850919651500484,0.7850919651500484,0.78702807357212,0.78702807357212,0.7947725072604066,0.7947725072604066,0.7986447241045499,0.7986447241045499,0.8034849951597289,0.8034849951597289,0.8044530493707648,0.8044530493707648,0.8063891577928364,0.8063891577928364,0.8112294288480155,0.8112294288480155,0.8151016456921588,0.8151016456921588,0.818973862536302,0.818973862536302,0.8199419167473379,0.8199419167473379,0.8218780251694094,0.8218780251694094,0.8257502420135527,0.8257502420135527,0.829622458857696,0.829622458857696,0.8354307841239109,0.8354307841239109,0.8431752178121975,0.8431752178121975,0.8489835430784124,0.8489835430784124,0.8499515972894482,0.8499515972894482,0.850919651500484,0.850919651500484,0.8528557599225557,0.8528557599225557,0.8538238141335914,0.8538238141335914,0.8576960309777347,0.8576960309777347,0.8596321393998064,0.8596321393998064,0.8635043562439496,0.8635043562439496,0.8664085188770572,0.8664085188770572,0.8712487899322362,0.8712487899322362,0.8751210067763795,0.8751210067763795,0.8838334946757018,0.8838334946757018,0.8848015488867377,0.8848015488867377,0.8877057115198451,0.8877057115198451,0.8925459825750242,0.8925459825750242,0.9002904162633107,0.9002904162633107,0.9031945788964182,0.9031945788964182,0.904162633107454,0.904162633107454,0.9060987415295256,0.9060987415295256,0.9080348499515973,0.9080348499515973,0.9128751210067764,0.9128751210067764,0.9138431752178122,0.9157792836398838,0.9196515004840271,0.9196515004840271,0.9215876089060987,0.9215876089060987,0.9225556631171346,0.9225556631171346,0.9244917715392061,0.9244917715392061,0.9264278799612778,0.9264278799612778,0.9293320425943853,0.9293320425943853,0.9332042594385286,0.9332042594385286,0.9380445304937076,0.9380445304937076,0.9390125847047435,0.9390125847047435,0.9399806389157793,0.9399806389157793,0.9419167473378509,0.9419167473378509,0.9428848015488868,0.9428848015488868,0.9448209099709584,0.9448209099709584,0.9457889641819942,0.9457889641819942,0.9467570183930301,0.9467570183930301,0.9486931268151017,0.9486931268151017,0.9496611810261375,0.9496611810261375,0.952565343659245,0.952565343659245,0.957405614714424,0.957405614714424,0.9622458857696031,0.9622458857696031,0.9632139399806389,0.9632139399806389,0.9641819941916747,0.9641819941916747,0.9661181026137464,0.9661181026137464,0.968054211035818,0.968054211035818,0.9709583736689255,0.9709583736689255,0.9719264278799613,0.9719264278799613,0.9748305905130688,0.9748305905130688,0.9767666989351403,0.9767666989351403,0.9777347531461762,0.9777347531461762,0.978702807357212,0.978702807357212,0.9806389157792836,0.9806389157792836,0.9816069699903195,0.9816069699903195,0.9825750242013552,0.9825750242013552,0.9835430784123911,0.9835430784123911,0.9845111326234269,0.9845111326234269,0.9854791868344628,0.9854791868344628,0.9854791868344628,0.9864472410454985,0.9864472410454985,0.989351403678606,0.989351403678606,0.9903194578896418,0.9903194578896418,0.9912875121006777,0.9912875121006777,0.9922555663117134,0.9922555663117134,0.9932236205227493,0.9932236205227493,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.995159728944821,0.995159728944821,0.9961277831558567,0.9961277831558567,0.9980638915779284,0.9980638915779284,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],"yaxis":"y"}],"layout":{"height":600,"legend":{"tracegroupgap":0},"shapes":[{"line":{"dash":"dash"},"type":"line","x0":0,"x1":1,"y0":0,"y1":1}],"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"title":{"text":"ROC Curve (AUC=0.9107)"},"width":800,"xaxis":{"anchor":"y","constrain":"domain","domain":[0,1],"title":{"text":"False Positive Rate"}},"yaxis":{"anchor":"x","domain":[0,1],"scaleanchor":"x","scaleratio":1,"title":{"text":"True Positive Rate"}}}},"text/html":["<div>                            <div id=\"cd0dcd7d-c3dd-4f68-8e77-0445e2180941\" class=\"plotly-graph-div\" style=\"height:600px; width:800px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"cd0dcd7d-c3dd-4f68-8e77-0445e2180941\")) {                    Plotly.newPlot(                        \"cd0dcd7d-c3dd-4f68-8e77-0445e2180941\",                        [{\"fillpattern\":{\"shape\":\"\"},\"hovertemplate\":\"False Positive Rate=%{x}\\u003cbr\\u003eTrue Positive Rate=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"stackgroup\":\"1\",\"x\":[0.0,0.0,0.00267379679144385,0.00267379679144385,0.00267379679144385,0.00267379679144385,0.00267379679144385,0.00267379679144385,0.00267379679144385,0.00267379679144385,0.00267379679144385,0.00267379679144385,0.00267379679144385,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.008021390374331552,0.008021390374331552,0.0106951871657754,0.0106951871657754,0.0106951871657754,0.0106951871657754,0.0106951871657754,0.0106951871657754,0.0106951871657754,0.0106951871657754,0.0106951871657754,0.0106951871657754,0.0106951871657754,0.0106951871657754,0.013368983957219251,0.013368983957219251,0.013368983957219251,0.013368983957219251,0.016042780748663103,0.016042780748663103,0.01871657754010695,0.01871657754010695,0.01871657754010695,0.01871657754010695,0.01871657754010695,0.01871657754010695,0.01871657754010695,0.01871657754010695,0.01871657754010695,0.01871657754010695,0.01871657754010695,0.01871657754010695,0.01871657754010695,0.01871657754010695,0.01871657754010695,0.01871657754010695,0.0213903743315508,0.0213903743315508,0.02406417112299465,0.02406417112299465,0.02406417112299465,0.02406417112299465,0.02406417112299465,0.026737967914438502,0.026737967914438502,0.029411764705882353,0.029411764705882353,0.03208556149732621,0.03208556149732621,0.0374331550802139,0.0374331550802139,0.040106951871657755,0.040106951871657755,0.040106951871657755,0.040106951871657755,0.0427807486631016,0.0427807486631016,0.045454545454545456,0.045454545454545456,0.0481283422459893,0.0481283422459893,0.0481283422459893,0.0481283422459893,0.05080213903743316,0.05080213903743316,0.05080213903743316,0.053475935828877004,0.053475935828877004,0.05614973262032086,0.05614973262032086,0.05614973262032086,0.05614973262032086,0.05614973262032086,0.05614973262032086,0.058823529411764705,0.058823529411764705,0.06149732620320856,0.06149732620320856,0.06417112299465241,0.06417112299465241,0.06417112299465241,0.06417112299465241,0.06684491978609626,0.06684491978609626,0.06951871657754011,0.06951871657754011,0.07219251336898395,0.07219251336898395,0.0748663101604278,0.0748663101604278,0.07754010695187166,0.07754010695187166,0.08021390374331551,0.08021390374331551,0.0855614973262032,0.0855614973262032,0.08823529411764706,0.08823529411764706,0.09090909090909091,0.09090909090909091,0.09358288770053476,0.09358288770053476,0.0962566844919786,0.0962566844919786,0.0962566844919786,0.0962566844919786,0.10160427807486631,0.10160427807486631,0.10427807486631016,0.10427807486631016,0.10695187165775401,0.10695187165775401,0.10962566844919786,0.10962566844919786,0.11229946524064172,0.11229946524064172,0.11497326203208556,0.11497326203208556,0.11764705882352941,0.11764705882352941,0.12032085561497326,0.12032085561497326,0.12299465240641712,0.12299465240641712,0.12566844919786097,0.12566844919786097,0.12834224598930483,0.12834224598930483,0.13101604278074866,0.13101604278074866,0.13368983957219252,0.13368983957219252,0.13636363636363635,0.13636363636363635,0.13903743315508021,0.13903743315508021,0.14171122994652408,0.14171122994652408,0.14705882352941177,0.14705882352941177,0.1497326203208556,0.1497326203208556,0.15240641711229946,0.15240641711229946,0.15508021390374332,0.15508021390374332,0.15775401069518716,0.15775401069518716,0.16042780748663102,0.16042780748663102,0.16310160427807488,0.16310160427807488,0.1657754010695187,0.1657754010695187,0.16844919786096257,0.16844919786096257,0.1711229946524064,0.1711229946524064,0.17379679144385027,0.17379679144385027,0.17647058823529413,0.17647058823529413,0.18449197860962566,0.18449197860962566,0.1925133689839572,0.1925133689839572,0.19518716577540107,0.19518716577540107,0.20320855614973263,0.20320855614973263,0.20588235294117646,0.20588235294117646,0.21122994652406418,0.21122994652406418,0.21390374331550802,0.21390374331550802,0.21657754010695188,0.21657754010695188,0.2192513368983957,0.2192513368983957,0.22192513368983957,0.22192513368983957,0.22459893048128343,0.22459893048128343,0.22727272727272727,0.22727272727272727,0.22994652406417113,0.22994652406417113,0.232620320855615,0.232620320855615,0.23529411764705882,0.23529411764705882,0.24331550802139038,0.24331550802139038,0.24866310160427807,0.24866310160427807,0.25133689839572193,0.25133689839572193,0.2540106951871658,0.2540106951871658,0.25935828877005346,0.25935828877005346,0.2647058823529412,0.2647058823529412,0.26737967914438504,0.26737967914438504,0.2700534759358289,0.2700534759358289,0.2727272727272727,0.2727272727272727,0.2727272727272727,0.2727272727272727,0.27540106951871657,0.27540106951871657,0.2807486631016043,0.2807486631016043,0.28342245989304815,0.28342245989304815,0.2914438502673797,0.2914438502673797,0.29411764705882354,0.29411764705882354,0.2967914438502674,0.2967914438502674,0.2994652406417112,0.2994652406417112,0.30213903743315507,0.30213903743315507,0.3048128342245989,0.3048128342245989,0.3074866310160428,0.3074866310160428,0.31283422459893045,0.31283422459893045,0.3155080213903743,0.3155080213903743,0.3181818181818182,0.3181818181818182,0.32085561497326204,0.32085561497326204,0.3235294117647059,0.3235294117647059,0.32887700534759357,0.32887700534759357,0.3315508021390374,0.3315508021390374,0.339572192513369,0.339572192513369,0.3422459893048128,0.3422459893048128,0.35294117647058826,0.35294117647058826,0.3582887700534759,0.3582887700534759,0.3609625668449198,0.3609625668449198,0.36363636363636365,0.36363636363636365,0.3689839572192513,0.3689839572192513,0.3770053475935829,0.3770053475935829,0.38235294117647056,0.38235294117647056,0.3877005347593583,0.3877005347593583,0.3983957219251337,0.3983957219251337,0.4037433155080214,0.4037433155080214,0.40641711229946526,0.40641711229946526,0.4090909090909091,0.4090909090909091,0.4117647058823529,0.4117647058823529,0.4144385026737968,0.4144385026737968,0.41711229946524064,0.41711229946524064,0.43315508021390375,0.43315508021390375,0.4385026737967914,0.4411764705882353,0.4411764705882353,0.45187165775401067,0.45187165775401067,0.45454545454545453,0.45454545454545453,0.46524064171123,0.46524064171123,0.4893048128342246,0.4893048128342246,0.4919786096256685,0.4919786096256685,0.4946524064171123,0.4946524064171123,0.5213903743315508,0.5267379679144385,0.5588235294117647,0.5588235294117647,0.5614973262032086,0.5614973262032086,0.5641711229946524,0.5641711229946524,0.6203208556149733,0.6229946524064172,0.6497326203208557,0.6550802139037433,0.7032085561497327,0.7032085561497327,0.7486631016042781,0.7566844919786097,0.767379679144385,0.7727272727272727,0.8048128342245989,0.8155080213903744,0.9010695187165776,0.9064171122994652,0.9652406417112299,0.9705882352941176,0.9866310160427807,0.9919786096256684,0.9946524064171123,1.0],\"xaxis\":\"x\",\"y\":[0.0,0.000968054211035818,0.000968054211035818,0.006776379477250726,0.01452081316553727,0.01936108422071636,0.022265246853823813,0.027105517909002903,0.030009680542110357,0.031945788964181994,0.03484995159728945,0.036786060019361085,0.04743465634075508,0.04743465634075508,0.0484027105517909,0.05033881897386254,0.05227492739593417,0.05421103581800581,0.05517909002904162,0.057115198451113264,0.060019361084220714,0.06292352371732816,0.06582768635043562,0.06776379477250725,0.07066795740561471,0.07260406582768635,0.07647628267182963,0.07744433688286544,0.0803484995159729,0.08131655372700872,0.08325266214908035,0.08615682478218781,0.08906098741529525,0.0968054211035818,0.10067763794772508,0.10261374636979671,0.10551790900290416,0.10842207163601161,0.10939012584704744,0.11132623426911907,0.1122942884801549,0.11423039690222653,0.12391093901258471,0.12391093901258471,0.12487899322362052,0.12487899322362052,0.14133591481122942,0.14327202323330107,0.17521781219748306,0.1771539206195547,0.20135527589545016,0.2042594385285576,0.21200387221684414,0.21393998063891578,0.24007744433688286,0.2420135527589545,0.26427879961277834,0.26427879961277834,0.26524685382381413,0.2700871248789932,0.2758954501452081,0.2758954501452081,0.27783155856727976,0.27783155856727976,0.2807357212003872,0.28267182962245885,0.3165537270087125,0.3194578896418199,0.3233301064859632,0.32526621490803487,0.3281703775411423,0.33010648596321396,0.34849951597289447,0.35333978702807356,0.3552758954501452,0.35721200387221685,0.36205227492739595,0.3639883833494676,0.3649564375605034,0.3649564375605034,0.3659244917715392,0.3659244917715392,0.3688286544046467,0.38915779283639884,0.3910939012584705,0.4085188770571152,0.4085188770571152,0.41626331074540174,0.41626331074540174,0.4298160696999032,0.4298160696999032,0.46466602129719264,0.46466602129719264,0.4985479186834463,0.4985479186834463,0.5014520813165537,0.5033881897386253,0.5217812197483059,0.5217812197483059,0.5333978702807357,0.5333978702807357,0.5450145208131656,0.5450145208131656,0.5469506292352372,0.5488867376573088,0.5498547918683446,0.5498547918683446,0.5517909002904162,0.5527589545014521,0.5527589545014521,0.5575992255566312,0.5575992255566312,0.558567279767667,0.5605033881897387,0.5672797676669894,0.569215876089061,0.5847047434656341,0.5847047434656341,0.5866408518877058,0.5866408518877058,0.5943852855759922,0.5943852855759922,0.6060019361084221,0.6079380445304937,0.611810261374637,0.611810261374637,0.6263310745401742,0.6263310745401742,0.6302032913843175,0.6302032913843175,0.6389157792836399,0.6389157792836399,0.6398838334946757,0.6398838334946757,0.648596321393998,0.648596321393998,0.6505324298160697,0.6505324298160697,0.6553727008712488,0.6553727008712488,0.6631171345595354,0.6631171345595354,0.665053242981607,0.6660212971926428,0.6698935140367861,0.6698935140367861,0.6747337850919651,0.6766698935140368,0.6882865440464666,0.6882865440464666,0.6960309777347532,0.6960309777347532,0.6989351403678606,0.6999031945788964,0.7028073572120038,0.7028073572120038,0.7086156824782188,0.7095837366892546,0.7250726040658277,0.7250726040658277,0.7299128751210068,0.7299128751210068,0.7318489835430784,0.7318489835430784,0.7337850919651501,0.7337850919651501,0.7366892545982575,0.7366892545982575,0.7424975798644724,0.7424975798644724,0.7666989351403679,0.7666989351403679,0.7686350435624395,0.7686350435624395,0.7705711519845111,0.7705711519845111,0.7841239109390126,0.7841239109390126,0.7850919651500484,0.7850919651500484,0.78702807357212,0.78702807357212,0.7947725072604066,0.7947725072604066,0.7986447241045499,0.7986447241045499,0.8034849951597289,0.8034849951597289,0.8044530493707648,0.8044530493707648,0.8063891577928364,0.8063891577928364,0.8112294288480155,0.8112294288480155,0.8151016456921588,0.8151016456921588,0.818973862536302,0.818973862536302,0.8199419167473379,0.8199419167473379,0.8218780251694094,0.8218780251694094,0.8257502420135527,0.8257502420135527,0.829622458857696,0.829622458857696,0.8354307841239109,0.8354307841239109,0.8431752178121975,0.8431752178121975,0.8489835430784124,0.8489835430784124,0.8499515972894482,0.8499515972894482,0.850919651500484,0.850919651500484,0.8528557599225557,0.8528557599225557,0.8538238141335914,0.8538238141335914,0.8576960309777347,0.8576960309777347,0.8596321393998064,0.8596321393998064,0.8635043562439496,0.8635043562439496,0.8664085188770572,0.8664085188770572,0.8712487899322362,0.8712487899322362,0.8751210067763795,0.8751210067763795,0.8838334946757018,0.8838334946757018,0.8848015488867377,0.8848015488867377,0.8877057115198451,0.8877057115198451,0.8925459825750242,0.8925459825750242,0.9002904162633107,0.9002904162633107,0.9031945788964182,0.9031945788964182,0.904162633107454,0.904162633107454,0.9060987415295256,0.9060987415295256,0.9080348499515973,0.9080348499515973,0.9128751210067764,0.9128751210067764,0.9138431752178122,0.9157792836398838,0.9196515004840271,0.9196515004840271,0.9215876089060987,0.9215876089060987,0.9225556631171346,0.9225556631171346,0.9244917715392061,0.9244917715392061,0.9264278799612778,0.9264278799612778,0.9293320425943853,0.9293320425943853,0.9332042594385286,0.9332042594385286,0.9380445304937076,0.9380445304937076,0.9390125847047435,0.9390125847047435,0.9399806389157793,0.9399806389157793,0.9419167473378509,0.9419167473378509,0.9428848015488868,0.9428848015488868,0.9448209099709584,0.9448209099709584,0.9457889641819942,0.9457889641819942,0.9467570183930301,0.9467570183930301,0.9486931268151017,0.9486931268151017,0.9496611810261375,0.9496611810261375,0.952565343659245,0.952565343659245,0.957405614714424,0.957405614714424,0.9622458857696031,0.9622458857696031,0.9632139399806389,0.9632139399806389,0.9641819941916747,0.9641819941916747,0.9661181026137464,0.9661181026137464,0.968054211035818,0.968054211035818,0.9709583736689255,0.9709583736689255,0.9719264278799613,0.9719264278799613,0.9748305905130688,0.9748305905130688,0.9767666989351403,0.9767666989351403,0.9777347531461762,0.9777347531461762,0.978702807357212,0.978702807357212,0.9806389157792836,0.9806389157792836,0.9816069699903195,0.9816069699903195,0.9825750242013552,0.9825750242013552,0.9835430784123911,0.9835430784123911,0.9845111326234269,0.9845111326234269,0.9854791868344628,0.9854791868344628,0.9854791868344628,0.9864472410454985,0.9864472410454985,0.989351403678606,0.989351403678606,0.9903194578896418,0.9903194578896418,0.9912875121006777,0.9912875121006777,0.9922555663117134,0.9922555663117134,0.9932236205227493,0.9932236205227493,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.995159728944821,0.995159728944821,0.9961277831558567,0.9961277831558567,0.9980638915779284,0.9980638915779284,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"False Positive Rate\"},\"constrain\":\"domain\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"True Positive Rate\"},\"scaleanchor\":\"x\",\"scaleratio\":1},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"ROC Curve (AUC=0.9107)\"},\"height\":600,\"width\":800,\"shapes\":[{\"line\":{\"dash\":\"dash\"},\"type\":\"line\",\"x0\":0,\"x1\":1,\"y0\":0,\"y1\":1}],\"showlegend\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('cd0dcd7d-c3dd-4f68-8e77-0445e2180941');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"fillpattern":{"shape":""},"hovertemplate":"Recall=%{x}<br>Precision=%{y}<extra></extra>","legendgroup":"","line":{"color":"#636efa"},"marker":{"symbol":"circle"},"mode":"lines","name":"","orientation":"v","showlegend":false,"stackgroup":"1","type":"scatter","x":[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9970958373668926,0.9961277831558567,0.9961277831558567,0.995159728944821,0.995159728944821,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9932236205227493,0.9932236205227493,0.9922555663117134,0.9922555663117134,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.989351403678606,0.989351403678606,0.9883833494675702,0.9874152952565344,0.9864472410454985,0.9864472410454985,0.9864472410454985,0.9864472410454985,0.9864472410454985,0.9854791868344628,0.9854791868344628,0.9854791868344628,0.9845111326234269,0.9845111326234269,0.9845111326234269,0.9845111326234269,0.9845111326234269,0.9845111326234269,0.9845111326234269,0.9835430784123911,0.9835430784123911,0.9825750242013552,0.9825750242013552,0.9816069699903195,0.9816069699903195,0.9806389157792836,0.9806389157792836,0.9796708615682478,0.978702807357212,0.978702807357212,0.9777347531461762,0.9777347531461762,0.9777347531461762,0.9767666989351403,0.9767666989351403,0.9767666989351403,0.9767666989351403,0.9767666989351403,0.9757986447241046,0.9748305905130688,0.9748305905130688,0.9748305905130688,0.9738625363020329,0.972894482090997,0.9719264278799613,0.9719264278799613,0.9719264278799613,0.9709583736689255,0.9709583736689255,0.9709583736689255,0.9709583736689255,0.9699903194578896,0.9690222652468539,0.968054211035818,0.968054211035818,0.968054211035818,0.9670861568247822,0.9661181026137464,0.9661181026137464,0.9651500484027106,0.9641819941916747,0.9641819941916747,0.9632139399806389,0.9632139399806389,0.9632139399806389,0.9622458857696031,0.9622458857696031,0.9622458857696031,0.9622458857696031,0.9622458857696031,0.9612778315585673,0.9603097773475314,0.9593417231364957,0.9583736689254598,0.957405614714424,0.957405614714424,0.9564375605033882,0.9554695062923524,0.9545014520813165,0.9535333978702807,0.952565343659245,0.952565343659245,0.952565343659245,0.952565343659245,0.9515972894482091,0.9506292352371732,0.9496611810261375,0.9496611810261375,0.9486931268151017,0.9486931268151017,0.9486931268151017,0.9477250726040658,0.9467570183930301,0.9467570183930301,0.9457889641819942,0.9457889641819942,0.9448209099709584,0.9448209099709584,0.9438528557599225,0.9428848015488868,0.9428848015488868,0.9419167473378509,0.9419167473378509,0.9419167473378509,0.9409486931268151,0.9399806389157793,0.9399806389157793,0.9390125847047435,0.9390125847047435,0.9380445304937076,0.9380445304937076,0.9370764762826719,0.936108422071636,0.9351403678606002,0.9341723136495643,0.9332042594385286,0.9332042594385286,0.9322362052274927,0.9312681510164569,0.9303000968054211,0.9293320425943853,0.9293320425943853,0.9283639883833494,0.9273959341723137,0.9264278799612778,0.9264278799612778,0.925459825750242,0.9244917715392061,0.9244917715392061,0.9244917715392061,0.9244917715392061,0.9235237173281704,0.9225556631171346,0.9225556631171346,0.9215876089060987,0.9215876089060987,0.9215876089060987,0.920619554695063,0.9196515004840271,0.9196515004840271,0.9186834462729913,0.9177153920619555,0.9167473378509197,0.9157792836398838,0.9138431752178122,0.9128751210067764,0.9128751210067764,0.9119070667957405,0.9109390125847048,0.9099709583736689,0.9090029041626331,0.9080348499515973,0.9080348499515973,0.9070667957405615,0.9060987415295256,0.9060987415295256,0.9051306873184899,0.904162633107454,0.904162633107454,0.904162633107454,0.9031945788964182,0.9031945788964182,0.9031945788964182,0.9022265246853823,0.9012584704743466,0.9002904162633107,0.9002904162633107,0.8993223620522749,0.8983543078412392,0.8973862536302033,0.8964181994191674,0.8954501452081317,0.8944820909970959,0.89351403678606,0.8925459825750242,0.8925459825750242,0.8915779283639884,0.8906098741529526,0.8896418199419167,0.888673765730881,0.8877057115198451,0.8877057115198451,0.8877057115198451,0.8867376573088093,0.8857696030977735,0.8848015488867377,0.8848015488867377,0.8848015488867377,0.8848015488867377,0.8838334946757018,0.8838334946757018,0.882865440464666,0.8818973862536302,0.8809293320425944,0.8799612778315585,0.8789932236205228,0.8780251694094869,0.8770571151984511,0.8760890609874153,0.8751210067763795,0.8751210067763795,0.8741529525653436,0.8731848983543078,0.872216844143272,0.8712487899322362,0.8712487899322362,0.8702807357212003,0.8693126815101646,0.8683446272991288,0.8673765730880929,0.8664085188770572,0.8664085188770572,0.8654404646660213,0.8644724104549855,0.8635043562439496,0.8635043562439496,0.8625363020329139,0.861568247821878,0.8606001936108422,0.8596321393998064,0.8596321393998064,0.8586640851887706,0.8576960309777347,0.8576960309777347,0.856727976766699,0.8557599225556631,0.8547918683446273,0.8538238141335914,0.8538238141335914,0.8528557599225557,0.8528557599225557,0.8518877057115198,0.850919651500484,0.850919651500484,0.850919651500484,0.8499515972894482,0.8499515972894482,0.8489835430784124,0.8489835430784124,0.8489835430784124,0.8489835430784124,0.8480154888673765,0.8470474346563408,0.846079380445305,0.8451113262342691,0.8441432720232332,0.8431752178121975,0.8431752178121975,0.8422071636011617,0.8412391093901258,0.8402710551790901,0.8393030009680542,0.8383349467570184,0.8373668925459826,0.8363988383349468,0.8354307841239109,0.8354307841239109,0.8354307841239109,0.8354307841239109,0.8344627299128751,0.8334946757018393,0.8325266214908035,0.8315585672797676,0.8305905130687319,0.829622458857696,0.829622458857696,0.829622458857696,0.829622458857696,0.8286544046466602,0.8276863504356244,0.8267182962245886,0.8257502420135527,0.8257502420135527,0.8247821878025169,0.8238141335914811,0.8228460793804453,0.8218780251694094,0.8218780251694094,0.8209099709583737,0.8199419167473379,0.8199419167473379,0.818973862536302,0.818973862536302,0.8180058083252663,0.8170377541142304,0.8160696999031946,0.8151016456921588,0.8151016456921588,0.814133591481123,0.8131655372700871,0.8121974830590513,0.8112294288480155,0.8112294288480155,0.8102613746369797,0.8092933204259438,0.8083252662149081,0.8073572120038722,0.8063891577928364,0.8063891577928364,0.8054211035818006,0.8044530493707648,0.8044530493707648,0.8034849951597289,0.8034849951597289,0.8025169409486931,0.8015488867376573,0.8005808325266215,0.7996127783155856,0.7986447241045499,0.7986447241045499,0.797676669893514,0.7967086156824782,0.7957405614714425,0.7947725072604066,0.7947725072604066,0.7938044530493708,0.7928363988383349,0.7918683446272992,0.7909002904162633,0.7899322362052275,0.7889641819941917,0.7879961277831559,0.78702807357212,0.78702807357212,0.78702807357212,0.7860600193610843,0.7850919651500484,0.7850919651500484,0.7841239109390126,0.7841239109390126,0.7831558567279767,0.782187802516941,0.7812197483059051,0.7802516940948693,0.7792836398838335,0.7783155856727977,0.7773475314617618,0.7763794772507261,0.7754114230396902,0.7744433688286544,0.7734753146176185,0.7725072604065828,0.771539206195547,0.7705711519845111,0.7705711519845111,0.7696030977734754,0.7686350435624395,0.7686350435624395,0.7676669893514037,0.7666989351403679,0.7666989351403679,0.7657308809293321,0.7647628267182962,0.7637947725072604,0.7628267182962246,0.7618586640851888,0.7608906098741529,0.7599225556631172,0.7589545014520813,0.7579864472410455,0.7570183930300097,0.7560503388189739,0.755082284607938,0.7541142303969022,0.7531461761858664,0.7521781219748306,0.7512100677637947,0.750242013552759,0.7492739593417231,0.7483059051306873,0.7473378509196515,0.7463697967086157,0.7454017424975798,0.744433688286544,0.7434656340755083,0.7424975798644724,0.7424975798644724,0.7415295256534365,0.7405614714424008,0.739593417231365,0.7386253630203291,0.7376573088092934,0.7366892545982575,0.7366892545982575,0.7357212003872217,0.7347531461761858,0.7337850919651501,0.7337850919651501,0.7328170377541142,0.7318489835430784,0.7318489835430784,0.7308809293320426,0.7299128751210068,0.7299128751210068,0.7289448209099709,0.7279767666989352,0.7270087124878993,0.7260406582768635,0.7250726040658277,0.7250726040658277,0.7241045498547919,0.723136495643756,0.7221684414327202,0.7212003872216844,0.7202323330106486,0.7192642787996127,0.718296224588577,0.7173281703775412,0.7163601161665053,0.7153920619554696,0.7144240077444337,0.7134559535333979,0.712487899322362,0.7115198451113263,0.7105517909002904,0.7095837366892546,0.7086156824782188,0.707647628267183,0.7066795740561471,0.7057115198451114,0.7047434656340755,0.7037754114230397,0.7028073572120038,0.7028073572120038,0.7018393030009681,0.7008712487899322,0.6999031945788964,0.6989351403678606,0.6979670861568248,0.6969990319457889,0.6960309777347532,0.6960309777347532,0.6950629235237173,0.6940948693126815,0.6931268151016456,0.6921587608906099,0.691190706679574,0.6902226524685382,0.6892545982575025,0.6882865440464666,0.6882865440464666,0.6882865440464666,0.6873184898354308,0.686350435624395,0.6853823814133592,0.6844143272023233,0.6834462729912875,0.6824782187802517,0.6815101645692159,0.68054211035818,0.6795740561471443,0.6786060019361084,0.6776379477250726,0.6766698935140368,0.6747337850919651,0.6737657308809293,0.6727976766698935,0.6718296224588577,0.6708615682478218,0.6698935140367861,0.6698935140367861,0.6689254598257502,0.6679574056147144,0.6669893514036787,0.6660212971926428,0.665053242981607,0.6640851887705711,0.6631171345595354,0.6631171345595354,0.6621490803484995,0.6611810261374637,0.6602129719264279,0.6592449177153921,0.6582768635043562,0.6573088092933205,0.6563407550822846,0.6553727008712488,0.6553727008712488,0.6544046466602129,0.6534365924491772,0.6524685382381413,0.6515004840271055,0.6505324298160697,0.6505324298160697,0.6505324298160697,0.6495643756050339,0.648596321393998,0.648596321393998,0.6476282671829623,0.6466602129719264,0.6456921587608906,0.6447241045498547,0.643756050338819,0.6427879961277831,0.6418199419167473,0.6408518877057116,0.6398838334946757,0.6398838334946757,0.6389157792836399,0.6389157792836399,0.6379477250726041,0.6369796708615683,0.6360116166505324,0.6350435624394967,0.6340755082284608,0.633107454017425,0.6321393998063891,0.6311713455953534,0.6302032913843175,0.6302032913843175,0.6292352371732817,0.6282671829622459,0.6272991287512101,0.6263310745401742,0.6263310745401742,0.6253630203291385,0.6243949661181026,0.6234269119070668,0.6224588576960309,0.6214908034849952,0.6205227492739593,0.6195546950629235,0.6185866408518877,0.6176185866408519,0.616650532429816,0.6156824782187803,0.6147144240077445,0.6137463697967086,0.6127783155856728,0.611810261374637,0.611810261374637,0.6108422071636012,0.6098741529525653,0.6089060987415296,0.6079380445304937,0.6060019361084221,0.6050338818973863,0.6040658276863504,0.6030977734753146,0.6021297192642788,0.601161665053243,0.6001936108422071,0.5992255566311714,0.5982575024201355,0.5972894482090997,0.5963213939980639,0.5953533397870281,0.5943852855759922,0.5943852855759922,0.5934172313649564,0.5924491771539206,0.5914811229428848,0.590513068731849,0.5895450145208132,0.5885769603097774,0.5876089060987415,0.5866408518877058,0.5866408518877058,0.5856727976766699,0.5847047434656341,0.5847047434656341,0.5837366892545982,0.5827686350435625,0.5818005808325266,0.5808325266214908,0.579864472410455,0.5788964181994192,0.5779283639883833,0.5769603097773476,0.5759922555663117,0.5750242013552759,0.57405614714424,0.5730880929332043,0.5721200387221684,0.5711519845111326,0.5701839303000968,0.569215876089061,0.5672797676669894,0.5663117134559535,0.5653436592449177,0.5643756050338818,0.5634075508228461,0.5624394966118103,0.5614714424007744,0.5605033881897387,0.558567279767667,0.5575992255566312,0.5575992255566312,0.5566311713455954,0.5556631171345595,0.5546950629235237,0.5537270087124879,0.5527589545014521,0.5527589545014521,0.5517909002904162,0.5498547918683446,0.5498547918683446,0.5488867376573088,0.5469506292352372,0.5459825750242013,0.5450145208131656,0.5450145208131656,0.5440464666021297,0.5430784123910939,0.542110358180058,0.5411423039690223,0.5401742497579864,0.5392061955469506,0.5382381413359149,0.537270087124879,0.5363020329138432,0.5353339787028074,0.5343659244917716,0.5333978702807357,0.5333978702807357,0.5324298160696999,0.5314617618586641,0.5304937076476283,0.5295256534365924,0.5285575992255567,0.5275895450145208,0.526621490803485,0.5256534365924492,0.5246853823814134,0.5237173281703775,0.5227492739593417,0.5217812197483059,0.5217812197483059,0.5208131655372701,0.5198451113262342,0.5188770571151985,0.5179090029041626,0.5169409486931268,0.515972894482091,0.5150048402710552,0.5140367860600193,0.5130687318489835,0.5121006776379478,0.5111326234269119,0.510164569215876,0.5091965150048403,0.5082284607938045,0.5072604065827686,0.5062923523717329,0.505324298160697,0.5043562439496612,0.5033881897386253,0.5014520813165537,0.5004840271055179,0.4995159728944821,0.4985479186834463,0.4985479186834463,0.4975798644724105,0.49661181026137463,0.49564375605033884,0.494675701839303,0.4937076476282672,0.4927395934172314,0.49177153920619554,0.49080348499515974,0.4898354307841239,0.4888673765730881,0.4878993223620523,0.48693126815101645,0.48596321393998065,0.4849951597289448,0.484027105517909,0.4830590513068732,0.48209099709583736,0.48112294288480156,0.4801548886737657,0.4791868344627299,0.4782187802516941,0.47725072604065827,0.4762826718296225,0.4753146176185866,0.4743465634075508,0.47337850919651503,0.4724104549854792,0.4714424007744434,0.47047434656340753,0.46950629235237173,0.46853823814133594,0.4675701839303001,0.4666021297192643,0.46563407550822844,0.46466602129719264,0.46466602129719264,0.46466602129719264,0.46369796708615685,0.462729912875121,0.4617618586640852,0.46079380445304935,0.45982575024201355,0.45885769603097776,0.4578896418199419,0.4569215876089061,0.45595353339787026,0.45498547918683446,0.45401742497579867,0.4530493707647628,0.452081316553727,0.45111326234269117,0.45014520813165537,0.4491771539206196,0.4482090997095837,0.44724104549854793,0.4462729912875121,0.4453049370764763,0.4443368828654405,0.44336882865440463,0.44240077444336884,0.441432720232333,0.4404646660212972,0.4394966118102614,0.43852855759922554,0.43756050338818975,0.4365924491771539,0.4356243949661181,0.4346563407550823,0.43368828654404645,0.43272023233301066,0.4317521781219748,0.430784123910939,0.4298160696999032,0.4298160696999032,0.42884801548886736,0.42787996127783157,0.4269119070667957,0.4259438528557599,0.4249757986447241,0.42400774443368827,0.4230396902226525,0.4220716360116166,0.42110358180058083,0.42013552758954503,0.4191674733785092,0.4181994191674734,0.41723136495643753,0.41626331074540174,0.41626331074540174,0.41529525653436594,0.4143272023233301,0.4133591481122943,0.41239109390125844,0.41142303969022265,0.41045498547918685,0.409486931268151,0.4085188770571152,0.4085188770571152,0.4075508228460794,0.40658276863504356,0.40561471442400776,0.4046466602129719,0.4036786060019361,0.4027105517909003,0.40174249757986447,0.40077444336882867,0.3998063891577928,0.398838334946757,0.3978702807357212,0.3969022265246854,0.3959341723136496,0.39496611810261373,0.39399806389157793,0.39303000968054214,0.3920619554695063,0.3910939012584705,0.38915779283639884,0.38818973862536305,0.3872216844143272,0.3862536302032914,0.38528557599225555,0.38431752178121975,0.38334946757018395,0.3823814133591481,0.3814133591481123,0.38044530493707646,0.37947725072604066,0.37850919651500486,0.377541142303969,0.3765730880929332,0.37560503388189737,0.37463697967086157,0.3736689254598258,0.3727008712487899,0.3717328170377541,0.3707647628267183,0.3697967086156825,0.3688286544046467,0.3659244917715392,0.3659244917715392,0.3649564375605034,0.3649564375605034,0.3639883833494676,0.36205227492739595,0.3610842207163601,0.3601161665053243,0.3591481122942885,0.35818005808325265,0.35721200387221685,0.3552758954501452,0.3543078412391094,0.35333978702807356,0.34849951597289447,0.3475314617618587,0.3465634075508228,0.345595353339787,0.34462729912875123,0.3436592449177154,0.3426911907066796,0.34172313649564373,0.34075508228460794,0.33978702807357214,0.3388189738625363,0.3378509196515005,0.33688286544046464,0.33591481122942884,0.33494675701839305,0.3339787028073572,0.3330106485963214,0.33204259438528555,0.33107454017424975,0.33010648596321396,0.3281703775411423,0.32720232333010646,0.32623426911907066,0.32526621490803487,0.3233301064859632,0.32236205227492737,0.3213939980638916,0.3204259438528558,0.3194578896418199,0.3165537270087125,0.3155856727976767,0.31461761858664083,0.31364956437560504,0.31268151016456924,0.3117134559535334,0.3107454017424976,0.30977734753146174,0.30880929332042595,0.30784123910939015,0.3068731848983543,0.3059051306873185,0.30493707647628265,0.30396902226524686,0.30300096805421106,0.3020329138431752,0.3010648596321394,0.30009680542110356,0.29912875121006777,0.29816069699903197,0.2971926427879961,0.2962245885769603,0.2952565343659245,0.2942884801548887,0.2933204259438529,0.29235237173281703,0.29138431752178123,0.2904162633107454,0.2894482090997096,0.2884801548886738,0.28751210067763794,0.28654404646660214,0.2855759922555663,0.2846079380445305,0.2836398838334947,0.28267182962245885,0.2807357212003872,0.2797676669893514,0.2787996127783156,0.27783155856727976,0.27783155856727976,0.27686350435624396,0.2758954501452081,0.2758954501452081,0.2749273959341723,0.2739593417231365,0.27299128751210067,0.27202323330106487,0.271055179090029,0.2700871248789932,0.26524685382381413,0.26427879961277834,0.26427879961277834,0.2633107454017425,0.2623426911907067,0.26137463697967084,0.26040658276863504,0.25943852855759925,0.2584704743465634,0.2575024201355276,0.25653436592449175,0.25556631171345595,0.25459825750242016,0.2536302032913843,0.2526621490803485,0.25169409486931266,0.25072604065827686,0.24975798644724104,0.24878993223620524,0.24782187802516942,0.2468538238141336,0.24588576960309777,0.24491771539206195,0.24394966118102615,0.24298160696999033,0.2420135527589545,0.24007744433688286,0.23910939012584706,0.23814133591481124,0.2371732817037754,0.2362052274927396,0.23523717328170377,0.23426911907066797,0.23330106485963215,0.23233301064859632,0.2313649564375605,0.23039690222652467,0.22942884801548888,0.22846079380445306,0.22749273959341723,0.2265246853823814,0.22555663117134558,0.2245885769603098,0.22362052274927396,0.22265246853823814,0.22168441432720232,0.2207163601161665,0.2197483059051307,0.21878025169409487,0.21781219748305905,0.21684414327202323,0.2158760890609874,0.2149080348499516,0.21393998063891578,0.21200387221684414,0.2110358180058083,0.21006776379477252,0.2090997095837367,0.20813165537270087,0.20716360116166505,0.20619554695062922,0.20522749273959343,0.2042594385285576,0.20135527589545016,0.20038722168441434,0.1994191674733785,0.1984511132623427,0.19748305905130686,0.19651500484027107,0.19554695062923524,0.19457889641819942,0.1936108422071636,0.19264278799612777,0.19167473378509198,0.19070667957405615,0.18973862536302033,0.1887705711519845,0.18780251694094868,0.1868344627299129,0.18586640851887706,0.18489835430784124,0.18393030009680542,0.1829622458857696,0.1819941916747338,0.18102613746369797,0.18005808325266215,0.17909002904162633,0.1781219748305905,0.1771539206195547,0.17521781219748306,0.17424975798644723,0.1732817037754114,0.17231364956437561,0.1713455953533398,0.17037754114230397,0.16940948693126814,0.16844143272023232,0.16747337850919652,0.1665053242981607,0.16553727008712488,0.16456921587608905,0.16360116166505323,0.16263310745401743,0.1616650532429816,0.1606969990319458,0.15972894482090996,0.15876089060987417,0.15779283639883834,0.15682478218780252,0.1558567279767667,0.15488867376573087,0.15392061955469508,0.15295256534365925,0.15198451113262343,0.1510164569215876,0.15004840271055178,0.14908034849951599,0.14811229428848016,0.14714424007744434,0.14617618586640851,0.1452081316553727,0.1442400774443369,0.14327202323330107,0.14133591481122942,0.1403678606001936,0.1393998063891578,0.13843175217812198,0.13746369796708616,0.13649564375605033,0.1355275895450145,0.1345595353339787,0.1335914811229429,0.13262342691190707,0.13165537270087124,0.13068731848983542,0.12971926427879962,0.1287512100677638,0.12778315585672798,0.12681510164569215,0.12584704743465633,0.12487899322362052,0.12487899322362052,0.12391093901258471,0.12391093901258471,0.12294288480154889,0.12197483059051308,0.12100677637947725,0.12003872216844143,0.11907066795740562,0.1181026137463698,0.11713455953533398,0.11616650532429816,0.11519845111326234,0.11423039690222653,0.1122942884801549,0.11132623426911907,0.10939012584704744,0.10842207163601161,0.10551790900290416,0.10454985479186835,0.10358180058083252,0.10261374636979671,0.10067763794772508,0.0968054211035818,0.09583736689254599,0.09486931268151017,0.09390125847047434,0.09293320425943853,0.09196515004840271,0.0909970958373669,0.09002904162633107,0.08906098741529525,0.08615682478218781,0.08518877057115198,0.08422071636011616,0.08325266214908035,0.08131655372700872,0.0803484995159729,0.07744433688286544,0.07647628267182963,0.07260406582768635,0.07066795740561471,0.0696999031945789,0.06873184898354308,0.06776379477250725,0.06582768635043562,0.06485963213939981,0.06389157792836399,0.06292352371732816,0.060019361084220714,0.0590513068731849,0.05808325266214908,0.057115198451113264,0.05517909002904162,0.05421103581800581,0.05227492739593417,0.051306873184898356,0.05033881897386254,0.0484027105517909,0.04743465634075508,0.04743465634075508,0.046466602129719266,0.04549854791868345,0.044530493707647625,0.04356243949661181,0.04259438528557599,0.041626331074540175,0.04065827686350436,0.03969022265246854,0.03872216844143272,0.0377541142303969,0.036786060019361085,0.03484995159728945,0.03388189738625363,0.03291384317521781,0.031945788964181994,0.030009680542110357,0.027105517909002903,0.026137463697967087,0.02516940948693127,0.02420135527589545,0.023233301064859633,0.022265246853823813,0.01936108422071636,0.018393030009680542,0.017424975798644726,0.016456921587608905,0.015488867376573089,0.01452081316553727,0.006776379477250726,0.005808325266214908,0.00484027105517909,0.003872216844143272,0.002904162633107454,0.001936108422071636,0.000968054211035818,0.000968054211035818,0],"xaxis":"x","y":[0.7341862117981521,0.7352313167259786,0.7357549857549858,0.7368045649072753,0.7373304782298359,0.7378571428571429,0.7383845604002859,0.7389127324749643,0.7394416607015032,0.7399713467048711,0.7410329985652798,0.741564967695621,0.7420977011494253,0.7426312005751258,0.7431654676258993,0.7437005039596832,0.7442363112391931,0.7447728911319395,0.7453102453102453,0.7458483754512636,0.7463872832369942,0.7469269703543022,0.7474674384949349,0.7480086893555394,0.7485507246376811,0.7490935460478607,0.7496371552975326,0.7501815541031227,0.7507267441860465,0.7512727272727273,0.7518195050946143,0.752367079388201,0.7529154518950437,0.754014598540146,0.7545653761869978,0.7551169590643275,0.7556693489392831,0.7562225475841874,0.7567765567765568,0.7573313782991202,0.7578870139398386,0.7584434654919237,0.7590007347538574,0.7595588235294117,0.7601177336276674,0.7606774668630338,0.7612380250552689,0.7617994100294986,0.7623616236162362,0.7629246676514032,0.7634885439763488,0.7640532544378699,0.764618800888231,0.7651851851851852,0.765752409191994,0.766320474777448,0.7668893838158871,0.7674591381872214,0.7680297397769517,0.7686011904761905,0.7691734921816828,0.7697466467958272,0.7703206562266965,0.7708955223880597,0.7714712471994025,0.7720478325859492,0.7743628185907047,0.7749437359339835,0.7755255255255256,0.7761081893313299,0.7766917293233083,0.7772761474793077,0.7778614457831325,0.7784476262245666,0.7790346907993967,0.779622641509434,0.7802114803625377,0.780801209372638,0.7813918305597579,0.7825757575757576,0.7831690674753601,0.783763277693475,0.7843583902809416,0.7849544072948328,0.7867479055597868,0.7873475609756098,0.7879481311975591,0.7885496183206107,0.7891520244461421,0.7897553516819572,0.7903596021423106,0.7909647779479326,0.7915708812260537,0.7921779141104295,0.7927858787413661,0.793394777265745,0.7940046118370484,0.7946153846153846,0.7952270977675134,0.7958397534668721,0.7964533538936006,0.7970679012345679,0.7969111969111969,0.7975270479134466,0.7981438515081206,0.7987616099071208,0.7993803253292022,0.8,0.8006206361520558,0.8012422360248447,0.8018648018648019,0.80248833592535,0.8031128404669261,0.8037383177570093,0.8043647700701481,0.8049921996879875,0.8056206088992974,0.80625,0.8068803752931978,0.8075117370892019,0.8081440877055599,0.8094117647058824,0.8100470957613815,0.8106834249803614,0.8113207547169812,0.8119590873328089,0.8125984251968504,0.8132387706855791,0.8138801261829653,0.8145224940805051,0.8151658767772512,0.8158102766798419,0.8163103721298496,0.8169572107765452,0.8176050753370341,0.8182539682539682,0.8189038919777601,0.8195548489666137,0.8202068416865553,0.820859872611465,0.8215139442231075,0.8221690590111643,0.8228252194732641,0.8234824281150159,0.82414068745004,0.8248,0.8254603682946358,0.8261217948717948,0.8267842822774659,0.8274478330658106,0.8281124497991967,0.8287781350482315,0.829444891391794,0.8301127214170693,0.8299758259468171,0.8298387096774194,0.8305084745762712,0.8303715670436187,0.8310428455941795,0.830906148867314,0.8315789473684211,0.8322528363047001,0.8329278183292782,0.8336038961038961,0.834281072298944,0.8349593495934959,0.8356387306753458,0.8363192182410424,0.837000814995925,0.8376835236541599,0.8383673469387755,0.8390522875816994,0.8404255319148937,0.8411138411138411,0.8418032786885246,0.8424938474159147,0.8431855500821018,0.8438783894823336,0.8445723684210527,0.8452674897119341,0.8459637561779242,0.8466611706512778,0.8473597359735974,0.847233691164327,0.8479338842975207,0.847808105872622,0.8485099337748344,0.848384424192212,0.8490878938640133,0.8497925311203319,0.8504983388704319,0.8512053200332502,0.8519134775374376,0.8526228143213989,0.8533333333333334,0.854045037531276,0.8547579298831386,0.8546365914786967,0.8553511705685619,0.8560669456066946,0.8567839195979899,0.8575020955574183,0.8573825503355704,0.8581024349286314,0.8579831932773109,0.8578637510513036,0.8577441077441077,0.8584667228306655,0.8591905564924115,0.859915611814346,0.8606418918918919,0.8605240912933221,0.8612521150592216,0.8627118644067797,0.8625954198473282,0.8633276740237691,0.8640611724723875,0.8647959183673469,0.865531914893617,0.8662691652470187,0.8670076726342711,0.8668941979522184,0.8676345004269855,0.8675213675213675,0.8682634730538922,0.8681506849315068,0.8688946015424165,0.8687821612349914,0.8695278969957082,0.8694158075601375,0.8693035253654342,0.8700516351118761,0.8699397071490095,0.8706896551724138,0.8714408973252804,0.8713298791018999,0.8720829732065687,0.8728373702422145,0.8735930735930736,0.8743500866551126,0.8742411101474414,0.8741319444444444,0.8748913987836664,0.8756521739130435,0.8755439512619669,0.8754355400696864,0.8753269398430689,0.8760907504363001,0.8768558951965065,0.8767482517482518,0.8775153105861767,0.8782837127845884,0.8790534618755478,0.8789473684210526,0.8788410886742757,0.8787346221441125,0.8795074758135444,0.8802816901408451,0.8801762114537445,0.8800705467372134,0.880847308031774,0.8807420494699647,0.8806366047745358,0.8814159292035398,0.8813108945969885,0.8820921985815603,0.8828748890860693,0.8827708703374778,0.8835555555555555,0.8843416370106761,0.8851291184327693,0.8859180035650623,0.8858162355040142,0.8857142857142857,0.8856121537086684,0.8855098389982111,0.8854073410922113,0.8862007168458781,0.8860986547085202,0.8859964093357271,0.8858939802336029,0.8857913669064749,0.8856885688568857,0.8864864864864865,0.8872858431018936,0.8880866425992779,0.8879855465221319,0.8878842676311031,0.8877828054298642,0.8885869565217391,0.8884859474161378,0.8892921960072595,0.8900999091734787,0.89,0.8898999090081893,0.8907103825136612,0.8906107566089334,0.8914233576642335,0.891324200913242,0.8921389396709324,0.8920402561756633,0.891941391941392,0.8927589367552704,0.8926605504587156,0.8934802571166207,0.8943014705882353,0.8942042318307267,0.8941068139963168,0.8949308755760369,0.8948339483394834,0.8956602031394275,0.8955637707948244,0.8963922294172063,0.8962962962962963,0.8962001853568119,0.8961038961038961,0.8960074280408542,0.895910780669145,0.8967441860465116,0.8966480446927374,0.896551724137931,0.8964552238805971,0.896358543417367,0.897196261682243,0.8971000935453695,0.897003745318352,0.8969072164948454,0.8977485928705441,0.8976525821596244,0.8975563909774437,0.8984007525870179,0.89924670433145,0.9000942507068803,0.9,0.8999055712936733,0.9007561436672968,0.9006622516556292,0.9015151515151515,0.9023696682464455,0.9022770398481973,0.9021842355175689,0.903041825095057,0.9029495718363464,0.9028571428571428,0.9027645376549094,0.9026717557251909,0.9024856596558317,0.9023923444976076,0.9032567049808429,0.9031639501438159,0.9030710172744721,0.9029779058597502,0.9028846153846154,0.9027911453320501,0.9036608863198459,0.9035679845708775,0.9034749034749034,0.9043478260869565,0.9042553191489362,0.904162633107454,0.9050387596899225,0.9059165858389913,0.9058252427184466,0.9067055393586005,0.9075875486381323,0.9074975657254138,0.9074074074074074,0.9073170731707317,0.908203125,0.9081133919843597,0.9080234833659491,0.9079333986287953,0.907843137254902,0.9077526987242395,0.9076620825147348,0.9075712881022615,0.90748031496063,0.9083743842364532,0.908284023668639,0.9081934846989141,0.908102766798419,0.9080118694362018,0.907920792079208,0.908820614469772,0.9097222222222222,0.9096325719960278,0.9095427435387674,0.909452736318408,0.9103585657370518,0.9112662013958126,0.9121756487025948,0.9120879120879121,0.913,0.9129129129129129,0.9128256513026052,0.9127382146439318,0.9126506024096386,0.9125628140703518,0.9124748490945674,0.9123867069486404,0.9122983870967742,0.9122098890010091,0.9131313131313131,0.9130434782608695,0.9129554655870445,0.9128672745694022,0.9127789046653144,0.9137055837563451,0.9136178861788617,0.91353001017294,0.9134419551934827,0.9133537206931702,0.9132653061224489,0.9141981613891726,0.9141104294478528,0.9140225179119754,0.9139344262295082,0.9148717948717948,0.9147843942505134,0.9146968139773896,0.9146090534979424,0.9145211122554068,0.9154639175257732,0.9153766769865841,0.9152892561983471,0.9162357807652534,0.9161490683229814,0.9160621761658031,0.9159751037344398,0.9158878504672897,0.9168399168399168,0.9167533818938606,0.9177083333333333,0.9176225234619395,0.9175365344467641,0.9184952978056427,0.9194560669456067,0.9193717277486911,0.9203354297693921,0.9202518363064008,0.9212184873949579,0.9221871713985279,0.9231578947368421,0.9230769230769231,0.9229957805907173,0.9229144667370645,0.9228329809725159,0.9227513227513228,0.9226694915254238,0.9236479321314952,0.9235668789808917,0.9234856535600425,0.9234042553191489,0.9233226837060703,0.9232409381663113,0.9231590181430096,0.9230769230769231,0.9229946524064171,0.923982869379015,0.92497320471597,0.9259656652360515,0.9258861439312567,0.9258064516129032,0.9257265877287406,0.9256465517241379,0.9255663430420712,0.9254859611231101,0.9264864864864865,0.9274891774891775,0.9284940411700975,0.928416485900217,0.9283387622149837,0.9282608695652174,0.9281828073993471,0.9291938997821351,0.9291166848418757,0.9290393013100436,0.9289617486338798,0.9288840262582057,0.9299014238773274,0.9298245614035088,0.9297475301866082,0.9307692307692308,0.9306930693069307,0.9317180616740088,0.9316427783902976,0.9315673289183223,0.9314917127071823,0.9314159292035398,0.9324473975636767,0.9323725055432373,0.9322974472807991,0.9322222222222222,0.932146829810901,0.933184855233853,0.9331103678929766,0.9330357142857143,0.9329608938547486,0.9328859060402684,0.9328107502799552,0.9338565022421524,0.9337822671156004,0.9337078651685393,0.9347581552305961,0.9346846846846847,0.9357384441939121,0.9356659142212189,0.9355932203389831,0.9355203619909502,0.9354473386183465,0.935374149659864,0.9364358683314415,0.9363636363636364,0.9362912400455062,0.9362186788154897,0.936145952109464,0.9372146118721462,0.9371428571428572,0.937070938215103,0.9369988545246277,0.9369266055045872,0.9368541905855339,0.9367816091954023,0.9367088607594937,0.9366359447004609,0.9377162629757786,0.9387990762124712,0.9387283236994219,0.9386574074074074,0.9397450753186558,0.9396751740139211,0.9407665505226481,0.9406976744186046,0.940628637951106,0.9405594405594405,0.94049008168028,0.9404205607476636,0.9403508771929825,0.9402810304449649,0.94021101992966,0.9401408450704225,0.9400705052878966,0.94,0.9399293286219081,0.9398584905660378,0.9397874852420307,0.9408983451536643,0.9408284023668639,0.9407582938388626,0.9418742586002372,0.9418052256532067,0.9417360285374554,0.9428571428571428,0.9427890345649583,0.9427207637231504,0.942652329749104,0.9425837320574163,0.9425149700598803,0.9424460431654677,0.9423769507803121,0.9423076923076923,0.9422382671480144,0.9421686746987952,0.9420989143546441,0.9420289855072463,0.9419588875453446,0.9418886198547215,0.9418181818181818,0.941747572815534,0.9416767922235723,0.9416058394160584,0.9415347137637028,0.9414634146341463,0.9413919413919414,0.941320293398533,0.9412484700122399,0.9411764705882353,0.9411042944785276,0.9422604422604423,0.942189421894219,0.9421182266009852,0.9420468557336621,0.9419753086419753,0.9419035846724351,0.9418316831683168,0.942998760842627,0.9429280397022333,0.9428571428571428,0.9427860696517413,0.9439601494396015,0.9438902743142145,0.9438202247191011,0.945,0.9449311639549437,0.9448621553884712,0.946047678795483,0.9459798994974874,0.9459119496855346,0.9458438287153652,0.9457755359394704,0.9457070707070707,0.9469026548672567,0.9468354430379747,0.9467680608365019,0.9467005076142132,0.9466327827191868,0.9465648854961832,0.9464968152866242,0.9464285714285714,0.946360153256705,0.9462915601023018,0.9462227912932138,0.9461538461538461,0.9460847240051348,0.9460154241645244,0.9459459459459459,0.9458762886597938,0.9458064516129032,0.9469598965071151,0.9468911917098446,0.9468223086900129,0.9467532467532468,0.9466840052015605,0.9466145833333334,0.9465449804432855,0.9477806788511749,0.9477124183006536,0.9476439790575916,0.9475753604193972,0.9487516425755584,0.9486842105263158,0.9486166007905138,0.9485488126649076,0.9498018494055482,0.9497354497354498,0.9496688741721855,0.9496021220159151,0.949535192563081,0.949468085106383,0.9494007989347537,0.9493333333333334,0.9492656875834445,0.9505347593582888,0.9518072289156626,0.9517426273458445,0.9516778523489933,0.9516129032258065,0.9515477792732167,0.9514824797843666,0.951417004048583,0.9513513513513514,0.9512855209742895,0.9512195121951219,0.9511533242876526,0.9510869565217391,0.9510204081632653,0.9508867667121419,0.9508196721311475,0.9507523939808481,0.9506849315068493,0.9506172839506173,0.9505494505494505,0.951856946354883,0.9517906336088154,0.9517241379310345,0.9516574585635359,0.9515905947441217,0.9528432732316228,0.9527777777777777,0.952712100139082,0.9540389972144847,0.9539748953974896,0.9539106145251397,0.9538461538461539,0.9537815126050421,0.9537166900420757,0.9536516853932584,0.9535864978902954,0.9535211267605633,0.9548660084626234,0.9548022598870056,0.9547383309759547,0.9546742209631728,0.9546099290780142,0.9545454545454546,0.9559032716927454,0.9572649572649573,0.9572039942938659,0.9571428571428572,0.9585121602288984,0.9584527220630372,0.9583931133428981,0.9583333333333334,0.958273381294964,0.9582132564841499,0.9581529581529582,0.958092485549133,0.9580318379160637,0.9579710144927536,0.9593613933236574,0.9593023255813954,0.9606986899563319,0.9606413994169096,0.9605839416058394,0.9605263157894737,0.9604685212298683,0.9604105571847508,0.960352422907489,0.9602941176470589,0.9602356406480118,0.9601769911504425,0.9615952732644018,0.9615384615384616,0.9614814814814815,0.9614243323442137,0.9613670133729569,0.9627976190476191,0.96274217585693,0.9626865671641791,0.9626307922272048,0.9625748502994012,0.9625187406296851,0.9624624624624625,0.9624060150375939,0.9623493975903614,0.9622926093514329,0.9622356495468278,0.962178517397882,0.9621212121212122,0.9620637329286799,0.9620060790273556,0.9619482496194824,0.9634146341463414,0.9633587786259542,0.963302752293578,0.9632465543644717,0.9631901840490797,0.963076923076923,0.963020030816641,0.9629629629629629,0.9629057187017002,0.9628482972136223,0.9627906976744186,0.9627329192546584,0.9626749611197511,0.9626168224299065,0.9625585023400937,0.9625,0.9624413145539906,0.9623824451410659,0.9638932496075353,0.9638364779874213,0.9637795275590552,0.9637223974763407,0.9636650868878357,0.9636075949367089,0.9635499207606973,0.9634920634920635,0.9634340222575517,0.964968152866242,0.9649122807017544,0.9648562300319489,0.9664,0.9663461538461539,0.9662921348314607,0.9662379421221865,0.966183574879227,0.9661290322580646,0.9660743134087237,0.9660194174757282,0.965964343598055,0.9659090909090909,0.9658536585365853,0.9657980456026058,0.965742251223491,0.9656862745098039,0.9656301145662848,0.9655737704918033,0.9655172413793104,0.9654036243822076,0.9653465346534653,0.9652892561983472,0.9652317880794702,0.9651741293532339,0.9651162790697675,0.9650582362728786,0.965,0.9648829431438127,0.964824120603015,0.9664429530201343,0.9663865546218487,0.9663299663299664,0.9662731871838112,0.9662162162162162,0.9661590524534687,0.9677966101694915,0.967741935483871,0.9676320272572402,0.9692832764505119,0.9692307692307692,0.9691252144082333,0.9690721649484536,0.9690189328743546,0.9706896551724138,0.9706390328151986,0.9705882352941176,0.9705372616984402,0.9704861111111112,0.9704347826086956,0.9703832752613241,0.9703315881326352,0.9702797202797203,0.9702276707530648,0.9701754385964912,0.9701230228471002,0.9700704225352113,0.9717813051146384,0.9717314487632509,0.9716814159292035,0.9716312056737588,0.9715808170515098,0.9715302491103203,0.9714795008912656,0.9714285714285714,0.9713774597495528,0.9713261648745519,0.9712746858168761,0.9712230215827338,0.9711711711711711,0.9729241877256317,0.972875226039783,0.9728260869565217,0.9727767695099818,0.9727272727272728,0.9726775956284153,0.9726277372262774,0.9725776965265083,0.9725274725274725,0.9724770642201835,0.9724264705882353,0.9723756906077348,0.9723247232472325,0.9722735674676525,0.9722222222222222,0.9721706864564007,0.9721189591078067,0.9720670391061452,0.9720149253731343,0.9719626168224299,0.9718574108818011,0.9718045112781954,0.9717514124293786,0.9716981132075472,0.9735349716446124,0.9734848484848485,0.9734345351043643,0.973384030418251,0.9733333333333334,0.9732824427480916,0.9732313575525813,0.9731800766283525,0.9731285988483686,0.9730769230769231,0.9730250481695568,0.972972972972973,0.9729206963249516,0.9728682170542635,0.9728155339805825,0.9727626459143969,0.9727095516569201,0.97265625,0.9726027397260274,0.9725490196078431,0.9724950884086444,0.9724409448818898,0.9723865877712031,0.9723320158102767,0.9722772277227723,0.9722222222222222,0.9721669980119284,0.9721115537848606,0.9720558882235529,0.972,0.9719438877755511,0.9718875502008032,0.971830985915493,0.9717741935483871,0.9717171717171718,0.97165991902834,0.973630831643002,0.975609756097561,0.9755600814663951,0.9755102040816327,0.9754601226993865,0.9754098360655737,0.9753593429158111,0.9753086419753086,0.9752577319587629,0.9752066115702479,0.9751552795031055,0.975103734439834,0.975051975051975,0.975,0.9749478079331941,0.9748953974895398,0.9748427672955975,0.9747899159663865,0.9747368421052631,0.9746835443037974,0.9746300211416491,0.9745762711864406,0.9745222929936306,0.9744680851063829,0.9744136460554371,0.9743589743589743,0.974304068522484,0.9742489270386266,0.9741935483870968,0.9741379310344828,0.9740820734341252,0.974025974025974,0.9739696312364425,0.9739130434782609,0.9738562091503268,0.9737991266375546,0.973741794310722,0.9736842105263158,0.9758241758241758,0.9757709251101322,0.9757174392935982,0.9756637168141593,0.975609756097561,0.9755555555555555,0.9755011135857461,0.9754464285714286,0.9753914988814317,0.9753363228699552,0.9752808988764045,0.9752252252252253,0.9751693002257337,0.9751131221719457,0.9750566893424036,0.9772727272727273,0.9772209567198178,0.9771689497716894,0.977116704805492,0.9770642201834863,0.9770114942528736,0.9769585253456221,0.976905311778291,0.9768518518518519,0.9791183294663574,0.9790697674418605,0.9790209790209791,0.9789719626168224,0.9789227166276346,0.9788732394366197,0.9788235294117648,0.9787735849056604,0.9787234042553191,0.9786729857819905,0.9786223277909739,0.9785714285714285,0.9785202863961814,0.9784688995215312,0.9784172661870504,0.9783653846153846,0.9783132530120482,0.9782608695652174,0.9782082324455206,0.9781021897810219,0.9780487804878049,0.9779951100244498,0.9779411764705882,0.9778869778869779,0.9778325123152709,0.9777777777777777,0.9777227722772277,0.9776674937965261,0.9776119402985075,0.9775561097256857,0.9775,0.9774436090225563,0.9773869346733668,0.9773299748110831,0.9772727272727273,0.9772151898734177,0.9771573604060914,0.9770992366412213,0.9770408163265306,0.9769820971867008,0.9769230769230769,0.9767441860465116,0.9792746113989638,0.9792207792207792,0.9817708333333334,0.9817232375979112,0.9816272965879265,0.9815789473684211,0.9815303430079155,0.9814814814814815,0.9814323607427056,0.9813829787234043,0.9812834224598931,0.9812332439678284,0.9811827956989247,0.9809264305177112,0.9808743169398907,0.9808219178082191,0.9807692307692307,0.9807162534435262,0.9806629834254144,0.9806094182825484,0.9805555555555555,0.9805013927576601,0.9804469273743017,0.9803921568627451,0.9803370786516854,0.9802816901408451,0.980225988700565,0.9801699716713881,0.9801136363636364,0.98005698005698,0.98,0.9799426934097422,0.9798850574712644,0.9797687861271677,0.9797101449275363,0.9796511627906976,0.9795918367346939,0.9794721407624634,0.9794117647058823,0.9793510324483776,0.9792899408284024,0.9792284866468842,0.9790419161676647,0.978978978978979,0.9789156626506024,0.9788519637462235,0.9787878787878788,0.9787234042553191,0.9786585365853658,0.9785932721712538,0.9785276073619632,0.9784615384615385,0.9783950617283951,0.978328173374613,0.9782608695652174,0.9781931464174455,0.978125,0.9780564263322884,0.9779874213836478,0.9779179810725552,0.9778481012658228,0.9777777777777777,0.9777070063694268,0.9776357827476039,0.9775641025641025,0.977491961414791,0.9774193548387097,0.9773462783171522,0.9772727272727273,0.9771986970684039,0.9771241830065359,0.9770491803278688,0.9769736842105263,0.976897689768977,0.9768211920529801,0.9767441860465116,0.9766666666666667,0.9765886287625418,0.9764309764309764,0.9763513513513513,0.976271186440678,0.9761904761904762,0.9795221843003413,0.9794520547945206,0.979381443298969,0.9827586206896551,0.9826989619377162,0.9826388888888888,0.9825783972125436,0.9825174825174825,0.9824561403508771,0.9823943661971831,0.982078853046595,0.9820143884892086,0.9855595667870036,0.9855072463768116,0.9854545454545455,0.9854014598540146,0.9853479853479854,0.9852941176470589,0.985239852398524,0.9851851851851852,0.9851301115241635,0.9850746268656716,0.9850187265917603,0.9849624060150376,0.9849056603773585,0.9848484848484849,0.9847908745247148,0.9847328244274809,0.9846743295019157,0.9846153846153847,0.9845559845559846,0.9844961240310077,0.9844357976653697,0.984375,0.984313725490196,0.984251968503937,0.9841269841269841,0.9840637450199203,0.984,0.9839357429718876,0.9838709677419355,0.9838056680161943,0.983739837398374,0.9836734693877551,0.9836065573770492,0.9835390946502057,0.9834710743801653,0.983402489626556,0.9833333333333333,0.9832635983263598,0.9831932773109243,0.9831223628691983,0.9830508474576272,0.9829787234042553,0.9829059829059829,0.9828326180257511,0.9827586206896551,0.9826839826839827,0.9826086956521739,0.982532751091703,0.9824561403508771,0.9823788546255506,0.9823008849557522,0.9822222222222222,0.9820627802690582,0.9819819819819819,0.9819004524886877,0.9818181818181818,0.9817351598173516,0.981651376146789,0.9815668202764977,0.9814814814814815,0.9813953488372092,0.9811320754716981,0.981042654028436,0.9809523809523809,0.9808612440191388,0.9807692307692307,0.9806763285024155,0.9805825242718447,0.9804878048780488,0.9803921568627451,0.9802955665024631,0.9801980198019802,0.9800995024875622,0.98,0.9798994974874372,0.9797979797979798,0.9796954314720813,0.9795918367346939,0.9794871794871794,0.979381443298969,0.9792746113989638,0.9791666666666666,0.9790575916230366,0.9789473684210527,0.9788359788359788,0.9787234042553191,0.9786096256684492,0.9783783783783784,0.9782608695652174,0.9781420765027322,0.978021978021978,0.9779005524861878,0.9777777777777777,0.9776536312849162,0.9775280898876404,0.9774011299435028,0.9772727272727273,0.9771428571428571,0.9770114942528736,0.976878612716763,0.9767441860465116,0.9766081871345029,0.9764705882352941,0.9763313609467456,0.9761904761904762,0.9760479041916168,0.9759036144578314,0.9757575757575757,0.975609756097561,0.9754601226993865,0.9753086419753086,0.9751552795031055,0.975,0.9748427672955975,0.9746835443037974,0.9745222929936306,0.9743589743589743,0.9741935483870968,0.974025974025974,0.9738562091503268,0.9736842105263158,0.9733333333333334,0.9731543624161074,0.972972972972973,0.9727891156462585,0.9726027397260274,0.9724137931034482,0.9722222222222222,0.972027972027972,0.971830985915493,0.9716312056737588,0.9714285714285714,0.9712230215827338,0.9710144927536232,0.9708029197080292,0.9705882352941176,0.9703703703703703,0.9701492537313433,0.9699248120300752,0.9772727272727273,0.9770992366412213,0.9846153846153847,0.9844961240310077,0.984375,0.984251968503937,0.9841269841269841,0.984,0.9838709677419355,0.983739837398374,0.9836065573770492,0.9834710743801653,0.9833333333333333,0.9830508474576272,0.9829059829059829,0.9826086956521739,0.9824561403508771,0.9819819819819819,0.9818181818181818,0.981651376146789,0.9814814814814815,0.9811320754716981,0.9803921568627451,0.9801980198019802,0.98,0.9797979797979798,0.9795918367346939,0.979381443298969,0.9791666666666666,0.9789473684210527,0.9787234042553191,0.978021978021978,0.9777777777777777,0.9775280898876404,0.9772727272727273,0.9767441860465116,0.9764705882352941,0.975609756097561,0.9753086419753086,0.974025974025974,0.9733333333333334,0.972972972972973,0.9726027397260274,0.9722222222222222,0.9714285714285714,0.9710144927536232,0.9705882352941176,0.9701492537313433,0.96875,0.9682539682539683,0.967741935483871,0.9672131147540983,0.9661016949152542,0.9655172413793104,0.9642857142857143,0.9636363636363636,0.9629629629629629,0.9615384615384616,0.9607843137254902,0.98,0.9795918367346939,0.9791666666666666,0.9787234042553191,0.9782608695652174,0.9777777777777777,0.9772727272727273,0.9767441860465116,0.9761904761904762,0.975609756097561,0.975,0.9743589743589743,0.972972972972973,0.9722222222222222,0.9714285714285714,0.9705882352941176,0.96875,0.9655172413793104,0.9642857142857143,0.9629629629629629,0.9615384615384616,0.96,0.9583333333333334,0.9523809523809523,0.95,0.9473684210526315,0.9444444444444444,0.9411764705882353,0.9375,0.875,0.8571428571428571,0.8333333333333334,0.8,0.75,0.6666666666666666,0.5,1,1],"yaxis":"y"}],"layout":{"height":600,"legend":{"tracegroupgap":0},"shapes":[{"line":{"dash":"dash"},"type":"line","x0":0,"x1":1,"y0":1,"y1":0}],"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"title":{"text":"Precision-Recall Curve (AUC=0.9107)"},"width":800,"xaxis":{"anchor":"y","constrain":"domain","domain":[0,1],"title":{"text":"Recall"}},"yaxis":{"anchor":"x","domain":[0,1],"scaleanchor":"x","scaleratio":1,"title":{"text":"Precision"}}}},"text/html":["<div>                            <div id=\"1ae98799-3f09-4d05-8ab4-ce28a95a9047\" class=\"plotly-graph-div\" style=\"height:600px; width:800px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"1ae98799-3f09-4d05-8ab4-ce28a95a9047\")) {                    Plotly.newPlot(                        \"1ae98799-3f09-4d05-8ab4-ce28a95a9047\",                        [{\"fillpattern\":{\"shape\":\"\"},\"hovertemplate\":\"Recall=%{x}\\u003cbr\\u003ePrecision=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"stackgroup\":\"1\",\"x\":[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9970958373668926,0.9961277831558567,0.9961277831558567,0.995159728944821,0.995159728944821,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9932236205227493,0.9932236205227493,0.9922555663117134,0.9922555663117134,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.989351403678606,0.989351403678606,0.9883833494675702,0.9874152952565344,0.9864472410454985,0.9864472410454985,0.9864472410454985,0.9864472410454985,0.9864472410454985,0.9854791868344628,0.9854791868344628,0.9854791868344628,0.9845111326234269,0.9845111326234269,0.9845111326234269,0.9845111326234269,0.9845111326234269,0.9845111326234269,0.9845111326234269,0.9835430784123911,0.9835430784123911,0.9825750242013552,0.9825750242013552,0.9816069699903195,0.9816069699903195,0.9806389157792836,0.9806389157792836,0.9796708615682478,0.978702807357212,0.978702807357212,0.9777347531461762,0.9777347531461762,0.9777347531461762,0.9767666989351403,0.9767666989351403,0.9767666989351403,0.9767666989351403,0.9767666989351403,0.9757986447241046,0.9748305905130688,0.9748305905130688,0.9748305905130688,0.9738625363020329,0.972894482090997,0.9719264278799613,0.9719264278799613,0.9719264278799613,0.9709583736689255,0.9709583736689255,0.9709583736689255,0.9709583736689255,0.9699903194578896,0.9690222652468539,0.968054211035818,0.968054211035818,0.968054211035818,0.9670861568247822,0.9661181026137464,0.9661181026137464,0.9651500484027106,0.9641819941916747,0.9641819941916747,0.9632139399806389,0.9632139399806389,0.9632139399806389,0.9622458857696031,0.9622458857696031,0.9622458857696031,0.9622458857696031,0.9622458857696031,0.9612778315585673,0.9603097773475314,0.9593417231364957,0.9583736689254598,0.957405614714424,0.957405614714424,0.9564375605033882,0.9554695062923524,0.9545014520813165,0.9535333978702807,0.952565343659245,0.952565343659245,0.952565343659245,0.952565343659245,0.9515972894482091,0.9506292352371732,0.9496611810261375,0.9496611810261375,0.9486931268151017,0.9486931268151017,0.9486931268151017,0.9477250726040658,0.9467570183930301,0.9467570183930301,0.9457889641819942,0.9457889641819942,0.9448209099709584,0.9448209099709584,0.9438528557599225,0.9428848015488868,0.9428848015488868,0.9419167473378509,0.9419167473378509,0.9419167473378509,0.9409486931268151,0.9399806389157793,0.9399806389157793,0.9390125847047435,0.9390125847047435,0.9380445304937076,0.9380445304937076,0.9370764762826719,0.936108422071636,0.9351403678606002,0.9341723136495643,0.9332042594385286,0.9332042594385286,0.9322362052274927,0.9312681510164569,0.9303000968054211,0.9293320425943853,0.9293320425943853,0.9283639883833494,0.9273959341723137,0.9264278799612778,0.9264278799612778,0.925459825750242,0.9244917715392061,0.9244917715392061,0.9244917715392061,0.9244917715392061,0.9235237173281704,0.9225556631171346,0.9225556631171346,0.9215876089060987,0.9215876089060987,0.9215876089060987,0.920619554695063,0.9196515004840271,0.9196515004840271,0.9186834462729913,0.9177153920619555,0.9167473378509197,0.9157792836398838,0.9138431752178122,0.9128751210067764,0.9128751210067764,0.9119070667957405,0.9109390125847048,0.9099709583736689,0.9090029041626331,0.9080348499515973,0.9080348499515973,0.9070667957405615,0.9060987415295256,0.9060987415295256,0.9051306873184899,0.904162633107454,0.904162633107454,0.904162633107454,0.9031945788964182,0.9031945788964182,0.9031945788964182,0.9022265246853823,0.9012584704743466,0.9002904162633107,0.9002904162633107,0.8993223620522749,0.8983543078412392,0.8973862536302033,0.8964181994191674,0.8954501452081317,0.8944820909970959,0.89351403678606,0.8925459825750242,0.8925459825750242,0.8915779283639884,0.8906098741529526,0.8896418199419167,0.888673765730881,0.8877057115198451,0.8877057115198451,0.8877057115198451,0.8867376573088093,0.8857696030977735,0.8848015488867377,0.8848015488867377,0.8848015488867377,0.8848015488867377,0.8838334946757018,0.8838334946757018,0.882865440464666,0.8818973862536302,0.8809293320425944,0.8799612778315585,0.8789932236205228,0.8780251694094869,0.8770571151984511,0.8760890609874153,0.8751210067763795,0.8751210067763795,0.8741529525653436,0.8731848983543078,0.872216844143272,0.8712487899322362,0.8712487899322362,0.8702807357212003,0.8693126815101646,0.8683446272991288,0.8673765730880929,0.8664085188770572,0.8664085188770572,0.8654404646660213,0.8644724104549855,0.8635043562439496,0.8635043562439496,0.8625363020329139,0.861568247821878,0.8606001936108422,0.8596321393998064,0.8596321393998064,0.8586640851887706,0.8576960309777347,0.8576960309777347,0.856727976766699,0.8557599225556631,0.8547918683446273,0.8538238141335914,0.8538238141335914,0.8528557599225557,0.8528557599225557,0.8518877057115198,0.850919651500484,0.850919651500484,0.850919651500484,0.8499515972894482,0.8499515972894482,0.8489835430784124,0.8489835430784124,0.8489835430784124,0.8489835430784124,0.8480154888673765,0.8470474346563408,0.846079380445305,0.8451113262342691,0.8441432720232332,0.8431752178121975,0.8431752178121975,0.8422071636011617,0.8412391093901258,0.8402710551790901,0.8393030009680542,0.8383349467570184,0.8373668925459826,0.8363988383349468,0.8354307841239109,0.8354307841239109,0.8354307841239109,0.8354307841239109,0.8344627299128751,0.8334946757018393,0.8325266214908035,0.8315585672797676,0.8305905130687319,0.829622458857696,0.829622458857696,0.829622458857696,0.829622458857696,0.8286544046466602,0.8276863504356244,0.8267182962245886,0.8257502420135527,0.8257502420135527,0.8247821878025169,0.8238141335914811,0.8228460793804453,0.8218780251694094,0.8218780251694094,0.8209099709583737,0.8199419167473379,0.8199419167473379,0.818973862536302,0.818973862536302,0.8180058083252663,0.8170377541142304,0.8160696999031946,0.8151016456921588,0.8151016456921588,0.814133591481123,0.8131655372700871,0.8121974830590513,0.8112294288480155,0.8112294288480155,0.8102613746369797,0.8092933204259438,0.8083252662149081,0.8073572120038722,0.8063891577928364,0.8063891577928364,0.8054211035818006,0.8044530493707648,0.8044530493707648,0.8034849951597289,0.8034849951597289,0.8025169409486931,0.8015488867376573,0.8005808325266215,0.7996127783155856,0.7986447241045499,0.7986447241045499,0.797676669893514,0.7967086156824782,0.7957405614714425,0.7947725072604066,0.7947725072604066,0.7938044530493708,0.7928363988383349,0.7918683446272992,0.7909002904162633,0.7899322362052275,0.7889641819941917,0.7879961277831559,0.78702807357212,0.78702807357212,0.78702807357212,0.7860600193610843,0.7850919651500484,0.7850919651500484,0.7841239109390126,0.7841239109390126,0.7831558567279767,0.782187802516941,0.7812197483059051,0.7802516940948693,0.7792836398838335,0.7783155856727977,0.7773475314617618,0.7763794772507261,0.7754114230396902,0.7744433688286544,0.7734753146176185,0.7725072604065828,0.771539206195547,0.7705711519845111,0.7705711519845111,0.7696030977734754,0.7686350435624395,0.7686350435624395,0.7676669893514037,0.7666989351403679,0.7666989351403679,0.7657308809293321,0.7647628267182962,0.7637947725072604,0.7628267182962246,0.7618586640851888,0.7608906098741529,0.7599225556631172,0.7589545014520813,0.7579864472410455,0.7570183930300097,0.7560503388189739,0.755082284607938,0.7541142303969022,0.7531461761858664,0.7521781219748306,0.7512100677637947,0.750242013552759,0.7492739593417231,0.7483059051306873,0.7473378509196515,0.7463697967086157,0.7454017424975798,0.744433688286544,0.7434656340755083,0.7424975798644724,0.7424975798644724,0.7415295256534365,0.7405614714424008,0.739593417231365,0.7386253630203291,0.7376573088092934,0.7366892545982575,0.7366892545982575,0.7357212003872217,0.7347531461761858,0.7337850919651501,0.7337850919651501,0.7328170377541142,0.7318489835430784,0.7318489835430784,0.7308809293320426,0.7299128751210068,0.7299128751210068,0.7289448209099709,0.7279767666989352,0.7270087124878993,0.7260406582768635,0.7250726040658277,0.7250726040658277,0.7241045498547919,0.723136495643756,0.7221684414327202,0.7212003872216844,0.7202323330106486,0.7192642787996127,0.718296224588577,0.7173281703775412,0.7163601161665053,0.7153920619554696,0.7144240077444337,0.7134559535333979,0.712487899322362,0.7115198451113263,0.7105517909002904,0.7095837366892546,0.7086156824782188,0.707647628267183,0.7066795740561471,0.7057115198451114,0.7047434656340755,0.7037754114230397,0.7028073572120038,0.7028073572120038,0.7018393030009681,0.7008712487899322,0.6999031945788964,0.6989351403678606,0.6979670861568248,0.6969990319457889,0.6960309777347532,0.6960309777347532,0.6950629235237173,0.6940948693126815,0.6931268151016456,0.6921587608906099,0.691190706679574,0.6902226524685382,0.6892545982575025,0.6882865440464666,0.6882865440464666,0.6882865440464666,0.6873184898354308,0.686350435624395,0.6853823814133592,0.6844143272023233,0.6834462729912875,0.6824782187802517,0.6815101645692159,0.68054211035818,0.6795740561471443,0.6786060019361084,0.6776379477250726,0.6766698935140368,0.6747337850919651,0.6737657308809293,0.6727976766698935,0.6718296224588577,0.6708615682478218,0.6698935140367861,0.6698935140367861,0.6689254598257502,0.6679574056147144,0.6669893514036787,0.6660212971926428,0.665053242981607,0.6640851887705711,0.6631171345595354,0.6631171345595354,0.6621490803484995,0.6611810261374637,0.6602129719264279,0.6592449177153921,0.6582768635043562,0.6573088092933205,0.6563407550822846,0.6553727008712488,0.6553727008712488,0.6544046466602129,0.6534365924491772,0.6524685382381413,0.6515004840271055,0.6505324298160697,0.6505324298160697,0.6505324298160697,0.6495643756050339,0.648596321393998,0.648596321393998,0.6476282671829623,0.6466602129719264,0.6456921587608906,0.6447241045498547,0.643756050338819,0.6427879961277831,0.6418199419167473,0.6408518877057116,0.6398838334946757,0.6398838334946757,0.6389157792836399,0.6389157792836399,0.6379477250726041,0.6369796708615683,0.6360116166505324,0.6350435624394967,0.6340755082284608,0.633107454017425,0.6321393998063891,0.6311713455953534,0.6302032913843175,0.6302032913843175,0.6292352371732817,0.6282671829622459,0.6272991287512101,0.6263310745401742,0.6263310745401742,0.6253630203291385,0.6243949661181026,0.6234269119070668,0.6224588576960309,0.6214908034849952,0.6205227492739593,0.6195546950629235,0.6185866408518877,0.6176185866408519,0.616650532429816,0.6156824782187803,0.6147144240077445,0.6137463697967086,0.6127783155856728,0.611810261374637,0.611810261374637,0.6108422071636012,0.6098741529525653,0.6089060987415296,0.6079380445304937,0.6060019361084221,0.6050338818973863,0.6040658276863504,0.6030977734753146,0.6021297192642788,0.601161665053243,0.6001936108422071,0.5992255566311714,0.5982575024201355,0.5972894482090997,0.5963213939980639,0.5953533397870281,0.5943852855759922,0.5943852855759922,0.5934172313649564,0.5924491771539206,0.5914811229428848,0.590513068731849,0.5895450145208132,0.5885769603097774,0.5876089060987415,0.5866408518877058,0.5866408518877058,0.5856727976766699,0.5847047434656341,0.5847047434656341,0.5837366892545982,0.5827686350435625,0.5818005808325266,0.5808325266214908,0.579864472410455,0.5788964181994192,0.5779283639883833,0.5769603097773476,0.5759922555663117,0.5750242013552759,0.57405614714424,0.5730880929332043,0.5721200387221684,0.5711519845111326,0.5701839303000968,0.569215876089061,0.5672797676669894,0.5663117134559535,0.5653436592449177,0.5643756050338818,0.5634075508228461,0.5624394966118103,0.5614714424007744,0.5605033881897387,0.558567279767667,0.5575992255566312,0.5575992255566312,0.5566311713455954,0.5556631171345595,0.5546950629235237,0.5537270087124879,0.5527589545014521,0.5527589545014521,0.5517909002904162,0.5498547918683446,0.5498547918683446,0.5488867376573088,0.5469506292352372,0.5459825750242013,0.5450145208131656,0.5450145208131656,0.5440464666021297,0.5430784123910939,0.542110358180058,0.5411423039690223,0.5401742497579864,0.5392061955469506,0.5382381413359149,0.537270087124879,0.5363020329138432,0.5353339787028074,0.5343659244917716,0.5333978702807357,0.5333978702807357,0.5324298160696999,0.5314617618586641,0.5304937076476283,0.5295256534365924,0.5285575992255567,0.5275895450145208,0.526621490803485,0.5256534365924492,0.5246853823814134,0.5237173281703775,0.5227492739593417,0.5217812197483059,0.5217812197483059,0.5208131655372701,0.5198451113262342,0.5188770571151985,0.5179090029041626,0.5169409486931268,0.515972894482091,0.5150048402710552,0.5140367860600193,0.5130687318489835,0.5121006776379478,0.5111326234269119,0.510164569215876,0.5091965150048403,0.5082284607938045,0.5072604065827686,0.5062923523717329,0.505324298160697,0.5043562439496612,0.5033881897386253,0.5014520813165537,0.5004840271055179,0.4995159728944821,0.4985479186834463,0.4985479186834463,0.4975798644724105,0.49661181026137463,0.49564375605033884,0.494675701839303,0.4937076476282672,0.4927395934172314,0.49177153920619554,0.49080348499515974,0.4898354307841239,0.4888673765730881,0.4878993223620523,0.48693126815101645,0.48596321393998065,0.4849951597289448,0.484027105517909,0.4830590513068732,0.48209099709583736,0.48112294288480156,0.4801548886737657,0.4791868344627299,0.4782187802516941,0.47725072604065827,0.4762826718296225,0.4753146176185866,0.4743465634075508,0.47337850919651503,0.4724104549854792,0.4714424007744434,0.47047434656340753,0.46950629235237173,0.46853823814133594,0.4675701839303001,0.4666021297192643,0.46563407550822844,0.46466602129719264,0.46466602129719264,0.46466602129719264,0.46369796708615685,0.462729912875121,0.4617618586640852,0.46079380445304935,0.45982575024201355,0.45885769603097776,0.4578896418199419,0.4569215876089061,0.45595353339787026,0.45498547918683446,0.45401742497579867,0.4530493707647628,0.452081316553727,0.45111326234269117,0.45014520813165537,0.4491771539206196,0.4482090997095837,0.44724104549854793,0.4462729912875121,0.4453049370764763,0.4443368828654405,0.44336882865440463,0.44240077444336884,0.441432720232333,0.4404646660212972,0.4394966118102614,0.43852855759922554,0.43756050338818975,0.4365924491771539,0.4356243949661181,0.4346563407550823,0.43368828654404645,0.43272023233301066,0.4317521781219748,0.430784123910939,0.4298160696999032,0.4298160696999032,0.42884801548886736,0.42787996127783157,0.4269119070667957,0.4259438528557599,0.4249757986447241,0.42400774443368827,0.4230396902226525,0.4220716360116166,0.42110358180058083,0.42013552758954503,0.4191674733785092,0.4181994191674734,0.41723136495643753,0.41626331074540174,0.41626331074540174,0.41529525653436594,0.4143272023233301,0.4133591481122943,0.41239109390125844,0.41142303969022265,0.41045498547918685,0.409486931268151,0.4085188770571152,0.4085188770571152,0.4075508228460794,0.40658276863504356,0.40561471442400776,0.4046466602129719,0.4036786060019361,0.4027105517909003,0.40174249757986447,0.40077444336882867,0.3998063891577928,0.398838334946757,0.3978702807357212,0.3969022265246854,0.3959341723136496,0.39496611810261373,0.39399806389157793,0.39303000968054214,0.3920619554695063,0.3910939012584705,0.38915779283639884,0.38818973862536305,0.3872216844143272,0.3862536302032914,0.38528557599225555,0.38431752178121975,0.38334946757018395,0.3823814133591481,0.3814133591481123,0.38044530493707646,0.37947725072604066,0.37850919651500486,0.377541142303969,0.3765730880929332,0.37560503388189737,0.37463697967086157,0.3736689254598258,0.3727008712487899,0.3717328170377541,0.3707647628267183,0.3697967086156825,0.3688286544046467,0.3659244917715392,0.3659244917715392,0.3649564375605034,0.3649564375605034,0.3639883833494676,0.36205227492739595,0.3610842207163601,0.3601161665053243,0.3591481122942885,0.35818005808325265,0.35721200387221685,0.3552758954501452,0.3543078412391094,0.35333978702807356,0.34849951597289447,0.3475314617618587,0.3465634075508228,0.345595353339787,0.34462729912875123,0.3436592449177154,0.3426911907066796,0.34172313649564373,0.34075508228460794,0.33978702807357214,0.3388189738625363,0.3378509196515005,0.33688286544046464,0.33591481122942884,0.33494675701839305,0.3339787028073572,0.3330106485963214,0.33204259438528555,0.33107454017424975,0.33010648596321396,0.3281703775411423,0.32720232333010646,0.32623426911907066,0.32526621490803487,0.3233301064859632,0.32236205227492737,0.3213939980638916,0.3204259438528558,0.3194578896418199,0.3165537270087125,0.3155856727976767,0.31461761858664083,0.31364956437560504,0.31268151016456924,0.3117134559535334,0.3107454017424976,0.30977734753146174,0.30880929332042595,0.30784123910939015,0.3068731848983543,0.3059051306873185,0.30493707647628265,0.30396902226524686,0.30300096805421106,0.3020329138431752,0.3010648596321394,0.30009680542110356,0.29912875121006777,0.29816069699903197,0.2971926427879961,0.2962245885769603,0.2952565343659245,0.2942884801548887,0.2933204259438529,0.29235237173281703,0.29138431752178123,0.2904162633107454,0.2894482090997096,0.2884801548886738,0.28751210067763794,0.28654404646660214,0.2855759922555663,0.2846079380445305,0.2836398838334947,0.28267182962245885,0.2807357212003872,0.2797676669893514,0.2787996127783156,0.27783155856727976,0.27783155856727976,0.27686350435624396,0.2758954501452081,0.2758954501452081,0.2749273959341723,0.2739593417231365,0.27299128751210067,0.27202323330106487,0.271055179090029,0.2700871248789932,0.26524685382381413,0.26427879961277834,0.26427879961277834,0.2633107454017425,0.2623426911907067,0.26137463697967084,0.26040658276863504,0.25943852855759925,0.2584704743465634,0.2575024201355276,0.25653436592449175,0.25556631171345595,0.25459825750242016,0.2536302032913843,0.2526621490803485,0.25169409486931266,0.25072604065827686,0.24975798644724104,0.24878993223620524,0.24782187802516942,0.2468538238141336,0.24588576960309777,0.24491771539206195,0.24394966118102615,0.24298160696999033,0.2420135527589545,0.24007744433688286,0.23910939012584706,0.23814133591481124,0.2371732817037754,0.2362052274927396,0.23523717328170377,0.23426911907066797,0.23330106485963215,0.23233301064859632,0.2313649564375605,0.23039690222652467,0.22942884801548888,0.22846079380445306,0.22749273959341723,0.2265246853823814,0.22555663117134558,0.2245885769603098,0.22362052274927396,0.22265246853823814,0.22168441432720232,0.2207163601161665,0.2197483059051307,0.21878025169409487,0.21781219748305905,0.21684414327202323,0.2158760890609874,0.2149080348499516,0.21393998063891578,0.21200387221684414,0.2110358180058083,0.21006776379477252,0.2090997095837367,0.20813165537270087,0.20716360116166505,0.20619554695062922,0.20522749273959343,0.2042594385285576,0.20135527589545016,0.20038722168441434,0.1994191674733785,0.1984511132623427,0.19748305905130686,0.19651500484027107,0.19554695062923524,0.19457889641819942,0.1936108422071636,0.19264278799612777,0.19167473378509198,0.19070667957405615,0.18973862536302033,0.1887705711519845,0.18780251694094868,0.1868344627299129,0.18586640851887706,0.18489835430784124,0.18393030009680542,0.1829622458857696,0.1819941916747338,0.18102613746369797,0.18005808325266215,0.17909002904162633,0.1781219748305905,0.1771539206195547,0.17521781219748306,0.17424975798644723,0.1732817037754114,0.17231364956437561,0.1713455953533398,0.17037754114230397,0.16940948693126814,0.16844143272023232,0.16747337850919652,0.1665053242981607,0.16553727008712488,0.16456921587608905,0.16360116166505323,0.16263310745401743,0.1616650532429816,0.1606969990319458,0.15972894482090996,0.15876089060987417,0.15779283639883834,0.15682478218780252,0.1558567279767667,0.15488867376573087,0.15392061955469508,0.15295256534365925,0.15198451113262343,0.1510164569215876,0.15004840271055178,0.14908034849951599,0.14811229428848016,0.14714424007744434,0.14617618586640851,0.1452081316553727,0.1442400774443369,0.14327202323330107,0.14133591481122942,0.1403678606001936,0.1393998063891578,0.13843175217812198,0.13746369796708616,0.13649564375605033,0.1355275895450145,0.1345595353339787,0.1335914811229429,0.13262342691190707,0.13165537270087124,0.13068731848983542,0.12971926427879962,0.1287512100677638,0.12778315585672798,0.12681510164569215,0.12584704743465633,0.12487899322362052,0.12487899322362052,0.12391093901258471,0.12391093901258471,0.12294288480154889,0.12197483059051308,0.12100677637947725,0.12003872216844143,0.11907066795740562,0.1181026137463698,0.11713455953533398,0.11616650532429816,0.11519845111326234,0.11423039690222653,0.1122942884801549,0.11132623426911907,0.10939012584704744,0.10842207163601161,0.10551790900290416,0.10454985479186835,0.10358180058083252,0.10261374636979671,0.10067763794772508,0.0968054211035818,0.09583736689254599,0.09486931268151017,0.09390125847047434,0.09293320425943853,0.09196515004840271,0.0909970958373669,0.09002904162633107,0.08906098741529525,0.08615682478218781,0.08518877057115198,0.08422071636011616,0.08325266214908035,0.08131655372700872,0.0803484995159729,0.07744433688286544,0.07647628267182963,0.07260406582768635,0.07066795740561471,0.0696999031945789,0.06873184898354308,0.06776379477250725,0.06582768635043562,0.06485963213939981,0.06389157792836399,0.06292352371732816,0.060019361084220714,0.0590513068731849,0.05808325266214908,0.057115198451113264,0.05517909002904162,0.05421103581800581,0.05227492739593417,0.051306873184898356,0.05033881897386254,0.0484027105517909,0.04743465634075508,0.04743465634075508,0.046466602129719266,0.04549854791868345,0.044530493707647625,0.04356243949661181,0.04259438528557599,0.041626331074540175,0.04065827686350436,0.03969022265246854,0.03872216844143272,0.0377541142303969,0.036786060019361085,0.03484995159728945,0.03388189738625363,0.03291384317521781,0.031945788964181994,0.030009680542110357,0.027105517909002903,0.026137463697967087,0.02516940948693127,0.02420135527589545,0.023233301064859633,0.022265246853823813,0.01936108422071636,0.018393030009680542,0.017424975798644726,0.016456921587608905,0.015488867376573089,0.01452081316553727,0.006776379477250726,0.005808325266214908,0.00484027105517909,0.003872216844143272,0.002904162633107454,0.001936108422071636,0.000968054211035818,0.000968054211035818,0.0],\"xaxis\":\"x\",\"y\":[0.7341862117981521,0.7352313167259786,0.7357549857549858,0.7368045649072753,0.7373304782298359,0.7378571428571429,0.7383845604002859,0.7389127324749643,0.7394416607015032,0.7399713467048711,0.7410329985652798,0.741564967695621,0.7420977011494253,0.7426312005751258,0.7431654676258993,0.7437005039596832,0.7442363112391931,0.7447728911319395,0.7453102453102453,0.7458483754512636,0.7463872832369942,0.7469269703543022,0.7474674384949349,0.7480086893555394,0.7485507246376811,0.7490935460478607,0.7496371552975326,0.7501815541031227,0.7507267441860465,0.7512727272727273,0.7518195050946143,0.752367079388201,0.7529154518950437,0.754014598540146,0.7545653761869978,0.7551169590643275,0.7556693489392831,0.7562225475841874,0.7567765567765568,0.7573313782991202,0.7578870139398386,0.7584434654919237,0.7590007347538574,0.7595588235294117,0.7601177336276674,0.7606774668630338,0.7612380250552689,0.7617994100294986,0.7623616236162362,0.7629246676514032,0.7634885439763488,0.7640532544378699,0.764618800888231,0.7651851851851852,0.765752409191994,0.766320474777448,0.7668893838158871,0.7674591381872214,0.7680297397769517,0.7686011904761905,0.7691734921816828,0.7697466467958272,0.7703206562266965,0.7708955223880597,0.7714712471994025,0.7720478325859492,0.7743628185907047,0.7749437359339835,0.7755255255255256,0.7761081893313299,0.7766917293233083,0.7772761474793077,0.7778614457831325,0.7784476262245666,0.7790346907993967,0.779622641509434,0.7802114803625377,0.780801209372638,0.7813918305597579,0.7825757575757576,0.7831690674753601,0.783763277693475,0.7843583902809416,0.7849544072948328,0.7867479055597868,0.7873475609756098,0.7879481311975591,0.7885496183206107,0.7891520244461421,0.7897553516819572,0.7903596021423106,0.7909647779479326,0.7915708812260537,0.7921779141104295,0.7927858787413661,0.793394777265745,0.7940046118370484,0.7946153846153846,0.7952270977675134,0.7958397534668721,0.7964533538936006,0.7970679012345679,0.7969111969111969,0.7975270479134466,0.7981438515081206,0.7987616099071208,0.7993803253292022,0.8,0.8006206361520558,0.8012422360248447,0.8018648018648019,0.80248833592535,0.8031128404669261,0.8037383177570093,0.8043647700701481,0.8049921996879875,0.8056206088992974,0.80625,0.8068803752931978,0.8075117370892019,0.8081440877055599,0.8094117647058824,0.8100470957613815,0.8106834249803614,0.8113207547169812,0.8119590873328089,0.8125984251968504,0.8132387706855791,0.8138801261829653,0.8145224940805051,0.8151658767772512,0.8158102766798419,0.8163103721298496,0.8169572107765452,0.8176050753370341,0.8182539682539682,0.8189038919777601,0.8195548489666137,0.8202068416865553,0.820859872611465,0.8215139442231075,0.8221690590111643,0.8228252194732641,0.8234824281150159,0.82414068745004,0.8248,0.8254603682946358,0.8261217948717948,0.8267842822774659,0.8274478330658106,0.8281124497991967,0.8287781350482315,0.829444891391794,0.8301127214170693,0.8299758259468171,0.8298387096774194,0.8305084745762712,0.8303715670436187,0.8310428455941795,0.830906148867314,0.8315789473684211,0.8322528363047001,0.8329278183292782,0.8336038961038961,0.834281072298944,0.8349593495934959,0.8356387306753458,0.8363192182410424,0.837000814995925,0.8376835236541599,0.8383673469387755,0.8390522875816994,0.8404255319148937,0.8411138411138411,0.8418032786885246,0.8424938474159147,0.8431855500821018,0.8438783894823336,0.8445723684210527,0.8452674897119341,0.8459637561779242,0.8466611706512778,0.8473597359735974,0.847233691164327,0.8479338842975207,0.847808105872622,0.8485099337748344,0.848384424192212,0.8490878938640133,0.8497925311203319,0.8504983388704319,0.8512053200332502,0.8519134775374376,0.8526228143213989,0.8533333333333334,0.854045037531276,0.8547579298831386,0.8546365914786967,0.8553511705685619,0.8560669456066946,0.8567839195979899,0.8575020955574183,0.8573825503355704,0.8581024349286314,0.8579831932773109,0.8578637510513036,0.8577441077441077,0.8584667228306655,0.8591905564924115,0.859915611814346,0.8606418918918919,0.8605240912933221,0.8612521150592216,0.8627118644067797,0.8625954198473282,0.8633276740237691,0.8640611724723875,0.8647959183673469,0.865531914893617,0.8662691652470187,0.8670076726342711,0.8668941979522184,0.8676345004269855,0.8675213675213675,0.8682634730538922,0.8681506849315068,0.8688946015424165,0.8687821612349914,0.8695278969957082,0.8694158075601375,0.8693035253654342,0.8700516351118761,0.8699397071490095,0.8706896551724138,0.8714408973252804,0.8713298791018999,0.8720829732065687,0.8728373702422145,0.8735930735930736,0.8743500866551126,0.8742411101474414,0.8741319444444444,0.8748913987836664,0.8756521739130435,0.8755439512619669,0.8754355400696864,0.8753269398430689,0.8760907504363001,0.8768558951965065,0.8767482517482518,0.8775153105861767,0.8782837127845884,0.8790534618755478,0.8789473684210526,0.8788410886742757,0.8787346221441125,0.8795074758135444,0.8802816901408451,0.8801762114537445,0.8800705467372134,0.880847308031774,0.8807420494699647,0.8806366047745358,0.8814159292035398,0.8813108945969885,0.8820921985815603,0.8828748890860693,0.8827708703374778,0.8835555555555555,0.8843416370106761,0.8851291184327693,0.8859180035650623,0.8858162355040142,0.8857142857142857,0.8856121537086684,0.8855098389982111,0.8854073410922113,0.8862007168458781,0.8860986547085202,0.8859964093357271,0.8858939802336029,0.8857913669064749,0.8856885688568857,0.8864864864864865,0.8872858431018936,0.8880866425992779,0.8879855465221319,0.8878842676311031,0.8877828054298642,0.8885869565217391,0.8884859474161378,0.8892921960072595,0.8900999091734787,0.89,0.8898999090081893,0.8907103825136612,0.8906107566089334,0.8914233576642335,0.891324200913242,0.8921389396709324,0.8920402561756633,0.891941391941392,0.8927589367552704,0.8926605504587156,0.8934802571166207,0.8943014705882353,0.8942042318307267,0.8941068139963168,0.8949308755760369,0.8948339483394834,0.8956602031394275,0.8955637707948244,0.8963922294172063,0.8962962962962963,0.8962001853568119,0.8961038961038961,0.8960074280408542,0.895910780669145,0.8967441860465116,0.8966480446927374,0.896551724137931,0.8964552238805971,0.896358543417367,0.897196261682243,0.8971000935453695,0.897003745318352,0.8969072164948454,0.8977485928705441,0.8976525821596244,0.8975563909774437,0.8984007525870179,0.89924670433145,0.9000942507068803,0.9,0.8999055712936733,0.9007561436672968,0.9006622516556292,0.9015151515151515,0.9023696682464455,0.9022770398481973,0.9021842355175689,0.903041825095057,0.9029495718363464,0.9028571428571428,0.9027645376549094,0.9026717557251909,0.9024856596558317,0.9023923444976076,0.9032567049808429,0.9031639501438159,0.9030710172744721,0.9029779058597502,0.9028846153846154,0.9027911453320501,0.9036608863198459,0.9035679845708775,0.9034749034749034,0.9043478260869565,0.9042553191489362,0.904162633107454,0.9050387596899225,0.9059165858389913,0.9058252427184466,0.9067055393586005,0.9075875486381323,0.9074975657254138,0.9074074074074074,0.9073170731707317,0.908203125,0.9081133919843597,0.9080234833659491,0.9079333986287953,0.907843137254902,0.9077526987242395,0.9076620825147348,0.9075712881022615,0.90748031496063,0.9083743842364532,0.908284023668639,0.9081934846989141,0.908102766798419,0.9080118694362018,0.907920792079208,0.908820614469772,0.9097222222222222,0.9096325719960278,0.9095427435387674,0.909452736318408,0.9103585657370518,0.9112662013958126,0.9121756487025948,0.9120879120879121,0.913,0.9129129129129129,0.9128256513026052,0.9127382146439318,0.9126506024096386,0.9125628140703518,0.9124748490945674,0.9123867069486404,0.9122983870967742,0.9122098890010091,0.9131313131313131,0.9130434782608695,0.9129554655870445,0.9128672745694022,0.9127789046653144,0.9137055837563451,0.9136178861788617,0.91353001017294,0.9134419551934827,0.9133537206931702,0.9132653061224489,0.9141981613891726,0.9141104294478528,0.9140225179119754,0.9139344262295082,0.9148717948717948,0.9147843942505134,0.9146968139773896,0.9146090534979424,0.9145211122554068,0.9154639175257732,0.9153766769865841,0.9152892561983471,0.9162357807652534,0.9161490683229814,0.9160621761658031,0.9159751037344398,0.9158878504672897,0.9168399168399168,0.9167533818938606,0.9177083333333333,0.9176225234619395,0.9175365344467641,0.9184952978056427,0.9194560669456067,0.9193717277486911,0.9203354297693921,0.9202518363064008,0.9212184873949579,0.9221871713985279,0.9231578947368421,0.9230769230769231,0.9229957805907173,0.9229144667370645,0.9228329809725159,0.9227513227513228,0.9226694915254238,0.9236479321314952,0.9235668789808917,0.9234856535600425,0.9234042553191489,0.9233226837060703,0.9232409381663113,0.9231590181430096,0.9230769230769231,0.9229946524064171,0.923982869379015,0.92497320471597,0.9259656652360515,0.9258861439312567,0.9258064516129032,0.9257265877287406,0.9256465517241379,0.9255663430420712,0.9254859611231101,0.9264864864864865,0.9274891774891775,0.9284940411700975,0.928416485900217,0.9283387622149837,0.9282608695652174,0.9281828073993471,0.9291938997821351,0.9291166848418757,0.9290393013100436,0.9289617486338798,0.9288840262582057,0.9299014238773274,0.9298245614035088,0.9297475301866082,0.9307692307692308,0.9306930693069307,0.9317180616740088,0.9316427783902976,0.9315673289183223,0.9314917127071823,0.9314159292035398,0.9324473975636767,0.9323725055432373,0.9322974472807991,0.9322222222222222,0.932146829810901,0.933184855233853,0.9331103678929766,0.9330357142857143,0.9329608938547486,0.9328859060402684,0.9328107502799552,0.9338565022421524,0.9337822671156004,0.9337078651685393,0.9347581552305961,0.9346846846846847,0.9357384441939121,0.9356659142212189,0.9355932203389831,0.9355203619909502,0.9354473386183465,0.935374149659864,0.9364358683314415,0.9363636363636364,0.9362912400455062,0.9362186788154897,0.936145952109464,0.9372146118721462,0.9371428571428572,0.937070938215103,0.9369988545246277,0.9369266055045872,0.9368541905855339,0.9367816091954023,0.9367088607594937,0.9366359447004609,0.9377162629757786,0.9387990762124712,0.9387283236994219,0.9386574074074074,0.9397450753186558,0.9396751740139211,0.9407665505226481,0.9406976744186046,0.940628637951106,0.9405594405594405,0.94049008168028,0.9404205607476636,0.9403508771929825,0.9402810304449649,0.94021101992966,0.9401408450704225,0.9400705052878966,0.94,0.9399293286219081,0.9398584905660378,0.9397874852420307,0.9408983451536643,0.9408284023668639,0.9407582938388626,0.9418742586002372,0.9418052256532067,0.9417360285374554,0.9428571428571428,0.9427890345649583,0.9427207637231504,0.942652329749104,0.9425837320574163,0.9425149700598803,0.9424460431654677,0.9423769507803121,0.9423076923076923,0.9422382671480144,0.9421686746987952,0.9420989143546441,0.9420289855072463,0.9419588875453446,0.9418886198547215,0.9418181818181818,0.941747572815534,0.9416767922235723,0.9416058394160584,0.9415347137637028,0.9414634146341463,0.9413919413919414,0.941320293398533,0.9412484700122399,0.9411764705882353,0.9411042944785276,0.9422604422604423,0.942189421894219,0.9421182266009852,0.9420468557336621,0.9419753086419753,0.9419035846724351,0.9418316831683168,0.942998760842627,0.9429280397022333,0.9428571428571428,0.9427860696517413,0.9439601494396015,0.9438902743142145,0.9438202247191011,0.945,0.9449311639549437,0.9448621553884712,0.946047678795483,0.9459798994974874,0.9459119496855346,0.9458438287153652,0.9457755359394704,0.9457070707070707,0.9469026548672567,0.9468354430379747,0.9467680608365019,0.9467005076142132,0.9466327827191868,0.9465648854961832,0.9464968152866242,0.9464285714285714,0.946360153256705,0.9462915601023018,0.9462227912932138,0.9461538461538461,0.9460847240051348,0.9460154241645244,0.9459459459459459,0.9458762886597938,0.9458064516129032,0.9469598965071151,0.9468911917098446,0.9468223086900129,0.9467532467532468,0.9466840052015605,0.9466145833333334,0.9465449804432855,0.9477806788511749,0.9477124183006536,0.9476439790575916,0.9475753604193972,0.9487516425755584,0.9486842105263158,0.9486166007905138,0.9485488126649076,0.9498018494055482,0.9497354497354498,0.9496688741721855,0.9496021220159151,0.949535192563081,0.949468085106383,0.9494007989347537,0.9493333333333334,0.9492656875834445,0.9505347593582888,0.9518072289156626,0.9517426273458445,0.9516778523489933,0.9516129032258065,0.9515477792732167,0.9514824797843666,0.951417004048583,0.9513513513513514,0.9512855209742895,0.9512195121951219,0.9511533242876526,0.9510869565217391,0.9510204081632653,0.9508867667121419,0.9508196721311475,0.9507523939808481,0.9506849315068493,0.9506172839506173,0.9505494505494505,0.951856946354883,0.9517906336088154,0.9517241379310345,0.9516574585635359,0.9515905947441217,0.9528432732316228,0.9527777777777777,0.952712100139082,0.9540389972144847,0.9539748953974896,0.9539106145251397,0.9538461538461539,0.9537815126050421,0.9537166900420757,0.9536516853932584,0.9535864978902954,0.9535211267605633,0.9548660084626234,0.9548022598870056,0.9547383309759547,0.9546742209631728,0.9546099290780142,0.9545454545454546,0.9559032716927454,0.9572649572649573,0.9572039942938659,0.9571428571428572,0.9585121602288984,0.9584527220630372,0.9583931133428981,0.9583333333333334,0.958273381294964,0.9582132564841499,0.9581529581529582,0.958092485549133,0.9580318379160637,0.9579710144927536,0.9593613933236574,0.9593023255813954,0.9606986899563319,0.9606413994169096,0.9605839416058394,0.9605263157894737,0.9604685212298683,0.9604105571847508,0.960352422907489,0.9602941176470589,0.9602356406480118,0.9601769911504425,0.9615952732644018,0.9615384615384616,0.9614814814814815,0.9614243323442137,0.9613670133729569,0.9627976190476191,0.96274217585693,0.9626865671641791,0.9626307922272048,0.9625748502994012,0.9625187406296851,0.9624624624624625,0.9624060150375939,0.9623493975903614,0.9622926093514329,0.9622356495468278,0.962178517397882,0.9621212121212122,0.9620637329286799,0.9620060790273556,0.9619482496194824,0.9634146341463414,0.9633587786259542,0.963302752293578,0.9632465543644717,0.9631901840490797,0.963076923076923,0.963020030816641,0.9629629629629629,0.9629057187017002,0.9628482972136223,0.9627906976744186,0.9627329192546584,0.9626749611197511,0.9626168224299065,0.9625585023400937,0.9625,0.9624413145539906,0.9623824451410659,0.9638932496075353,0.9638364779874213,0.9637795275590552,0.9637223974763407,0.9636650868878357,0.9636075949367089,0.9635499207606973,0.9634920634920635,0.9634340222575517,0.964968152866242,0.9649122807017544,0.9648562300319489,0.9664,0.9663461538461539,0.9662921348314607,0.9662379421221865,0.966183574879227,0.9661290322580646,0.9660743134087237,0.9660194174757282,0.965964343598055,0.9659090909090909,0.9658536585365853,0.9657980456026058,0.965742251223491,0.9656862745098039,0.9656301145662848,0.9655737704918033,0.9655172413793104,0.9654036243822076,0.9653465346534653,0.9652892561983472,0.9652317880794702,0.9651741293532339,0.9651162790697675,0.9650582362728786,0.965,0.9648829431438127,0.964824120603015,0.9664429530201343,0.9663865546218487,0.9663299663299664,0.9662731871838112,0.9662162162162162,0.9661590524534687,0.9677966101694915,0.967741935483871,0.9676320272572402,0.9692832764505119,0.9692307692307692,0.9691252144082333,0.9690721649484536,0.9690189328743546,0.9706896551724138,0.9706390328151986,0.9705882352941176,0.9705372616984402,0.9704861111111112,0.9704347826086956,0.9703832752613241,0.9703315881326352,0.9702797202797203,0.9702276707530648,0.9701754385964912,0.9701230228471002,0.9700704225352113,0.9717813051146384,0.9717314487632509,0.9716814159292035,0.9716312056737588,0.9715808170515098,0.9715302491103203,0.9714795008912656,0.9714285714285714,0.9713774597495528,0.9713261648745519,0.9712746858168761,0.9712230215827338,0.9711711711711711,0.9729241877256317,0.972875226039783,0.9728260869565217,0.9727767695099818,0.9727272727272728,0.9726775956284153,0.9726277372262774,0.9725776965265083,0.9725274725274725,0.9724770642201835,0.9724264705882353,0.9723756906077348,0.9723247232472325,0.9722735674676525,0.9722222222222222,0.9721706864564007,0.9721189591078067,0.9720670391061452,0.9720149253731343,0.9719626168224299,0.9718574108818011,0.9718045112781954,0.9717514124293786,0.9716981132075472,0.9735349716446124,0.9734848484848485,0.9734345351043643,0.973384030418251,0.9733333333333334,0.9732824427480916,0.9732313575525813,0.9731800766283525,0.9731285988483686,0.9730769230769231,0.9730250481695568,0.972972972972973,0.9729206963249516,0.9728682170542635,0.9728155339805825,0.9727626459143969,0.9727095516569201,0.97265625,0.9726027397260274,0.9725490196078431,0.9724950884086444,0.9724409448818898,0.9723865877712031,0.9723320158102767,0.9722772277227723,0.9722222222222222,0.9721669980119284,0.9721115537848606,0.9720558882235529,0.972,0.9719438877755511,0.9718875502008032,0.971830985915493,0.9717741935483871,0.9717171717171718,0.97165991902834,0.973630831643002,0.975609756097561,0.9755600814663951,0.9755102040816327,0.9754601226993865,0.9754098360655737,0.9753593429158111,0.9753086419753086,0.9752577319587629,0.9752066115702479,0.9751552795031055,0.975103734439834,0.975051975051975,0.975,0.9749478079331941,0.9748953974895398,0.9748427672955975,0.9747899159663865,0.9747368421052631,0.9746835443037974,0.9746300211416491,0.9745762711864406,0.9745222929936306,0.9744680851063829,0.9744136460554371,0.9743589743589743,0.974304068522484,0.9742489270386266,0.9741935483870968,0.9741379310344828,0.9740820734341252,0.974025974025974,0.9739696312364425,0.9739130434782609,0.9738562091503268,0.9737991266375546,0.973741794310722,0.9736842105263158,0.9758241758241758,0.9757709251101322,0.9757174392935982,0.9756637168141593,0.975609756097561,0.9755555555555555,0.9755011135857461,0.9754464285714286,0.9753914988814317,0.9753363228699552,0.9752808988764045,0.9752252252252253,0.9751693002257337,0.9751131221719457,0.9750566893424036,0.9772727272727273,0.9772209567198178,0.9771689497716894,0.977116704805492,0.9770642201834863,0.9770114942528736,0.9769585253456221,0.976905311778291,0.9768518518518519,0.9791183294663574,0.9790697674418605,0.9790209790209791,0.9789719626168224,0.9789227166276346,0.9788732394366197,0.9788235294117648,0.9787735849056604,0.9787234042553191,0.9786729857819905,0.9786223277909739,0.9785714285714285,0.9785202863961814,0.9784688995215312,0.9784172661870504,0.9783653846153846,0.9783132530120482,0.9782608695652174,0.9782082324455206,0.9781021897810219,0.9780487804878049,0.9779951100244498,0.9779411764705882,0.9778869778869779,0.9778325123152709,0.9777777777777777,0.9777227722772277,0.9776674937965261,0.9776119402985075,0.9775561097256857,0.9775,0.9774436090225563,0.9773869346733668,0.9773299748110831,0.9772727272727273,0.9772151898734177,0.9771573604060914,0.9770992366412213,0.9770408163265306,0.9769820971867008,0.9769230769230769,0.9767441860465116,0.9792746113989638,0.9792207792207792,0.9817708333333334,0.9817232375979112,0.9816272965879265,0.9815789473684211,0.9815303430079155,0.9814814814814815,0.9814323607427056,0.9813829787234043,0.9812834224598931,0.9812332439678284,0.9811827956989247,0.9809264305177112,0.9808743169398907,0.9808219178082191,0.9807692307692307,0.9807162534435262,0.9806629834254144,0.9806094182825484,0.9805555555555555,0.9805013927576601,0.9804469273743017,0.9803921568627451,0.9803370786516854,0.9802816901408451,0.980225988700565,0.9801699716713881,0.9801136363636364,0.98005698005698,0.98,0.9799426934097422,0.9798850574712644,0.9797687861271677,0.9797101449275363,0.9796511627906976,0.9795918367346939,0.9794721407624634,0.9794117647058823,0.9793510324483776,0.9792899408284024,0.9792284866468842,0.9790419161676647,0.978978978978979,0.9789156626506024,0.9788519637462235,0.9787878787878788,0.9787234042553191,0.9786585365853658,0.9785932721712538,0.9785276073619632,0.9784615384615385,0.9783950617283951,0.978328173374613,0.9782608695652174,0.9781931464174455,0.978125,0.9780564263322884,0.9779874213836478,0.9779179810725552,0.9778481012658228,0.9777777777777777,0.9777070063694268,0.9776357827476039,0.9775641025641025,0.977491961414791,0.9774193548387097,0.9773462783171522,0.9772727272727273,0.9771986970684039,0.9771241830065359,0.9770491803278688,0.9769736842105263,0.976897689768977,0.9768211920529801,0.9767441860465116,0.9766666666666667,0.9765886287625418,0.9764309764309764,0.9763513513513513,0.976271186440678,0.9761904761904762,0.9795221843003413,0.9794520547945206,0.979381443298969,0.9827586206896551,0.9826989619377162,0.9826388888888888,0.9825783972125436,0.9825174825174825,0.9824561403508771,0.9823943661971831,0.982078853046595,0.9820143884892086,0.9855595667870036,0.9855072463768116,0.9854545454545455,0.9854014598540146,0.9853479853479854,0.9852941176470589,0.985239852398524,0.9851851851851852,0.9851301115241635,0.9850746268656716,0.9850187265917603,0.9849624060150376,0.9849056603773585,0.9848484848484849,0.9847908745247148,0.9847328244274809,0.9846743295019157,0.9846153846153847,0.9845559845559846,0.9844961240310077,0.9844357976653697,0.984375,0.984313725490196,0.984251968503937,0.9841269841269841,0.9840637450199203,0.984,0.9839357429718876,0.9838709677419355,0.9838056680161943,0.983739837398374,0.9836734693877551,0.9836065573770492,0.9835390946502057,0.9834710743801653,0.983402489626556,0.9833333333333333,0.9832635983263598,0.9831932773109243,0.9831223628691983,0.9830508474576272,0.9829787234042553,0.9829059829059829,0.9828326180257511,0.9827586206896551,0.9826839826839827,0.9826086956521739,0.982532751091703,0.9824561403508771,0.9823788546255506,0.9823008849557522,0.9822222222222222,0.9820627802690582,0.9819819819819819,0.9819004524886877,0.9818181818181818,0.9817351598173516,0.981651376146789,0.9815668202764977,0.9814814814814815,0.9813953488372092,0.9811320754716981,0.981042654028436,0.9809523809523809,0.9808612440191388,0.9807692307692307,0.9806763285024155,0.9805825242718447,0.9804878048780488,0.9803921568627451,0.9802955665024631,0.9801980198019802,0.9800995024875622,0.98,0.9798994974874372,0.9797979797979798,0.9796954314720813,0.9795918367346939,0.9794871794871794,0.979381443298969,0.9792746113989638,0.9791666666666666,0.9790575916230366,0.9789473684210527,0.9788359788359788,0.9787234042553191,0.9786096256684492,0.9783783783783784,0.9782608695652174,0.9781420765027322,0.978021978021978,0.9779005524861878,0.9777777777777777,0.9776536312849162,0.9775280898876404,0.9774011299435028,0.9772727272727273,0.9771428571428571,0.9770114942528736,0.976878612716763,0.9767441860465116,0.9766081871345029,0.9764705882352941,0.9763313609467456,0.9761904761904762,0.9760479041916168,0.9759036144578314,0.9757575757575757,0.975609756097561,0.9754601226993865,0.9753086419753086,0.9751552795031055,0.975,0.9748427672955975,0.9746835443037974,0.9745222929936306,0.9743589743589743,0.9741935483870968,0.974025974025974,0.9738562091503268,0.9736842105263158,0.9733333333333334,0.9731543624161074,0.972972972972973,0.9727891156462585,0.9726027397260274,0.9724137931034482,0.9722222222222222,0.972027972027972,0.971830985915493,0.9716312056737588,0.9714285714285714,0.9712230215827338,0.9710144927536232,0.9708029197080292,0.9705882352941176,0.9703703703703703,0.9701492537313433,0.9699248120300752,0.9772727272727273,0.9770992366412213,0.9846153846153847,0.9844961240310077,0.984375,0.984251968503937,0.9841269841269841,0.984,0.9838709677419355,0.983739837398374,0.9836065573770492,0.9834710743801653,0.9833333333333333,0.9830508474576272,0.9829059829059829,0.9826086956521739,0.9824561403508771,0.9819819819819819,0.9818181818181818,0.981651376146789,0.9814814814814815,0.9811320754716981,0.9803921568627451,0.9801980198019802,0.98,0.9797979797979798,0.9795918367346939,0.979381443298969,0.9791666666666666,0.9789473684210527,0.9787234042553191,0.978021978021978,0.9777777777777777,0.9775280898876404,0.9772727272727273,0.9767441860465116,0.9764705882352941,0.975609756097561,0.9753086419753086,0.974025974025974,0.9733333333333334,0.972972972972973,0.9726027397260274,0.9722222222222222,0.9714285714285714,0.9710144927536232,0.9705882352941176,0.9701492537313433,0.96875,0.9682539682539683,0.967741935483871,0.9672131147540983,0.9661016949152542,0.9655172413793104,0.9642857142857143,0.9636363636363636,0.9629629629629629,0.9615384615384616,0.9607843137254902,0.98,0.9795918367346939,0.9791666666666666,0.9787234042553191,0.9782608695652174,0.9777777777777777,0.9772727272727273,0.9767441860465116,0.9761904761904762,0.975609756097561,0.975,0.9743589743589743,0.972972972972973,0.9722222222222222,0.9714285714285714,0.9705882352941176,0.96875,0.9655172413793104,0.9642857142857143,0.9629629629629629,0.9615384615384616,0.96,0.9583333333333334,0.9523809523809523,0.95,0.9473684210526315,0.9444444444444444,0.9411764705882353,0.9375,0.875,0.8571428571428571,0.8333333333333334,0.8,0.75,0.6666666666666666,0.5,1.0,1.0],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Recall\"},\"constrain\":\"domain\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Precision\"},\"scaleanchor\":\"x\",\"scaleratio\":1},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Precision-Recall Curve (AUC=0.9107)\"},\"height\":600,\"width\":800,\"shapes\":[{\"line\":{\"dash\":\"dash\"},\"type\":\"line\",\"x0\":0,\"x1\":1,\"y0\":1,\"y1\":0}],\"showlegend\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('1ae98799-3f09-4d05-8ab4-ce28a95a9047');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"}],"source":["target_score = lgb_clf.predict_proba(features_valid)[:, 1]\n","\n","fpr, tpr, thresholds = roc_curve(target_valid, target_score)\n","\n","fig = px.area(\n","    x=fpr, y=tpr,\n","    title=f'ROC Curve (AUC={auc(fpr, tpr):.4f})',\n","    labels=dict(x='False Positive Rate', y='True Positive Rate'),\n","    width=800, height=600\n",")\n","fig.add_shape(\n","    type='line', line=dict(dash='dash'),\n","    x0=0, x1=1, y0=0, y1=1\n",")\n","\n","fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n","fig.update_xaxes(constrain='domain')\n","fig.update_layout(showlegend=False)\n","fig.show()\n","\n","precision, recall, thresholds = precision_recall_curve(target_valid, target_score)\n","\n","fig = px.area(\n","    x=recall, y=precision,\n","    title=f'Precision-Recall Curve (AUC={auc(fpr, tpr):.4f})',\n","    labels=dict(x='Recall', y='Precision'),\n","    width=800, height=600\n",")\n","fig.add_shape(\n","    type='line', line=dict(dash='dash'),\n","    x0=0, x1=1, y0=1, y1=0\n",")\n","fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n","fig.update_xaxes(constrain='domain')\n","fig.update_layout(showlegend=False)\n","fig.show()"]},{"cell_type":"markdown","metadata":{},"source":["--------"]},{"cell_type":"markdown","metadata":{},"source":["# XGBoost"]},{"cell_type":"code","execution_count":92,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T16:54:34.856327Z","iopub.status.busy":"2023-11-30T16:54:34.855760Z","iopub.status.idle":"2023-11-30T17:05:01.539192Z","shell.execute_reply":"2023-11-30T17:05:01.538397Z","shell.execute_reply.started":"2023-11-30T16:54:34.856295Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Runtime:\n","CPU times: user 9.49 s, sys: 2.39 s, total: 11.9 s\n","Wall time: 2min 15s\n"]}],"source":["%%time\n","\n","xgb_model = xgb.XGBClassifier(random_state=random_state) # fix encoding if issues arise\n","\n","xgb_params = {\n","#'min_child_weight': [1, 5, 10],\n","#'gamma': [0.5, 1, 1.5, 2, 5],\n","#'subsample': [0.6, 0.8, 1.0],\n","#'colsample_bytree': [0.6, 0.8, 1.0],\n","'booster': ['dart', 'gblinear', 'gbtree'],\n","#'max_leaves': [0,6,12,16,25,35],\n","'learning_rate': [0.01, 0.05, 0.08, 0.1, 0.15, 0.2],\n","#'max_depth': [1,,6,8,12,15,18,20],\n","'eval_metric': ['auc'],\n","}\n","\n","xgb_clf = RandomizedSearchCV(xgb_model, xgb_params, scoring='roc_auc', n_jobs=-1, cv=cv)\n","xgb_clf.fit(features_train, target_train)\n","# create a variable for the best model\n","best_xgb = xgb_clf.best_estimator_\n","xgb_pred = best_xgb.predict(features_valid)\n","print('Runtime:')"]},{"cell_type":"code","execution_count":93,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 1000x500 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["sns.set(style=\"white\", color_codes=True)\n","plt.rcParams['axes.linewidth'] = 0.1\n","\n","fig, ax = plt.subplots(figsize = (10,5))\n","disp = CalibrationDisplay.from_estimator(xgb_clf, features_valid, target_valid, ax=ax)\n","plt.title('Calibration Chart - XGB Classifier', fontsize=10)\n","ax.set_xlabel('Mean predicted probability (Positive class: 1)', fontsize=10)\n","ax.set_ylabel('Fraction of positives (Positive class: 1)',fontsize=10)\n","\n","ax.tick_params(color='gray', labelcolor='gray')\n","for spine in ax.spines.values():\n","    spine.set_edgecolor('gray')\n","\n","\n","fig.tight_layout()\n","plt.legend(fontsize=8)\n","plt.show()"]},{"cell_type":"code","execution_count":94,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T17:05:01.545140Z","iopub.status.busy":"2023-11-30T17:05:01.543025Z","iopub.status.idle":"2023-11-30T17:05:07.446876Z","shell.execute_reply":"2023-11-30T17:05:07.446006Z","shell.execute_reply.started":"2023-11-30T17:05:01.545108Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Cross Validation Scores: [0.92986224 0.91388249 0.92603687 0.87318548 0.93358295 0.90967742\n"," 0.90014401 0.89451325 0.90941401 0.90311489 0.88544262 0.88245968\n"," 0.92200461 0.8890841  0.93078917 0.91131912 0.93355415 0.89343318\n"," 0.9351884  0.9088939  0.89475041 0.92108295 0.9141129  0.91382488\n"," 0.89634217 0.93257488 0.92623848 0.90460829 0.91146556 0.88060564\n"," 0.91150442 0.89634217 0.90573157 0.93508065 0.92088134 0.92635369\n"," 0.90869816 0.90216014 0.88869626 0.90242141 0.92808661 0.92684332\n"," 0.88461982 0.88338134 0.91131912 0.8750576  0.91926843 0.92413594\n"," 0.8925393  0.91525081]\n"]}],"source":["xgb_scores = cross_val_score(xgb_model, features_train, target_train, cv=cv, scoring='roc_auc')\n","print('Cross Validation Scores: {}'.format(xgb_scores))"]},{"cell_type":"code","execution_count":95,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T17:05:07.453675Z","iopub.status.busy":"2023-11-30T17:05:07.451234Z","iopub.status.idle":"2023-11-30T17:05:07.470522Z","shell.execute_reply":"2023-11-30T17:05:07.469855Z","shell.execute_reply.started":"2023-11-30T17:05:07.453628Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Best hyperparameters: {'learning_rate': 0.2, 'eval_metric': 'auc', 'booster': 'dart'}\n","\n","Best score: 0.910742213150237\n","\n","Average Cross Validation Score: 0.908791215308284\n","\n","ROC AUC Score - Validation Dataset: 0.9211217004622846\n"]}],"source":["# summary\n","print('Best hyperparameters:',  xgb_clf.best_params_)\n","print()\n","print('Best score:',  xgb_clf.best_score_)\n","print()\n","print('Average Cross Validation Score: {}'.format(xgb_scores.mean()))\n","print()\n","print('ROC AUC Score - Validation Dataset:',  roc_auc_score(target_valid, xgb_clf.predict_proba(features_valid)[:, 1]))"]},{"cell_type":"markdown","metadata":{},"source":["# ROC AUC Curve - XGBoost"]},{"cell_type":"code","execution_count":96,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T17:05:07.476704Z","iopub.status.busy":"2023-11-30T17:05:07.474433Z","iopub.status.idle":"2023-11-30T17:05:07.619121Z","shell.execute_reply":"2023-11-30T17:05:07.618202Z","shell.execute_reply.started":"2023-11-30T17:05:07.476645Z"},"trusted":true},"outputs":[{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"fillpattern":{"shape":""},"hovertemplate":"False Positive Rate=%{x}<br>True Positive Rate=%{y}<extra></extra>","legendgroup":"","line":{"color":"#636efa"},"marker":{"symbol":"circle"},"mode":"lines","name":"","orientation":"v","showlegend":false,"stackgroup":"1","type":"scatter","x":[0,0,0,0.00267379679144385,0.00267379679144385,0.00267379679144385,0.00267379679144385,0.0053475935828877,0.0053475935828877,0.008021390374331552,0.008021390374331552,0.013368983957219251,0.013368983957219251,0.013368983957219251,0.013368983957219251,0.016042780748663103,0.016042780748663103,0.016042780748663103,0.016042780748663103,0.01871657754010695,0.01871657754010695,0.01871657754010695,0.01871657754010695,0.0213903743315508,0.0213903743315508,0.02406417112299465,0.02406417112299465,0.02406417112299465,0.02406417112299465,0.02406417112299465,0.02406417112299465,0.026737967914438502,0.026737967914438502,0.029411764705882353,0.029411764705882353,0.03208556149732621,0.03208556149732621,0.034759358288770054,0.034759358288770054,0.0374331550802139,0.0374331550802139,0.040106951871657755,0.040106951871657755,0.0427807486631016,0.0427807486631016,0.045454545454545456,0.045454545454545456,0.0481283422459893,0.0481283422459893,0.05080213903743316,0.05080213903743316,0.053475935828877004,0.053475935828877004,0.05614973262032086,0.05614973262032086,0.058823529411764705,0.058823529411764705,0.06149732620320856,0.06149732620320856,0.06417112299465241,0.06417112299465241,0.06684491978609626,0.06684491978609626,0.06951871657754011,0.06951871657754011,0.07219251336898395,0.07219251336898395,0.0748663101604278,0.0748663101604278,0.07754010695187166,0.07754010695187166,0.08021390374331551,0.08021390374331551,0.08288770053475936,0.08288770053475936,0.0855614973262032,0.0855614973262032,0.08823529411764706,0.08823529411764706,0.09090909090909091,0.09090909090909091,0.0962566844919786,0.0962566844919786,0.09893048128342247,0.09893048128342247,0.10160427807486631,0.10160427807486631,0.10695187165775401,0.10695187165775401,0.10962566844919786,0.10962566844919786,0.11229946524064172,0.11229946524064172,0.11497326203208556,0.11497326203208556,0.11764705882352941,0.11764705882352941,0.12032085561497326,0.12032085561497326,0.12566844919786097,0.12566844919786097,0.12834224598930483,0.12834224598930483,0.13101604278074866,0.13101604278074866,0.13368983957219252,0.13368983957219252,0.13636363636363635,0.13636363636363635,0.13903743315508021,0.13903743315508021,0.14171122994652408,0.14171122994652408,0.1443850267379679,0.1443850267379679,0.14705882352941177,0.14705882352941177,0.1497326203208556,0.1497326203208556,0.15240641711229946,0.15240641711229946,0.15508021390374332,0.15508021390374332,0.15775401069518716,0.15775401069518716,0.16042780748663102,0.16042780748663102,0.16310160427807488,0.16310160427807488,0.1657754010695187,0.1657754010695187,0.1711229946524064,0.1711229946524064,0.17379679144385027,0.17379679144385027,0.18449197860962566,0.18449197860962566,0.18983957219251338,0.18983957219251338,0.1925133689839572,0.1925133689839572,0.19786096256684493,0.19786096256684493,0.20053475935828877,0.20053475935828877,0.20320855614973263,0.20320855614973263,0.20588235294117646,0.20588235294117646,0.21122994652406418,0.21122994652406418,0.21390374331550802,0.21390374331550802,0.21657754010695188,0.21657754010695188,0.2192513368983957,0.2192513368983957,0.22192513368983957,0.22192513368983957,0.22459893048128343,0.22459893048128343,0.22727272727272727,0.22727272727272727,0.22994652406417113,0.22994652406417113,0.23796791443850268,0.23796791443850268,0.24064171122994651,0.24064171122994651,0.24331550802139038,0.24331550802139038,0.24598930481283424,0.24598930481283424,0.24866310160427807,0.24866310160427807,0.2540106951871658,0.2540106951871658,0.2620320855614973,0.2620320855614973,0.2647058823529412,0.2647058823529412,0.27540106951871657,0.27540106951871657,0.27807486631016043,0.27807486631016043,0.2807486631016043,0.2807486631016043,0.28342245989304815,0.28342245989304815,0.28609625668449196,0.28609625668449196,0.29411764705882354,0.29411764705882354,0.30213903743315507,0.30213903743315507,0.3155080213903743,0.3155080213903743,0.32085561497326204,0.32085561497326204,0.3235294117647059,0.3235294117647059,0.339572192513369,0.339572192513369,0.3422459893048128,0.3422459893048128,0.34759358288770054,0.34759358288770054,0.3502673796791444,0.3502673796791444,0.36363636363636365,0.36363636363636365,0.3663101604278075,0.3663101604278075,0.37967914438502676,0.37967914438502676,0.3850267379679144,0.3850267379679144,0.3877005347593583,0.3877005347593583,0.39037433155080214,0.39037433155080214,0.393048128342246,0.393048128342246,0.39572192513368987,0.39572192513368987,0.40106951871657753,0.40106951871657753,0.40641711229946526,0.40641711229946526,0.42780748663101603,0.42780748663101603,0.4304812834224599,0.4304812834224599,0.44385026737967914,0.44385026737967914,0.45454545454545453,0.45454545454545453,0.4893048128342246,0.4893048128342246,0.5026737967914439,0.5026737967914439,0.5080213903743316,0.5080213903743316,0.5294117647058824,0.5347593582887701,0.5588235294117647,0.5588235294117647,1],"xaxis":"x","y":[0,0.000968054211035818,0.015488867376573089,0.015488867376573089,0.027105517909002903,0.02904162633107454,0.031945788964181994,0.031945788964181994,0.044530493707647625,0.044530493707647625,0.05517909002904162,0.05517909002904162,0.08615682478218781,0.08809293320425944,0.14133591481122942,0.14133591481122942,0.2042594385285576,0.20619554695062922,0.22749273959341723,0.22749273959341723,0.27783155856727976,0.2797676669893514,0.2971926427879961,0.2971926427879961,0.3388189738625363,0.3388189738625363,0.38528557599225555,0.3872216844143272,0.38818973862536305,0.39012584704743464,0.3978702807357212,0.3978702807357212,0.42400774443368827,0.42400774443368827,0.4453049370764763,0.4453049370764763,0.462729912875121,0.462729912875121,0.46950629235237173,0.46950629235237173,0.48596321393998065,0.48596321393998065,0.5014520813165537,0.5014520813165537,0.5091965150048403,0.5091965150048403,0.5450145208131656,0.5450145208131656,0.547918683446273,0.547918683446273,0.5682478218780251,0.5682478218780251,0.5750242013552759,0.5750242013552759,0.5808325266214908,0.5808325266214908,0.643756050338819,0.643756050338819,0.6563407550822846,0.6563407550822846,0.665053242981607,0.665053242981607,0.6766698935140368,0.6766698935140368,0.6795740561471443,0.6795740561471443,0.68054211035818,0.68054211035818,0.6844143272023233,0.6844143272023233,0.6892545982575025,0.6892545982575025,0.6931268151016456,0.6931268151016456,0.6940948693126815,0.6940948693126815,0.7057115198451114,0.7057115198451114,0.707647628267183,0.707647628267183,0.7144240077444337,0.7144240077444337,0.7192642787996127,0.7192642787996127,0.7337850919651501,0.7337850919651501,0.739593417231365,0.739593417231365,0.7473378509196515,0.7473378509196515,0.7512100677637947,0.7512100677637947,0.755082284607938,0.755082284607938,0.7608906098741529,0.7608906098741529,0.7783155856727977,0.7783155856727977,0.7889641819941917,0.7889641819941917,0.7947725072604066,0.7947725072604066,0.7996127783155856,0.7996127783155856,0.8073572120038722,0.8073572120038722,0.8092933204259438,0.8092933204259438,0.814133591481123,0.814133591481123,0.8151016456921588,0.8151016456921588,0.8160696999031946,0.8160696999031946,0.8354307841239109,0.8354307841239109,0.8363988383349468,0.8363988383349468,0.8383349467570184,0.8383349467570184,0.8402710551790901,0.8402710551790901,0.8412391093901258,0.8412391093901258,0.8480154888673765,0.8480154888673765,0.856727976766699,0.856727976766699,0.8586640851887706,0.8586640851887706,0.8664085188770572,0.8664085188770572,0.8673765730880929,0.8673765730880929,0.8731848983543078,0.8731848983543078,0.8789932236205228,0.8789932236205228,0.8818973862536302,0.8818973862536302,0.8838334946757018,0.8838334946757018,0.8848015488867377,0.8848015488867377,0.8857696030977735,0.8857696030977735,0.8867376573088093,0.8867376573088093,0.8906098741529526,0.8906098741529526,0.8925459825750242,0.8925459825750242,0.8944820909970959,0.8944820909970959,0.8973862536302033,0.8973862536302033,0.8983543078412392,0.8983543078412392,0.8993223620522749,0.8993223620522749,0.9070667957405615,0.9070667957405615,0.9119070667957405,0.9119070667957405,0.914811229428848,0.914811229428848,0.9177153920619555,0.9177153920619555,0.9186834462729913,0.9186834462729913,0.9244917715392061,0.9244917715392061,0.925459825750242,0.925459825750242,0.9370764762826719,0.9370764762826719,0.9380445304937076,0.9380445304937076,0.9419167473378509,0.9419167473378509,0.9438528557599225,0.9438528557599225,0.9448209099709584,0.9448209099709584,0.9515972894482091,0.9515972894482091,0.9535333978702807,0.9535333978702807,0.957405614714424,0.957405614714424,0.9593417231364957,0.9593417231364957,0.9622458857696031,0.9622458857696031,0.9641819941916747,0.9641819941916747,0.9690222652468539,0.9690222652468539,0.9699903194578896,0.9699903194578896,0.9709583736689255,0.9709583736689255,0.9719264278799613,0.9719264278799613,0.972894482090997,0.972894482090997,0.9738625363020329,0.9738625363020329,0.9748305905130688,0.9748305905130688,0.9757986447241046,0.9757986447241046,0.9767666989351403,0.9767666989351403,0.9777347531461762,0.9777347531461762,0.978702807357212,0.978702807357212,0.9806389157792836,0.9806389157792836,0.9835430784123911,0.9835430784123911,0.9854791868344628,0.9854791868344628,0.989351403678606,0.989351403678606,0.9903194578896418,0.9903194578896418,0.9912875121006777,0.9912875121006777,0.9932236205227493,0.9932236205227493,0.9941916747337851,0.9941916747337851,0.995159728944821,0.995159728944821,0.9961277831558567,0.9961277831558567,0.9970958373668926,0.9970958373668926,0.9980638915779284,0.9980638915779284,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,1,1],"yaxis":"y"}],"layout":{"height":600,"legend":{"tracegroupgap":0},"shapes":[{"line":{"dash":"dash"},"type":"line","x0":0,"x1":1,"y0":0,"y1":1}],"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"title":{"text":"ROC Curve (AUC=0.9211)"},"width":800,"xaxis":{"anchor":"y","constrain":"domain","domain":[0,1],"title":{"text":"False Positive Rate"}},"yaxis":{"anchor":"x","domain":[0,1],"scaleanchor":"x","scaleratio":1,"title":{"text":"True Positive Rate"}}}},"text/html":["<div>                            <div id=\"5b5a5fe0-ee37-4a0a-af9e-d5fc5e29fd51\" class=\"plotly-graph-div\" style=\"height:600px; width:800px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"5b5a5fe0-ee37-4a0a-af9e-d5fc5e29fd51\")) {                    Plotly.newPlot(                        \"5b5a5fe0-ee37-4a0a-af9e-d5fc5e29fd51\",                        [{\"fillpattern\":{\"shape\":\"\"},\"hovertemplate\":\"False Positive Rate=%{x}\\u003cbr\\u003eTrue Positive Rate=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"stackgroup\":\"1\",\"x\":[0.0,0.0,0.0,0.00267379679144385,0.00267379679144385,0.00267379679144385,0.00267379679144385,0.0053475935828877,0.0053475935828877,0.008021390374331552,0.008021390374331552,0.013368983957219251,0.013368983957219251,0.013368983957219251,0.013368983957219251,0.016042780748663103,0.016042780748663103,0.016042780748663103,0.016042780748663103,0.01871657754010695,0.01871657754010695,0.01871657754010695,0.01871657754010695,0.0213903743315508,0.0213903743315508,0.02406417112299465,0.02406417112299465,0.02406417112299465,0.02406417112299465,0.02406417112299465,0.02406417112299465,0.026737967914438502,0.026737967914438502,0.029411764705882353,0.029411764705882353,0.03208556149732621,0.03208556149732621,0.034759358288770054,0.034759358288770054,0.0374331550802139,0.0374331550802139,0.040106951871657755,0.040106951871657755,0.0427807486631016,0.0427807486631016,0.045454545454545456,0.045454545454545456,0.0481283422459893,0.0481283422459893,0.05080213903743316,0.05080213903743316,0.053475935828877004,0.053475935828877004,0.05614973262032086,0.05614973262032086,0.058823529411764705,0.058823529411764705,0.06149732620320856,0.06149732620320856,0.06417112299465241,0.06417112299465241,0.06684491978609626,0.06684491978609626,0.06951871657754011,0.06951871657754011,0.07219251336898395,0.07219251336898395,0.0748663101604278,0.0748663101604278,0.07754010695187166,0.07754010695187166,0.08021390374331551,0.08021390374331551,0.08288770053475936,0.08288770053475936,0.0855614973262032,0.0855614973262032,0.08823529411764706,0.08823529411764706,0.09090909090909091,0.09090909090909091,0.0962566844919786,0.0962566844919786,0.09893048128342247,0.09893048128342247,0.10160427807486631,0.10160427807486631,0.10695187165775401,0.10695187165775401,0.10962566844919786,0.10962566844919786,0.11229946524064172,0.11229946524064172,0.11497326203208556,0.11497326203208556,0.11764705882352941,0.11764705882352941,0.12032085561497326,0.12032085561497326,0.12566844919786097,0.12566844919786097,0.12834224598930483,0.12834224598930483,0.13101604278074866,0.13101604278074866,0.13368983957219252,0.13368983957219252,0.13636363636363635,0.13636363636363635,0.13903743315508021,0.13903743315508021,0.14171122994652408,0.14171122994652408,0.1443850267379679,0.1443850267379679,0.14705882352941177,0.14705882352941177,0.1497326203208556,0.1497326203208556,0.15240641711229946,0.15240641711229946,0.15508021390374332,0.15508021390374332,0.15775401069518716,0.15775401069518716,0.16042780748663102,0.16042780748663102,0.16310160427807488,0.16310160427807488,0.1657754010695187,0.1657754010695187,0.1711229946524064,0.1711229946524064,0.17379679144385027,0.17379679144385027,0.18449197860962566,0.18449197860962566,0.18983957219251338,0.18983957219251338,0.1925133689839572,0.1925133689839572,0.19786096256684493,0.19786096256684493,0.20053475935828877,0.20053475935828877,0.20320855614973263,0.20320855614973263,0.20588235294117646,0.20588235294117646,0.21122994652406418,0.21122994652406418,0.21390374331550802,0.21390374331550802,0.21657754010695188,0.21657754010695188,0.2192513368983957,0.2192513368983957,0.22192513368983957,0.22192513368983957,0.22459893048128343,0.22459893048128343,0.22727272727272727,0.22727272727272727,0.22994652406417113,0.22994652406417113,0.23796791443850268,0.23796791443850268,0.24064171122994651,0.24064171122994651,0.24331550802139038,0.24331550802139038,0.24598930481283424,0.24598930481283424,0.24866310160427807,0.24866310160427807,0.2540106951871658,0.2540106951871658,0.2620320855614973,0.2620320855614973,0.2647058823529412,0.2647058823529412,0.27540106951871657,0.27540106951871657,0.27807486631016043,0.27807486631016043,0.2807486631016043,0.2807486631016043,0.28342245989304815,0.28342245989304815,0.28609625668449196,0.28609625668449196,0.29411764705882354,0.29411764705882354,0.30213903743315507,0.30213903743315507,0.3155080213903743,0.3155080213903743,0.32085561497326204,0.32085561497326204,0.3235294117647059,0.3235294117647059,0.339572192513369,0.339572192513369,0.3422459893048128,0.3422459893048128,0.34759358288770054,0.34759358288770054,0.3502673796791444,0.3502673796791444,0.36363636363636365,0.36363636363636365,0.3663101604278075,0.3663101604278075,0.37967914438502676,0.37967914438502676,0.3850267379679144,0.3850267379679144,0.3877005347593583,0.3877005347593583,0.39037433155080214,0.39037433155080214,0.393048128342246,0.393048128342246,0.39572192513368987,0.39572192513368987,0.40106951871657753,0.40106951871657753,0.40641711229946526,0.40641711229946526,0.42780748663101603,0.42780748663101603,0.4304812834224599,0.4304812834224599,0.44385026737967914,0.44385026737967914,0.45454545454545453,0.45454545454545453,0.4893048128342246,0.4893048128342246,0.5026737967914439,0.5026737967914439,0.5080213903743316,0.5080213903743316,0.5294117647058824,0.5347593582887701,0.5588235294117647,0.5588235294117647,1.0],\"xaxis\":\"x\",\"y\":[0.0,0.000968054211035818,0.015488867376573089,0.015488867376573089,0.027105517909002903,0.02904162633107454,0.031945788964181994,0.031945788964181994,0.044530493707647625,0.044530493707647625,0.05517909002904162,0.05517909002904162,0.08615682478218781,0.08809293320425944,0.14133591481122942,0.14133591481122942,0.2042594385285576,0.20619554695062922,0.22749273959341723,0.22749273959341723,0.27783155856727976,0.2797676669893514,0.2971926427879961,0.2971926427879961,0.3388189738625363,0.3388189738625363,0.38528557599225555,0.3872216844143272,0.38818973862536305,0.39012584704743464,0.3978702807357212,0.3978702807357212,0.42400774443368827,0.42400774443368827,0.4453049370764763,0.4453049370764763,0.462729912875121,0.462729912875121,0.46950629235237173,0.46950629235237173,0.48596321393998065,0.48596321393998065,0.5014520813165537,0.5014520813165537,0.5091965150048403,0.5091965150048403,0.5450145208131656,0.5450145208131656,0.547918683446273,0.547918683446273,0.5682478218780251,0.5682478218780251,0.5750242013552759,0.5750242013552759,0.5808325266214908,0.5808325266214908,0.643756050338819,0.643756050338819,0.6563407550822846,0.6563407550822846,0.665053242981607,0.665053242981607,0.6766698935140368,0.6766698935140368,0.6795740561471443,0.6795740561471443,0.68054211035818,0.68054211035818,0.6844143272023233,0.6844143272023233,0.6892545982575025,0.6892545982575025,0.6931268151016456,0.6931268151016456,0.6940948693126815,0.6940948693126815,0.7057115198451114,0.7057115198451114,0.707647628267183,0.707647628267183,0.7144240077444337,0.7144240077444337,0.7192642787996127,0.7192642787996127,0.7337850919651501,0.7337850919651501,0.739593417231365,0.739593417231365,0.7473378509196515,0.7473378509196515,0.7512100677637947,0.7512100677637947,0.755082284607938,0.755082284607938,0.7608906098741529,0.7608906098741529,0.7783155856727977,0.7783155856727977,0.7889641819941917,0.7889641819941917,0.7947725072604066,0.7947725072604066,0.7996127783155856,0.7996127783155856,0.8073572120038722,0.8073572120038722,0.8092933204259438,0.8092933204259438,0.814133591481123,0.814133591481123,0.8151016456921588,0.8151016456921588,0.8160696999031946,0.8160696999031946,0.8354307841239109,0.8354307841239109,0.8363988383349468,0.8363988383349468,0.8383349467570184,0.8383349467570184,0.8402710551790901,0.8402710551790901,0.8412391093901258,0.8412391093901258,0.8480154888673765,0.8480154888673765,0.856727976766699,0.856727976766699,0.8586640851887706,0.8586640851887706,0.8664085188770572,0.8664085188770572,0.8673765730880929,0.8673765730880929,0.8731848983543078,0.8731848983543078,0.8789932236205228,0.8789932236205228,0.8818973862536302,0.8818973862536302,0.8838334946757018,0.8838334946757018,0.8848015488867377,0.8848015488867377,0.8857696030977735,0.8857696030977735,0.8867376573088093,0.8867376573088093,0.8906098741529526,0.8906098741529526,0.8925459825750242,0.8925459825750242,0.8944820909970959,0.8944820909970959,0.8973862536302033,0.8973862536302033,0.8983543078412392,0.8983543078412392,0.8993223620522749,0.8993223620522749,0.9070667957405615,0.9070667957405615,0.9119070667957405,0.9119070667957405,0.914811229428848,0.914811229428848,0.9177153920619555,0.9177153920619555,0.9186834462729913,0.9186834462729913,0.9244917715392061,0.9244917715392061,0.925459825750242,0.925459825750242,0.9370764762826719,0.9370764762826719,0.9380445304937076,0.9380445304937076,0.9419167473378509,0.9419167473378509,0.9438528557599225,0.9438528557599225,0.9448209099709584,0.9448209099709584,0.9515972894482091,0.9515972894482091,0.9535333978702807,0.9535333978702807,0.957405614714424,0.957405614714424,0.9593417231364957,0.9593417231364957,0.9622458857696031,0.9622458857696031,0.9641819941916747,0.9641819941916747,0.9690222652468539,0.9690222652468539,0.9699903194578896,0.9699903194578896,0.9709583736689255,0.9709583736689255,0.9719264278799613,0.9719264278799613,0.972894482090997,0.972894482090997,0.9738625363020329,0.9738625363020329,0.9748305905130688,0.9748305905130688,0.9757986447241046,0.9757986447241046,0.9767666989351403,0.9767666989351403,0.9777347531461762,0.9777347531461762,0.978702807357212,0.978702807357212,0.9806389157792836,0.9806389157792836,0.9835430784123911,0.9835430784123911,0.9854791868344628,0.9854791868344628,0.989351403678606,0.989351403678606,0.9903194578896418,0.9903194578896418,0.9912875121006777,0.9912875121006777,0.9932236205227493,0.9932236205227493,0.9941916747337851,0.9941916747337851,0.995159728944821,0.995159728944821,0.9961277831558567,0.9961277831558567,0.9970958373668926,0.9970958373668926,0.9980638915779284,0.9980638915779284,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,1.0,1.0],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"False Positive Rate\"},\"constrain\":\"domain\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"True Positive Rate\"},\"scaleanchor\":\"x\",\"scaleratio\":1},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"ROC Curve (AUC=0.9211)\"},\"height\":600,\"width\":800,\"shapes\":[{\"line\":{\"dash\":\"dash\"},\"type\":\"line\",\"x0\":0,\"x1\":1,\"y0\":0,\"y1\":1}],\"showlegend\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('5b5a5fe0-ee37-4a0a-af9e-d5fc5e29fd51');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"fillpattern":{"shape":""},"hovertemplate":"Recall=%{x}<br>Precision=%{y}<extra></extra>","legendgroup":"","line":{"color":"#636efa"},"marker":{"symbol":"circle"},"mode":"lines","name":"","orientation":"v","showlegend":false,"stackgroup":"1","type":"scatter","x":[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9932236205227493,0.9932236205227493,0.9922555663117134,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.989351403678606,0.989351403678606,0.989351403678606,0.9883833494675702,0.9874152952565344,0.9864472410454985,0.9854791868344628,0.9854791868344628,0.9845111326234269,0.9835430784123911,0.9835430784123911,0.9825750242013552,0.9816069699903195,0.9806389157792836,0.9806389157792836,0.9796708615682478,0.978702807357212,0.978702807357212,0.9777347531461762,0.9777347531461762,0.9777347531461762,0.9767666989351403,0.9767666989351403,0.9767666989351403,0.9767666989351403,0.9767666989351403,0.9767666989351403,0.9757986447241046,0.9757986447241046,0.9748305905130688,0.9748305905130688,0.9748305905130688,0.9748305905130688,0.9748305905130688,0.9748305905130688,0.9738625363020329,0.9738625363020329,0.972894482090997,0.972894482090997,0.972894482090997,0.9719264278799613,0.9719264278799613,0.9709583736689255,0.9709583736689255,0.9709583736689255,0.9709583736689255,0.9709583736689255,0.9709583736689255,0.9709583736689255,0.9699903194578896,0.9699903194578896,0.9690222652468539,0.9690222652468539,0.9690222652468539,0.968054211035818,0.9670861568247822,0.9661181026137464,0.9651500484027106,0.9641819941916747,0.9641819941916747,0.9641819941916747,0.9641819941916747,0.9641819941916747,0.9641819941916747,0.9632139399806389,0.9622458857696031,0.9622458857696031,0.9622458857696031,0.9622458857696031,0.9612778315585673,0.9603097773475314,0.9593417231364957,0.9593417231364957,0.9593417231364957,0.9593417231364957,0.9583736689254598,0.957405614714424,0.957405614714424,0.9564375605033882,0.9554695062923524,0.9545014520813165,0.9535333978702807,0.9535333978702807,0.952565343659245,0.9515972894482091,0.9515972894482091,0.9506292352371732,0.9496611810261375,0.9486931268151017,0.9477250726040658,0.9467570183930301,0.9457889641819942,0.9448209099709584,0.9448209099709584,0.9438528557599225,0.9438528557599225,0.9438528557599225,0.9438528557599225,0.9438528557599225,0.9428848015488868,0.9419167473378509,0.9419167473378509,0.9409486931268151,0.9399806389157793,0.9390125847047435,0.9380445304937076,0.9380445304937076,0.9380445304937076,0.9380445304937076,0.9370764762826719,0.9370764762826719,0.9370764762826719,0.936108422071636,0.9351403678606002,0.9341723136495643,0.9332042594385286,0.9322362052274927,0.9312681510164569,0.9303000968054211,0.9293320425943853,0.9283639883833494,0.9273959341723137,0.9264278799612778,0.925459825750242,0.925459825750242,0.9244917715392061,0.9244917715392061,0.9235237173281704,0.9225556631171346,0.9215876089060987,0.920619554695063,0.9196515004840271,0.9186834462729913,0.9186834462729913,0.9177153920619555,0.9177153920619555,0.9167473378509197,0.9157792836398838,0.914811229428848,0.914811229428848,0.914811229428848,0.914811229428848,0.9138431752178122,0.9128751210067764,0.9119070667957405,0.9119070667957405,0.9109390125847048,0.9099709583736689,0.9090029041626331,0.9080348499515973,0.9070667957405615,0.9070667957405615,0.9060987415295256,0.9051306873184899,0.904162633107454,0.9031945788964182,0.9022265246853823,0.9012584704743466,0.9002904162633107,0.8993223620522749,0.8993223620522749,0.8983543078412392,0.8983543078412392,0.8973862536302033,0.8973862536302033,0.8964181994191674,0.8954501452081317,0.8944820909970959,0.8944820909970959,0.89351403678606,0.8925459825750242,0.8925459825750242,0.8915779283639884,0.8906098741529526,0.8906098741529526,0.8906098741529526,0.8896418199419167,0.888673765730881,0.8877057115198451,0.8867376573088093,0.8867376573088093,0.8857696030977735,0.8857696030977735,0.8848015488867377,0.8848015488867377,0.8838334946757018,0.8838334946757018,0.8838334946757018,0.882865440464666,0.8818973862536302,0.8818973862536302,0.8809293320425944,0.8799612778315585,0.8789932236205228,0.8789932236205228,0.8789932236205228,0.8780251694094869,0.8770571151984511,0.8760890609874153,0.8751210067763795,0.8741529525653436,0.8731848983543078,0.8731848983543078,0.8731848983543078,0.8731848983543078,0.8731848983543078,0.872216844143272,0.8712487899322362,0.8702807357212003,0.8693126815101646,0.8683446272991288,0.8673765730880929,0.8673765730880929,0.8664085188770572,0.8664085188770572,0.8664085188770572,0.8654404646660213,0.8644724104549855,0.8635043562439496,0.8625363020329139,0.861568247821878,0.8606001936108422,0.8596321393998064,0.8586640851887706,0.8586640851887706,0.8576960309777347,0.856727976766699,0.856727976766699,0.8557599225556631,0.8547918683446273,0.8538238141335914,0.8528557599225557,0.8518877057115198,0.850919651500484,0.8499515972894482,0.8489835430784124,0.8480154888673765,0.8480154888673765,0.8470474346563408,0.846079380445305,0.8451113262342691,0.8441432720232332,0.8431752178121975,0.8422071636011617,0.8412391093901258,0.8412391093901258,0.8402710551790901,0.8402710551790901,0.8393030009680542,0.8383349467570184,0.8383349467570184,0.8373668925459826,0.8363988383349468,0.8363988383349468,0.8354307841239109,0.8354307841239109,0.8344627299128751,0.8334946757018393,0.8325266214908035,0.8315585672797676,0.8305905130687319,0.829622458857696,0.8286544046466602,0.8276863504356244,0.8267182962245886,0.8257502420135527,0.8247821878025169,0.8238141335914811,0.8228460793804453,0.8218780251694094,0.8209099709583737,0.8199419167473379,0.818973862536302,0.8180058083252663,0.8170377541142304,0.8160696999031946,0.8160696999031946,0.8151016456921588,0.8151016456921588,0.814133591481123,0.814133591481123,0.8131655372700871,0.8121974830590513,0.8112294288480155,0.8102613746369797,0.8092933204259438,0.8092933204259438,0.8083252662149081,0.8073572120038722,0.8073572120038722,0.8063891577928364,0.8054211035818006,0.8044530493707648,0.8034849951597289,0.8025169409486931,0.8015488867376573,0.8005808325266215,0.7996127783155856,0.7996127783155856,0.7986447241045499,0.797676669893514,0.7967086156824782,0.7957405614714425,0.7947725072604066,0.7947725072604066,0.7938044530493708,0.7928363988383349,0.7918683446272992,0.7909002904162633,0.7899322362052275,0.7889641819941917,0.7889641819941917,0.7889641819941917,0.7879961277831559,0.78702807357212,0.7860600193610843,0.7850919651500484,0.7841239109390126,0.7831558567279767,0.782187802516941,0.7812197483059051,0.7802516940948693,0.7792836398838335,0.7783155856727977,0.7783155856727977,0.7773475314617618,0.7763794772507261,0.7754114230396902,0.7744433688286544,0.7734753146176185,0.7725072604065828,0.771539206195547,0.7705711519845111,0.7696030977734754,0.7686350435624395,0.7676669893514037,0.7666989351403679,0.7657308809293321,0.7647628267182962,0.7637947725072604,0.7628267182962246,0.7618586640851888,0.7608906098741529,0.7608906098741529,0.7599225556631172,0.7589545014520813,0.7579864472410455,0.7570183930300097,0.7560503388189739,0.755082284607938,0.755082284607938,0.7541142303969022,0.7531461761858664,0.7521781219748306,0.7512100677637947,0.7512100677637947,0.750242013552759,0.7492739593417231,0.7483059051306873,0.7473378509196515,0.7473378509196515,0.7463697967086157,0.7454017424975798,0.744433688286544,0.7434656340755083,0.7424975798644724,0.7415295256534365,0.7405614714424008,0.739593417231365,0.739593417231365,0.739593417231365,0.7386253630203291,0.7376573088092934,0.7366892545982575,0.7357212003872217,0.7347531461761858,0.7337850919651501,0.7337850919651501,0.7328170377541142,0.7318489835430784,0.7308809293320426,0.7299128751210068,0.7289448209099709,0.7279767666989352,0.7270087124878993,0.7260406582768635,0.7250726040658277,0.7241045498547919,0.723136495643756,0.7221684414327202,0.7212003872216844,0.7202323330106486,0.7192642787996127,0.7192642787996127,0.718296224588577,0.7173281703775412,0.7163601161665053,0.7153920619554696,0.7144240077444337,0.7144240077444337,0.7144240077444337,0.7134559535333979,0.712487899322362,0.7115198451113263,0.7105517909002904,0.7095837366892546,0.7086156824782188,0.707647628267183,0.707647628267183,0.7066795740561471,0.7057115198451114,0.7057115198451114,0.7047434656340755,0.7037754114230397,0.7028073572120038,0.7018393030009681,0.7008712487899322,0.6999031945788964,0.6989351403678606,0.6979670861568248,0.6969990319457889,0.6960309777347532,0.6950629235237173,0.6940948693126815,0.6940948693126815,0.6931268151016456,0.6931268151016456,0.6921587608906099,0.691190706679574,0.6902226524685382,0.6892545982575025,0.6892545982575025,0.6882865440464666,0.6873184898354308,0.686350435624395,0.6853823814133592,0.6844143272023233,0.6844143272023233,0.6834462729912875,0.6824782187802517,0.6815101645692159,0.68054211035818,0.68054211035818,0.6795740561471443,0.6795740561471443,0.6786060019361084,0.6776379477250726,0.6766698935140368,0.6766698935140368,0.675701839303001,0.6747337850919651,0.6737657308809293,0.6727976766698935,0.6718296224588577,0.6708615682478218,0.6698935140367861,0.6689254598257502,0.6679574056147144,0.6669893514036787,0.6660212971926428,0.665053242981607,0.665053242981607,0.6640851887705711,0.6631171345595354,0.6621490803484995,0.6611810261374637,0.6602129719264279,0.6592449177153921,0.6582768635043562,0.6573088092933205,0.6563407550822846,0.6563407550822846,0.6553727008712488,0.6544046466602129,0.6534365924491772,0.6524685382381413,0.6515004840271055,0.6505324298160697,0.6495643756050339,0.648596321393998,0.6476282671829623,0.6466602129719264,0.6456921587608906,0.6447241045498547,0.643756050338819,0.643756050338819,0.6427879961277831,0.6418199419167473,0.6408518877057116,0.6398838334946757,0.6389157792836399,0.6379477250726041,0.6369796708615683,0.6360116166505324,0.6350435624394967,0.6340755082284608,0.633107454017425,0.6321393998063891,0.6311713455953534,0.6302032913843175,0.6292352371732817,0.6282671829622459,0.6272991287512101,0.6263310745401742,0.6253630203291385,0.6243949661181026,0.6234269119070668,0.6224588576960309,0.6214908034849952,0.6205227492739593,0.6195546950629235,0.6185866408518877,0.6176185866408519,0.616650532429816,0.6156824782187803,0.6147144240077445,0.6137463697967086,0.6127783155856728,0.611810261374637,0.6108422071636012,0.6098741529525653,0.6089060987415296,0.6079380445304937,0.6069699903194579,0.6060019361084221,0.6050338818973863,0.6040658276863504,0.6030977734753146,0.6021297192642788,0.601161665053243,0.6001936108422071,0.5992255566311714,0.5982575024201355,0.5972894482090997,0.5963213939980639,0.5953533397870281,0.5943852855759922,0.5934172313649564,0.5924491771539206,0.5914811229428848,0.590513068731849,0.5895450145208132,0.5885769603097774,0.5876089060987415,0.5866408518877058,0.5856727976766699,0.5847047434656341,0.5837366892545982,0.5827686350435625,0.5818005808325266,0.5808325266214908,0.5808325266214908,0.579864472410455,0.5788964181994192,0.5779283639883833,0.5769603097773476,0.5759922555663117,0.5750242013552759,0.5750242013552759,0.57405614714424,0.5730880929332043,0.5721200387221684,0.5711519845111326,0.5701839303000968,0.569215876089061,0.5682478218780251,0.5682478218780251,0.5672797676669894,0.5663117134559535,0.5653436592449177,0.5643756050338818,0.5634075508228461,0.5624394966118103,0.5614714424007744,0.5605033881897387,0.5595353339787028,0.558567279767667,0.5575992255566312,0.5566311713455954,0.5556631171345595,0.5546950629235237,0.5537270087124879,0.5527589545014521,0.5517909002904162,0.5508228460793805,0.5498547918683446,0.5488867376573088,0.547918683446273,0.547918683446273,0.5469506292352372,0.5459825750242013,0.5450145208131656,0.5450145208131656,0.5440464666021297,0.5430784123910939,0.542110358180058,0.5411423039690223,0.5401742497579864,0.5392061955469506,0.5382381413359149,0.537270087124879,0.5363020329138432,0.5353339787028074,0.5343659244917716,0.5333978702807357,0.5324298160696999,0.5314617618586641,0.5304937076476283,0.5295256534365924,0.5285575992255567,0.5275895450145208,0.526621490803485,0.5256534365924492,0.5246853823814134,0.5237173281703775,0.5227492739593417,0.5217812197483059,0.5208131655372701,0.5198451113262342,0.5188770571151985,0.5179090029041626,0.5169409486931268,0.515972894482091,0.5150048402710552,0.5140367860600193,0.5130687318489835,0.5121006776379478,0.5111326234269119,0.510164569215876,0.5091965150048403,0.5091965150048403,0.5082284607938045,0.5072604065827686,0.5062923523717329,0.505324298160697,0.5043562439496612,0.5033881897386253,0.5024201355275896,0.5014520813165537,0.5014520813165537,0.5004840271055179,0.4995159728944821,0.4985479186834463,0.4975798644724105,0.49661181026137463,0.49564375605033884,0.494675701839303,0.4937076476282672,0.4927395934172314,0.49177153920619554,0.49080348499515974,0.4898354307841239,0.4888673765730881,0.4878993223620523,0.48693126815101645,0.48596321393998065,0.48596321393998065,0.4849951597289448,0.484027105517909,0.4830590513068732,0.48209099709583736,0.48112294288480156,0.4801548886737657,0.4791868344627299,0.4782187802516941,0.47725072604065827,0.4762826718296225,0.4753146176185866,0.4743465634075508,0.47337850919651503,0.4724104549854792,0.4714424007744434,0.47047434656340753,0.46950629235237173,0.46950629235237173,0.46853823814133594,0.4675701839303001,0.4666021297192643,0.46563407550822844,0.46466602129719264,0.46369796708615685,0.462729912875121,0.462729912875121,0.4617618586640852,0.46079380445304935,0.45982575024201355,0.45885769603097776,0.4578896418199419,0.4569215876089061,0.45595353339787026,0.45498547918683446,0.45401742497579867,0.4530493707647628,0.452081316553727,0.45111326234269117,0.45014520813165537,0.4491771539206196,0.4482090997095837,0.44724104549854793,0.4462729912875121,0.4453049370764763,0.4453049370764763,0.4443368828654405,0.44336882865440463,0.44240077444336884,0.441432720232333,0.4404646660212972,0.4394966118102614,0.43852855759922554,0.43756050338818975,0.4365924491771539,0.4356243949661181,0.4346563407550823,0.43368828654404645,0.43272023233301066,0.4317521781219748,0.430784123910939,0.4298160696999032,0.42884801548886736,0.42787996127783157,0.4269119070667957,0.4259438528557599,0.4249757986447241,0.42400774443368827,0.42400774443368827,0.4230396902226525,0.4220716360116166,0.42110358180058083,0.42013552758954503,0.4191674733785092,0.4181994191674734,0.41723136495643753,0.41626331074540174,0.41529525653436594,0.4143272023233301,0.4133591481122943,0.41239109390125844,0.41142303969022265,0.41045498547918685,0.409486931268151,0.4085188770571152,0.4075508228460794,0.40658276863504356,0.40561471442400776,0.4046466602129719,0.4036786060019361,0.4027105517909003,0.40174249757986447,0.40077444336882867,0.3998063891577928,0.398838334946757,0.3978702807357212,0.3978702807357212,0.3969022265246854,0.3959341723136496,0.39496611810261373,0.39399806389157793,0.39303000968054214,0.3920619554695063,0.3910939012584705,0.39012584704743464,0.38818973862536305,0.3872216844143272,0.38528557599225555,0.38431752178121975,0.38334946757018395,0.3823814133591481,0.3814133591481123,0.38044530493707646,0.37947725072604066,0.37850919651500486,0.377541142303969,0.3765730880929332,0.37560503388189737,0.37463697967086157,0.3736689254598258,0.3727008712487899,0.3717328170377541,0.3707647628267183,0.3697967086156825,0.3688286544046467,0.36786060019361083,0.36689254598257504,0.3659244917715392,0.3649564375605034,0.3639883833494676,0.36302032913843174,0.36205227492739595,0.3610842207163601,0.3601161665053243,0.3591481122942885,0.35818005808325265,0.35721200387221685,0.356243949661181,0.3552758954501452,0.3543078412391094,0.35333978702807356,0.35237173281703776,0.3514036786060019,0.3504356243949661,0.3494675701839303,0.34849951597289447,0.3475314617618587,0.3465634075508228,0.345595353339787,0.34462729912875123,0.3436592449177154,0.3426911907066796,0.34172313649564373,0.34075508228460794,0.33978702807357214,0.3388189738625363,0.3388189738625363,0.3378509196515005,0.33688286544046464,0.33591481122942884,0.33494675701839305,0.3339787028073572,0.3330106485963214,0.33204259438528555,0.33107454017424975,0.33010648596321396,0.3291384317521781,0.3281703775411423,0.32720232333010646,0.32623426911907066,0.32526621490803487,0.324298160696999,0.3233301064859632,0.32236205227492737,0.3213939980638916,0.3204259438528558,0.3194578896418199,0.31848983543078413,0.31752178121974833,0.3165537270087125,0.3155856727976767,0.31461761858664083,0.31364956437560504,0.31268151016456924,0.3117134559535334,0.3107454017424976,0.30977734753146174,0.30880929332042595,0.30784123910939015,0.3068731848983543,0.3059051306873185,0.30493707647628265,0.30396902226524686,0.30300096805421106,0.3020329138431752,0.3010648596321394,0.30009680542110356,0.29912875121006777,0.29816069699903197,0.2971926427879961,0.2971926427879961,0.2962245885769603,0.2952565343659245,0.2942884801548887,0.2933204259438529,0.29235237173281703,0.29138431752178123,0.2904162633107454,0.2894482090997096,0.2884801548886738,0.28751210067763794,0.28654404646660214,0.2855759922555663,0.2846079380445305,0.2836398838334947,0.28267182962245885,0.28170377541142305,0.2807357212003872,0.2797676669893514,0.27783155856727976,0.27686350435624396,0.2758954501452081,0.2749273959341723,0.2739593417231365,0.27299128751210067,0.27202323330106487,0.271055179090029,0.2700871248789932,0.2691190706679574,0.2681510164569216,0.2671829622458858,0.26621490803484993,0.26524685382381413,0.26427879961277834,0.2633107454017425,0.2623426911907067,0.26137463697967084,0.26040658276863504,0.25943852855759925,0.2584704743465634,0.2575024201355276,0.25653436592449175,0.25556631171345595,0.25459825750242016,0.2536302032913843,0.2526621490803485,0.25169409486931266,0.25072604065827686,0.24975798644724104,0.24878993223620524,0.24782187802516942,0.2468538238141336,0.24588576960309777,0.24491771539206195,0.24394966118102615,0.24298160696999033,0.2420135527589545,0.24104549854791868,0.24007744433688286,0.23910939012584706,0.23814133591481124,0.2371732817037754,0.2362052274927396,0.23523717328170377,0.23426911907066797,0.23330106485963215,0.23233301064859632,0.2313649564375605,0.23039690222652467,0.22942884801548888,0.22846079380445306,0.22749273959341723,0.22749273959341723,0.2265246853823814,0.22555663117134558,0.2245885769603098,0.22362052274927396,0.22265246853823814,0.22168441432720232,0.2207163601161665,0.2197483059051307,0.21878025169409487,0.21781219748305905,0.21684414327202323,0.2158760890609874,0.2149080348499516,0.21393998063891578,0.21297192642787996,0.21200387221684414,0.2110358180058083,0.21006776379477252,0.2090997095837367,0.20813165537270087,0.20716360116166505,0.20619554695062922,0.2042594385285576,0.20329138431752178,0.20232333010648595,0.20135527589545016,0.20038722168441434,0.1994191674733785,0.1984511132623427,0.19748305905130686,0.19651500484027107,0.19554695062923524,0.19457889641819942,0.1936108422071636,0.19264278799612777,0.19167473378509198,0.19070667957405615,0.18973862536302033,0.1887705711519845,0.18780251694094868,0.1868344627299129,0.18586640851887706,0.18489835430784124,0.18393030009680542,0.1829622458857696,0.1819941916747338,0.18102613746369797,0.18005808325266215,0.17909002904162633,0.1781219748305905,0.1771539206195547,0.17618586640851888,0.17521781219748306,0.17424975798644723,0.1732817037754114,0.17231364956437561,0.1713455953533398,0.17037754114230397,0.16940948693126814,0.16844143272023232,0.16747337850919652,0.1665053242981607,0.16553727008712488,0.16456921587608905,0.16360116166505323,0.16263310745401743,0.1616650532429816,0.1606969990319458,0.15972894482090996,0.15876089060987417,0.15779283639883834,0.15682478218780252,0.1558567279767667,0.15488867376573087,0.15392061955469508,0.15295256534365925,0.15198451113262343,0.1510164569215876,0.15004840271055178,0.14908034849951599,0.14811229428848016,0.14714424007744434,0.14617618586640851,0.1452081316553727,0.1442400774443369,0.14327202323330107,0.14230396902226525,0.14133591481122942,0.14133591481122942,0.1403678606001936,0.1393998063891578,0.13843175217812198,0.13746369796708616,0.13649564375605033,0.1355275895450145,0.1345595353339787,0.1335914811229429,0.13262342691190707,0.13165537270087124,0.13068731848983542,0.12971926427879962,0.1287512100677638,0.12778315585672798,0.12681510164569215,0.12584704743465633,0.12487899322362052,0.12391093901258471,0.12294288480154889,0.12197483059051308,0.12100677637947725,0.12003872216844143,0.11907066795740562,0.1181026137463698,0.11713455953533398,0.11616650532429816,0.11519845111326234,0.11423039690222653,0.1132623426911907,0.1122942884801549,0.11132623426911907,0.11035818005808325,0.10939012584704744,0.10842207163601161,0.1074540174249758,0.10648596321393998,0.10551790900290416,0.10454985479186835,0.10358180058083252,0.10261374636979671,0.10164569215876089,0.10067763794772508,0.09970958373668926,0.09874152952565343,0.09777347531461762,0.0968054211035818,0.09583736689254599,0.09486931268151017,0.09390125847047434,0.09293320425943853,0.09196515004840271,0.0909970958373669,0.09002904162633107,0.08906098741529525,0.08809293320425944,0.08615682478218781,0.08518877057115198,0.08422071636011616,0.08325266214908035,0.08228460793804453,0.08131655372700872,0.0803484995159729,0.07938044530493708,0.07841239109390126,0.07744433688286544,0.07647628267182963,0.0755082284607938,0.07454017424975799,0.07357212003872217,0.07260406582768635,0.07163601161665054,0.07066795740561471,0.0696999031945789,0.06873184898354308,0.06776379477250725,0.06679574056147145,0.06582768635043562,0.06485963213939981,0.06389157792836399,0.06292352371732816,0.061955469506292354,0.06098741529525654,0.060019361084220714,0.0590513068731849,0.05808325266214908,0.057115198451113264,0.05614714424007745,0.05517909002904162,0.05517909002904162,0.05517909002904162,0.05421103581800581,0.05324298160696999,0.05227492739593417,0.051306873184898356,0.05033881897386254,0.049370764762826716,0.0484027105517909,0.04743465634075508,0.046466602129719266,0.04549854791868345,0.044530493707647625,0.044530493707647625,0.04356243949661181,0.04259438528557599,0.041626331074540175,0.04065827686350436,0.03969022265246854,0.03872216844143272,0.0377541142303969,0.036786060019361085,0.03581800580832527,0.03484995159728945,0.03388189738625363,0.03291384317521781,0.031945788964181994,0.031945788964181994,0.030977734753146177,0.030009680542110357,0.02904162633107454,0.027105517909002903,0.026137463697967087,0.02516940948693127,0.02420135527589545,0.023233301064859633,0.022265246853823813,0.021297192642787996,0.02032913843175218,0.01936108422071636,0.018393030009680542,0.017424975798644726,0.016456921587608905,0.015488867376573089,0.015488867376573089,0.01452081316553727,0.013552758954501452,0.012584704743465635,0.011616650532429816,0.010648596321393998,0.00968054211035818,0.008712487899322363,0.007744433688286544,0.006776379477250726,0.005808325266214908,0.00484027105517909,0.003872216844143272,0.002904162633107454,0.001936108422071636,0.000968054211035818,0],"xaxis":"x","y":[0.7341862117981521,0.7347083926031295,0.7352313167259786,0.7357549857549858,0.7362794012829651,0.7368045649072753,0.7373304782298359,0.7378571428571429,0.7383845604002859,0.7389127324749643,0.7394416607015032,0.7399713467048711,0.7405017921146954,0.7410329985652798,0.741564967695621,0.7420977011494253,0.7426312005751258,0.7431654676258993,0.7437005039596832,0.7442363112391931,0.7447728911319395,0.7453102453102453,0.7458483754512636,0.7463872832369942,0.7469269703543022,0.7474674384949349,0.7480086893555394,0.7485507246376811,0.7490935460478607,0.7496371552975326,0.7501815541031227,0.7507267441860465,0.7512727272727273,0.7518195050946143,0.752367079388201,0.7529154518950437,0.7534646243617797,0.754014598540146,0.7545653761869978,0.7551169590643275,0.7556693489392831,0.7562225475841874,0.7567765567765568,0.7573313782991202,0.7578870139398386,0.7584434654919237,0.7590007347538574,0.7595588235294117,0.7601177336276674,0.7606774668630338,0.7612380250552689,0.7617994100294986,0.7623616236162362,0.7629246676514032,0.7634885439763488,0.7640532544378699,0.764618800888231,0.7651851851851852,0.765752409191994,0.766320474777448,0.7668893838158871,0.7674591381872214,0.7680297397769517,0.7686011904761905,0.7691734921816828,0.7697466467958272,0.7703206562266965,0.7708955223880597,0.7714712471994025,0.7720478325859492,0.7726252804786836,0.7732035928143712,0.7737827715355805,0.7743628185907047,0.7749437359339835,0.7755255255255256,0.7761081893313299,0.7766917293233083,0.7772761474793077,0.7778614457831325,0.7784476262245666,0.7790346907993967,0.779622641509434,0.7802114803625377,0.780801209372638,0.7813918305597579,0.7819833459500378,0.7825757575757576,0.7831690674753601,0.783763277693475,0.7843583902809416,0.7849544072948328,0.785551330798479,0.7861491628614916,0.7867479055597868,0.7873475609756098,0.7879481311975591,0.7885496183206107,0.7891520244461421,0.7897553516819572,0.7903596021423106,0.7909647779479326,0.7915708812260537,0.7921779141104295,0.7927858787413661,0.793394777265745,0.7940046118370484,0.7946153846153846,0.7952270977675134,0.7958397534668721,0.7964533538936006,0.7970679012345679,0.7976833976833977,0.7982998454404946,0.7989172467130704,0.7995356037151703,0.8001549186676995,0.8007751937984496,0.8013964313421257,0.8020186335403726,0.8026418026418026,0.8032659409020217,0.8038910505836576,0.8045171339563862,0.8051441932969603,0.8057722308892356,0.8064012490241999,0.80703125,0.8076622361219703,0.8082942097026604,0.8089271730618638,0.8095611285266457,0.8101960784313725,0.8108320251177394,0.8114689709347996,0.8121069182389937,0.8127458693941778,0.8133858267716535,0.814026792750197,0.8146687697160884,0.8153117600631413,0.815955766192733,0.8166007905138339,0.817246835443038,0.8178939034045922,0.8185419968304279,0.8191911181601903,0.8198412698412698,0.8204924543288324,0.8211446740858506,0.8217979315831344,0.822452229299363,0.8231075697211155,0.8237639553429027,0.8244213886671987,0.8250798722044729,0.8257394084732215,0.8264,0.8270616493194556,0.8277243589743589,0.8283881315156375,0.8290529695024077,0.8297188755020081,0.8303858520900321,0.831053901850362,0.8317230273752013,0.8315874294923449,0.832258064516129,0.8329297820823245,0.8336025848142165,0.8342764753435732,0.8349514563106796,0.8356275303643724,0.8363047001620746,0.8369829683698297,0.8376623376623377,0.8390243902439024,0.8397070789259561,0.8403908794788274,0.8410757946210269,0.8417618270799347,0.8424489795918367,0.8431372549019608,0.8438266557645135,0.8445171849427169,0.8443898443898444,0.8450819672131148,0.8457752255947498,0.8456486042692939,0.8463434675431388,0.8470394736842105,0.8477366255144033,0.8484349258649094,0.8491343775762572,0.849009900990099,0.8497109826589595,0.8504132231404958,0.8511166253101737,0.8518211920529801,0.8525269262634632,0.8532338308457711,0.8539419087136929,0.8546511627906976,0.8553615960099751,0.8560732113144759,0.8567860116569526,0.8575,0.8582151793160967,0.8580968280467446,0.858813700918964,0.8595317725752508,0.8602510460251046,0.8609715242881072,0.8608549874266554,0.8615771812080537,0.8623005877413937,0.8630252100840337,0.8637510513036165,0.8644781144781145,0.8643639427127211,0.8650927487352446,0.8649789029535865,0.8648648648648649,0.8655959425190194,0.8663282571912013,0.8670618120237087,0.8677966101694915,0.8685326547921968,0.8692699490662139,0.8700084961767205,0.8707482993197279,0.8706382978723404,0.8713798977853492,0.8721227621483376,0.8720136518771331,0.8727583262169086,0.8735042735042735,0.8733960650128315,0.8732876712328768,0.8731790916880892,0.8730703259005146,0.8738197424892704,0.8737113402061856,0.8736027515047291,0.8743545611015491,0.8742463393626184,0.8741379310344828,0.8740293356341674,0.8747841105354058,0.874675885911841,0.8745674740484429,0.8753246753246753,0.8752166377816292,0.8759757155247181,0.8767361111111112,0.8766290182450044,0.8773913043478261,0.8781549173194082,0.8789198606271778,0.8796861377506539,0.8804537521815009,0.880349344978166,0.8811188811188811,0.8810148731408574,0.8817863397548161,0.8825591586327782,0.8833333333333333,0.884108867427568,0.8848857644991213,0.8847845206684257,0.8855633802816901,0.8854625550660793,0.8862433862433863,0.8870255957634599,0.8869257950530035,0.887709991158267,0.8876106194690265,0.8883968113374667,0.8891843971631206,0.8899733806566105,0.8907637655417406,0.8915555555555555,0.8923487544483986,0.8922528940338379,0.893048128342246,0.8929527207850134,0.89375,0.8945487042001787,0.8944543828264758,0.8943598925693823,0.8942652329749103,0.8941704035874439,0.8940754039497307,0.894878706199461,0.89568345323741,0.8964896489648965,0.8972972972972973,0.8981064021641119,0.898014440433213,0.8979223125564589,0.8987341772151899,0.8995475113122172,0.9003623188405797,0.900271985494107,0.9001814882032668,0.9000908265213442,0.9009090909090909,0.9017288444040037,0.9025500910746812,0.902461257976299,0.9023722627737226,0.9031963470319635,0.903107861060329,0.9030192131747484,0.9029304029304029,0.9028414298808433,0.9036697247706422,0.9035812672176309,0.9034926470588235,0.9043238270469182,0.9042357274401474,0.904147465437788,0.9040590405904059,0.9039704524469068,0.9038817005545287,0.9037927844588344,0.9037037037037037,0.9045412418906394,0.9044526901669759,0.9052924791086351,0.9061338289962825,0.9069767441860465,0.9078212290502793,0.907735321528425,0.9076492537313433,0.9084967320261438,0.908411214953271,0.9083255378858747,0.9082397003745318,0.9081537019681349,0.9090056285178236,0.9098591549295775,0.9107142857142857,0.9106302916274694,0.911487758945386,0.9123468426013195,0.9122641509433962,0.9121813031161473,0.9120982986767486,0.9120151371807,0.9119318181818182,0.9118483412322275,0.9117647058823529,0.9116809116809117,0.9115969581749049,0.9115128449096099,0.9114285714285715,0.9113441372735939,0.9122137404580153,0.9121298949379179,0.9130019120458891,0.9129186602870814,0.9128352490421456,0.912751677852349,0.9126679462571977,0.9125840537944284,0.9125,0.9133782483156881,0.9132947976878613,0.914175506268081,0.9140926640926641,0.9140096618357488,0.913926499032882,0.914811229428848,0.9156976744186046,0.9165858389912707,0.916504854368932,0.9164237123420796,0.9163424124513618,0.9172346640701071,0.9171539961013645,0.9170731707317074,0.9169921875,0.916911045943304,0.9168297455968689,0.9177277179236043,0.9176470588235294,0.9175662414131501,0.9174852652259332,0.9174041297935103,0.9173228346456693,0.9172413793103448,0.9171597633136095,0.9170779861796644,0.9179841897233202,0.9179030662710188,0.9188118811881189,0.9187314172447968,0.9196428571428571,0.9195630585898709,0.9194831013916501,0.9194029850746268,0.9203187250996016,0.9202392821535393,0.9201596806387226,0.9210789210789211,0.921,0.9209209209209209,0.9218436873747495,0.9227683049147443,0.9226907630522089,0.9226130653266331,0.9225352112676056,0.9224572004028198,0.9233870967741935,0.9233097880928355,0.9242424242424242,0.9241658240647118,0.9251012145748988,0.9250253292806484,0.9259634888438134,0.9269035532994924,0.926829268292683,0.9267548321464903,0.9276985743380856,0.9276248725790011,0.9275510204081633,0.9274770173646578,0.9284253578732107,0.9293756397134084,0.9293032786885246,0.9292307692307692,0.9291581108829569,0.9290853031860226,0.9290123456790124,0.9289392378990731,0.9298969072164949,0.9308565531475749,0.9318181818181818,0.9327817993795243,0.932712215320911,0.9326424870466321,0.9325726141078838,0.9325025960539979,0.9324324324324325,0.9323621227887617,0.9333333333333333,0.9332638164754953,0.9342379958246346,0.93521421107628,0.9351464435146444,0.9350785340314136,0.9350104821802935,0.9349422875131165,0.9348739495798319,0.9348054679284963,0.9347368421052632,0.934668071654373,0.9356540084388185,0.9355860612460402,0.9355179704016914,0.9365079365079365,0.9364406779661016,0.936373276776246,0.9363057324840764,0.9362380446333688,0.9361702127659575,0.9361022364217252,0.9360341151385928,0.935965848452508,0.9358974358974359,0.9368983957219251,0.936830835117773,0.9367631296891747,0.9366952789699571,0.9366272824919442,0.9365591397849462,0.9364908503767492,0.9364224137931034,0.9374325782092773,0.937365010799136,0.9383783783783783,0.9383116883116883,0.9382448537378115,0.9392624728850325,0.9391965255157437,0.9391304347826087,0.940152339499456,0.9400871459694989,0.9411123227917121,0.9410480349344978,0.940983606557377,0.9409190371991247,0.940854326396495,0.9407894736842105,0.9407244785949506,0.9406593406593406,0.9405940594059405,0.9405286343612335,0.9404630650496141,0.9403973509933775,0.9403314917127071,0.9402654867256637,0.9401993355481728,0.9401330376940134,0.9400665926748057,0.94,0.9399332591768632,0.9398663697104677,0.939799331103679,0.9408482142857143,0.9407821229050279,0.941834451901566,0.9417693169092946,0.9428251121076233,0.9427609427609428,0.9426966292134832,0.9426321709786277,0.9425675675675675,0.9425028184892897,0.9435665914221218,0.943502824858757,0.9434389140271493,0.9445073612684032,0.9444444444444444,0.9443813847900113,0.9443181818181818,0.944254835039818,0.9441913439635535,0.9441277080957811,0.9440639269406392,0.944,0.9450800915331807,0.9450171821305842,0.944954128440367,0.9448909299655568,0.9448275862068966,0.9447640966628308,0.945852534562212,0.9457900807381776,0.9457274826789839,0.945664739884393,0.9456018518518519,0.9455388180764774,0.9454756380510441,0.9465737514518002,0.9476744186046512,0.9476135040745053,0.9475524475524476,0.9474912485414235,0.947429906542056,0.9473684210526315,0.9473067915690867,0.9472450175849941,0.9471830985915493,0.9471210340775558,0.9470588235294117,0.9469964664310954,0.9481132075471698,0.948051948051948,0.9479905437352246,0.9479289940828403,0.9478672985781991,0.9478054567022538,0.9477434679334917,0.9476813317479191,0.9476190476190476,0.9475566150178785,0.9474940334128878,0.9474313022700119,0.9473684210526315,0.9473053892215569,0.947242206235012,0.9471788715486195,0.9471153846153846,0.9470517448856799,0.946987951807229,0.9481302774427021,0.9480676328502415,0.9480048367593712,0.9479418886198547,0.9478787878787879,0.9478155339805825,0.9477521263669502,0.948905109489051,0.9488428745432399,0.948780487804878,0.9487179487179487,0.9486552567237164,0.9498164014687882,0.9497549019607843,0.9496932515337423,0.9496314496314496,0.949569495694957,0.9507389162561576,0.9506781750924784,0.9506172839506173,0.9505562422744128,0.9504950495049505,0.9504337050805453,0.9503722084367245,0.9503105590062112,0.9502487562189055,0.9514321295143213,0.9526184538653366,0.9525593008739076,0.9525,0.9524405506883604,0.9523809523809523,0.9523212045169385,0.9522613065326633,0.9534591194968554,0.9534005037783375,0.9533417402269861,0.9532828282828283,0.9532237673830595,0.9531645569620253,0.9531051964512041,0.9530456852791879,0.9529860228716646,0.9529262086513995,0.9528662420382166,0.9528061224489796,0.9527458492975734,0.9526854219948849,0.9526248399487837,0.9525641025641025,0.9537869062901155,0.9537275064267352,0.9536679536679536,0.9536082474226805,0.9535483870967741,0.9534883720930233,0.9547218628719275,0.9559585492227979,0.9559014267185474,0.9558441558441558,0.9557867360208062,0.9557291666666666,0.9556714471968709,0.9556135770234987,0.9555555555555556,0.9568062827225131,0.9567496723460026,0.9566929133858267,0.9579500657030223,0.9578947368421052,0.9578392621870883,0.9577836411609498,0.9577278731836195,0.9576719576719577,0.9576158940397351,0.9575596816976127,0.9575033200531209,0.9574468085106383,0.9573901464713716,0.9573333333333334,0.9572763684913218,0.9585561497326203,0.9585006693440429,0.9597855227882037,0.959731543624161,0.9596774193548387,0.9596231493943472,0.9595687331536388,0.9608636977058029,0.9608108108108108,0.9607577807848444,0.9607046070460704,0.9606512890094979,0.9605978260869565,0.9619047619047619,0.9618528610354223,0.9618008185538881,0.9617486338797814,0.9616963064295485,0.963013698630137,0.9629629629629629,0.9642857142857143,0.9642365887207703,0.9641873278236914,0.9641379310344828,0.9654696132596685,0.9654218533886584,0.9653739612188366,0.9653259361997226,0.9652777777777778,0.9652294853963839,0.9651810584958217,0.9651324965132496,0.9650837988826816,0.965034965034965,0.9649859943977591,0.9649368863955119,0.9648876404494382,0.9662447257383966,0.9661971830985916,0.9661495063469676,0.9661016949152542,0.9660537482319661,0.9660056657223796,0.9659574468085106,0.9659090909090909,0.9658605974395448,0.9658119658119658,0.9671897289586305,0.9671428571428572,0.9670958512160229,0.9670487106017192,0.9670014347202296,0.9669540229885057,0.9669064748201439,0.9668587896253602,0.9668109668109668,0.9667630057803468,0.9667149059334298,0.9666666666666667,0.9666182873730044,0.9665697674418605,0.9679767103347889,0.967930029154519,0.9678832116788321,0.9678362573099415,0.9677891654465594,0.967741935483871,0.9676945668135095,0.9676470588235294,0.96759941089838,0.967551622418879,0.9675036927621861,0.9674556213017751,0.9674074074074074,0.9673590504451038,0.9673105497771174,0.9672619047619048,0.9672131147540983,0.9671641791044776,0.9671150971599403,0.9670658682634731,0.967016491754123,0.9669669669669669,0.9669172932330827,0.9668674698795181,0.9668174962292609,0.9667673716012085,0.9667170953101362,0.9666666666666667,0.9666160849772383,0.9665653495440729,0.9665144596651446,0.9664634146341463,0.966412213740458,0.9663608562691132,0.9663093415007658,0.9662576687116564,0.9662058371735791,0.9661538461538461,0.9661016949152542,0.9660493827160493,0.9659969088098919,0.9659442724458205,0.9658914728682171,0.9658385093167702,0.9657853810264385,0.9657320872274143,0.9656786271450858,0.965625,0.9655712050078247,0.9655172413793104,0.9654631083202512,0.9654088050314465,0.9653543307086614,0.9652996845425867,0.9652448657187994,0.9651898734177216,0.96513470681458,0.9650793650793651,0.9650238473767886,0.964968152866242,0.9649122807017544,0.9648562300319489,0.9648,0.9647435897435898,0.9646869983948636,0.9646302250803859,0.966183574879227,0.9661290322580646,0.9660743134087237,0.9660194174757282,0.965964343598055,0.9659090909090909,0.9658536585365853,0.9674267100977199,0.967373572593801,0.9673202614379085,0.967266775777414,0.9672131147540983,0.9671592775041051,0.9671052631578947,0.9670510708401977,0.9686468646864687,0.968595041322314,0.9685430463576159,0.9684908789386402,0.96843853820598,0.9683860232945092,0.9683333333333334,0.9682804674457429,0.9682274247491639,0.9681742043551089,0.9681208053691275,0.9680672268907563,0.968013468013468,0.9679595278246206,0.9679054054054054,0.9678510998307953,0.9677966101694915,0.967741935483871,0.967687074829932,0.9676320272572402,0.9675767918088737,0.9675213675213675,0.9691780821917808,0.9691252144082333,0.9690721649484536,0.9690189328743546,0.9706896551724138,0.9706390328151986,0.9705882352941176,0.9705372616984402,0.9704861111111112,0.9704347826086956,0.9703832752613241,0.9703315881326352,0.9702797202797203,0.9702276707530648,0.9701754385964912,0.9701230228471002,0.9700704225352113,0.9700176366843033,0.9699646643109541,0.9699115044247788,0.9698581560283688,0.9698046181172292,0.9697508896797153,0.9696969696969697,0.9696428571428571,0.9695885509838998,0.9695340501792115,0.9694793536804309,0.9694244604316546,0.9693693693693693,0.9693140794223827,0.969258589511754,0.9692028985507246,0.969147005444646,0.9690909090909091,0.9690346083788707,0.968978102189781,0.9689213893967094,0.9688644688644689,0.9688073394495413,0.96875,0.9686924493554327,0.9704797047970479,0.9704251386321626,0.9703703703703703,0.9703153988868275,0.9702602230483272,0.9702048417132216,0.9701492537313433,0.9700934579439252,0.9700374531835206,0.9718574108818011,0.9718045112781954,0.9717514124293786,0.9716981132075472,0.9716446124763705,0.9715909090909091,0.9715370018975332,0.9714828897338403,0.9714285714285714,0.9713740458015268,0.97131931166348,0.9712643678160919,0.9712092130518234,0.9711538461538461,0.9710982658959537,0.971042471042471,0.9709864603481625,0.9728682170542635,0.9728155339805825,0.9727626459143969,0.9727095516569201,0.97265625,0.9726027397260274,0.9725490196078431,0.9724950884086444,0.9724409448818898,0.9723865877712031,0.9723320158102767,0.9722772277227723,0.9722222222222222,0.9721669980119284,0.9721115537848606,0.9720558882235529,0.972,0.9719438877755511,0.9738955823293173,0.9738430583501007,0.9737903225806451,0.9737373737373738,0.9736842105263158,0.973630831643002,0.9735772357723578,0.9735234215885947,0.9755102040816327,0.9754601226993865,0.9754098360655737,0.9753593429158111,0.9753086419753086,0.9752577319587629,0.9752066115702479,0.9751552795031055,0.975103734439834,0.975051975051975,0.975,0.9749478079331941,0.9748953974895398,0.9748427672955975,0.9747899159663865,0.9747368421052631,0.9746835443037974,0.9746300211416491,0.9745762711864406,0.9766454352441614,0.9765957446808511,0.976545842217484,0.9764957264957265,0.9764453961456103,0.9763948497854077,0.9763440860215054,0.9762931034482759,0.9762419006479481,0.9761904761904762,0.9761388286334056,0.9760869565217392,0.9760348583877996,0.9759825327510917,0.975929978118162,0.9758771929824561,0.9758241758241758,0.9757709251101322,0.9757174392935982,0.9756637168141593,0.975609756097561,0.9755555555555555,0.9755011135857461,0.9776785714285714,0.9776286353467561,0.9775784753363229,0.9775280898876404,0.9774774774774775,0.9774266365688488,0.9773755656108597,0.9773242630385488,0.9772727272727273,0.9772209567198178,0.9771689497716894,0.977116704805492,0.9770642201834863,0.9770114942528736,0.9769585253456221,0.976905311778291,0.9768518518518519,0.9767981438515081,0.9767441860465116,0.9766899766899767,0.9766355140186916,0.9765807962529274,0.9765258215962441,0.9764705882352941,0.9764150943396226,0.9763593380614657,0.976303317535545,0.9762470308788599,0.9785714285714285,0.9785202863961814,0.9784688995215312,0.9784172661870504,0.9783653846153846,0.9783132530120482,0.9782608695652174,0.9782082324455206,0.9781553398058253,0.9780487804878049,0.9779951100244498,0.9778869778869779,0.9778325123152709,0.9777777777777777,0.9777227722772277,0.9776674937965261,0.9776119402985075,0.9775561097256857,0.9775,0.9774436090225563,0.9773869346733668,0.9773299748110831,0.9772727272727273,0.9772151898734177,0.9771573604060914,0.9770992366412213,0.9770408163265306,0.9769820971867008,0.9769230769230769,0.9768637532133676,0.9768041237113402,0.9767441860465116,0.9766839378238342,0.9766233766233766,0.9765625,0.9765013054830287,0.9764397905759162,0.9763779527559056,0.9763157894736842,0.9762532981530343,0.9761904761904762,0.9761273209549072,0.976063829787234,0.976,0.9759358288770054,0.9758713136729222,0.9758064516129032,0.9757412398921833,0.9756756756756757,0.975609756097561,0.9755434782608695,0.9754768392370572,0.9754098360655737,0.9753424657534246,0.9752747252747253,0.9752066115702479,0.9751381215469613,0.9750692520775623,0.975,0.9749303621169917,0.9776536312849162,0.9775910364145658,0.9775280898876404,0.9774647887323944,0.9774011299435028,0.9773371104815864,0.9772727272727273,0.9772079772079773,0.9771428571428571,0.9770773638968482,0.9770114942528736,0.9769452449567724,0.976878612716763,0.9768115942028985,0.9767441860465116,0.9766763848396501,0.9766081871345029,0.9765395894428153,0.9764705882352941,0.976401179941003,0.9763313609467456,0.9762611275964391,0.9761904761904762,0.9761194029850746,0.9760479041916168,0.975975975975976,0.9759036144578314,0.9758308157099698,0.9757575757575757,0.9756838905775076,0.975609756097561,0.9755351681957186,0.9754601226993865,0.9753846153846154,0.9753086419753086,0.9752321981424149,0.9751552795031055,0.9750778816199377,0.975,0.9749216300940439,0.9748427672955975,0.9747634069400631,0.9746835443037974,0.9746031746031746,0.9777070063694268,0.9776357827476039,0.9775641025641025,0.977491961414791,0.9774193548387097,0.9773462783171522,0.9772727272727273,0.9771986970684039,0.9771241830065359,0.9770491803278688,0.9769736842105263,0.976897689768977,0.9768211920529801,0.9767441860465116,0.9766666666666667,0.9765886287625418,0.9765100671140939,0.9764309764309764,0.9763513513513513,0.9761904761904762,0.9761092150170648,0.976027397260274,0.9759450171821306,0.9758620689655172,0.9757785467128027,0.9756944444444444,0.975609756097561,0.9755244755244755,0.9754385964912281,0.9753521126760564,0.9752650176678446,0.975177304964539,0.9750889679715302,0.975,0.974910394265233,0.9748201438848921,0.9747292418772563,0.9746376811594203,0.9745454545454545,0.9744525547445255,0.9743589743589743,0.9742647058823529,0.974169741697417,0.9740740740740741,0.9739776951672863,0.9738805970149254,0.9737827715355806,0.9736842105263158,0.9735849056603774,0.9734848484848485,0.973384030418251,0.9732824427480916,0.9731800766283525,0.9730769230769231,0.972972972972973,0.9728682170542635,0.9727626459143969,0.97265625,0.9725490196078431,0.9724409448818898,0.9723320158102767,0.9722222222222222,0.9721115537848606,0.972,0.9718875502008032,0.9717741935483871,0.97165991902834,0.9715447154471545,0.9714285714285714,0.9713114754098361,0.9711934156378601,0.9710743801652892,0.975103734439834,0.975,0.9748953974895398,0.9747899159663865,0.9746835443037974,0.9745762711864406,0.9744680851063829,0.9743589743589743,0.9742489270386266,0.9741379310344828,0.974025974025974,0.9739130434782609,0.9737991266375546,0.9736842105263158,0.973568281938326,0.9734513274336283,0.9733333333333334,0.9732142857142857,0.9730941704035875,0.972972972972973,0.9728506787330317,0.9727272727272728,0.9726027397260274,0.9723502304147466,0.9722222222222222,0.9720930232558139,0.9719626168224299,0.971830985915493,0.9716981132075472,0.9715639810426541,0.9714285714285714,0.9712918660287081,0.9711538461538461,0.9710144927536232,0.970873786407767,0.9707317073170731,0.9705882352941176,0.9704433497536946,0.9702970297029703,0.9701492537313433,0.97,0.9698492462311558,0.9696969696969697,0.9695431472081218,0.9693877551020408,0.9692307692307692,0.9690721649484536,0.9689119170984456,0.96875,0.9685863874345549,0.968421052631579,0.9682539682539683,0.9680851063829787,0.9679144385026738,0.967741935483871,0.9675675675675676,0.967391304347826,0.9672131147540983,0.967032967032967,0.9668508287292817,0.9666666666666667,0.9664804469273743,0.9662921348314607,0.9661016949152542,0.9659090909090909,0.9657142857142857,0.9655172413793104,0.9653179190751445,0.9651162790697675,0.9649122807017544,0.9647058823529412,0.9644970414201184,0.9642857142857143,0.9640718562874252,0.963855421686747,0.9636363636363636,0.9634146341463414,0.9631901840490797,0.9629629629629629,0.9627329192546584,0.9625,0.9622641509433962,0.9620253164556962,0.9617834394904459,0.9615384615384616,0.9612903225806452,0.961038961038961,0.9607843137254902,0.9605263157894737,0.9668874172185431,0.9666666666666667,0.9664429530201343,0.9662162162162162,0.9659863945578231,0.9657534246575342,0.9655172413793104,0.9652777777777778,0.965034965034965,0.9647887323943662,0.9645390070921985,0.9642857142857143,0.9640287769784173,0.9637681159420289,0.9635036496350365,0.9632352941176471,0.9629629629629629,0.9626865671641791,0.9624060150375939,0.9621212121212122,0.9618320610687023,0.9615384615384616,0.9612403100775194,0.9609375,0.9606299212598425,0.9603174603174603,0.96,0.9596774193548387,0.959349593495935,0.9590163934426229,0.9586776859504132,0.9583333333333334,0.957983193277311,0.9576271186440678,0.9572649572649573,0.9568965517241379,0.9565217391304348,0.956140350877193,0.9557522123893806,0.9553571428571429,0.954954954954955,0.9545454545454546,0.9541284403669725,0.9537037037037037,0.9532710280373832,0.9528301886792453,0.9523809523809523,0.9519230769230769,0.9514563106796117,0.9509803921568627,0.9504950495049505,0.95,0.9494949494949495,0.9489795918367347,0.9484536082474226,0.9479166666666666,0.9468085106382979,0.946236559139785,0.9456521739130435,0.945054945054945,0.9444444444444444,0.9438202247191011,0.9431818181818182,0.9425287356321839,0.9418604651162791,0.9411764705882353,0.9404761904761905,0.9397590361445783,0.9390243902439024,0.9382716049382716,0.9375,0.9367088607594937,0.9358974358974359,0.935064935064935,0.9342105263157895,0.9333333333333333,0.9324324324324325,0.9315068493150684,0.9305555555555556,0.9295774647887324,0.9285714285714286,0.927536231884058,0.9264705882352942,0.9253731343283582,0.9242424242424242,0.9230769230769231,0.921875,0.9206349206349206,0.9193548387096774,0.9344262295081968,0.95,0.9491525423728814,0.9482758620689655,0.9473684210526315,0.9464285714285714,0.9454545454545454,0.9444444444444444,0.9433962264150944,0.9423076923076923,0.9411764705882353,0.94,0.9387755102040817,0.9583333333333334,0.9574468085106383,0.9565217391304348,0.9555555555555556,0.9545454545454546,0.9534883720930233,0.9523809523809523,0.9512195121951219,0.95,0.9487179487179487,0.9473684210526315,0.9459459459459459,0.9444444444444444,0.9428571428571428,0.9705882352941176,0.9696969696969697,0.96875,0.967741935483871,0.9655172413793104,0.9642857142857143,0.9629629629629629,0.9615384615384616,0.96,0.9583333333333334,0.9565217391304348,0.9545454545454546,0.9523809523809523,0.95,0.9473684210526315,0.9444444444444444,0.9411764705882353,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],"yaxis":"y"}],"layout":{"height":600,"legend":{"tracegroupgap":0},"shapes":[{"line":{"dash":"dash"},"type":"line","x0":0,"x1":1,"y0":1,"y1":0}],"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"title":{"text":"Precision-Recall Curve (AUC=0.9211)"},"width":800,"xaxis":{"anchor":"y","constrain":"domain","domain":[0,1],"title":{"text":"Recall"}},"yaxis":{"anchor":"x","domain":[0,1],"scaleanchor":"x","scaleratio":1,"title":{"text":"Precision"}}}},"text/html":["<div>                            <div id=\"dcda244e-352d-496c-a7aa-b31a11c93156\" class=\"plotly-graph-div\" style=\"height:600px; width:800px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"dcda244e-352d-496c-a7aa-b31a11c93156\")) {                    Plotly.newPlot(                        \"dcda244e-352d-496c-a7aa-b31a11c93156\",                        [{\"fillpattern\":{\"shape\":\"\"},\"hovertemplate\":\"Recall=%{x}\\u003cbr\\u003ePrecision=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"stackgroup\":\"1\",\"x\":[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9932236205227493,0.9932236205227493,0.9922555663117134,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.989351403678606,0.989351403678606,0.989351403678606,0.9883833494675702,0.9874152952565344,0.9864472410454985,0.9854791868344628,0.9854791868344628,0.9845111326234269,0.9835430784123911,0.9835430784123911,0.9825750242013552,0.9816069699903195,0.9806389157792836,0.9806389157792836,0.9796708615682478,0.978702807357212,0.978702807357212,0.9777347531461762,0.9777347531461762,0.9777347531461762,0.9767666989351403,0.9767666989351403,0.9767666989351403,0.9767666989351403,0.9767666989351403,0.9767666989351403,0.9757986447241046,0.9757986447241046,0.9748305905130688,0.9748305905130688,0.9748305905130688,0.9748305905130688,0.9748305905130688,0.9748305905130688,0.9738625363020329,0.9738625363020329,0.972894482090997,0.972894482090997,0.972894482090997,0.9719264278799613,0.9719264278799613,0.9709583736689255,0.9709583736689255,0.9709583736689255,0.9709583736689255,0.9709583736689255,0.9709583736689255,0.9709583736689255,0.9699903194578896,0.9699903194578896,0.9690222652468539,0.9690222652468539,0.9690222652468539,0.968054211035818,0.9670861568247822,0.9661181026137464,0.9651500484027106,0.9641819941916747,0.9641819941916747,0.9641819941916747,0.9641819941916747,0.9641819941916747,0.9641819941916747,0.9632139399806389,0.9622458857696031,0.9622458857696031,0.9622458857696031,0.9622458857696031,0.9612778315585673,0.9603097773475314,0.9593417231364957,0.9593417231364957,0.9593417231364957,0.9593417231364957,0.9583736689254598,0.957405614714424,0.957405614714424,0.9564375605033882,0.9554695062923524,0.9545014520813165,0.9535333978702807,0.9535333978702807,0.952565343659245,0.9515972894482091,0.9515972894482091,0.9506292352371732,0.9496611810261375,0.9486931268151017,0.9477250726040658,0.9467570183930301,0.9457889641819942,0.9448209099709584,0.9448209099709584,0.9438528557599225,0.9438528557599225,0.9438528557599225,0.9438528557599225,0.9438528557599225,0.9428848015488868,0.9419167473378509,0.9419167473378509,0.9409486931268151,0.9399806389157793,0.9390125847047435,0.9380445304937076,0.9380445304937076,0.9380445304937076,0.9380445304937076,0.9370764762826719,0.9370764762826719,0.9370764762826719,0.936108422071636,0.9351403678606002,0.9341723136495643,0.9332042594385286,0.9322362052274927,0.9312681510164569,0.9303000968054211,0.9293320425943853,0.9283639883833494,0.9273959341723137,0.9264278799612778,0.925459825750242,0.925459825750242,0.9244917715392061,0.9244917715392061,0.9235237173281704,0.9225556631171346,0.9215876089060987,0.920619554695063,0.9196515004840271,0.9186834462729913,0.9186834462729913,0.9177153920619555,0.9177153920619555,0.9167473378509197,0.9157792836398838,0.914811229428848,0.914811229428848,0.914811229428848,0.914811229428848,0.9138431752178122,0.9128751210067764,0.9119070667957405,0.9119070667957405,0.9109390125847048,0.9099709583736689,0.9090029041626331,0.9080348499515973,0.9070667957405615,0.9070667957405615,0.9060987415295256,0.9051306873184899,0.904162633107454,0.9031945788964182,0.9022265246853823,0.9012584704743466,0.9002904162633107,0.8993223620522749,0.8993223620522749,0.8983543078412392,0.8983543078412392,0.8973862536302033,0.8973862536302033,0.8964181994191674,0.8954501452081317,0.8944820909970959,0.8944820909970959,0.89351403678606,0.8925459825750242,0.8925459825750242,0.8915779283639884,0.8906098741529526,0.8906098741529526,0.8906098741529526,0.8896418199419167,0.888673765730881,0.8877057115198451,0.8867376573088093,0.8867376573088093,0.8857696030977735,0.8857696030977735,0.8848015488867377,0.8848015488867377,0.8838334946757018,0.8838334946757018,0.8838334946757018,0.882865440464666,0.8818973862536302,0.8818973862536302,0.8809293320425944,0.8799612778315585,0.8789932236205228,0.8789932236205228,0.8789932236205228,0.8780251694094869,0.8770571151984511,0.8760890609874153,0.8751210067763795,0.8741529525653436,0.8731848983543078,0.8731848983543078,0.8731848983543078,0.8731848983543078,0.8731848983543078,0.872216844143272,0.8712487899322362,0.8702807357212003,0.8693126815101646,0.8683446272991288,0.8673765730880929,0.8673765730880929,0.8664085188770572,0.8664085188770572,0.8664085188770572,0.8654404646660213,0.8644724104549855,0.8635043562439496,0.8625363020329139,0.861568247821878,0.8606001936108422,0.8596321393998064,0.8586640851887706,0.8586640851887706,0.8576960309777347,0.856727976766699,0.856727976766699,0.8557599225556631,0.8547918683446273,0.8538238141335914,0.8528557599225557,0.8518877057115198,0.850919651500484,0.8499515972894482,0.8489835430784124,0.8480154888673765,0.8480154888673765,0.8470474346563408,0.846079380445305,0.8451113262342691,0.8441432720232332,0.8431752178121975,0.8422071636011617,0.8412391093901258,0.8412391093901258,0.8402710551790901,0.8402710551790901,0.8393030009680542,0.8383349467570184,0.8383349467570184,0.8373668925459826,0.8363988383349468,0.8363988383349468,0.8354307841239109,0.8354307841239109,0.8344627299128751,0.8334946757018393,0.8325266214908035,0.8315585672797676,0.8305905130687319,0.829622458857696,0.8286544046466602,0.8276863504356244,0.8267182962245886,0.8257502420135527,0.8247821878025169,0.8238141335914811,0.8228460793804453,0.8218780251694094,0.8209099709583737,0.8199419167473379,0.818973862536302,0.8180058083252663,0.8170377541142304,0.8160696999031946,0.8160696999031946,0.8151016456921588,0.8151016456921588,0.814133591481123,0.814133591481123,0.8131655372700871,0.8121974830590513,0.8112294288480155,0.8102613746369797,0.8092933204259438,0.8092933204259438,0.8083252662149081,0.8073572120038722,0.8073572120038722,0.8063891577928364,0.8054211035818006,0.8044530493707648,0.8034849951597289,0.8025169409486931,0.8015488867376573,0.8005808325266215,0.7996127783155856,0.7996127783155856,0.7986447241045499,0.797676669893514,0.7967086156824782,0.7957405614714425,0.7947725072604066,0.7947725072604066,0.7938044530493708,0.7928363988383349,0.7918683446272992,0.7909002904162633,0.7899322362052275,0.7889641819941917,0.7889641819941917,0.7889641819941917,0.7879961277831559,0.78702807357212,0.7860600193610843,0.7850919651500484,0.7841239109390126,0.7831558567279767,0.782187802516941,0.7812197483059051,0.7802516940948693,0.7792836398838335,0.7783155856727977,0.7783155856727977,0.7773475314617618,0.7763794772507261,0.7754114230396902,0.7744433688286544,0.7734753146176185,0.7725072604065828,0.771539206195547,0.7705711519845111,0.7696030977734754,0.7686350435624395,0.7676669893514037,0.7666989351403679,0.7657308809293321,0.7647628267182962,0.7637947725072604,0.7628267182962246,0.7618586640851888,0.7608906098741529,0.7608906098741529,0.7599225556631172,0.7589545014520813,0.7579864472410455,0.7570183930300097,0.7560503388189739,0.755082284607938,0.755082284607938,0.7541142303969022,0.7531461761858664,0.7521781219748306,0.7512100677637947,0.7512100677637947,0.750242013552759,0.7492739593417231,0.7483059051306873,0.7473378509196515,0.7473378509196515,0.7463697967086157,0.7454017424975798,0.744433688286544,0.7434656340755083,0.7424975798644724,0.7415295256534365,0.7405614714424008,0.739593417231365,0.739593417231365,0.739593417231365,0.7386253630203291,0.7376573088092934,0.7366892545982575,0.7357212003872217,0.7347531461761858,0.7337850919651501,0.7337850919651501,0.7328170377541142,0.7318489835430784,0.7308809293320426,0.7299128751210068,0.7289448209099709,0.7279767666989352,0.7270087124878993,0.7260406582768635,0.7250726040658277,0.7241045498547919,0.723136495643756,0.7221684414327202,0.7212003872216844,0.7202323330106486,0.7192642787996127,0.7192642787996127,0.718296224588577,0.7173281703775412,0.7163601161665053,0.7153920619554696,0.7144240077444337,0.7144240077444337,0.7144240077444337,0.7134559535333979,0.712487899322362,0.7115198451113263,0.7105517909002904,0.7095837366892546,0.7086156824782188,0.707647628267183,0.707647628267183,0.7066795740561471,0.7057115198451114,0.7057115198451114,0.7047434656340755,0.7037754114230397,0.7028073572120038,0.7018393030009681,0.7008712487899322,0.6999031945788964,0.6989351403678606,0.6979670861568248,0.6969990319457889,0.6960309777347532,0.6950629235237173,0.6940948693126815,0.6940948693126815,0.6931268151016456,0.6931268151016456,0.6921587608906099,0.691190706679574,0.6902226524685382,0.6892545982575025,0.6892545982575025,0.6882865440464666,0.6873184898354308,0.686350435624395,0.6853823814133592,0.6844143272023233,0.6844143272023233,0.6834462729912875,0.6824782187802517,0.6815101645692159,0.68054211035818,0.68054211035818,0.6795740561471443,0.6795740561471443,0.6786060019361084,0.6776379477250726,0.6766698935140368,0.6766698935140368,0.675701839303001,0.6747337850919651,0.6737657308809293,0.6727976766698935,0.6718296224588577,0.6708615682478218,0.6698935140367861,0.6689254598257502,0.6679574056147144,0.6669893514036787,0.6660212971926428,0.665053242981607,0.665053242981607,0.6640851887705711,0.6631171345595354,0.6621490803484995,0.6611810261374637,0.6602129719264279,0.6592449177153921,0.6582768635043562,0.6573088092933205,0.6563407550822846,0.6563407550822846,0.6553727008712488,0.6544046466602129,0.6534365924491772,0.6524685382381413,0.6515004840271055,0.6505324298160697,0.6495643756050339,0.648596321393998,0.6476282671829623,0.6466602129719264,0.6456921587608906,0.6447241045498547,0.643756050338819,0.643756050338819,0.6427879961277831,0.6418199419167473,0.6408518877057116,0.6398838334946757,0.6389157792836399,0.6379477250726041,0.6369796708615683,0.6360116166505324,0.6350435624394967,0.6340755082284608,0.633107454017425,0.6321393998063891,0.6311713455953534,0.6302032913843175,0.6292352371732817,0.6282671829622459,0.6272991287512101,0.6263310745401742,0.6253630203291385,0.6243949661181026,0.6234269119070668,0.6224588576960309,0.6214908034849952,0.6205227492739593,0.6195546950629235,0.6185866408518877,0.6176185866408519,0.616650532429816,0.6156824782187803,0.6147144240077445,0.6137463697967086,0.6127783155856728,0.611810261374637,0.6108422071636012,0.6098741529525653,0.6089060987415296,0.6079380445304937,0.6069699903194579,0.6060019361084221,0.6050338818973863,0.6040658276863504,0.6030977734753146,0.6021297192642788,0.601161665053243,0.6001936108422071,0.5992255566311714,0.5982575024201355,0.5972894482090997,0.5963213939980639,0.5953533397870281,0.5943852855759922,0.5934172313649564,0.5924491771539206,0.5914811229428848,0.590513068731849,0.5895450145208132,0.5885769603097774,0.5876089060987415,0.5866408518877058,0.5856727976766699,0.5847047434656341,0.5837366892545982,0.5827686350435625,0.5818005808325266,0.5808325266214908,0.5808325266214908,0.579864472410455,0.5788964181994192,0.5779283639883833,0.5769603097773476,0.5759922555663117,0.5750242013552759,0.5750242013552759,0.57405614714424,0.5730880929332043,0.5721200387221684,0.5711519845111326,0.5701839303000968,0.569215876089061,0.5682478218780251,0.5682478218780251,0.5672797676669894,0.5663117134559535,0.5653436592449177,0.5643756050338818,0.5634075508228461,0.5624394966118103,0.5614714424007744,0.5605033881897387,0.5595353339787028,0.558567279767667,0.5575992255566312,0.5566311713455954,0.5556631171345595,0.5546950629235237,0.5537270087124879,0.5527589545014521,0.5517909002904162,0.5508228460793805,0.5498547918683446,0.5488867376573088,0.547918683446273,0.547918683446273,0.5469506292352372,0.5459825750242013,0.5450145208131656,0.5450145208131656,0.5440464666021297,0.5430784123910939,0.542110358180058,0.5411423039690223,0.5401742497579864,0.5392061955469506,0.5382381413359149,0.537270087124879,0.5363020329138432,0.5353339787028074,0.5343659244917716,0.5333978702807357,0.5324298160696999,0.5314617618586641,0.5304937076476283,0.5295256534365924,0.5285575992255567,0.5275895450145208,0.526621490803485,0.5256534365924492,0.5246853823814134,0.5237173281703775,0.5227492739593417,0.5217812197483059,0.5208131655372701,0.5198451113262342,0.5188770571151985,0.5179090029041626,0.5169409486931268,0.515972894482091,0.5150048402710552,0.5140367860600193,0.5130687318489835,0.5121006776379478,0.5111326234269119,0.510164569215876,0.5091965150048403,0.5091965150048403,0.5082284607938045,0.5072604065827686,0.5062923523717329,0.505324298160697,0.5043562439496612,0.5033881897386253,0.5024201355275896,0.5014520813165537,0.5014520813165537,0.5004840271055179,0.4995159728944821,0.4985479186834463,0.4975798644724105,0.49661181026137463,0.49564375605033884,0.494675701839303,0.4937076476282672,0.4927395934172314,0.49177153920619554,0.49080348499515974,0.4898354307841239,0.4888673765730881,0.4878993223620523,0.48693126815101645,0.48596321393998065,0.48596321393998065,0.4849951597289448,0.484027105517909,0.4830590513068732,0.48209099709583736,0.48112294288480156,0.4801548886737657,0.4791868344627299,0.4782187802516941,0.47725072604065827,0.4762826718296225,0.4753146176185866,0.4743465634075508,0.47337850919651503,0.4724104549854792,0.4714424007744434,0.47047434656340753,0.46950629235237173,0.46950629235237173,0.46853823814133594,0.4675701839303001,0.4666021297192643,0.46563407550822844,0.46466602129719264,0.46369796708615685,0.462729912875121,0.462729912875121,0.4617618586640852,0.46079380445304935,0.45982575024201355,0.45885769603097776,0.4578896418199419,0.4569215876089061,0.45595353339787026,0.45498547918683446,0.45401742497579867,0.4530493707647628,0.452081316553727,0.45111326234269117,0.45014520813165537,0.4491771539206196,0.4482090997095837,0.44724104549854793,0.4462729912875121,0.4453049370764763,0.4453049370764763,0.4443368828654405,0.44336882865440463,0.44240077444336884,0.441432720232333,0.4404646660212972,0.4394966118102614,0.43852855759922554,0.43756050338818975,0.4365924491771539,0.4356243949661181,0.4346563407550823,0.43368828654404645,0.43272023233301066,0.4317521781219748,0.430784123910939,0.4298160696999032,0.42884801548886736,0.42787996127783157,0.4269119070667957,0.4259438528557599,0.4249757986447241,0.42400774443368827,0.42400774443368827,0.4230396902226525,0.4220716360116166,0.42110358180058083,0.42013552758954503,0.4191674733785092,0.4181994191674734,0.41723136495643753,0.41626331074540174,0.41529525653436594,0.4143272023233301,0.4133591481122943,0.41239109390125844,0.41142303969022265,0.41045498547918685,0.409486931268151,0.4085188770571152,0.4075508228460794,0.40658276863504356,0.40561471442400776,0.4046466602129719,0.4036786060019361,0.4027105517909003,0.40174249757986447,0.40077444336882867,0.3998063891577928,0.398838334946757,0.3978702807357212,0.3978702807357212,0.3969022265246854,0.3959341723136496,0.39496611810261373,0.39399806389157793,0.39303000968054214,0.3920619554695063,0.3910939012584705,0.39012584704743464,0.38818973862536305,0.3872216844143272,0.38528557599225555,0.38431752178121975,0.38334946757018395,0.3823814133591481,0.3814133591481123,0.38044530493707646,0.37947725072604066,0.37850919651500486,0.377541142303969,0.3765730880929332,0.37560503388189737,0.37463697967086157,0.3736689254598258,0.3727008712487899,0.3717328170377541,0.3707647628267183,0.3697967086156825,0.3688286544046467,0.36786060019361083,0.36689254598257504,0.3659244917715392,0.3649564375605034,0.3639883833494676,0.36302032913843174,0.36205227492739595,0.3610842207163601,0.3601161665053243,0.3591481122942885,0.35818005808325265,0.35721200387221685,0.356243949661181,0.3552758954501452,0.3543078412391094,0.35333978702807356,0.35237173281703776,0.3514036786060019,0.3504356243949661,0.3494675701839303,0.34849951597289447,0.3475314617618587,0.3465634075508228,0.345595353339787,0.34462729912875123,0.3436592449177154,0.3426911907066796,0.34172313649564373,0.34075508228460794,0.33978702807357214,0.3388189738625363,0.3388189738625363,0.3378509196515005,0.33688286544046464,0.33591481122942884,0.33494675701839305,0.3339787028073572,0.3330106485963214,0.33204259438528555,0.33107454017424975,0.33010648596321396,0.3291384317521781,0.3281703775411423,0.32720232333010646,0.32623426911907066,0.32526621490803487,0.324298160696999,0.3233301064859632,0.32236205227492737,0.3213939980638916,0.3204259438528558,0.3194578896418199,0.31848983543078413,0.31752178121974833,0.3165537270087125,0.3155856727976767,0.31461761858664083,0.31364956437560504,0.31268151016456924,0.3117134559535334,0.3107454017424976,0.30977734753146174,0.30880929332042595,0.30784123910939015,0.3068731848983543,0.3059051306873185,0.30493707647628265,0.30396902226524686,0.30300096805421106,0.3020329138431752,0.3010648596321394,0.30009680542110356,0.29912875121006777,0.29816069699903197,0.2971926427879961,0.2971926427879961,0.2962245885769603,0.2952565343659245,0.2942884801548887,0.2933204259438529,0.29235237173281703,0.29138431752178123,0.2904162633107454,0.2894482090997096,0.2884801548886738,0.28751210067763794,0.28654404646660214,0.2855759922555663,0.2846079380445305,0.2836398838334947,0.28267182962245885,0.28170377541142305,0.2807357212003872,0.2797676669893514,0.27783155856727976,0.27686350435624396,0.2758954501452081,0.2749273959341723,0.2739593417231365,0.27299128751210067,0.27202323330106487,0.271055179090029,0.2700871248789932,0.2691190706679574,0.2681510164569216,0.2671829622458858,0.26621490803484993,0.26524685382381413,0.26427879961277834,0.2633107454017425,0.2623426911907067,0.26137463697967084,0.26040658276863504,0.25943852855759925,0.2584704743465634,0.2575024201355276,0.25653436592449175,0.25556631171345595,0.25459825750242016,0.2536302032913843,0.2526621490803485,0.25169409486931266,0.25072604065827686,0.24975798644724104,0.24878993223620524,0.24782187802516942,0.2468538238141336,0.24588576960309777,0.24491771539206195,0.24394966118102615,0.24298160696999033,0.2420135527589545,0.24104549854791868,0.24007744433688286,0.23910939012584706,0.23814133591481124,0.2371732817037754,0.2362052274927396,0.23523717328170377,0.23426911907066797,0.23330106485963215,0.23233301064859632,0.2313649564375605,0.23039690222652467,0.22942884801548888,0.22846079380445306,0.22749273959341723,0.22749273959341723,0.2265246853823814,0.22555663117134558,0.2245885769603098,0.22362052274927396,0.22265246853823814,0.22168441432720232,0.2207163601161665,0.2197483059051307,0.21878025169409487,0.21781219748305905,0.21684414327202323,0.2158760890609874,0.2149080348499516,0.21393998063891578,0.21297192642787996,0.21200387221684414,0.2110358180058083,0.21006776379477252,0.2090997095837367,0.20813165537270087,0.20716360116166505,0.20619554695062922,0.2042594385285576,0.20329138431752178,0.20232333010648595,0.20135527589545016,0.20038722168441434,0.1994191674733785,0.1984511132623427,0.19748305905130686,0.19651500484027107,0.19554695062923524,0.19457889641819942,0.1936108422071636,0.19264278799612777,0.19167473378509198,0.19070667957405615,0.18973862536302033,0.1887705711519845,0.18780251694094868,0.1868344627299129,0.18586640851887706,0.18489835430784124,0.18393030009680542,0.1829622458857696,0.1819941916747338,0.18102613746369797,0.18005808325266215,0.17909002904162633,0.1781219748305905,0.1771539206195547,0.17618586640851888,0.17521781219748306,0.17424975798644723,0.1732817037754114,0.17231364956437561,0.1713455953533398,0.17037754114230397,0.16940948693126814,0.16844143272023232,0.16747337850919652,0.1665053242981607,0.16553727008712488,0.16456921587608905,0.16360116166505323,0.16263310745401743,0.1616650532429816,0.1606969990319458,0.15972894482090996,0.15876089060987417,0.15779283639883834,0.15682478218780252,0.1558567279767667,0.15488867376573087,0.15392061955469508,0.15295256534365925,0.15198451113262343,0.1510164569215876,0.15004840271055178,0.14908034849951599,0.14811229428848016,0.14714424007744434,0.14617618586640851,0.1452081316553727,0.1442400774443369,0.14327202323330107,0.14230396902226525,0.14133591481122942,0.14133591481122942,0.1403678606001936,0.1393998063891578,0.13843175217812198,0.13746369796708616,0.13649564375605033,0.1355275895450145,0.1345595353339787,0.1335914811229429,0.13262342691190707,0.13165537270087124,0.13068731848983542,0.12971926427879962,0.1287512100677638,0.12778315585672798,0.12681510164569215,0.12584704743465633,0.12487899322362052,0.12391093901258471,0.12294288480154889,0.12197483059051308,0.12100677637947725,0.12003872216844143,0.11907066795740562,0.1181026137463698,0.11713455953533398,0.11616650532429816,0.11519845111326234,0.11423039690222653,0.1132623426911907,0.1122942884801549,0.11132623426911907,0.11035818005808325,0.10939012584704744,0.10842207163601161,0.1074540174249758,0.10648596321393998,0.10551790900290416,0.10454985479186835,0.10358180058083252,0.10261374636979671,0.10164569215876089,0.10067763794772508,0.09970958373668926,0.09874152952565343,0.09777347531461762,0.0968054211035818,0.09583736689254599,0.09486931268151017,0.09390125847047434,0.09293320425943853,0.09196515004840271,0.0909970958373669,0.09002904162633107,0.08906098741529525,0.08809293320425944,0.08615682478218781,0.08518877057115198,0.08422071636011616,0.08325266214908035,0.08228460793804453,0.08131655372700872,0.0803484995159729,0.07938044530493708,0.07841239109390126,0.07744433688286544,0.07647628267182963,0.0755082284607938,0.07454017424975799,0.07357212003872217,0.07260406582768635,0.07163601161665054,0.07066795740561471,0.0696999031945789,0.06873184898354308,0.06776379477250725,0.06679574056147145,0.06582768635043562,0.06485963213939981,0.06389157792836399,0.06292352371732816,0.061955469506292354,0.06098741529525654,0.060019361084220714,0.0590513068731849,0.05808325266214908,0.057115198451113264,0.05614714424007745,0.05517909002904162,0.05517909002904162,0.05517909002904162,0.05421103581800581,0.05324298160696999,0.05227492739593417,0.051306873184898356,0.05033881897386254,0.049370764762826716,0.0484027105517909,0.04743465634075508,0.046466602129719266,0.04549854791868345,0.044530493707647625,0.044530493707647625,0.04356243949661181,0.04259438528557599,0.041626331074540175,0.04065827686350436,0.03969022265246854,0.03872216844143272,0.0377541142303969,0.036786060019361085,0.03581800580832527,0.03484995159728945,0.03388189738625363,0.03291384317521781,0.031945788964181994,0.031945788964181994,0.030977734753146177,0.030009680542110357,0.02904162633107454,0.027105517909002903,0.026137463697967087,0.02516940948693127,0.02420135527589545,0.023233301064859633,0.022265246853823813,0.021297192642787996,0.02032913843175218,0.01936108422071636,0.018393030009680542,0.017424975798644726,0.016456921587608905,0.015488867376573089,0.015488867376573089,0.01452081316553727,0.013552758954501452,0.012584704743465635,0.011616650532429816,0.010648596321393998,0.00968054211035818,0.008712487899322363,0.007744433688286544,0.006776379477250726,0.005808325266214908,0.00484027105517909,0.003872216844143272,0.002904162633107454,0.001936108422071636,0.000968054211035818,0.0],\"xaxis\":\"x\",\"y\":[0.7341862117981521,0.7347083926031295,0.7352313167259786,0.7357549857549858,0.7362794012829651,0.7368045649072753,0.7373304782298359,0.7378571428571429,0.7383845604002859,0.7389127324749643,0.7394416607015032,0.7399713467048711,0.7405017921146954,0.7410329985652798,0.741564967695621,0.7420977011494253,0.7426312005751258,0.7431654676258993,0.7437005039596832,0.7442363112391931,0.7447728911319395,0.7453102453102453,0.7458483754512636,0.7463872832369942,0.7469269703543022,0.7474674384949349,0.7480086893555394,0.7485507246376811,0.7490935460478607,0.7496371552975326,0.7501815541031227,0.7507267441860465,0.7512727272727273,0.7518195050946143,0.752367079388201,0.7529154518950437,0.7534646243617797,0.754014598540146,0.7545653761869978,0.7551169590643275,0.7556693489392831,0.7562225475841874,0.7567765567765568,0.7573313782991202,0.7578870139398386,0.7584434654919237,0.7590007347538574,0.7595588235294117,0.7601177336276674,0.7606774668630338,0.7612380250552689,0.7617994100294986,0.7623616236162362,0.7629246676514032,0.7634885439763488,0.7640532544378699,0.764618800888231,0.7651851851851852,0.765752409191994,0.766320474777448,0.7668893838158871,0.7674591381872214,0.7680297397769517,0.7686011904761905,0.7691734921816828,0.7697466467958272,0.7703206562266965,0.7708955223880597,0.7714712471994025,0.7720478325859492,0.7726252804786836,0.7732035928143712,0.7737827715355805,0.7743628185907047,0.7749437359339835,0.7755255255255256,0.7761081893313299,0.7766917293233083,0.7772761474793077,0.7778614457831325,0.7784476262245666,0.7790346907993967,0.779622641509434,0.7802114803625377,0.780801209372638,0.7813918305597579,0.7819833459500378,0.7825757575757576,0.7831690674753601,0.783763277693475,0.7843583902809416,0.7849544072948328,0.785551330798479,0.7861491628614916,0.7867479055597868,0.7873475609756098,0.7879481311975591,0.7885496183206107,0.7891520244461421,0.7897553516819572,0.7903596021423106,0.7909647779479326,0.7915708812260537,0.7921779141104295,0.7927858787413661,0.793394777265745,0.7940046118370484,0.7946153846153846,0.7952270977675134,0.7958397534668721,0.7964533538936006,0.7970679012345679,0.7976833976833977,0.7982998454404946,0.7989172467130704,0.7995356037151703,0.8001549186676995,0.8007751937984496,0.8013964313421257,0.8020186335403726,0.8026418026418026,0.8032659409020217,0.8038910505836576,0.8045171339563862,0.8051441932969603,0.8057722308892356,0.8064012490241999,0.80703125,0.8076622361219703,0.8082942097026604,0.8089271730618638,0.8095611285266457,0.8101960784313725,0.8108320251177394,0.8114689709347996,0.8121069182389937,0.8127458693941778,0.8133858267716535,0.814026792750197,0.8146687697160884,0.8153117600631413,0.815955766192733,0.8166007905138339,0.817246835443038,0.8178939034045922,0.8185419968304279,0.8191911181601903,0.8198412698412698,0.8204924543288324,0.8211446740858506,0.8217979315831344,0.822452229299363,0.8231075697211155,0.8237639553429027,0.8244213886671987,0.8250798722044729,0.8257394084732215,0.8264,0.8270616493194556,0.8277243589743589,0.8283881315156375,0.8290529695024077,0.8297188755020081,0.8303858520900321,0.831053901850362,0.8317230273752013,0.8315874294923449,0.832258064516129,0.8329297820823245,0.8336025848142165,0.8342764753435732,0.8349514563106796,0.8356275303643724,0.8363047001620746,0.8369829683698297,0.8376623376623377,0.8390243902439024,0.8397070789259561,0.8403908794788274,0.8410757946210269,0.8417618270799347,0.8424489795918367,0.8431372549019608,0.8438266557645135,0.8445171849427169,0.8443898443898444,0.8450819672131148,0.8457752255947498,0.8456486042692939,0.8463434675431388,0.8470394736842105,0.8477366255144033,0.8484349258649094,0.8491343775762572,0.849009900990099,0.8497109826589595,0.8504132231404958,0.8511166253101737,0.8518211920529801,0.8525269262634632,0.8532338308457711,0.8539419087136929,0.8546511627906976,0.8553615960099751,0.8560732113144759,0.8567860116569526,0.8575,0.8582151793160967,0.8580968280467446,0.858813700918964,0.8595317725752508,0.8602510460251046,0.8609715242881072,0.8608549874266554,0.8615771812080537,0.8623005877413937,0.8630252100840337,0.8637510513036165,0.8644781144781145,0.8643639427127211,0.8650927487352446,0.8649789029535865,0.8648648648648649,0.8655959425190194,0.8663282571912013,0.8670618120237087,0.8677966101694915,0.8685326547921968,0.8692699490662139,0.8700084961767205,0.8707482993197279,0.8706382978723404,0.8713798977853492,0.8721227621483376,0.8720136518771331,0.8727583262169086,0.8735042735042735,0.8733960650128315,0.8732876712328768,0.8731790916880892,0.8730703259005146,0.8738197424892704,0.8737113402061856,0.8736027515047291,0.8743545611015491,0.8742463393626184,0.8741379310344828,0.8740293356341674,0.8747841105354058,0.874675885911841,0.8745674740484429,0.8753246753246753,0.8752166377816292,0.8759757155247181,0.8767361111111112,0.8766290182450044,0.8773913043478261,0.8781549173194082,0.8789198606271778,0.8796861377506539,0.8804537521815009,0.880349344978166,0.8811188811188811,0.8810148731408574,0.8817863397548161,0.8825591586327782,0.8833333333333333,0.884108867427568,0.8848857644991213,0.8847845206684257,0.8855633802816901,0.8854625550660793,0.8862433862433863,0.8870255957634599,0.8869257950530035,0.887709991158267,0.8876106194690265,0.8883968113374667,0.8891843971631206,0.8899733806566105,0.8907637655417406,0.8915555555555555,0.8923487544483986,0.8922528940338379,0.893048128342246,0.8929527207850134,0.89375,0.8945487042001787,0.8944543828264758,0.8943598925693823,0.8942652329749103,0.8941704035874439,0.8940754039497307,0.894878706199461,0.89568345323741,0.8964896489648965,0.8972972972972973,0.8981064021641119,0.898014440433213,0.8979223125564589,0.8987341772151899,0.8995475113122172,0.9003623188405797,0.900271985494107,0.9001814882032668,0.9000908265213442,0.9009090909090909,0.9017288444040037,0.9025500910746812,0.902461257976299,0.9023722627737226,0.9031963470319635,0.903107861060329,0.9030192131747484,0.9029304029304029,0.9028414298808433,0.9036697247706422,0.9035812672176309,0.9034926470588235,0.9043238270469182,0.9042357274401474,0.904147465437788,0.9040590405904059,0.9039704524469068,0.9038817005545287,0.9037927844588344,0.9037037037037037,0.9045412418906394,0.9044526901669759,0.9052924791086351,0.9061338289962825,0.9069767441860465,0.9078212290502793,0.907735321528425,0.9076492537313433,0.9084967320261438,0.908411214953271,0.9083255378858747,0.9082397003745318,0.9081537019681349,0.9090056285178236,0.9098591549295775,0.9107142857142857,0.9106302916274694,0.911487758945386,0.9123468426013195,0.9122641509433962,0.9121813031161473,0.9120982986767486,0.9120151371807,0.9119318181818182,0.9118483412322275,0.9117647058823529,0.9116809116809117,0.9115969581749049,0.9115128449096099,0.9114285714285715,0.9113441372735939,0.9122137404580153,0.9121298949379179,0.9130019120458891,0.9129186602870814,0.9128352490421456,0.912751677852349,0.9126679462571977,0.9125840537944284,0.9125,0.9133782483156881,0.9132947976878613,0.914175506268081,0.9140926640926641,0.9140096618357488,0.913926499032882,0.914811229428848,0.9156976744186046,0.9165858389912707,0.916504854368932,0.9164237123420796,0.9163424124513618,0.9172346640701071,0.9171539961013645,0.9170731707317074,0.9169921875,0.916911045943304,0.9168297455968689,0.9177277179236043,0.9176470588235294,0.9175662414131501,0.9174852652259332,0.9174041297935103,0.9173228346456693,0.9172413793103448,0.9171597633136095,0.9170779861796644,0.9179841897233202,0.9179030662710188,0.9188118811881189,0.9187314172447968,0.9196428571428571,0.9195630585898709,0.9194831013916501,0.9194029850746268,0.9203187250996016,0.9202392821535393,0.9201596806387226,0.9210789210789211,0.921,0.9209209209209209,0.9218436873747495,0.9227683049147443,0.9226907630522089,0.9226130653266331,0.9225352112676056,0.9224572004028198,0.9233870967741935,0.9233097880928355,0.9242424242424242,0.9241658240647118,0.9251012145748988,0.9250253292806484,0.9259634888438134,0.9269035532994924,0.926829268292683,0.9267548321464903,0.9276985743380856,0.9276248725790011,0.9275510204081633,0.9274770173646578,0.9284253578732107,0.9293756397134084,0.9293032786885246,0.9292307692307692,0.9291581108829569,0.9290853031860226,0.9290123456790124,0.9289392378990731,0.9298969072164949,0.9308565531475749,0.9318181818181818,0.9327817993795243,0.932712215320911,0.9326424870466321,0.9325726141078838,0.9325025960539979,0.9324324324324325,0.9323621227887617,0.9333333333333333,0.9332638164754953,0.9342379958246346,0.93521421107628,0.9351464435146444,0.9350785340314136,0.9350104821802935,0.9349422875131165,0.9348739495798319,0.9348054679284963,0.9347368421052632,0.934668071654373,0.9356540084388185,0.9355860612460402,0.9355179704016914,0.9365079365079365,0.9364406779661016,0.936373276776246,0.9363057324840764,0.9362380446333688,0.9361702127659575,0.9361022364217252,0.9360341151385928,0.935965848452508,0.9358974358974359,0.9368983957219251,0.936830835117773,0.9367631296891747,0.9366952789699571,0.9366272824919442,0.9365591397849462,0.9364908503767492,0.9364224137931034,0.9374325782092773,0.937365010799136,0.9383783783783783,0.9383116883116883,0.9382448537378115,0.9392624728850325,0.9391965255157437,0.9391304347826087,0.940152339499456,0.9400871459694989,0.9411123227917121,0.9410480349344978,0.940983606557377,0.9409190371991247,0.940854326396495,0.9407894736842105,0.9407244785949506,0.9406593406593406,0.9405940594059405,0.9405286343612335,0.9404630650496141,0.9403973509933775,0.9403314917127071,0.9402654867256637,0.9401993355481728,0.9401330376940134,0.9400665926748057,0.94,0.9399332591768632,0.9398663697104677,0.939799331103679,0.9408482142857143,0.9407821229050279,0.941834451901566,0.9417693169092946,0.9428251121076233,0.9427609427609428,0.9426966292134832,0.9426321709786277,0.9425675675675675,0.9425028184892897,0.9435665914221218,0.943502824858757,0.9434389140271493,0.9445073612684032,0.9444444444444444,0.9443813847900113,0.9443181818181818,0.944254835039818,0.9441913439635535,0.9441277080957811,0.9440639269406392,0.944,0.9450800915331807,0.9450171821305842,0.944954128440367,0.9448909299655568,0.9448275862068966,0.9447640966628308,0.945852534562212,0.9457900807381776,0.9457274826789839,0.945664739884393,0.9456018518518519,0.9455388180764774,0.9454756380510441,0.9465737514518002,0.9476744186046512,0.9476135040745053,0.9475524475524476,0.9474912485414235,0.947429906542056,0.9473684210526315,0.9473067915690867,0.9472450175849941,0.9471830985915493,0.9471210340775558,0.9470588235294117,0.9469964664310954,0.9481132075471698,0.948051948051948,0.9479905437352246,0.9479289940828403,0.9478672985781991,0.9478054567022538,0.9477434679334917,0.9476813317479191,0.9476190476190476,0.9475566150178785,0.9474940334128878,0.9474313022700119,0.9473684210526315,0.9473053892215569,0.947242206235012,0.9471788715486195,0.9471153846153846,0.9470517448856799,0.946987951807229,0.9481302774427021,0.9480676328502415,0.9480048367593712,0.9479418886198547,0.9478787878787879,0.9478155339805825,0.9477521263669502,0.948905109489051,0.9488428745432399,0.948780487804878,0.9487179487179487,0.9486552567237164,0.9498164014687882,0.9497549019607843,0.9496932515337423,0.9496314496314496,0.949569495694957,0.9507389162561576,0.9506781750924784,0.9506172839506173,0.9505562422744128,0.9504950495049505,0.9504337050805453,0.9503722084367245,0.9503105590062112,0.9502487562189055,0.9514321295143213,0.9526184538653366,0.9525593008739076,0.9525,0.9524405506883604,0.9523809523809523,0.9523212045169385,0.9522613065326633,0.9534591194968554,0.9534005037783375,0.9533417402269861,0.9532828282828283,0.9532237673830595,0.9531645569620253,0.9531051964512041,0.9530456852791879,0.9529860228716646,0.9529262086513995,0.9528662420382166,0.9528061224489796,0.9527458492975734,0.9526854219948849,0.9526248399487837,0.9525641025641025,0.9537869062901155,0.9537275064267352,0.9536679536679536,0.9536082474226805,0.9535483870967741,0.9534883720930233,0.9547218628719275,0.9559585492227979,0.9559014267185474,0.9558441558441558,0.9557867360208062,0.9557291666666666,0.9556714471968709,0.9556135770234987,0.9555555555555556,0.9568062827225131,0.9567496723460026,0.9566929133858267,0.9579500657030223,0.9578947368421052,0.9578392621870883,0.9577836411609498,0.9577278731836195,0.9576719576719577,0.9576158940397351,0.9575596816976127,0.9575033200531209,0.9574468085106383,0.9573901464713716,0.9573333333333334,0.9572763684913218,0.9585561497326203,0.9585006693440429,0.9597855227882037,0.959731543624161,0.9596774193548387,0.9596231493943472,0.9595687331536388,0.9608636977058029,0.9608108108108108,0.9607577807848444,0.9607046070460704,0.9606512890094979,0.9605978260869565,0.9619047619047619,0.9618528610354223,0.9618008185538881,0.9617486338797814,0.9616963064295485,0.963013698630137,0.9629629629629629,0.9642857142857143,0.9642365887207703,0.9641873278236914,0.9641379310344828,0.9654696132596685,0.9654218533886584,0.9653739612188366,0.9653259361997226,0.9652777777777778,0.9652294853963839,0.9651810584958217,0.9651324965132496,0.9650837988826816,0.965034965034965,0.9649859943977591,0.9649368863955119,0.9648876404494382,0.9662447257383966,0.9661971830985916,0.9661495063469676,0.9661016949152542,0.9660537482319661,0.9660056657223796,0.9659574468085106,0.9659090909090909,0.9658605974395448,0.9658119658119658,0.9671897289586305,0.9671428571428572,0.9670958512160229,0.9670487106017192,0.9670014347202296,0.9669540229885057,0.9669064748201439,0.9668587896253602,0.9668109668109668,0.9667630057803468,0.9667149059334298,0.9666666666666667,0.9666182873730044,0.9665697674418605,0.9679767103347889,0.967930029154519,0.9678832116788321,0.9678362573099415,0.9677891654465594,0.967741935483871,0.9676945668135095,0.9676470588235294,0.96759941089838,0.967551622418879,0.9675036927621861,0.9674556213017751,0.9674074074074074,0.9673590504451038,0.9673105497771174,0.9672619047619048,0.9672131147540983,0.9671641791044776,0.9671150971599403,0.9670658682634731,0.967016491754123,0.9669669669669669,0.9669172932330827,0.9668674698795181,0.9668174962292609,0.9667673716012085,0.9667170953101362,0.9666666666666667,0.9666160849772383,0.9665653495440729,0.9665144596651446,0.9664634146341463,0.966412213740458,0.9663608562691132,0.9663093415007658,0.9662576687116564,0.9662058371735791,0.9661538461538461,0.9661016949152542,0.9660493827160493,0.9659969088098919,0.9659442724458205,0.9658914728682171,0.9658385093167702,0.9657853810264385,0.9657320872274143,0.9656786271450858,0.965625,0.9655712050078247,0.9655172413793104,0.9654631083202512,0.9654088050314465,0.9653543307086614,0.9652996845425867,0.9652448657187994,0.9651898734177216,0.96513470681458,0.9650793650793651,0.9650238473767886,0.964968152866242,0.9649122807017544,0.9648562300319489,0.9648,0.9647435897435898,0.9646869983948636,0.9646302250803859,0.966183574879227,0.9661290322580646,0.9660743134087237,0.9660194174757282,0.965964343598055,0.9659090909090909,0.9658536585365853,0.9674267100977199,0.967373572593801,0.9673202614379085,0.967266775777414,0.9672131147540983,0.9671592775041051,0.9671052631578947,0.9670510708401977,0.9686468646864687,0.968595041322314,0.9685430463576159,0.9684908789386402,0.96843853820598,0.9683860232945092,0.9683333333333334,0.9682804674457429,0.9682274247491639,0.9681742043551089,0.9681208053691275,0.9680672268907563,0.968013468013468,0.9679595278246206,0.9679054054054054,0.9678510998307953,0.9677966101694915,0.967741935483871,0.967687074829932,0.9676320272572402,0.9675767918088737,0.9675213675213675,0.9691780821917808,0.9691252144082333,0.9690721649484536,0.9690189328743546,0.9706896551724138,0.9706390328151986,0.9705882352941176,0.9705372616984402,0.9704861111111112,0.9704347826086956,0.9703832752613241,0.9703315881326352,0.9702797202797203,0.9702276707530648,0.9701754385964912,0.9701230228471002,0.9700704225352113,0.9700176366843033,0.9699646643109541,0.9699115044247788,0.9698581560283688,0.9698046181172292,0.9697508896797153,0.9696969696969697,0.9696428571428571,0.9695885509838998,0.9695340501792115,0.9694793536804309,0.9694244604316546,0.9693693693693693,0.9693140794223827,0.969258589511754,0.9692028985507246,0.969147005444646,0.9690909090909091,0.9690346083788707,0.968978102189781,0.9689213893967094,0.9688644688644689,0.9688073394495413,0.96875,0.9686924493554327,0.9704797047970479,0.9704251386321626,0.9703703703703703,0.9703153988868275,0.9702602230483272,0.9702048417132216,0.9701492537313433,0.9700934579439252,0.9700374531835206,0.9718574108818011,0.9718045112781954,0.9717514124293786,0.9716981132075472,0.9716446124763705,0.9715909090909091,0.9715370018975332,0.9714828897338403,0.9714285714285714,0.9713740458015268,0.97131931166348,0.9712643678160919,0.9712092130518234,0.9711538461538461,0.9710982658959537,0.971042471042471,0.9709864603481625,0.9728682170542635,0.9728155339805825,0.9727626459143969,0.9727095516569201,0.97265625,0.9726027397260274,0.9725490196078431,0.9724950884086444,0.9724409448818898,0.9723865877712031,0.9723320158102767,0.9722772277227723,0.9722222222222222,0.9721669980119284,0.9721115537848606,0.9720558882235529,0.972,0.9719438877755511,0.9738955823293173,0.9738430583501007,0.9737903225806451,0.9737373737373738,0.9736842105263158,0.973630831643002,0.9735772357723578,0.9735234215885947,0.9755102040816327,0.9754601226993865,0.9754098360655737,0.9753593429158111,0.9753086419753086,0.9752577319587629,0.9752066115702479,0.9751552795031055,0.975103734439834,0.975051975051975,0.975,0.9749478079331941,0.9748953974895398,0.9748427672955975,0.9747899159663865,0.9747368421052631,0.9746835443037974,0.9746300211416491,0.9745762711864406,0.9766454352441614,0.9765957446808511,0.976545842217484,0.9764957264957265,0.9764453961456103,0.9763948497854077,0.9763440860215054,0.9762931034482759,0.9762419006479481,0.9761904761904762,0.9761388286334056,0.9760869565217392,0.9760348583877996,0.9759825327510917,0.975929978118162,0.9758771929824561,0.9758241758241758,0.9757709251101322,0.9757174392935982,0.9756637168141593,0.975609756097561,0.9755555555555555,0.9755011135857461,0.9776785714285714,0.9776286353467561,0.9775784753363229,0.9775280898876404,0.9774774774774775,0.9774266365688488,0.9773755656108597,0.9773242630385488,0.9772727272727273,0.9772209567198178,0.9771689497716894,0.977116704805492,0.9770642201834863,0.9770114942528736,0.9769585253456221,0.976905311778291,0.9768518518518519,0.9767981438515081,0.9767441860465116,0.9766899766899767,0.9766355140186916,0.9765807962529274,0.9765258215962441,0.9764705882352941,0.9764150943396226,0.9763593380614657,0.976303317535545,0.9762470308788599,0.9785714285714285,0.9785202863961814,0.9784688995215312,0.9784172661870504,0.9783653846153846,0.9783132530120482,0.9782608695652174,0.9782082324455206,0.9781553398058253,0.9780487804878049,0.9779951100244498,0.9778869778869779,0.9778325123152709,0.9777777777777777,0.9777227722772277,0.9776674937965261,0.9776119402985075,0.9775561097256857,0.9775,0.9774436090225563,0.9773869346733668,0.9773299748110831,0.9772727272727273,0.9772151898734177,0.9771573604060914,0.9770992366412213,0.9770408163265306,0.9769820971867008,0.9769230769230769,0.9768637532133676,0.9768041237113402,0.9767441860465116,0.9766839378238342,0.9766233766233766,0.9765625,0.9765013054830287,0.9764397905759162,0.9763779527559056,0.9763157894736842,0.9762532981530343,0.9761904761904762,0.9761273209549072,0.976063829787234,0.976,0.9759358288770054,0.9758713136729222,0.9758064516129032,0.9757412398921833,0.9756756756756757,0.975609756097561,0.9755434782608695,0.9754768392370572,0.9754098360655737,0.9753424657534246,0.9752747252747253,0.9752066115702479,0.9751381215469613,0.9750692520775623,0.975,0.9749303621169917,0.9776536312849162,0.9775910364145658,0.9775280898876404,0.9774647887323944,0.9774011299435028,0.9773371104815864,0.9772727272727273,0.9772079772079773,0.9771428571428571,0.9770773638968482,0.9770114942528736,0.9769452449567724,0.976878612716763,0.9768115942028985,0.9767441860465116,0.9766763848396501,0.9766081871345029,0.9765395894428153,0.9764705882352941,0.976401179941003,0.9763313609467456,0.9762611275964391,0.9761904761904762,0.9761194029850746,0.9760479041916168,0.975975975975976,0.9759036144578314,0.9758308157099698,0.9757575757575757,0.9756838905775076,0.975609756097561,0.9755351681957186,0.9754601226993865,0.9753846153846154,0.9753086419753086,0.9752321981424149,0.9751552795031055,0.9750778816199377,0.975,0.9749216300940439,0.9748427672955975,0.9747634069400631,0.9746835443037974,0.9746031746031746,0.9777070063694268,0.9776357827476039,0.9775641025641025,0.977491961414791,0.9774193548387097,0.9773462783171522,0.9772727272727273,0.9771986970684039,0.9771241830065359,0.9770491803278688,0.9769736842105263,0.976897689768977,0.9768211920529801,0.9767441860465116,0.9766666666666667,0.9765886287625418,0.9765100671140939,0.9764309764309764,0.9763513513513513,0.9761904761904762,0.9761092150170648,0.976027397260274,0.9759450171821306,0.9758620689655172,0.9757785467128027,0.9756944444444444,0.975609756097561,0.9755244755244755,0.9754385964912281,0.9753521126760564,0.9752650176678446,0.975177304964539,0.9750889679715302,0.975,0.974910394265233,0.9748201438848921,0.9747292418772563,0.9746376811594203,0.9745454545454545,0.9744525547445255,0.9743589743589743,0.9742647058823529,0.974169741697417,0.9740740740740741,0.9739776951672863,0.9738805970149254,0.9737827715355806,0.9736842105263158,0.9735849056603774,0.9734848484848485,0.973384030418251,0.9732824427480916,0.9731800766283525,0.9730769230769231,0.972972972972973,0.9728682170542635,0.9727626459143969,0.97265625,0.9725490196078431,0.9724409448818898,0.9723320158102767,0.9722222222222222,0.9721115537848606,0.972,0.9718875502008032,0.9717741935483871,0.97165991902834,0.9715447154471545,0.9714285714285714,0.9713114754098361,0.9711934156378601,0.9710743801652892,0.975103734439834,0.975,0.9748953974895398,0.9747899159663865,0.9746835443037974,0.9745762711864406,0.9744680851063829,0.9743589743589743,0.9742489270386266,0.9741379310344828,0.974025974025974,0.9739130434782609,0.9737991266375546,0.9736842105263158,0.973568281938326,0.9734513274336283,0.9733333333333334,0.9732142857142857,0.9730941704035875,0.972972972972973,0.9728506787330317,0.9727272727272728,0.9726027397260274,0.9723502304147466,0.9722222222222222,0.9720930232558139,0.9719626168224299,0.971830985915493,0.9716981132075472,0.9715639810426541,0.9714285714285714,0.9712918660287081,0.9711538461538461,0.9710144927536232,0.970873786407767,0.9707317073170731,0.9705882352941176,0.9704433497536946,0.9702970297029703,0.9701492537313433,0.97,0.9698492462311558,0.9696969696969697,0.9695431472081218,0.9693877551020408,0.9692307692307692,0.9690721649484536,0.9689119170984456,0.96875,0.9685863874345549,0.968421052631579,0.9682539682539683,0.9680851063829787,0.9679144385026738,0.967741935483871,0.9675675675675676,0.967391304347826,0.9672131147540983,0.967032967032967,0.9668508287292817,0.9666666666666667,0.9664804469273743,0.9662921348314607,0.9661016949152542,0.9659090909090909,0.9657142857142857,0.9655172413793104,0.9653179190751445,0.9651162790697675,0.9649122807017544,0.9647058823529412,0.9644970414201184,0.9642857142857143,0.9640718562874252,0.963855421686747,0.9636363636363636,0.9634146341463414,0.9631901840490797,0.9629629629629629,0.9627329192546584,0.9625,0.9622641509433962,0.9620253164556962,0.9617834394904459,0.9615384615384616,0.9612903225806452,0.961038961038961,0.9607843137254902,0.9605263157894737,0.9668874172185431,0.9666666666666667,0.9664429530201343,0.9662162162162162,0.9659863945578231,0.9657534246575342,0.9655172413793104,0.9652777777777778,0.965034965034965,0.9647887323943662,0.9645390070921985,0.9642857142857143,0.9640287769784173,0.9637681159420289,0.9635036496350365,0.9632352941176471,0.9629629629629629,0.9626865671641791,0.9624060150375939,0.9621212121212122,0.9618320610687023,0.9615384615384616,0.9612403100775194,0.9609375,0.9606299212598425,0.9603174603174603,0.96,0.9596774193548387,0.959349593495935,0.9590163934426229,0.9586776859504132,0.9583333333333334,0.957983193277311,0.9576271186440678,0.9572649572649573,0.9568965517241379,0.9565217391304348,0.956140350877193,0.9557522123893806,0.9553571428571429,0.954954954954955,0.9545454545454546,0.9541284403669725,0.9537037037037037,0.9532710280373832,0.9528301886792453,0.9523809523809523,0.9519230769230769,0.9514563106796117,0.9509803921568627,0.9504950495049505,0.95,0.9494949494949495,0.9489795918367347,0.9484536082474226,0.9479166666666666,0.9468085106382979,0.946236559139785,0.9456521739130435,0.945054945054945,0.9444444444444444,0.9438202247191011,0.9431818181818182,0.9425287356321839,0.9418604651162791,0.9411764705882353,0.9404761904761905,0.9397590361445783,0.9390243902439024,0.9382716049382716,0.9375,0.9367088607594937,0.9358974358974359,0.935064935064935,0.9342105263157895,0.9333333333333333,0.9324324324324325,0.9315068493150684,0.9305555555555556,0.9295774647887324,0.9285714285714286,0.927536231884058,0.9264705882352942,0.9253731343283582,0.9242424242424242,0.9230769230769231,0.921875,0.9206349206349206,0.9193548387096774,0.9344262295081968,0.95,0.9491525423728814,0.9482758620689655,0.9473684210526315,0.9464285714285714,0.9454545454545454,0.9444444444444444,0.9433962264150944,0.9423076923076923,0.9411764705882353,0.94,0.9387755102040817,0.9583333333333334,0.9574468085106383,0.9565217391304348,0.9555555555555556,0.9545454545454546,0.9534883720930233,0.9523809523809523,0.9512195121951219,0.95,0.9487179487179487,0.9473684210526315,0.9459459459459459,0.9444444444444444,0.9428571428571428,0.9705882352941176,0.9696969696969697,0.96875,0.967741935483871,0.9655172413793104,0.9642857142857143,0.9629629629629629,0.9615384615384616,0.96,0.9583333333333334,0.9565217391304348,0.9545454545454546,0.9523809523809523,0.95,0.9473684210526315,0.9444444444444444,0.9411764705882353,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Recall\"},\"constrain\":\"domain\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Precision\"},\"scaleanchor\":\"x\",\"scaleratio\":1},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Precision-Recall Curve (AUC=0.9211)\"},\"height\":600,\"width\":800,\"shapes\":[{\"line\":{\"dash\":\"dash\"},\"type\":\"line\",\"x0\":0,\"x1\":1,\"y0\":1,\"y1\":0}],\"showlegend\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('dcda244e-352d-496c-a7aa-b31a11c93156');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"}],"source":["target_score = xgb_clf.predict_proba(features_valid)[:, 1]\n","\n","fpr, tpr, thresholds = roc_curve(target_valid, target_score)\n","\n","fig = px.area(\n","    x=fpr, y=tpr,\n","    title=f'ROC Curve (AUC={auc(fpr, tpr):.4f})',\n","    labels=dict(x='False Positive Rate', y='True Positive Rate'),\n","    width=800, height=600\n",")\n","fig.add_shape(\n","    type='line', line=dict(dash='dash'),\n","    x0=0, x1=1, y0=0, y1=1\n",")\n","\n","fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n","fig.update_xaxes(constrain='domain')\n","fig.update_layout(showlegend=False)\n","fig.show()\n","\n","precision, recall, thresholds = precision_recall_curve(target_valid, target_score)\n","\n","fig = px.area(\n","    x=recall, y=precision,\n","    title=f'Precision-Recall Curve (AUC={auc(fpr, tpr):.4f})',\n","    labels=dict(x='Recall', y='Precision'),\n","    width=800, height=600\n",")\n","fig.add_shape(\n","    type='line', line=dict(dash='dash'),\n","    x0=0, x1=1, y0=1, y1=0\n",")\n","fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n","fig.update_xaxes(constrain='domain')\n","fig.update_layout(showlegend=False)\n","fig.show()"]},{"cell_type":"markdown","metadata":{},"source":["--------"]},{"cell_type":"markdown","metadata":{},"source":["# Final Evaluation"]},{"cell_type":"markdown","metadata":{},"source":["`Model Selection - Average Score Comparison`\n","\n","`Note`\n","\n","- We've selected LightGBM as our optimal model based on score comparisons, it also performs much better compared to other models when it comes to scoring and speed. XGBClassifier is similar to our LightGBM model but takes considerably longer to compute."]},{"cell_type":"code","execution_count":97,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T17:05:07.620683Z","iopub.status.busy":"2023-11-30T17:05:07.620368Z","iopub.status.idle":"2023-11-30T17:05:07.627835Z","shell.execute_reply":"2023-11-30T17:05:07.626805Z","shell.execute_reply.started":"2023-11-30T17:05:07.620644Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Average Cross Validation Scores:\n","RandomForestClassifier: 0.8760777711552042\n","DecisionTreeClassifier: 0.7530509062867848\n","ExtraTreesClassifier: 0.8479972754101266\n","\n","LogisticRegression: 0.829162458233739\n","RidgeClassifier: 0.8259667628691291\n","\n","LightGBM: 0.9078685635877259\n","XGBoost: 0.908791215308284\n"]}],"source":["print('Average Cross Validation Scores:')\n","print('RandomForestClassifier: {}'.format(forest_scores.mean()))\n","print('DecisionTreeClassifier: {}'.format(tree_scores.mean()))\n","print('ExtraTreesClassifier: {}'.format(extra_trees_scores.mean()))\n","print()\n","print('LogisticRegression: {}'.format(log_scores.mean()))\n","print('RidgeClassifier: {}'.format(ridge_scores.mean()))\n","print()\n","print('LightGBM: {}'.format(lgb_scores.mean()))\n","print('XGBoost: {}'.format(xgb_scores.mean()))"]},{"cell_type":"markdown","metadata":{},"source":["`Model Selection - Feature Importances`"]},{"cell_type":"code","execution_count":98,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[LightGBM] [Info] Number of positive: 3097, number of negative: 1121\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001960 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 4218, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734234 -> initscore=1.016213\n","[LightGBM] [Info] Start training from score 1.016213\n"]},{"name":"stdout","output_type":"stream","text":["Feature Importance:\n"]},{"data":{"text/plain":["{'total_charges': 224,\n"," 'monthly_charges': 131,\n"," 'begin_month': 82,\n"," 'begin_year': 63,\n"," 'contract_type': 51,\n"," 'internet_service': 25,\n"," 'payment_method': 18,\n"," 'streaming_movies': 15,\n"," 'senior_citizen': 13,\n"," 'online_security': 13,\n"," 'streaming_tv': 13,\n"," 'begin_dayofweek': 12,\n"," 'tech_support': 9,\n"," 'multiple_lines': 9,\n"," 'paperless_billing': 5,\n"," 'dependents': 5,\n"," 'online_backup': 4,\n"," 'gender': 3,\n"," 'partner': 3,\n"," 'device_protection': 2}"]},"execution_count":98,"metadata":{},"output_type":"execute_result"}],"source":["boost = lgb_model.fit(features_train, target_train).booster_\n","# print('Feature names',boost.feature_name())\n","\n","print('Feature Importance:')\n","{k: v for k, v in sorted(zip(boost.feature_name(), lgb_clf.best_estimator_.feature_importances_), key= lambda x: x[1], reverse=True)}"]},{"cell_type":"code","execution_count":99,"metadata":{},"outputs":[],"source":["r = {k: v for k, v in sorted(zip(boost.feature_name(), lgb_clf.best_estimator_.feature_importances_), key= lambda x: x[1], reverse=True)}"]},{"cell_type":"code","execution_count":100,"metadata":{},"outputs":[{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"fill":"toself","r":[224,131,82,63,51,25,18,15,13,13],"theta":["total_charges","monthly_charges","begin_month","begin_year","contract_type","internet_service","payment_method","streaming_movies","senior_citizen","online_security"],"type":"scatterpolar"}],"layout":{"autosize":false,"polar":{"angularaxis":{"direction":"clockwise","period":6},"radialaxis":{"angle":-45}},"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"#E5ECF6","showlakes":true,"showland":true,"subunitcolor":"white"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"bgcolor":"#E5ECF6","radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"bgcolor":"#E5ECF6","caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","zerolinewidth":2}}},"title":{"text":"<b>Top 10 Most Important Features</b><br><sup>LightGBM</sup>"}}},"text/html":["<div>                            <div id=\"556f6474-199a-4217-b10f-fa199645dad5\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"556f6474-199a-4217-b10f-fa199645dad5\")) {                    Plotly.newPlot(                        \"556f6474-199a-4217-b10f-fa199645dad5\",                        [{\"r\":[224,131,82,63,51,25,18,15,13,13],\"theta\":[\"total_charges\",\"monthly_charges\",\"begin_month\",\"begin_year\",\"contract_type\",\"internet_service\",\"payment_method\",\"streaming_movies\",\"senior_citizen\",\"online_security\"],\"type\":\"scatterpolar\",\"fill\":\"toself\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"polar\":{\"radialaxis\":{\"angle\":-45},\"angularaxis\":{\"direction\":\"clockwise\",\"period\":6}},\"title\":{\"text\":\"\\u003cb\\u003eTop 10 Most Important Features\\u003c\\u002fb\\u003e\\u003cbr\\u003e\\u003csup\\u003eLightGBM\\u003c\\u002fsup\\u003e\"},\"autosize\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('556f6474-199a-4217-b10f-fa199645dad5');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"}],"source":["fig = go.Figure(data=go.Scatterpolar(r = list(r.values())[:10],\n","               theta= list(r.keys())[:10]))\n","\n","fig.update_traces(fill='toself')\n","fig.update_layout(polar=dict(radialaxis_angle=-45, angularaxis= dict(direction='clockwise',period=6)))\n","\n","fig.update_layout(title_text='<b>Top 10 Most Important Features</b><br><sup>LightGBM</sup>',autosize=False)\n","\n","fig.show()"]},{"cell_type":"markdown","metadata":{},"source":["`Model Selection - Confusion Matrix`\n"]},{"cell_type":"code","execution_count":101,"metadata":{},"outputs":[{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"colorscale":[[0,"rgb(247,251,255)"],[0.125,"rgb(222,235,247)"],[0.25,"rgb(198,219,239)"],[0.375,"rgb(158,202,225)"],[0.5,"rgb(107,174,214)"],[0.625,"rgb(66,146,198)"],[0.75,"rgb(33,113,181)"],[0.875,"rgb(8,81,156)"],[1,"rgb(8,48,107)"]],"reversescale":false,"showscale":true,"type":"heatmap","x":["Class: 0","Class: 1"],"y":["Class: 0","Class: 1"],"z":[[239,135],[37,996]]}],"layout":{"annotations":[{"font":{"color":"#000000"},"showarrow":false,"text":"239","x":"Class: 0","xref":"x","y":"Class: 0","yref":"y"},{"font":{"color":"#000000"},"showarrow":false,"text":"135","x":"Class: 1","xref":"x","y":"Class: 0","yref":"y"},{"font":{"color":"#000000"},"showarrow":false,"text":"37","x":"Class: 0","xref":"x","y":"Class: 1","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"996","x":"Class: 1","xref":"x","y":"Class: 1","yref":"y"},{"font":{"color":"black","size":14},"showarrow":false,"text":"Predicted value","x":0.5,"xref":"paper","y":-0.15,"yref":"paper"},{"font":{"color":"black","size":14},"showarrow":false,"text":"Real value","textangle":-90,"x":-0.15,"xref":"paper","y":0.5,"yref":"paper"}],"height":500,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"#E5ECF6","showlakes":true,"showland":true,"subunitcolor":"white"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"bgcolor":"#E5ECF6","radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"bgcolor":"#E5ECF6","caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","zerolinewidth":2}}},"title":{"text":"<b>Confusion matrix</b><br><sup>LightGBM</sup>"},"width":500,"xaxis":{"dtick":1,"gridcolor":"rgb(0, 0, 0)","side":"top","ticks":""},"yaxis":{"dtick":1,"ticks":"","ticksuffix":"  "}}},"text/html":["<div>                            <div id=\"e140a42f-6d7f-43a4-88d0-91b6e030e3bf\" class=\"plotly-graph-div\" style=\"height:500px; width:500px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"e140a42f-6d7f-43a4-88d0-91b6e030e3bf\")) {                    Plotly.newPlot(                        \"e140a42f-6d7f-43a4-88d0-91b6e030e3bf\",                        [{\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"reversescale\":false,\"showscale\":true,\"x\":[\"Class: 0\",\"Class: 1\"],\"y\":[\"Class: 0\",\"Class: 1\"],\"z\":[[239,135],[37,996]],\"type\":\"heatmap\"}],                        {\"annotations\":[{\"font\":{\"color\":\"#000000\"},\"showarrow\":false,\"text\":\"239\",\"x\":\"Class: 0\",\"xref\":\"x\",\"y\":\"Class: 0\",\"yref\":\"y\"},{\"font\":{\"color\":\"#000000\"},\"showarrow\":false,\"text\":\"135\",\"x\":\"Class: 1\",\"xref\":\"x\",\"y\":\"Class: 0\",\"yref\":\"y\"},{\"font\":{\"color\":\"#000000\"},\"showarrow\":false,\"text\":\"37\",\"x\":\"Class: 0\",\"xref\":\"x\",\"y\":\"Class: 1\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"996\",\"x\":\"Class: 1\",\"xref\":\"x\",\"y\":\"Class: 1\",\"yref\":\"y\"},{\"font\":{\"color\":\"black\",\"size\":14},\"showarrow\":false,\"text\":\"Predicted value\",\"x\":0.5,\"xref\":\"paper\",\"y\":-0.15,\"yref\":\"paper\"},{\"font\":{\"color\":\"black\",\"size\":14},\"showarrow\":false,\"text\":\"Real value\",\"textangle\":-90,\"x\":-0.15,\"xref\":\"paper\",\"y\":0.5,\"yref\":\"paper\"}],\"xaxis\":{\"dtick\":1,\"gridcolor\":\"rgb(0, 0, 0)\",\"side\":\"top\",\"ticks\":\"\"},\"yaxis\":{\"dtick\":1,\"ticks\":\"\",\"ticksuffix\":\"  \"},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"\\u003cb\\u003eConfusion matrix\\u003c\\u002fb\\u003e\\u003cbr\\u003e\\u003csup\\u003eLightGBM\\u003c\\u002fsup\\u003e\"},\"height\":500,\"width\":500},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('e140a42f-6d7f-43a4-88d0-91b6e030e3bf');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"}],"source":["import plotly.figure_factory as ff\n","\n","# heatmap\n","\n","cm = confusion_matrix(target_valid, lgb_pred)\n","\n","labels = ['Class: 0', 'Class: 1']\n","heatmap = go.Heatmap(z=cm, x=labels, y=labels, colorscale='Blues')\n","\n","# data labels\n","data_labels = [[y for y in x] for x in cm]\n","\n","# figure\n","fig = ff.create_annotated_heatmap(z=cm, x=labels, y=labels, annotation_text=data_labels, colorscale='Blues')\n","\n","# title\n","fig.update_layout(title_text='<b>Confusion matrix</b><br><sup>LightGBM</sup>'\n","                  #xaxis = dict(title='x'),\n","                  #yaxis = dict(title='x')\n","                 )\n","\n","# add custom xaxis title\n","fig.add_annotation(dict(font=dict(color=\"black\",size=14),\n","                        x=0.5,\n","                        y=-0.15,\n","                        showarrow=False,\n","                        text=\"Predicted value\",\n","                        xref=\"paper\",\n","                        yref=\"paper\"))\n","\n","# add custom yaxis title\n","fig.add_annotation(dict(font=dict(color=\"black\",size=14),\n","                        x=-0.15,\n","                        y=0.5,\n","                        showarrow=False,\n","                        text=\"Real value\",\n","                        textangle=-90,\n","                        xref=\"paper\",\n","                        yref=\"paper\"))\n","\n","# margin update\n","fig.update_layout(height=500, width=500)\n","\n","# colorbar\n","fig['data'][0]['showscale'] = True\n","\n","\n","fig.show()"]},{"cell_type":"markdown","metadata":{},"source":["`Model Selection - Final Evaluation`"]},{"cell_type":"markdown","metadata":{},"source":["`Note`\n","\n","After further review, given the ROC curve is calculated by taking each possible probability I've replaced my final ROC AUC Score with predictions using `.predict_proba()` which yields better results (91.56% vs 80.15% in the previously reviewed solution code)."]},{"cell_type":"code","execution_count":102,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T17:05:07.684311Z","iopub.status.busy":"2023-11-30T17:05:07.683993Z","iopub.status.idle":"2023-11-30T17:05:07.817022Z","shell.execute_reply":"2023-11-30T17:05:07.816316Z","shell.execute_reply.started":"2023-11-30T17:05:07.684279Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Final evaluation on test set:\n","\n","[LightGBM] [Info] Number of positive: 3097, number of negative: 1121\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000700 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 4218, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734234 -> initscore=1.016213\n","[LightGBM] [Info] Start training from score 1.016213\n"]},{"name":"stdout","output_type":"stream","text":["ROC AUC Score: 91.56 %\n"]}],"source":["print('Final evaluation on test set:')\n","print()\n","# model\n","final_model = lgb.LGBMClassifier(random_state=random_state)\n","# train\n","final_model.fit(features_train, target_train)\n","# predict\n","final_predictions_test = final_model.predict(features_test)\n","final_predictions_test_proba = final_model.predict_proba(features_test)[:, 1]\n","# accuracy check\n","# final_model_accuracy = accuracy_score(target_test, final_predictions_test)\n","# final_model_f1 = f1_score(target_test, final_predictions_test)\n","final_model_roc_auc = roc_auc_score(target_test, final_predictions_test_proba)\n","#result\n","print('ROC AUC Score:',   round((final_model_roc_auc * 100), 2),'%') "]},{"cell_type":"markdown","metadata":{},"source":["# Part 3: Solution Report"]},{"cell_type":"markdown","metadata":{},"source":["`What steps of the plan were performed and what steps were skipped (explain why)?`\n","- We performed most of the steps from Part 1 minus the following:\n","    - Time series analyses - this was not needed afterall our general EDA/preprocessing was sufficient but could have been performed to paint a picture on the sign-up dates for each client.\n","\n","`What difficulties did you encounter and how did you manage to solve them?`\n","- Initially, we found some slight difficulties performing the ideal process of scaling and taking into account class imbalancing in models. We took more time to read documentation and found our effective solutions. This was as simple as moving the order of our code, fitting our scaler on just the training dataset and leveraging `RepeatedStratifiedKFold()` in our `RandomizedSearchGridCV()` for each model.\n","\n","- There were also some minor road bumps with some of the missing data which was not perceptible at first glance. We ran an iterative function to find said discrepancies and select our method of handling such (replacing, filling in or removing).\n","\n","`What were some of the key steps to solving the task?`\n","- Putting the project plan together and understanding the business goals first and foremost.\n","- Choosing this scoring metric before the analysis, so there are no distractions when making task decisions.\n","    - Not using an absolute measure (accuracy) but a relative-to-each-class measure (like ROC AUC).\n","- Getting a grasp on what type of data we are working with (especifially the data imbalance point) and how it will be consumed by our multiple model choices.\n","- Taking into account some of the decisions we make in EDA/Preprocessing and how they will later impact our results. Noting such decisions as we go and leaving the door open for futher flexibility in case of issues (like easily being able to amend our choices if we hit a roadblock or being able revert back to original).\n","- On the modeling side of things, having a benchmark model scenario to compare to (a dummy model) as well as deploying any type of gridsearch so we can find optimal model parameters and tune accordingly. \n","- Cross comparing model scores to find the ideal model but also taking into account some of the other values such as computing speed/burden. A compromise will have to be made at times (*e.g. not always selecting the highest scoring model*)\n","\n","\n","`What is your final model and what quality score does it have?`\n","- Our final model is the LightGBM model given there was a good balance of a high `cross_val_score` and computing speed. This originally yielded us an AUC ROC score of 80.15% based on using `.predict()` but after futher review, we've deployed `.predict_proba()` in the score calculation which yielded us a 91.56% score on a new, imbalanced test dataset. The recommendation to Interconnect is to use LightGBM to predict the customer churn rate given the scoring, its speed and the further flexibility the model deploys if modifications are needed as data changes or evolves.\n"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4018738,"sourceId":6991786,"sourceType":"datasetVersion"}],"dockerImageVersionId":30587,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":true,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false}},"nbformat":4,"nbformat_minor":4}
