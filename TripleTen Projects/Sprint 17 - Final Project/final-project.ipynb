{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Part 1: Project Workplan"]},{"cell_type":"markdown","metadata":{},"source":["**The aim of our project is to predict churn rates* for our customer, Interconnect.**\n","- From our results/final report, the company will be better prepared when it comes to forecasting which clients are in a higher likelihood of disconneting their services (which more than likely is to a competitor with more enticing perks).\n","\n","\n","- Interconnect will then plan on offering a larger scope of benefits to those clients in danger of turning over. This may also prove particularly useful in its market share battle against its competitors as the telecomm industry sprints to expand their perks each year as new cell phones come out (a constant cycle).\n","\n","-----\n","\n","`Step 1 - Initialization`\n","- Import all required and prospective libraries that will be leveraged in future stages of the project.\n","\n","\n","- Download the data and briefly inspect each DataFrame structure.\n","\n","`Step 2 - Preprocessing & EDA`\n","- Determine the necessary process to clean and massage the data.\n","\n","\n","- Create short, concise summaries on each DataFrame along with visualizations (plots) for thought organization and guidance.\n","\n","\n","- Perform EDA, including but not limited to: dtype and naming revisions, class balancing, value scaling, feature engineering, encoding and merging.\n"," - Fill in any gaps due to changes made to the DataFrame(s).\n","\n","\n","- Deploy time series tools/analysis to get a sense of trends and seasonality to paint a more complete picture.\n","\n","`Step 3 - Model Selection, Training and Fine-Tuning`\n","- Select various models based on the goal, binary classification. Compare initial scoring performance across the model selections, incorporate a dummy model benchmark.\n","\n","\n","- Fine-tune models using hyperparameters and gridsearches. Include gradient boosting techniques. \n","\n","`Step 4 - Model Evaluation`\n","- Decide on the optimal model based on cross comparisons and boosting techniques. Perform model evaluation based on a new set of data (test dataset) and document results. \n","\n","\n","- If statisfactory, record why the model was selected, its results (along with speed and accuracy insights) and what needs to be done in order to monitor/manage the model in a go-forward basis.\n","\n","`Step 5 - Comprehensive Report`\n","- Create an extensive report on the process/steps taken, the results and the overall recommendations.\n"," - Illustrate findings/results incorporating 'quick hits' or 'highlights' so the customer has a better handle on the report and can easily share internally.\n","\n","\n","\n","\n","--------\n","\n","**The churn rate measures a company's loss in subscribers for a given period of time. The cost of acquiring new customers is much higher than it is to retain current customers.*"]},{"cell_type":"markdown","metadata":{},"source":["-----------"]},{"cell_type":"markdown","metadata":{},"source":["# Part 2: Solution Code"]},{"cell_type":"markdown","metadata":{},"source":["# Initialization"]},{"cell_type":"code","execution_count":568,"metadata":{"execution":{"iopub.execute_input":"2023-12-01T00:01:09.452543Z","iopub.status.busy":"2023-12-01T00:01:09.451781Z","iopub.status.idle":"2023-12-01T00:01:09.464746Z","shell.execute_reply":"2023-12-01T00:01:09.463770Z","shell.execute_reply.started":"2023-12-01T00:01:09.452511Z"},"trusted":true},"outputs":[],"source":["def warn(*args, **kwargs): # attempt at removing warnings\n","    pass\n","import warnings\n","warnings.warn = warn\n","\n","warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n","warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n","warnings.filterwarnings(\"ignore\", category=FutureWarning) \n","warnings.filterwarnings(\"ignore\", category=UserWarning) \n","\n","from warnings import simplefilter\n","simplefilter(action='ignore', category=FutureWarning)"]},{"cell_type":"code","execution_count":569,"metadata":{"execution":{"iopub.execute_input":"2023-12-01T00:01:09.466923Z","iopub.status.busy":"2023-12-01T00:01:09.466547Z","iopub.status.idle":"2023-12-01T00:01:16.067426Z","shell.execute_reply":"2023-12-01T00:01:16.066500Z","shell.execute_reply.started":"2023-12-01T00:01:09.466895Z"},"trusted":true},"outputs":[{"data":{"text/html":["        <script type=\"text/javascript\">\n","        window.PlotlyConfig = {MathJaxConfig: 'local'};\n","        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n","        if (typeof require !== 'undefined') {\n","        require.undef(\"plotly\");\n","        requirejs.config({\n","            paths: {\n","                'plotly': ['https://cdn.plot.ly/plotly-2.27.0.min']\n","            }\n","        });\n","        require(['plotly'], function(Plotly) {\n","            window._Plotly = Plotly;\n","        });\n","        }\n","        </script>\n","        "]},"metadata":{},"output_type":"display_data"}],"source":["# common libraries\n","import pandas as pd\n","import numpy as np\n","from functools import reduce\n","from numpy import unique\n","\n","# other libraries\n","# from scipy.stats import randint as \n","\n","# viz libraries\n","import plotly.express as px\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","px.defaults.template = \"plotly_white\"\n","import plotly.graph_objects as go\n","from plotly.subplots import make_subplots\n","# import plotly.figure_factory as ff\n","from plotly.offline import init_notebook_mode, iplot, plot\n","init_notebook_mode(connected=True)\n","# import pygwalker as pyg # leveraging once DFs are merged\n","\n","# sklearn\n","from sklearn.metrics import roc_auc_score, f1_score\n","from sklearn.metrics import confusion_matrix, classification_report, precision_recall_curve, accuracy_score, ConfusionMatrixDisplay, auc, roc_curve\n","from sklearn.linear_model import LogisticRegression, RidgeClassifier\n","from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n","from sklearn.model_selection import train_test_split, RandomizedSearchCV, TimeSeriesSplit, cross_val_score\n","from sklearn.utils import shuffle, resample\n","from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.dummy import DummyClassifier\n","from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n","from sklearn.pipeline import Pipeline\n","from sklearn.model_selection import KFold, StratifiedKFold, RepeatedStratifiedKFold\n","from sklearn.calibration import calibration_curve, CalibrationDisplay\n","\n","# gradient boosting\n","import lightgbm as lgb\n","import xgboost as xgb"]},{"cell_type":"code","execution_count":570,"metadata":{"execution":{"iopub.execute_input":"2023-12-01T00:01:16.069338Z","iopub.status.busy":"2023-12-01T00:01:16.069046Z","iopub.status.idle":"2023-12-01T00:01:16.166613Z","shell.execute_reply":"2023-12-01T00:01:16.165661Z","shell.execute_reply.started":"2023-12-01T00:01:16.069312Z"},"trusted":true},"outputs":[],"source":["try:\n","    contract_data = pd.read_csv('/kaggle/input/final-provider/contract.csv') # index_col=[0], parse_dates=[0]\n","    personal_data = pd.read_csv('/kaggle/input/final-provider/personal.csv') \n","    internet_data = pd.read_csv('/kaggle/input/final-provider/internet.csv') \n","    phone_data = pd.read_csv('/kaggle/input/final-provider/phone.csv') \n","except:\n","    contract_data = pd.read_csv('/Users/dani/Data Science/TripleTen Projects/Project Data/Final Project/contract.csv') # index_col=[0], parse_dates=[0]\n","    personal_data = pd.read_csv('/Users/dani/Data Science/TripleTen Projects/Project Data/Final Project/personal.csv') \n","    internet_data = pd.read_csv('/Users/dani/Data Science/TripleTen Projects/Project Data/Final Project/internet.csv') \n","    phone_data = pd.read_csv('/Users/dani/Data Science/TripleTen Projects/Project Data/Final Project/phone.csv') "]},{"cell_type":"markdown","metadata":{},"source":["-----------"]},{"cell_type":"markdown","metadata":{},"source":["# Exploratory Data Analysis"]},{"cell_type":"code","execution_count":571,"metadata":{"execution":{"iopub.execute_input":"2023-12-01T00:01:16.168419Z","iopub.status.busy":"2023-12-01T00:01:16.168112Z","iopub.status.idle":"2023-12-01T00:01:16.172765Z","shell.execute_reply":"2023-12-01T00:01:16.171720Z","shell.execute_reply.started":"2023-12-01T00:01:16.168393Z"},"trusted":true},"outputs":[],"source":["encoder = LabelEncoder() "]},{"cell_type":"code","execution_count":572,"metadata":{"execution":{"iopub.execute_input":"2023-12-01T00:01:16.176302Z","iopub.status.busy":"2023-12-01T00:01:16.175779Z","iopub.status.idle":"2023-12-01T00:01:16.188455Z","shell.execute_reply":"2023-12-01T00:01:16.187339Z","shell.execute_reply.started":"2023-12-01T00:01:16.176263Z"},"trusted":true},"outputs":[],"source":["# to bypass limitations and encode multiple columns\n","class MultiColumnLabelEncoder:\n","    def __init__(self,columns = None):\n","        self.columns = columns # column names to encode\n","\n","    def fit(self,X,y=None):\n","        return self \n","\n","    def transform(self,X):\n","        '''\n","        Transforms columns of X specified in self.columns using\n","        LabelEncoder(). If no columns specified, transforms all\n","        columns in X.\n","        '''\n","        output = X.copy()\n","        if self.columns is not None:\n","            for col in self.columns:\n","                output[col] = LabelEncoder().fit_transform(output[col])\n","        else:\n","            for colname,col in output.iteritems():\n","                output[colname] = LabelEncoder().fit_transform(col)\n","        return output\n","\n","    def fit_transform(self,X,y=None):\n","        return self.fit(X,y).transform(X)"]},{"cell_type":"code","execution_count":573,"metadata":{},"outputs":[],"source":["# function to classify features\n","def classify_features(df):\n","    categorical_features = []\n","    non_categorical_features = []\n","    discrete_features = []\n","    continuous_features = []\n","\n","    for column in df.columns:\n","        if df[column].dtype in ['object', 'bool', 'category']: \n","            if df[column].nunique() < 15:\n","                categorical_features.append(column)\n","            else: \n","                non_categorical_features.append(column)\n","        elif df[column].dtype in ['int64', 'float64']:\n","            if df[column].nunique() < 10:\n","                discrete_features.append(column)\n","            else: \n","                continuous_features.append(column)\n","    return categorical_features, non_categorical_features, discrete_features, continuous_features"]},{"cell_type":"markdown","metadata":{},"source":["-----------"]},{"cell_type":"markdown","metadata":{},"source":["# Contract data"]},{"cell_type":"code","execution_count":574,"metadata":{"execution":{"iopub.execute_input":"2023-12-01T00:01:16.190169Z","iopub.status.busy":"2023-12-01T00:01:16.189761Z","iopub.status.idle":"2023-12-01T00:01:16.228222Z","shell.execute_reply":"2023-12-01T00:01:16.227238Z","shell.execute_reply.started":"2023-12-01T00:01:16.190139Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 7043 entries, 0 to 7042\n","Data columns (total 8 columns):\n"," #   Column            Non-Null Count  Dtype  \n","---  ------            --------------  -----  \n"," 0   customerID        7043 non-null   object \n"," 1   BeginDate         7043 non-null   object \n"," 2   EndDate           7043 non-null   object \n"," 3   Type              7043 non-null   object \n"," 4   PaperlessBilling  7043 non-null   object \n"," 5   PaymentMethod     7043 non-null   object \n"," 6   MonthlyCharges    7043 non-null   float64\n"," 7   TotalCharges      7043 non-null   object \n","dtypes: float64(1), object(7)\n","memory usage: 440.3+ KB\n"]}],"source":["contract_data.info()"]},{"cell_type":"code","execution_count":575,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Categorical Features: ['EndDate', 'Type', 'PaperlessBilling', 'PaymentMethod']\n","Non-Categorical Features: ['customerID', 'BeginDate', 'TotalCharges']\n","Discrete Features: []\n","Continuous Features: ['MonthlyCharges']\n"]}],"source":["categorical, non_categorical, discrete, continuous = classify_features(contract_data)\n","\n","print(\"Categorical Features:\", categorical)\n","print(\"Non-Categorical Features:\", non_categorical)\n","print(\"Discrete Features:\", discrete)\n","print(\"Continuous Features:\", continuous)"]},{"cell_type":"code","execution_count":576,"metadata":{"execution":{"iopub.execute_input":"2023-12-01T00:01:16.229899Z","iopub.status.busy":"2023-12-01T00:01:16.229534Z","iopub.status.idle":"2023-12-01T00:01:16.249827Z","shell.execute_reply":"2023-12-01T00:01:16.248847Z","shell.execute_reply.started":"2023-12-01T00:01:16.229869Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>MonthlyCharges</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>7043.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>64.761692</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>30.090047</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>18.250000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>35.500000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>70.350000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>89.850000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>118.750000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       MonthlyCharges\n","count     7043.000000\n","mean        64.761692\n","std         30.090047\n","min         18.250000\n","25%         35.500000\n","50%         70.350000\n","75%         89.850000\n","max        118.750000"]},"execution_count":576,"metadata":{},"output_type":"execute_result"}],"source":["contract_data.describe()"]},{"cell_type":"code","execution_count":577,"metadata":{"execution":{"iopub.execute_input":"2023-12-01T00:01:16.251631Z","iopub.status.busy":"2023-12-01T00:01:16.251230Z","iopub.status.idle":"2023-12-01T00:01:16.266840Z","shell.execute_reply":"2023-12-01T00:01:16.265843Z","shell.execute_reply.started":"2023-12-01T00:01:16.251595Z"},"trusted":true},"outputs":[{"data":{"text/plain":["customerID          0\n","BeginDate           0\n","EndDate             0\n","Type                0\n","PaperlessBilling    0\n","PaymentMethod       0\n","MonthlyCharges      0\n","TotalCharges        0\n","dtype: int64"]},"execution_count":577,"metadata":{},"output_type":"execute_result"}],"source":["contract_data.isna().sum()"]},{"cell_type":"code","execution_count":578,"metadata":{"execution":{"iopub.execute_input":"2023-12-01T00:01:16.268495Z","iopub.status.busy":"2023-12-01T00:01:16.268149Z","iopub.status.idle":"2023-12-01T00:01:16.288021Z","shell.execute_reply":"2023-12-01T00:01:16.286925Z","shell.execute_reply.started":"2023-12-01T00:01:16.268467Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>customerID</th>\n","      <th>BeginDate</th>\n","      <th>EndDate</th>\n","      <th>Type</th>\n","      <th>PaperlessBilling</th>\n","      <th>PaymentMethod</th>\n","      <th>MonthlyCharges</th>\n","      <th>TotalCharges</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>7590-VHVEG</td>\n","      <td>2020-01-01</td>\n","      <td>No</td>\n","      <td>Month-to-month</td>\n","      <td>Yes</td>\n","      <td>Electronic check</td>\n","      <td>29.85</td>\n","      <td>29.85</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5575-GNVDE</td>\n","      <td>2017-04-01</td>\n","      <td>No</td>\n","      <td>One year</td>\n","      <td>No</td>\n","      <td>Mailed check</td>\n","      <td>56.95</td>\n","      <td>1889.5</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3668-QPYBK</td>\n","      <td>2019-10-01</td>\n","      <td>2019-12-01 00:00:00</td>\n","      <td>Month-to-month</td>\n","      <td>Yes</td>\n","      <td>Mailed check</td>\n","      <td>53.85</td>\n","      <td>108.15</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>7795-CFOCW</td>\n","      <td>2016-05-01</td>\n","      <td>No</td>\n","      <td>One year</td>\n","      <td>No</td>\n","      <td>Bank transfer (automatic)</td>\n","      <td>42.30</td>\n","      <td>1840.75</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>9237-HQITU</td>\n","      <td>2019-09-01</td>\n","      <td>2019-11-01 00:00:00</td>\n","      <td>Month-to-month</td>\n","      <td>Yes</td>\n","      <td>Electronic check</td>\n","      <td>70.70</td>\n","      <td>151.65</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7038</th>\n","      <td>6840-RESVB</td>\n","      <td>2018-02-01</td>\n","      <td>No</td>\n","      <td>One year</td>\n","      <td>Yes</td>\n","      <td>Mailed check</td>\n","      <td>84.80</td>\n","      <td>1990.5</td>\n","    </tr>\n","    <tr>\n","      <th>7039</th>\n","      <td>2234-XADUH</td>\n","      <td>2014-02-01</td>\n","      <td>No</td>\n","      <td>One year</td>\n","      <td>Yes</td>\n","      <td>Credit card (automatic)</td>\n","      <td>103.20</td>\n","      <td>7362.9</td>\n","    </tr>\n","    <tr>\n","      <th>7040</th>\n","      <td>4801-JZAZL</td>\n","      <td>2019-03-01</td>\n","      <td>No</td>\n","      <td>Month-to-month</td>\n","      <td>Yes</td>\n","      <td>Electronic check</td>\n","      <td>29.60</td>\n","      <td>346.45</td>\n","    </tr>\n","    <tr>\n","      <th>7041</th>\n","      <td>8361-LTMKD</td>\n","      <td>2019-07-01</td>\n","      <td>2019-11-01 00:00:00</td>\n","      <td>Month-to-month</td>\n","      <td>Yes</td>\n","      <td>Mailed check</td>\n","      <td>74.40</td>\n","      <td>306.6</td>\n","    </tr>\n","    <tr>\n","      <th>7042</th>\n","      <td>3186-AJIEK</td>\n","      <td>2014-08-01</td>\n","      <td>No</td>\n","      <td>Two year</td>\n","      <td>Yes</td>\n","      <td>Bank transfer (automatic)</td>\n","      <td>105.65</td>\n","      <td>6844.5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7043 rows × 8 columns</p>\n","</div>"],"text/plain":["      customerID   BeginDate              EndDate            Type  \\\n","0     7590-VHVEG  2020-01-01                   No  Month-to-month   \n","1     5575-GNVDE  2017-04-01                   No        One year   \n","2     3668-QPYBK  2019-10-01  2019-12-01 00:00:00  Month-to-month   \n","3     7795-CFOCW  2016-05-01                   No        One year   \n","4     9237-HQITU  2019-09-01  2019-11-01 00:00:00  Month-to-month   \n","...          ...         ...                  ...             ...   \n","7038  6840-RESVB  2018-02-01                   No        One year   \n","7039  2234-XADUH  2014-02-01                   No        One year   \n","7040  4801-JZAZL  2019-03-01                   No  Month-to-month   \n","7041  8361-LTMKD  2019-07-01  2019-11-01 00:00:00  Month-to-month   \n","7042  3186-AJIEK  2014-08-01                   No        Two year   \n","\n","     PaperlessBilling              PaymentMethod  MonthlyCharges TotalCharges  \n","0                 Yes           Electronic check           29.85        29.85  \n","1                  No               Mailed check           56.95       1889.5  \n","2                 Yes               Mailed check           53.85       108.15  \n","3                  No  Bank transfer (automatic)           42.30      1840.75  \n","4                 Yes           Electronic check           70.70       151.65  \n","...               ...                        ...             ...          ...  \n","7038              Yes               Mailed check           84.80       1990.5  \n","7039              Yes    Credit card (automatic)          103.20       7362.9  \n","7040              Yes           Electronic check           29.60       346.45  \n","7041              Yes               Mailed check           74.40        306.6  \n","7042              Yes  Bank transfer (automatic)          105.65       6844.5  \n","\n","[7043 rows x 8 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["display(contract_data)"]},{"cell_type":"markdown","metadata":{},"source":["`Preprocessing`"]},{"cell_type":"code","execution_count":579,"metadata":{"execution":{"iopub.execute_input":"2023-12-01T00:01:16.290000Z","iopub.status.busy":"2023-12-01T00:01:16.289422Z","iopub.status.idle":"2023-12-01T00:01:16.458983Z","shell.execute_reply":"2023-12-01T00:01:16.457771Z","shell.execute_reply.started":"2023-12-01T00:01:16.289959Z"},"trusted":true},"outputs":[{"data":{"text/plain":["[' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","Index: 7032 entries, 0 to 7042\n","Data columns (total 8 columns):\n"," #   Column             Non-Null Count  Dtype         \n","---  ------             --------------  -----         \n"," 0   customer_id        7032 non-null   object        \n"," 1   begin_date         7032 non-null   datetime64[ns]\n"," 2   end_date           7032 non-null   object        \n"," 3   contract_type      7032 non-null   object        \n"," 4   paperless_billing  7032 non-null   object        \n"," 5   payment_method     7032 non-null   object        \n"," 6   monthly_charges    7032 non-null   float64       \n"," 7   total_charges      7032 non-null   float64       \n","dtypes: datetime64[ns](1), float64(2), object(5)\n","memory usage: 494.4+ KB\n"]}],"source":["contract_df = contract_data.copy()\n","# column renaming\n","contract_df = contract_df.rename(columns={\"customerID\": \"customer_id\", \"BeginDate\": \"begin_date\", \"EndDate\": \"end_date\", \"Type\": \"contract_type\",\n","                           \"PaperlessBilling\": \"paperless_billing\", \"PaymentMethod\": \"payment_method\", \"MonthlyCharges\": \"monthly_charges\",\n","                           \"TotalCharges\": \"total_charges\"})\n","\n","# datatype conversions\n","contract_df['begin_date'] = pd.to_datetime(contract_df['begin_date'])\n","\n","\n","# display(contract_df.iloc[488]) # first error callout, turns out there are 11 rows without a 'total_charges' value\n","# display(contract_df['total_charges'].isnull().sum()) \n","problem_cells = [ ]\n","\n","for value in contract_df['total_charges']:\n","    try:\n","        pd.to_numeric(value)\n","    except:\n","        problem_cells.append(value)\n","        \n","display(problem_cells)\n","display()\n","\n","contract_df['total_charges'].replace(\" \", np.nan, inplace=True) # replacing empty strings so we can drop the rows\n","contract_df['total_charges'] = pd.to_numeric(contract_df['total_charges']) # conversion to match 'monthly_charges'\n","contract_df = contract_df.dropna(subset=['total_charges']) # 11 rows should not make that big of a dent given it's a tiny percentage of total\n","\n","contract_df.info()"]},{"cell_type":"code","execution_count":580,"metadata":{"execution":{"iopub.execute_input":"2023-12-01T00:01:16.462269Z","iopub.status.busy":"2023-12-01T00:01:16.461895Z","iopub.status.idle":"2023-12-01T00:01:16.492390Z","shell.execute_reply":"2023-12-01T00:01:16.491408Z","shell.execute_reply.started":"2023-12-01T00:01:16.462237Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>customer_id</th>\n","      <th>begin_date</th>\n","      <th>contract_type</th>\n","      <th>paperless_billing</th>\n","      <th>payment_method</th>\n","      <th>monthly_charges</th>\n","      <th>total_charges</th>\n","      <th>churn_target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>7590-VHVEG</td>\n","      <td>2020-01-01</td>\n","      <td>Month-to-month</td>\n","      <td>Yes</td>\n","      <td>Electronic check</td>\n","      <td>29.85</td>\n","      <td>29.85</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5575-GNVDE</td>\n","      <td>2017-04-01</td>\n","      <td>One year</td>\n","      <td>No</td>\n","      <td>Mailed check</td>\n","      <td>56.95</td>\n","      <td>1889.50</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3668-QPYBK</td>\n","      <td>2019-10-01</td>\n","      <td>Month-to-month</td>\n","      <td>Yes</td>\n","      <td>Mailed check</td>\n","      <td>53.85</td>\n","      <td>108.15</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>7795-CFOCW</td>\n","      <td>2016-05-01</td>\n","      <td>One year</td>\n","      <td>No</td>\n","      <td>Bank transfer (automatic)</td>\n","      <td>42.30</td>\n","      <td>1840.75</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>9237-HQITU</td>\n","      <td>2019-09-01</td>\n","      <td>Month-to-month</td>\n","      <td>Yes</td>\n","      <td>Electronic check</td>\n","      <td>70.70</td>\n","      <td>151.65</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7038</th>\n","      <td>6840-RESVB</td>\n","      <td>2018-02-01</td>\n","      <td>One year</td>\n","      <td>Yes</td>\n","      <td>Mailed check</td>\n","      <td>84.80</td>\n","      <td>1990.50</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7039</th>\n","      <td>2234-XADUH</td>\n","      <td>2014-02-01</td>\n","      <td>One year</td>\n","      <td>Yes</td>\n","      <td>Credit card (automatic)</td>\n","      <td>103.20</td>\n","      <td>7362.90</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7040</th>\n","      <td>4801-JZAZL</td>\n","      <td>2019-03-01</td>\n","      <td>Month-to-month</td>\n","      <td>Yes</td>\n","      <td>Electronic check</td>\n","      <td>29.60</td>\n","      <td>346.45</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7041</th>\n","      <td>8361-LTMKD</td>\n","      <td>2019-07-01</td>\n","      <td>Month-to-month</td>\n","      <td>Yes</td>\n","      <td>Mailed check</td>\n","      <td>74.40</td>\n","      <td>306.60</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7042</th>\n","      <td>3186-AJIEK</td>\n","      <td>2014-08-01</td>\n","      <td>Two year</td>\n","      <td>Yes</td>\n","      <td>Bank transfer (automatic)</td>\n","      <td>105.65</td>\n","      <td>6844.50</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7032 rows × 8 columns</p>\n","</div>"],"text/plain":["     customer_id begin_date   contract_type paperless_billing  \\\n","0     7590-VHVEG 2020-01-01  Month-to-month               Yes   \n","1     5575-GNVDE 2017-04-01        One year                No   \n","2     3668-QPYBK 2019-10-01  Month-to-month               Yes   \n","3     7795-CFOCW 2016-05-01        One year                No   \n","4     9237-HQITU 2019-09-01  Month-to-month               Yes   \n","...          ...        ...             ...               ...   \n","7038  6840-RESVB 2018-02-01        One year               Yes   \n","7039  2234-XADUH 2014-02-01        One year               Yes   \n","7040  4801-JZAZL 2019-03-01  Month-to-month               Yes   \n","7041  8361-LTMKD 2019-07-01  Month-to-month               Yes   \n","7042  3186-AJIEK 2014-08-01        Two year               Yes   \n","\n","                 payment_method  monthly_charges  total_charges  churn_target  \n","0              Electronic check            29.85          29.85             1  \n","1                  Mailed check            56.95        1889.50             1  \n","2                  Mailed check            53.85         108.15             0  \n","3     Bank transfer (automatic)            42.30        1840.75             1  \n","4              Electronic check            70.70         151.65             0  \n","...                         ...              ...            ...           ...  \n","7038               Mailed check            84.80        1990.50             1  \n","7039    Credit card (automatic)           103.20        7362.90             1  \n","7040           Electronic check            29.60         346.45             1  \n","7041               Mailed check            74.40         306.60             0  \n","7042  Bank transfer (automatic)           105.65        6844.50             1  \n","\n","[7032 rows x 8 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["# target handling\n","contract_df.query('end_date == \" \"') # no empty cells in target column\n","\n","contract_df['churn_target'] = np.where(contract_df['end_date'] == 'No', 1, 0) # 1 = no churn, 0 = churn\n","contract_df = contract_df.drop(['end_date'], axis=1)\n","\n","display(contract_df)"]},{"cell_type":"code","execution_count":581,"metadata":{"execution":{"iopub.execute_input":"2023-12-01T00:01:54.691356Z","iopub.status.busy":"2023-12-01T00:01:54.690923Z","iopub.status.idle":"2023-12-01T00:01:56.224365Z","shell.execute_reply":"2023-12-01T00:01:56.223272Z","shell.execute_reply.started":"2023-12-01T00:01:54.691321Z"},"trusted":true},"outputs":[{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"alignmentgroup":"True","hovertemplate":"variable=0<br>payment_method=%{x}<br>value=%{y}<extra></extra>","legendgroup":"0","marker":{"color":"#636efa","pattern":{"shape":""}},"name":"0","offsetgroup":"0","orientation":"v","showlegend":true,"textposition":"auto","texttemplate":"%{y}","type":"bar","x":["Bank transfer (automatic)","Credit card (automatic)","Electronic check","Mailed check"],"xaxis":"x","y":[589,580,1850,893],"yaxis":"y"}],"layout":{"autosize":false,"barmode":"relative","legend":{"title":{"text":"variable"},"tracegroupgap":0},"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"title":{"text":"Customer Payment Method"},"xaxis":{"anchor":"y","domain":[0,1],"title":{"text":"payment_method"}},"yaxis":{"anchor":"x","domain":[0,1],"title":{"text":"value"}}}},"text/html":["<div>                            <div id=\"2a574f29-7566-4f0a-b960-11bd5347ee18\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"2a574f29-7566-4f0a-b960-11bd5347ee18\")) {                    Plotly.newPlot(                        \"2a574f29-7566-4f0a-b960-11bd5347ee18\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=0\\u003cbr\\u003epayment_method=%{x}\\u003cbr\\u003evalue=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"0\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"0\",\"offsetgroup\":\"0\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"texttemplate\":\"%{y}\",\"x\":[\"Bank transfer (automatic)\",\"Credit card (automatic)\",\"Electronic check\",\"Mailed check\"],\"xaxis\":\"x\",\"y\":[589,580,1850,893],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"payment_method\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"value\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Customer Payment Method\"},\"barmode\":\"relative\",\"showlegend\":false,\"autosize\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('2a574f29-7566-4f0a-b960-11bd5347ee18');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"alignmentgroup":"True","hovertemplate":"variable=0<br>contract_type=%{x}<br>value=%{y}<extra></extra>","legendgroup":"0","marker":{"color":"#636efa","pattern":{"shape":""}},"name":"0","offsetgroup":"0","orientation":"v","showlegend":true,"textposition":"auto","texttemplate":"%{y}","type":"bar","x":["Month-to-month","One year","Two year"],"xaxis":"x","y":[1850,398,580],"yaxis":"y"}],"layout":{"autosize":false,"barmode":"relative","legend":{"title":{"text":"variable"},"tracegroupgap":0},"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"title":{"text":"Customer Contract Type"},"xaxis":{"anchor":"y","domain":[0,1],"title":{"text":"contract_type"}},"yaxis":{"anchor":"x","domain":[0,1],"title":{"text":"value"}}}},"text/html":["<div>                            <div id=\"a30fba25-448d-4433-b829-0980df81ccb6\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"a30fba25-448d-4433-b829-0980df81ccb6\")) {                    Plotly.newPlot(                        \"a30fba25-448d-4433-b829-0980df81ccb6\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=0\\u003cbr\\u003econtract_type=%{x}\\u003cbr\\u003evalue=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"0\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"0\",\"offsetgroup\":\"0\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"texttemplate\":\"%{y}\",\"x\":[\"Month-to-month\",\"One year\",\"Two year\"],\"xaxis\":\"x\",\"y\":[1850,398,580],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"contract_type\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"value\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Customer Contract Type\"},\"barmode\":\"relative\",\"showlegend\":false,\"autosize\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('a30fba25-448d-4433-b829-0980df81ccb6');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"}],"source":["payment_grp = contract_df.groupby(['contract_type','payment_method']).size().reset_index().groupby('payment_method')[[0]].max()\n","# display(payment_grp)\n","fig = px.bar(payment_grp,title=\"Customer Payment Method\",text_auto = True)\n","fig.update_layout(showlegend=False,autosize=False)\n","fig.show()\n","\n","contract_type_grp = contract_df.groupby(['contract_type','payment_method']).size().reset_index().groupby('contract_type')[[0]].max()\n","# display(contract_type_grp)\n","fig = px.bar(contract_type_grp,title=\"Customer Contract Type\",text_auto = True)\n","fig.update_layout(showlegend=False,autosize=False)\n","fig.show()"]},{"cell_type":"code","execution_count":582,"metadata":{},"outputs":[{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAABNAAAAJTCAYAAADJxuupAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAACZnElEQVR4nOzdd3yNd//H8XcSiSwrEkHMGjEixFa1YsbemxLUqCqqRm2ldlHE3qP2bmuUolqbiipiBYkVYofM8/sjdX5OE6eJioT79Xw8PO6c6/pe1/X5Hpr75J3vsDAYDAYBAAAAAAAAiJdlchcAAAAAAAAApGQEaAAAAAAAAIAZBGgAAAAAAACAGQRoAAAAAAAAgBkEaAAAAAAAAIAZBGgAAAAAAACAGQRoAAAAAAAAgBkEaAAAAAAAAIAZBGgAAAB45xkMBkVHRyd3GWZFRUUldwkJ8q7UCQDA25QquQsAAABAyvT06VOtWrVKv/zyiy5duqTHjx/LwcFB7u7uqlGjhpo0aSI7O7vkLlOnT5/WmDFjNGnSJGXLli25y4nXjz/+qBUrVmjFihUJau/t7a3g4OA4x62treXg4KAcOXKocuXKatWqlZycnN5IjdHR0Vq1apUOHTqk6dOnv5F7AgDwviBAAwAAQByHDx9Wnz59dO/ePZPjDx480OHDh3X48GEtW7ZMfn5+ypMnTzJVKQ0aNEgbN26UwWBIthrMuXPnjvr06aNjx47Jzc3tP98vMjJSDx480IMHD+Tv769Vq1Zp1qxZ8vDw+E/3vXTpknr37q2AgACVLl36P9cJAMD7hgANAAAAJo4fP65OnTopMjJSkpQuXTpVrFhR6dOn1/nz53XkyBFJUmBgoLp27ar169crXbp0yVLrhg0bkuW5CXXlyhUdO3bsP92jUqVKyp8/v2JiYvT8+XNdvnxZR44cUXR0tO7cuaNu3bpp8+bNypgx42s/49SpUwoICPhPdQIA8D4jQAMAAIBRRESEvvjiC2N4Vrp0ac2YMcMkIPvll1/02WefKTIyUtevX9fy5cv16aefJlfJ771atWqpcePGJsf8/f3VsWNHPXnyRCEhIZo1a5aGDBmSTBUCAPD+YxMBAAAAGG3dulU3b96UJNnb22vatGlxRpdVqVJFLVu2lI2NjYoXLy4HB4c49wkNDdWMGTNUv359FS9eXF5eXmrcuLHmz5+v58+fx2nfrl07ubu7y93dXZcuXdKxY8fUoUMHFS9eXCVLllT37t1NRkht2LBB7u7uJveoWrWq3N3dFRQUJCl2HbEX9wwODtYnn3yiIkWKqEyZMlq2bJmk2M0HVqxYoRYtWqhEiRIqWLCgihcvrsaNG2vp0qXxbkwQHh6uRYsWqUmTJvLy8lLx4sVVr149TZkyRaGhocZ2AwcOVPv27Y2vg4OD5e7uLm9v73/9e/g3np6eJqHl+vXrFRERYdLmwIED6tKli8qVK6dChQrJ09NTNWvW1DfffKNHjx4Z27Vr106DBg0yvj5y5Ijc3d3Vrl0747GIiAjNmTNHDRs2lJeXlwoWLKhSpUqpZcuW2rRp03/uDwAAKR0j0AAAAGC0d+9e49eVK1d+5QL1vXv3Vv/+/WVjYxPn3J9//qkePXro9u3bJsfPnDmjM2fOaNOmTZo/f74yZ84c7723bdum2bNnKyYmxnhsz549Onr0qDZt2vRaGwX06NFD586dkxQbBr1Yt+2bb77R0qVLTdo+ffrUWOuZM2c0fvx447lHjx7J19dXp0+fNrkmICBAAQEB2rZtm77//ntlypQp0TUmVs2aNY21hYWF6c8//1Tx4sUlSTt37tTnn39u8h5GR0crMDBQgYGBOnDggNavX5+gTSBiYmLUt29f7dq1y+T4o0ePdPLkSZ08eVLXrl1Tr1693mDvAABIWRiBBgAAAKMzZ84Yvy5YsOAr2zk6OsYbnj169EifffaZMTzLkCGDGjdurLp168re3l6SdOHCBXXv3l1RUVHx3tvPz08ZM2ZU69atValSJePxx48fa+3atZKk/Pnzq0uXLibXtWzZUl26dFGaNGni3PPcuXMqVaqUWrdurcKFC6tMmTI6f/68MTyztrZW/fr19fHHH6tkyZLG6zZv3mwyqmzUqFHG8MzGxkZ169ZVq1atjOuPBQUFaeTIkZJi1y6rW7euyXvWpUsXtWzZMt5+J5abm5vxPZViNwKQYjcaGDVqlDE8++ijj9ShQwfVrFlTVlZWxrb79++XJNWtW9fkfc6SJYu6dOlirH3v3r3G8MzBwUFNmzZVu3btTP59LFmyJMVu5AAAwJvACDQAAAAYvRwWpU+fPtHXr1y5Ujdu3JAUG/CsWrXKOBrr0qVLat68uZ48eaK//vpLW7ZsibO2lxQb4GzYsME4+q1nz57GAOfChQuSJA8PD3l4eGjevHnG67p06fLK0WkeHh5aunSpLC3///fH4eHhat26tc6fP69GjRqpWbNmkmKnddasWVNXr16VwWBQUFCQnJycdPPmTf3www+SJCsrK61YsUKenp6SpE6dOsnHx0dRUVG6dOmSHj9+LB8fHzk5OWnbtm2SYjdj6NevX6LfU3McHBwUFhYmSXr48KHxfxs0aKBz587Jzc1No0aNMrb/6quvtH79eknS9evXJUktWrSQtbW19u3bJ0nKnj27SZ2pU6dWs2bNdP78efXq1UsVKlSQJD1//lzlypVTWFiYnjx5ovv3779yxCIAAO86AjQAAAAYvTwq7OXpfwn1008/Gb/u3r27yVTGPHnyqF27dpo1a5YkadeuXfEGaA0aNDAJYkqVKmUM0J4+fZromiTJx8fHJDyTYtcRexGASbEjt86fP69Dhw7p8ePHxuPh4eGSpKNHjxrfk2LFiplcmz17dq1fv17ZsmWLd024t+HFem3Ozs768ssvjccNBoOuXr2qY8eO6ezZs8bj8a1FF5/y5curfPnyxtfh4eH6888/dfDgQZNRZwm9HwAA7yICNAAAABilT59eISEhkqQHDx4k+vpr164Zvy5cuHCc8y8fe7nty/65NtrLgdTrhHpS7Gi4+Ny/f19r1qzR3r179eeff8ZZiP/lZ966dct4LGvWrHHa/XNTg7fh5UAxbdq0xq+joqK0efNm7dy5UydOnDDZNOCFxEy5vHnzplatWqUDBw7o3Llz8U6/fd2/GwAA3gUEaAAAADByd3c3Bmh//fXXK9vt3r1bGzZsUPXq1eXt7W0Mb1KlMv/x8uXQxsLCIt42qVOnNnn9z5Fjr8PR0THOscDAQLVp00Z3796VFDvNs0yZMipevLhmz54dZ6OAl8W3O+fbdvv2beP0TUnKlSuXpNiRYB06dNDJkyclxYaHPj4+8vLy0smTJ7V69epEPefEiRPq1KmTwsLCZGFhoRIlSqhUqVLy8vLSkCFDdOfOnTfWJwAAUioCNAAAABhVrlxZBw4ckCT9+uuvunfvnnGB/Je9GLX1888/y8vLS6tWrZIUOzLrxWinv/76S4UKFTK57uVQLmfOnEnVjTisra3jHJs6daoxPOvbt6+6du1qPDd79uw47V8eGXflypU45xcvXqyIiAjlzZtXJUqUULp06d5E6a/04u9Jkuzs7FS0aFFJ0oYNG4zhWYUKFTR37lxjCPliDbnEGDt2rDGomzRpksnGCK/aCAIAgPcNu3ACAADAqHHjxsqQIYMkKSwsTH379o0z/W/JkiXau3ev8XXz5s2NX3t7exu/njVrlnE0mxQbOi1fvtz4unr16v+53pdHp5kLc+Ib7Xbu3Dnj1y9vmHDu3DmTcy+mJpYqVcr4vLNnz+rgwYPGNjdv3tS0adM0efJkde/e3Tjd88Wul1LsGmtvyu3btzVz5kzj66ZNmxp35Hy59nTp0hlrfvz4sfbs2ROnX5Lp+/jPOl/1Pv36668mm06wCycA4H3GCDQAAAAYOTg4aMKECeratatiYmJ06NAhVa9eXVWqVJGDg4NOnTplMrWxePHiatCggfF1q1attGrVKoWGhiooKEj169dX5cqVFRkZqd27dxtHMnl4eKhevXr/uV5HR0djwDd8+HC5uLiod+/er9yN82UuLi7GkWTffPON/P39FR4erp07d5qESC82EciSJYtq165t3FWzS5cuqlq1qpycnLRr1y5j30qXLm1cD+3lqaN37tzRgAEDJEnjx49PcB+3b9+uy5cvS4oNCW/fvq19+/YZ1z9zdXVVt27djO1f3rhh27ZtevbsmVxcXLR7926TQPPlRf9frvP06dMaNmyY7OzsNGjQILm4uCg4OFhS7Ei92rVr6+7duyZh3D/vBwDA+4YADQAAACYqVqyoWbNm6csvv9SjR4/04MEDbdy4MU47Ly8vzZw502SUVaZMmTR9+nR9/vnnunv3rkJDQ7VhwwaT6/Lnzy8/Pz+T615XiRIl9Msvv0iSDh06JCl2NFZCArROnTrp6NGjMhgMev78udatW2c8lyZNGuNOnIGBgcbjw4YN05UrV3TmzBlFRkZq+/btJvd0dXXVN998Y3z9wQcfKH369MYNGTZt2iRLS0uNGTPmX9eLe2Hfvn3at29fvOdcXV3l5+cnZ2dn47GmTZtq6dKlevjwoaTY9eri69fVq1eNx4sWLSpra2tFRkYqKipKq1evVtasWTVo0CB16tRJo0aNkiQ9fPhQ33///Svvly9fvgT1CQCAdw1TOAEAABBH5cqVtWvXLvXq1Uuenp5KmzatUqVKpYwZM6pChQqaMGGCVq5cKScnpzjXlixZUlu3blXPnj1VoEAB2dvby97eXoULF1b//v21du1aubq6vpE6hw8fLm9vb5NnvJjKmJA+Llq0SKVKlVLatGlla2urAgUKaPDgwZo6daqx3c6dO41fp0uXTitXrtSXX36pQoUKyc7OTtbW1sqVK5c6duyoTZs2KXv27Mb2NjY2mjFjhooUKSJra2ulS5dOZcqUee3RWqlSpVL69OlVvHhxffnll9q2bZs8PDxM2mTOnFnr1q1TrVq15OLiImtra2XLlk0dOnTQDz/8IBsbG0nSb7/9ZhzF5uLiom+//Vb58uWTtbW1MmTIYNwxtU2bNpo6daqKFClifJ+LFi2qiRMnGkfUSdKOHTteq08AALwLLAwsVgAAAAAAAAC8EiPQAAAAAAAAADMI0AAAAAAAAAAzCNAAAAAAAAAAMwjQAAAAAAAAADMI0AAAAAAAAAAzCNAAAAAAAAAAMwjQAAAAAAAAADMI0AAAAAAAAAAzCNAAAAAAAAAAMwjQAAAAAAAAADMI0AAAAAAAAAAzCNAAAAAAAAAAMwjQAAAAAAAAADMI0AAAAAAAAAAzCNAAAAAAAAAAMwjQAAAAAAAAADMI0AAAAJAsQkJC1KdPnzjH+/Tpo5CQkNe659y5c3X37t3/Wlqi+Pn56YsvvpDBYPhP92nXrl2irzlx4oTWr1//n54LAAD+HQEaAAAA3htnz579z0FWYoSFhen8+fNydnbW6dOn39pzXyhevLiaNGny1p8LAMD/mlTJXQAAAADwKj/++KN+//13xcTEqECBAmrTpo2srKy0du1a/fnnnwoLC5ODg4M+//xz7d+/Xw8ePNDkyZP11Vdfafjw4SpTpoxOnTolg8Ggpk2bateuXbp165ZatmypcuXK6fr161q6dKnCw8P16NEj1axZUz4+PtqwYYNu3Lihu3fv6vHjx6pcubLq1asXp77ff/9d+fLlU6FChbR79255enpKkvbv3y9/f389e/ZMd+7cUc6cOdWtWzelSpUq3tozZMggSTIYDOrXr5/69u0rNzc3RUVFqW/fvho7dqx27dqlI0eOyMrKSrlz55avr6/279+vc+fO6ZNPPtGmTZvinAcAAG8GARoAAACSzYMHDzR48OA4xyTp9OnTunDhgkaOHClLS0stWrRIe/bskaenp4KCgjR8+HBZWlpqzpw5OnjwoBo0aKC9e/fqiy++UNq0aSVJ6dKl09ixYzV37lxt375dgwYN0oULF7R8+XKVK1dO+/btU7169eTp6ak7d+5o8ODB8vHxkSTjMwwGg4YOHapChQopT548JrXu379f9evXV4ECBbRixQqFhobKyclJknThwgWNHTtWtra2Gj58uPz9/eXm5hZv7bVr15YkWVhYqEKFCjpw4IBatGihEydOqECBArKwsNCuXbs0ffp0WVhYaMmSJbp3756xjrCwsHjPZ8yYMUn+3gAA+F9DgAYAAIBkkz59eo0ZM8bk2It10U6fPq3Lly9r2LBhkqTIyEhZWlqqevXqatu2rfbt26cbN27owoULypQpU7z39/LykiQ5OzsrQ4YMsrKyUsaMGfX06VNJUuvWreXv768tW7bo+vXrev78ufHasmXLys7OTlLsVMnz58+bBGjXr1/XrVu35OnpKRsbGxUsWFC//PKLcUplvnz5ZG9vL0nKli2bnj59KldX13+tvWLFivr666/VvHlz/frrr6pVq5bs7e3l5uam4cOHq1ixYqpWrZpJOPZv5wEAwH9DgAYAAIAUyWAwqFatWsYRYWFhYbKwsNCVK1c0Y8YM+fj4qHTp0rKysnrlumdWVlbxfv3C9OnTZWdnpxIlSqhs2bI6dOiQ8Zyl5f8vF2wwGGRhYWFy7f79+xUTE6MBAwZIksLDw3Xt2jU1bNhQkmRjY2Nsa2FhIYPBkKDanZyclDVrVh09elQ3btxQoUKFJMk4es7f318TJkxQjx49TK6L73yBAgXif3MBAECisIkAAAAAUqSCBQvqt99+0/PnzxUTE6OZM2ca1/wqXLiwqlWrJjc3N50+fVoxMTGSYkOvF18nxJkzZ9SsWTOVKFFC586dkyTj9cePH1dkZKSePHmikydPysPDw3hdVFSUfvvtN/Xr109TpkzRlClTNG3aNMXExOjEiROvfJ652l9WqVIlLV++XOXLl5eFhYVCQkI0ePBg5cqVS02bNlWRIkV07do1Y/t/Ow8AAP4bRqABAAAgRSpevLiuX7+uESNGKCYmRgULFlS1atX08OFDTZs2TV999ZWsrKyUI0cO3blzx3jNpEmT1K9fvwQ9o1GjRho9erTs7e3l6uqqTJkyGe9lZ2en0aNHKywsTHXq1FH27NmN1508eVLp06c3GeFlbW2tatWqac+ePSpXrly8zytTpswra/9n3+fOnasKFSpIklxcXFSmTBkNHTpUNjY2cnZ2VoUKFXT06FGz5wEAwJthYXib+3wDAAAA74ANGzZIkho3bvzWn20wGHTmzBn98MMPxumhAAAgeTECDQAAAEhBVqxYoePHj+uLL75I7lIAAMDfGIEGAAAAAAAAmMEmAgAAAAAAAIAZBGgAAAAAAACAGQRoAAAAAAAAgBkEaAAAAAAAAIAZBGgAAAAAAACAGQRoAAAAAAAAgBkEaAAAAAAAAIAZBGgAAAAAAACAGQRoAAAAAAAAgBkEaAAAAAAAAIAZBGgAAAAAAACAGQRoAAAAAAAAgBkEaAAAAAAAAIAZBGgAAAAAAACAGQRoAAAAAAAAgBkEaAAAAAAAAIAZBGgAAAAAAACAGQRoAAAAAAAAgBkEaAAAAAAAAIAZBGgAAAAAAACAGQRoAAAAAAAAgBkEaAAAAAAAAIAZqZK7AOB9dvzezeQuAQDeKSUyZpEkBYeFJ3MlAPBucbNPLUk6FXonmSsBgHdHUadMCW7LCDQAAAAAAADADAI0AAAAAAAAwAwCNAAAAAAAAMAMAjQAAAAAAADADAI0AAAAAAAAwAwCNAAAAAAAAMAMAjQAAAAAAADADAI0AAAAAAAAwAwCNAAAAAAAAMAMAjQAAAAAAADADAI0AAAAAAAAwAwCNAAAAAAAAMAMAjQAAAAAAADADAI0AAAAAAAAwAwCNAAAAAAAAMAMAjQAAAAAAADADAI0AAAAAAAAwAwCNAAAAAAAAMAMAjQAAAAAAADADAI0AAAAAAAAwAwCNAAAAAAAAMAMAjQAAAAAAADADAI0AAAAAAAAwAwCNAAAAAAAAMAMAjQAAAAAAADADAI0AAAAAAAAwAwCNAAAAAAAAMAMAjQAAAAAAADADAI0AAAAAAAAwAwCNAAAAAAAAMAMAjQAAAAAAADADAI0AAAAAAAAwAwCNAAAAAAAAMAMAjQAAAAAAADADAI0AAAAAAAAwAwCNAAAAAAAAMAMAjQAAAAAAADADAI0AAAAAAAAwAwCNAAAAAAAAMAMAjQAAAAAAADADAI0AAAAAAAAwAwCNAAAAAAAAMAMAjQAAAAAAADADAI0AAAAAAAAwAwCNAAAAAAAAMAMAjQAAAAAAADADAI0AAAAAAAAwAwCNAAAAAAAAMAMAjQAAAAAAADAjFTJXQAA4L+LCA9Xp2q1FR0dbXI8tZ2tFu3eLkk6uu9XbVy8TDevXVN6Jyd9VKuGGrRvo1TW1sb2AafPaM2cebp45qxs7ezkVb6cWnbvonROTm+1PwDwtsTExGjt8qXatm6dQu7cVrYcOdWyQ0dVq13H2Gb7ls1as3Sxgq9fl7OLi2rWa6A2nTrLKlX8H6VnTZ6kgLN/acr8hW+rGwDwVkWEh+vjqjXj+expp2V7dkqSggOvavnMWfrrxElZWlmpkFcxte/VU65uWY3tL58/r9Vz5uvi2bMyxBj0QQF3te7RVR+4u7/V/gAJkewBmre3t4KDg42vra2t5ebmpmbNmqlz585v9Fnt2rWTm5ubxo0bl6D29+/f188//6xmzZq90ToS6/r16+rdu7fOnz+vqlWratq0aW/0/qNHj1a2bNnUoUOHN3K/sLAwbdy4UW3atHkj93tdN27c0MmTJ1WnTuwHYG9vbzVq1EifffbZv17bs2dPNWzYUNWqVUvqMoE3IujyFUVHR6vH8MEmH0osLa0kSaePHNPUr4apbNUqatX9EwVduaJVs+bp8cOH6tD3c0nSxb/OanTP3nLLlUPdhg6STWob/bBytYZ98qnGLp4ne0fHZOkbACSlRbNmavXiRerQ/VMVKFxYhw8c0DeDB8nCwkJVfWpr/crlmjlxgipWq66uvfvq4f37WjTLT5cCzmvk5Clx7rdm6RKtXb5URUuUTIbeAMDbcf3vz56fjRgqVzc343FLy9hJbndv39bQrj2UNUcOfT5quMKfh2vV3Hka/XlfTV6+RDa2qXXrepBG9PhMH7i7q/tXAyVZaOvK7zWs66easGShsubMkUy9A+KX7AGaJPn6+srX11eS9Pz5c/n7+2vIkCGys7NL1hBmwoQJCgoKSvYAbfny5bp165Y2b96s9OnTv9F7Hz9+XAcOHNDWrVvf2D0XLlyoDRs2JHuANmDAALm5uRkDtHXr1il16tQJuvbLL79Uu3btVLJkyTf+ngNJ4eqFi7KyslKZKpVkbWMT5/y+H35SRtdM+nT4YFlaWalI6ZJ6GHpfP65aq7a9PlWqVKm0efFy2Ts4aPD0qXJMm0aSVLhEcfVr1V5bl69Si25v9pcaAJDcnj97pvUrlqtx6zZq7dtJklS8TFkFnP1LG79fqco1amrZ3DkqUbacRkycbLwuX8GC6tSsiY4dOqiSZctJkm4GB2nWt5P1+769cnBMkyz9AYC3JfDCBVlZWalslcrxfvZcO3+R7B0dNHT6FKW2tZUkZcqaRRP6D9Slc+dUsFhR/bh2nVKnttXAyRNka2cnSfIoWVyfNm6mn9auV6d+fd5ml4B/lSLWQLO3t5eLi4tcXFyUPXt21alTR/Xq1dP69euTtS6DwZCsz3/h0aNHyp07t/LkyaOMGTO+0XtPmTJF7dq1k/VLU7j+q5Tyvv2Tk5OTHBwcEtQ2Z86cKlasmJYsWZLEVQFvRuCFi8qaM0e8H2AkKTIiQqnt7GRpZWU85pguraIiI/U8LEySFHz1qtyLFjGGZ5KU2tZWeQoV1B8HDyZtBwAgGVjb2Gj64mVq3u5jk+OprK0VERGh+/fu6dHDhypXoaLJ+dx58yld+gw69Ot+4zG/SRMVfO2qJs+Zp7xMPQLwngsMuKisOXPG+9nTYDDo8N59qlK3jjE8k6Q8BQtoztZNKlisqCQpW66cqte6pTE8kyRbOztldMmk2y/NUgNSihQRoMXH9qX/0CTp4cOHGjJkiCpUqKDChQurXLlyGjJkiJ49eyZJOnz4sAoVKqR9+/apbt268vDwUK1atfTzzz/He/+oqCj16tVLlStX1rVr1+KcHzhwoDZu3KgjR47I/e8PQe3atdPQoUPVrFkzlSxZUlu2bFFERITGjx8vb29veXh4qHTp0vr8888VGhoqSQoKCpK7u7t27NihZs2aycPDQ97e3lq9erXxWffu3VOvXr1UpkwZeXp6qmXLljpy5IjxmRs2bNDRo0fl7u6uw4cPS5LWr18vHx8feXp6ysfHR0uWLFFMTIzJM+fMmaPy5curatWqevLkSZw++vv76/jx46pZs2ai3md3d3cFBQUZr3n52PTp0zVjxgwFBwebtNu0aZPq168vT09PeXt7y8/Pzzhf/kW9P/zwgxo2bKgiRYqocePGunTpkmbOnKkPP/xQpUuX1siRI43hXExMjObMmaOaNWvKw8NDxYsXV+fOnY1/l+3atdORI0e0ceNGeXt7S4qdwjl9+nRj3b/++qtatGihokWLqmLFipoyZYrJHP7atWtr5cqVCg8Pj/ffEJCSXL1wUZZWVhr7eT919K6lLjXraf74yXr2NDYcq96koW5dD9K2lav09PFjXfjzjLavXqdi5crKMW1aSVKadOkUcut2nHvfCb6hO8E332p/AOBtsLKyUp78+eXk7CyDwaDQe/e0cuECnTh8SPWbN5djmjSySpVKt2+afg98/OiRHj9+pJsvfR7y/bSn5q9Zz9RNAP8TXoxAG/15X7WrUl0da9TW3HET9expmEJu3lTYkydyyeyq+RO/VccatdWmUlVN6D9I9+7cMd6jRuNGqt+2tcl9b10P0vXLl5Utd+633SXgX6XIAM3f31/btm0zmTo5cOBA/fXXX5oxY4Z27NihQYMGadOmTSZBVHR0tCZOnKjBgwdr27Ztyp8/vwYMGKCnT5+a3D86Olr9+/fXn3/+qWXLlilHjrhzqwcPHiwfHx95eXnpwIEDxuNr165V+/bttXLlSlWoUEETJkzQzp07NW7cOO3YsUPjxo3ToUOHNGvWLJP7jR07Vt26ddNPP/2kypUra8SIEbp+/bokacSIEQoPD9fy5cu1detW5c6dWz169FBYWJimT59uUoeXl5dWr16tCRMmqGfPnvrhhx/Uu3dvzZs3T5MmTTJ55saNG7VkyRJNnTpVjvGsXbR7924VLlxYzs7OiXqfzXkxHTdz5sw6cOCAsmTJosWLF2vo0KFq0aKFtmzZos8//1wLFiyIsxbdlClT9NVXX2nt2rV69OiRWrVqpcDAQC1btkx9+vTRypUr9csvv0iSli5dqgULFmjgwIHasWOHZs6cqcDAQOM9p0+fLi8vL/n4+GjdunVx6jx58qQ++eQTlShRQhs2bNDo0aO1atUq+fn5GdtUqlRJjx490vHjxxPUdyC5GAwGXb94WbeDg1WiYnn1nzxeDT9uq4O7dmtCvwGKiYlR4RLFVa9NS62cMVtdatbT8E8+VdoMGdRz5BDjfSrX9VHg+QAtnTpd90Pu6sG9e/p+5hwFBwbq+fPnydhDAEh6e7b/pKbVqmj+9Gkq81EFVa9dV7Z2dqpSo6Y2rf5eP23aqMePHula4BWNHtRfVlZWev78mfH63HnzycLCIhl7AABvh8Fg0LWLl3QrOEglK3ykQd9OVOMO7fXbrp819osv9ej+A0nSCr/ZCr0bot5fj1DXQf115XyARn76uZ4/exbvfSOeh2vm12NkndpGPs2avMUeAQmTItZAmzNnjhYujN2lKDIyUpGRkSpatKjq1atnbFO+fHmVKlXKOBosW7ZsWr58uQICAkzu1bt3b5UrF7sWRY8ePbRjxw4FBATIy8tLUuzIpUGDBunUqVNatmyZ3F5a8PBladKkka2traytreXi4mI8XrBgQZO6ihQpolq1aqlkydjfNrq5uenDDz+MU1eHDh1UtWpVSVKfPn20YsUKnTp1StmzZ9e1a9eUP39+Zc+eXba2tho8eLDq1asnKysrpU+fPk4dfn5+6t69u3Ftr+zZs+vJkycaOXKkPv/8c+MzW7durbx5877yff/jjz+UP39+k2MJfZ9fxcHBQfb29rKyspKLi4sMBoPmzZuntm3bGtdEy5Urlx48eKCJEyeqV69exmt9fX1VunRpSVL16tW1bNkyjRo1SnZ2dsqTJ4+mT5+uCxcuyNvbWzly5ND48eNVpUoV4/teq1Ytbd8eu9tg+vTpZW1tLVtbWznFs3vgsmXLVLRoUfXv31+SlCdPHo0aNUr37t0ztrGzs1O2bNl08uRJffjhhwnqP5AcDAaDvpgwRmnTp1e2D2J/W1fQq6jSZXSS38gx8j98VMd/PaC9235Sww7t5FGyuEJu3tL6BYs1rk9/DZ7+rVLb2qpK/boKexqmdfMXavua9bKwsFDpKpXkXb+e9v34UzL3EgCSVgGPIpoyf6EuX7igRX4zNODT7poyf6H6DB4qa2sbTRo1QhNHDldqW1u16uCrsKdhJlOTAOB/hcFgUP+J45Q2fXpl//uzZyGvYkqf0UnTR3ytPw7HzqZKl8FJ/caOMW4skDlbNg3p0k0HduxStYb1Te757GmYJg4YpIt/nVXfb76WS5bMb7dTQAKkiACtZcuWateunaTYqZVXr17VlClT1KZNG61du1Y2NjZq3bq19uzZo40bNyowMFAXL15UUFCQPvjgA5N7vfz6xairyMhI47GffvpJkZGRypMnj0kwllA5c+Y0ed2gQQP9/vvvmjRpkgIDA3X58mVduXLFGKi9kCdPHuPXadKkMamrZ8+e+vLLL7Vjxw6VKFFCH330kerWrRvvgvehoaG6deuWvv32W5PdOGNiYhQeHq6goCDjdf+s9Z/u3r0rT09Pk2MJfZ8TKjQ0VHfv3lWJEiVMjpcuXVqRkZG6fPmycV23l+u1t7eXs7Oz7F6eD29rq4iICEmx0zFPnTqladOm6cqVK7py5YouXrwoV1fXBNUVEBCg8uXLmxx7eSrrC05OTrp7927COgskE0tLSxUq7hXnuNeHZSVJgecDtGfzNjVo30bNP+lkPJ+nUEH1b9NBe7f9qJpNG0uS6rRqrprNGut2ULDSpEuntBnSy2/UN3JMk/btdAYAkolb9uxyy55dRUuUlIODg8YNGyL/E8dVtERJfTlipHr2H6BbN28oc5assrO314+bNsgte/bkLhsA3jpLS0sVjuezZ/EPYweyvFh2p1i5MsbwTJLyexSWvaOjrvxjcMbd27c1vt8A3bh2Xb1Hj1SpihWSsHrg9aWIKZzp0qVTzpw5lTNnTuXJk0fe3t4aMWKEzp07p99//10xMTHq2rWrRo8erVSpUql27dqaM2eOihcvHudeNq9YxPCFTJkyafXq1bp165ZmzJiR6Fr/uTbbsGHD1KdPH0VGRsrb21uTJ082jgxLaF3Vq1fXr7/+qnHjxsnNzU2LFi1SrVq1dOHChTjXvFjn7MXUyhd/tmzZop07dyr7Sx/k/lnrP1laWpqs+ZWY9/llL9/jVX18VT9Spfr/DPflr1/U9ypz585V+/btdf/+fZUrV04jR4407uSaEP981qtER0ebrQNICe6H3NWezdt09x/rl0WERxi/NhgMyu9ZxOR8tty55JgurYKuBEqSLp89pyN79ytVqlRyy5VTaTOklxQbwOVyz5ekfQCA5PAgNFQ7t27R/dB7JsfzFSwoSboXEqKD+/fpzz9Oys7eXrnz5JWdvb3uh95TyO3bxnYA8L8kNOSuft68JZ7PnrFrRzs4OsrCwkJRLw1keSE6Olo2Lw0UuXbxkgZ37qq7t29r8NTJKlO5UtIWD/wHKTYZeHmx+LNnz2r//v2aNm2a+vXrp/r16ytHjhy6du1aond8LFWqlIoWLap+/fppwYIF+vPPP1/Z9t/Wsbh//75Wr16t4cOHa9CgQWrcuLEKFiyoy5cvJ7iuiIgIjR07VtevX1ft2rU1evRo/fzzz7K0tNTevXvjtM+YMaOcnJx0/fp1Y+iYM2dOnTlzRlOnTk3QM19wcXHR/fv3ja8T8j6/2K3z5U0JAgMDTe778vvm7OwsZ2fnOOuIHTt2TNbW1vGuP5cQs2fP1qeffqoRI0aoRYsWKlasmAIDAxP8vufJk0enT582ObZkyRKTdfek2BF0mTJleq0agbclOjpa88dP0u5NW02OH9q9R5ZWlvIoVUKWVpY6d8rf5PyNq9f05OEjZcqaVZL018k/NHPEaD19/NjY5vSRYwq6EqiSFT9K+o4AwFsWHh6uccOG6KeNG02OH/t75+EP8uXX1nVrNfvbySbn169YLksrK5WtwA96AP73xERHa+64idq1abPJ8d9/3iNLKysVK1dGBYsV1eG9+xUZ8f+/0D199JjCnz1TwaKxu3DevX1bX/fqI8lCX8/xUyGvYm+xF0DipYgpnGFhYQoJCZH094KE167pm2++UaZMmVSuXDk9evRIqVKl0k8//SQnJyc9ePBAs2fPVkhIiHFKX2K1bNlSW7Zs0aBBg7R+/fp4R4jZ29vrzp07un79usnIrhccHR2VJk0a42L8z58/1/Lly3XmzBkV/fubwr+xsbHR6dOndezYMQ0dOlTOzs7av3+/wsLCjOu2vczCwkJdunTRlClTlDVrVlWsWFHnz5/XiBEjVLVq1Xj78Sqenp7as2eP8bWzs/O/vs/58+eXvb295s6dq969e+vq1atatGhRnPft4cOHunLlirJly6ZOnTppypQpyp49u8qXLy9/f3/NmDFDLVq0UJo0afTw4cME1/xClixZ9Ntvv8nb21uWlpbavHmzdu7cabIhgoODg4KDg3Xr1i1lzmw6h75z585q0qSJpk2bpgYNGujq1avy8/NT+/btjW3u37+vGzduxJnmCqQ0zpldVamOj7atXCWb1DbKV6Swzp86rc1LV6hGk0bKW7iQfJo31Q8rVkmSipQqqbu3bmnDwiVyzuwq7/qxo2Y/qlldW5au1HdDRqpum5a6e/u2ln/np/yeHvqoZvXk7CIAJAnXLFnk06CRls6bIyvrVMrnXkD+J0/o+0ULVbthI+XKk0eNWrXWgB7dNHPSBH1YqbJOHDmslQsXqGUHX6ZwAvif5JzZVZXr1NaWFd/LJnVq5fcorHP+p7VxyTLVatJYWXPkUOvuXTXi014a2/dL1WvTSg9DQ7Vi5mzlK1xIJSvELqWz6Ntpenj/vrr076ewp2EK+POM8Rn2DvbsxIkUJ0UEaAsXLjRuImBpaan06dOrZMmSmjRpkuzs7GRnZ6dx48Zp+vTpWrFihVxcXFS5cmV16NDBJABKDAsLC40ePVoNGjSQn5+fevfuHadNw4YNtWvXLtWtW1c7d+6Mc97a2lrTpk3TuHHjVK9ePaVLl05lypRR3759NWfOHD17xe4i/zRlyhSNHTtW3bt31+PHj/XBBx9o0qRJcdZRe8HX11epU6fWsmXLNG7cODk7O6t58+YmC/InRLVq1TRnzhyFhobKyclJrq6u//o+Ozo6auLEiZo0aZJq166tAgUKaMCAAfr000+N961Ro4bWrFmj+vXra/ny5fL19ZWNjY2WLFmib775RpkzZ1aXLl3UqVOnV5X2ryZMmKBRo0apSZMmcnBwUNGiRTVy5EiNGDFCN27cUNasWdWyZUsNGDBA9evX18G/f5P8QsGCBTVz5kx99913mjdvnjJlyqT27dure/fuxjZHjhxR2rRpVapUqdeuE3hbfL/so0xZs+jAjl3atGSZnFxc1LRzR9Vt01KS1LpndzllctHPG7fox+/XKH1GJxUpXUotunaWw9/rMqbPmFEDp07U8u/8NOWrobJ3dFSlOrXUrEsnWVpZJWf3ACDJ9B48RFmyuemH9et1++YNuWTOrI7de6h5+w6SpFLlPtTgb8Zp+fx52rZ+nVyzZFHP/gPVuFXr5C0cAJJRl/5fyNUtq/Zv36ENi5fKycVFzbt0Uv02rSRJ+Yt4aPiMaVo1Z54mDxqi1La2KlXxI7X77FNZWlkpKjJSJ377XZI0b8KkOPcv5FVMI/ymv9U+Af/GwpDYOZB4r7Rq1UrVqlX7T2HW+6pr164qUKCA+vTp89r3OH7v5husCADefyUyZpEkBYeFJ3MlAPBucbOPXVfqVOidZK4EAN4dRZ0SvmRTil0DDW9H7969tXLlyteeCvu+unTpkk6fPq2OHTsmdykAAAAAACCZEaD9jytTpowqVqyoZcuWJXcpKcqkSZM0bNgwpU+fPrlLAQAAAAAAyYwpnEASYgonACQOUzgB4PUwhRMAEo8pnAAAAAAAAMAbQoAGAAAAAAAAmEGABgAAAAAAAJhBgAYAAAAAAACYQYAGAAAAAAAAmEGABgAAAAAAAJhBgAYAAAAAAACYQYAGAAAAAAAAmEGABgAAAAAAAJhBgAYAAAAAAACYQYAGAAAAAAAAmEGABgAAAAAAAJhBgAYAAAAAAACYQYAGAAAAAAAAmEGABgAAAAAAAJhBgAYAAAAAAACYQYAGAAAAAAAAmEGABgAAAAAAAJhBgAYAAAAAAACYQYAGAAAAAAAAmEGABgAAAAAAAJhBgAYAAAAAAACYQYAGAAAAAAAAmEGABgAAAAAAAJhBgAYAAAAAAACYQYAGAAAAAAAAmEGABgAAAAAAAJhBgAYAAAAAAACYQYAGAAAAAAAAmEGABgAAAAAAAJhBgAYAAAAAAACYQYAGAAAAAAAAmEGABgAAAAAAAJhBgAYAAAAAAACYQYAGAAAAAAAAmEGABgAAAAAAAJhBgAYAAAAAAACYQYAGAAAAAAAAmEGABgAAAAAAAJhBgAYAAAAAAACYQYAGAAAAAAAAmEGABgAAAAAAAJhBgAYAAAAAAACYQYAGAAAAAAAAmEGABgAAAAAAAJhBgAYAAAAAAACYQYAGAAAAAAAAmEGABgAAAAAAAJhhYTAYDMldBAAAAAAAAJBSMQINAAAAAAAAMCNVchcAvM/874ckdwkA8E7xzOAiSQp6+jyZKwGAd0s2B1tJ0ol7t5K5EgB4dxTPmDnBbRmBBgAAAAAAAJhBgAYAAAAAAACYQYAGAAAAAAAAmEGABgAAAAAAAJhBgAYAAAAAAACYQYAGAAAAAAAAmEGABgAAAAAAAJhBgAYAAAAAAACYQYAGAAAAAAAAmEGABgAAAAAAAJhBgAYAAAAAAACYQYAGAAAAAAAAmEGABgAAAAAAAJhBgAYAAAAAAACYQYAGAAAAAAAAmEGABgAAAAAAAJhBgAYAAAAAAACYQYAGAAAAAAAAmEGABgAAAAAAAJhBgAYAAAAAAACYQYAGAAAAAAAAmEGABgAAAAAAAJhBgAYAAAAAAACYQYAGAAAAAAAAmEGABgAAAAAAAJhBgAYAAAAAAACYQYAGAAAAAAAAmEGABgAAAAAAAJhBgAYAAAAAAACYQYAGAAAAAAAAmEGABgAAAAAAAJhBgAYAAAAAAACYQYAGAAAAAAAAmEGABgAAAAAAAJhBgAYAAAAAAACYQYAGAAAAAAAAmEGABgAAAAAAAJhBgAYAAAAAAACYQYAGAAAAAAAAmEGABgAAAAAAAJhBgAYAAAAAAACYQYAGAAAAAAAAmEGABgAAAAAAAJhBgAYAAAAAAACYQYAGAAAAAAAAmEGABgAAAAAAAJhBgAYAAAAAAACYQYAGAAAAAAAAmEGABgAAAAAAAJiRKrkLeBOioqK0YsUKbd68WVeuXFHq1KlVqFAhffLJJypbtuwbf96GDRs0aNAgnT9/XpLk7e2tRo0a6bPPPpPBYNCmTZtUsWJFZcyY8Y0/OzFerutVnjx5ombNmmnRokXKnDnzG3nuhQsXFBwcrMqVK7+R+72uX375RdmzZ1fevHl1+PBhtW/fXrt371a2bNnMXnf79m116NBBa9eulaOj41uqFvhvIsLD1d67hqKjo02Op7az0/JfdsVpv3jqd/ph1RqtPXTA5Pj5039qpd9sXT5/XrZ29irnXUWtun0iOwf7JK0fAJJLTEyM1i1fpm3r1ynkzm1ly5FTLT7uoGq16xjbbN+yWWuXLVHw9etydnFRjXr11ca3s6xS/f9H6ds3bmjOtCk6deyoYgwGeRTzUvc+Xyhr9uzJ0S0ASFIR4eHyreYT72fPxbu3S5KO7vtVGxcv1Y1r15XeyUkf1aqhhu3bKJW1tbH9g9BQLf9upk4dOqLo6GgVK1dG7Xr1VAbn5P1ZGojPOx+ghYeHq2PHjrp586Z69eolLy8vPX/+XOvXr1fHjh01YcIE1atXL0lrWLdunVKnTi1JOnr0qAYOHKjdu3cn6TPflAkTJqh27dpvLDyTpK5du6pRo0bJGqAFBwerW7duWrp0qfLmzSsvLy8dOHBATk5O/3qtq6urateurfHjx+vrr79+C9UC/931y1cUHR2tXiOGyTVbVuNxS0urOG3/OvmHfly9Ns7xqxcualTPz1WkZAn1GztGoSF3tcJvtm5cu6Yh075N0voBILksnuWn1UsWqUP3HnIv5KHDv/2qsUO+kqWlpbxr+Wj9yhXymzRBFatV1ye9++rh/ftaPMtPlwMCNGJS7PfG8OfP9WWProqJjlbP/gOV2tZWi2f5qe8nnTR/zTo5pkmbzL0EgDfrxWfPT4cPkavby589Yye5+R85qilfDVXZqlXUsvsnCroSqFWz5urxwwfq2Le3JCk6Kkrj+/bXs6dh6tS/r6KjovT9rLka2/sLfbN4vlKleufjCrxn3vl/kdOmTdP58+e1bds2ZcmSxXh88ODBevLkiUaPHi1vb285ODgkWQ0vhzIGgyHJnvOmXb16VZs2bdKvv/6a3KW8cf/8e7CxsZGLi0uCr2/Xrp0qVqyozp07K2fOnG+6POCNCwy4ICsrK5X1rixrG5tXtnsWFia/0d/IycVF9+7cMTm3bdUaOaZNqy/GjZH1S78Z9Bv9jYKvXpNbzhxJVj8AJIfnz55p/crlatyqjVp17CRJKl6mjC6cPasN369Upeo1tGzeHJUoW1bDJ0wyXpevQAF1bt5Uxw4dVMmy5XT65AkFX7umibPmqniZMpKk7DlzqUPjBvpt717VrFc/WfoHAEnl6oWLsrKyUpkqleL97Lnvh5+U0dVVPYcPkaWVlTxLl9LD0Pv6cdUatevVU6lSpdKhPXsVGHBBE1csUbbcuSRJOfPlU/+2HXRo9y/6qGb1t9wrwLx3eg20yMhIrV+/Xo0bNzYJz17o3bu35s2bJ1tbW0mSu7u7vvvuO1WpUkUfffSRAgMDFRERoYkTJ6pChQry8vJS8+bNdeCA6ZSmXbt2qV69eipSpIhat26tGzdumJz39vbW9OnTjdMEJalq1arasGFDvHXfvXtX/fv3V5kyZVSiRAl17dpVV69elRQ7jWDOnDmqWbOmPDw8VLx4cXXu3FnXrl0zXh9fPx4/fqwBAwaoZMmSKlu2rBYtWvSv79/ixYtVtmxZpUuXznjs2LFjat++vYoXLy4PDw/5+Pho8+bNxvMDBw5Uu3btTO7z8jFvb28FBwdrxowZxmMPHjzQyJEjValSJXl6eqply5Y6fPiw8frp06erQ4cOmjFjhj788EN5eXlp2LBhunnzprp27aqiRYuqevXq2rt3r/GaGzduqE+fPipXrpwKFy6sihUrauLEiYqJiVFQUJCqVq0qSWrfvr3x78bd3V1BQUGSYv/tTJs2TVWqVFHRokXVuHFj/fbbb8b7p0+fXuXKldPixYv/9X0EUoIrFy4oa66cZsMzSVo23U/pnTKqct3acc617NpFX3070SQ8S2Ud+3uWyIjwN1swAKQA1jY2+m7RUjVr197keCrrVIqMCNf90Ht6/PChylaoaHI+d958Spc+gw7//UvIiIgISZK94///wjbt35+vHj18kIQ9AIDkcfXCRWXNmeOVnz0jIyKU2s5Wllb/PxsiTbq0ioqM1POwMEmxo9Sy5shhDM8kKVvuXMqaK6f+OHgoSesHXkeCAjRvb29VrVo1wX/eluvXr+vBgwcqXrx4vOddXV3l6ekpq5f+o125cqW+++47zZgxQ7ly5dKgQYP022+/adKkSdq4caN8fHzUrVs3Y1hz4sQJffbZZ6pZs6a2bNmiRo0aae7cufE+z8vLS9OnT5ckrV27VrVrx/0BNSoqSr6+vrp48aL8/Py0Zs0axcTEqHPnzoqOjtbSpUu1YMECDRw4UDt27NDMmTMVGBiocePGmdznn/3o3bu3/P39NXv2bC1atEh79+5VcHCw2fdv9+7dqlSpkvH17du31alTJxUpUkQbN27Upk2b5OnpqcGDB+vu3btm7/XCunXrlDlzZvn6+mr69OmKjo6Wr6+vjh07pokTJ2rDhg3Knz+/OnXqJH9/f+N1x44d05UrV7RixQoNGTJEq1evVtOmTeXj46MNGzYoT548GjhwoHFkWffu3fX48WMtWrRI27dvl6+vr+bPn689e/YoS5YsWrs2dnra9OnT5evrG6fOMWPGaNWqVRowYIC2bt2qChUqqFu3brp8+bKxTeXKlbVnz54E9RtIbi9GoH3dq4/aVq6mDjV8NGfcBD17GmZsc+rwUe3/abt6DB0kSwuLOPfImMlFOfPllRQ7KsP/yFF9P2uu3D2LKFe+fG+tLwDwtlhZWSlP/vxycnaWwWBQ6L17+n7RAp04fFj1m7WQo2MaWaVKpds3b5pc9/jRIz1+/Eg3g2N/MVeybDnlyP2B5k6bohtBQQq9e1ffjR8rO3t7la/snRxdA4AkdfXCRVlaWembz79QB++a6lyzruaPn2T87FmjSSPduh6kbStX6enjx7rw5xn9tHqdipUrK8e0sdPagwOvKnOOuOtTZ3Zz041r199qf4CESNAUztKlS8vi7x+2YmJi9MMPPyhNmjSqVKmSXFxc9ODBA/32228KDQ1VixYtkrTglz18+FCSTEZQ/ZsGDRqoSJEikmKnMG7btk2bNm1SwYIFJUkdO3bUuXPntGDBAlWuXFnLly9X8eLF1bNnT0lS7ty5FRAQoKVLl8a5t42NjbEWJycn48i3lx08eFDnz5/X9u3blTt3bknS6NGjtXjxYj18+FA5cuTQ+PHjVaVKFUmSm5ubatWqpe3bt7+yH5cvX9aBAwe0ePFilSxZUpI0efJk4z3ic/PmTd2+fVvu7u7GY+Hh4frss8/UqVMn49/3J598ok2bNikwMFDOzs7/9vbKyclJVlZWsre3V/r06bVv3z6dOXNGW7duVf78+SVJI0eO1OnTp7VgwQJNmzZNUuy/q5EjR8rR0VG5c+fWxIkTVbZsWTVs2FCS1KpVK/3yyy8KCQlR2rRp1aBBA/n4+BhHHnbo0EHz5s3T+fPnVa1aNeO02nTp0sWZvvvkyROtW7dOQ4cOVa1atSRJffr0kcFg0JMnT4zt8uXLp1u3bunmzZvxjnAEUgqDwaBrFy/JIIOq1q+rJh0/1qW/zmrtgkUKuhKokbNm6FlYmGZ9M1YtunRS1hzmp2IaDAb51qqjyPAIpUmXTp2+6POWegIAyeeXHds15quBkqQyH1VQtdp1lNrWVpWr19Dm1auU64M8+si7qh6EhmrmxPGysrLS82fPJEk2qVOr37ARGtKnl9rVj918wNrGRqOnfqes/7J5EQC8a17+7Oldv64adWivS2fPacPCxQoKDNSwmd+pcIniqtemlVbMmKUVM2ZJknLlz6fPRg413ufZk6fKHM/3SFt7ez17+vSt9QdIqAQFaC+Pfpo0aZI8PT21YMEC2dnZGY9HRkaqe/fuCgsLi+8WSeJFSPLgwYMEX/PyelZ//fWXJKl169YmbSIjI5X271Q8ICBA5cuXNznv5eUVb4CWEAEBAUqXLp0xPJNiR8oNGDBAUuxov1OnTmnatGm6cuWKrly5oosXL8rV1fWV/QgICJAkY6AmSc7OzspuZtenkJAQSabrt+XIkUONGzfW0qVLFRAQoGvXruncuXOSFGd3lcT0N02aNMbwTJIsLCxUsmRJk6myGTNmNNnx0t7eXjle+iH/RRgZEREhW1tbtW3bVtu3b5e/v7+uXr2q8+fP6+7du4qJifnXmq5cuaLIyEgVLVrU5Hjfvn1NXr94b0JCQgjQkKIZDAYNmDhOaTOkV/YPPpAkFfIqpvQZM+q7EaN06tBh/b77FzlnclWdVv/+S47o6GgNmDBekRHh2rh0uYZ1/1Rfz/FjFBqA91qBwh6aMm+hLl8I0KJZMzWwZw99O2+B+gweKmsbG03+eqQmjRqh1La2atmho8LCwpT6788np44f04BPu8ujaDE1bdtOlpZW2rZhrYZ/0Udjp/vJ8xWzJQDgXWQwGNRvwjdKkz69sn8Q+3NtQa+iSp/RSTNHjpb/4SM69utv2rvtRzXq0F4eJYsr5OYtrVuwWOP6fKnB06cota2tYgyv/tnN0uKdXm0K76lEbyKwdu1ajRs3ziQ8kyRra2u1a9dOffv2fWs7F2bPnl3Ozs46ceJEvNMlL126pDFjxmjQoEHK9/cPfi+PCnsxHXDFihVxRim92D3EwsIiTijz8vpAifVvO4nMnTtXM2fOVKNGjVSuXDl16NBBu3fv1g8//GDS7uV+vDw6MKHPetG/l6+5ePGiWrdurcKFC+vDDz9UjRo1lCFDBjVr1sxszVFRUa8896pNFQwGg0l98b2nL2r8p7CwMLVt21bPnz9XrVq11KhRI3l6eqpNmzZm6zT3rPi8eG9eVQeQUlhaWqpwibg/nBUvX06SdPncef32888av2i+DDExio6JUczf/21GR0XJwtLS5N95qlSpVLRMKUlSQa9i+rRRU/24eq16DPnqLfQGAJJH1uzZlTV7dnmWKCF7R0eNHzZEp0+ckGeJEvpy+Ej1/HKAbt+8IdcsWWVnb6+fNm1U1r9/WbliwTw5Z8qkb6bPlM3f6wGVLFdOvTq016zJEzVrxffJ2TUAeKMsLS1VqLhXnONeH5aVJF05f0F7Nm9Vg/Zt1fyTTsbzeQoV1JdtPtbebT+qZtPGsndwMK6H9rJnYU9l55h0mwACr+u1koEXUyf/6caNG0qdOvV/KigxLC0t1bRpU23YsEE3/7E2hSTNnz9fp0+flpubW7zXvwjVQkJClDNnTuOfDRs2GDcAKFCggE6ePGly3Z9//vnKmiziWVfoZXnz5tXDhw+NmwZIUmhoqMqUKaM//vhDs2fP1qeffqoRI0aoRYsWKlasmAIDA83u7vli+umJEyeMxx49emSy8cA/vdiRMjQ01Hhs1apVypgxoxYtWqQuXbqoUqVKxrXPXjzf2traZJqjJJO+/JO7u7seP35sHCX34l7Hjx9X3rx5X3mdOQcOHNCZM2e0dOlS9erVS7Vr15ajo6Pu3btnrNPc30POnDllbW2t06dPmxxv3ry5yaYB9+7dkyRlypTpteoE3pbQkLv6edMWhdy6ZXI8Ijx24f9dm7YoMjxCfVu3V8uPKqvlR5W1fuFiSVLLjyrLb/RYSdKxXw/or5N/mNzDwdFRrm5uCk3gOogA8C55cD9UO7dt1f3QeybH8xUoIEm6e/eODu7fpz//OCk7e3vlypNXdvb2uh96TyG3bytfgdjPYLdv3pR7wULG8EyK/Zzq4eWlwMuX3l6HAOAtCA25q92bt+rurdsmxyPCI4xfGwwGuXt6mJzPljuXHNOlU9CVK5KkLDly6FY863bfDgqWW66ccY4DyS3RAZq3t7cmTZpksmOhwWDQrl27NHXq1HhHgiWlbt26KVeuXGrdurU2bdqka9euyd/fX4MGDdKmTZv09ddfy97ePt5r8+XLpypVqmj48OHas2ePrl+/rnnz5mnOnDnG6YO+vr46d+6cxo8frytXrmjLli1avnz5K+t58axz587paTzztsuVKycPDw8NGDBA/v7+unDhggYMGCAnJycVLlxYWbJk0W+//aaLFy/q8uXLmjJlinbu3Gnc3Sk+OXLkUK1atTRq1Cj9/vvvCggIUP/+/c1e4+rqqixZshinsUpS5syZdevWLe3bt0/BwcHauXOnRowYIen/d5cqVqyYzp07py1btuj69euaOXOmSTgmSQ4ODgoMDNTdu3f10UcfqWDBgvriiy905MgRXbp0SaNGjVJAQIA+/vjjV9ZnTubMmSVJW7ZsUXBwsI4dO6YePXooMjLy/3fB+vvvISAgQI8fPza53s7OTm3bttW0adO0e/duXbt2Td9++60CAgJUseL/77L1119/KWvWrARoSPGio6M0Z9wE7dq42eT47z/vkaWVlYbNmKpxi+ab/KnaoJ4kadyi+WreOXajjW2r1mjehEkmU7bv3bmjoCuBypnn9QJvAEjJwp+Ha/ywIfpp0yaT48cOHZQkfZAvv7auW6vZU741Ob9+xQpZWlmp3N+7c+bIlVvnzvxp8tnLYDDoL39/ZXnFL3IB4F0VEx2t+eMnafemLSbHD+6O/exZpFQJWVpZ6dwpf5PzN65e05OHD5Upa1ZJkmeZkroReFVBVwKNbYKuBCo48Ko8S5dM8n4AiZXoKZyDBg3SxYsX1alTJ+Oi+ffv31d0dLTKly+vL7/8MinqfCU7OzstX75cCxcu1Lx583Tjxg3Z2tqqUKFCWrZsmXFR/VeZMmWKpkyZomHDhhkX8R8zZowaNWokKXZ017x58zRx4kQtX75c+fLlU7du3TRp0qR475c/f35VqlRJvXv3Vt++fePsAGlpaSk/Pz+NHTtWHTt2lIWFhcqWLav58+fL2tpaEyZM0KhRo9SkSRM5ODioaNGiGjlypEaMGKEbN24o69/fbP5p/PjxGj9+vPr06aOYmBi1aNHCZHRZfKpWrapDhw6pQ4cOkqT27dvr8uXLxvAtV65c6tu3r7777judPn1aFStWVP369XX27FmNHj1aUVFR8vHx0ccff2wySq9du3YaP368Lly4oC1btmjhwoUaP368evbsqYiICHl4eGjx4sUqVqyY2fpexdPTU4MGDdLixYs1depUubq6qnbt2sqSJYtxVFmGDBnUpEkTTZgwQVevXlX16tVN7tG3b19ZWVlp+PDhevz4sQoUKKC5c+fqg7/Xj5Kkw4cPy9ubnbOQ8rlkzqwqdWtry4rvlTp1auUv4qFzp/y1Ycky1WraON5NA44fiP0lSJ6CBYzHmvp20Ne9+mjKkOGq3rC+Ht1/oHWLFsshbRrVa93yrfUHAN4W1yxZVKtBQy2bN0epUqVSXvcCOn3yhL5fvFA+DRsp1wd51LhVaw34tLv8Jk1UuUqVdPLIEX2/aIFaduhonMLZtssn+ty3gwb17KEmbdrKyspKP23epL/8T2n4hPg/MwLAu8o5s6sq1fHR1pWrZJ06tfIXKaxzp05r89LlqtGkkfIWLiSf5k21bcUqSVKRUiV199ZtrV+4WM6ZM8u7fl1JUrmq3tq8ZIXG9+2vlt0/kSStmjVX2fN8oLLer94QD0guFgZzcwNfwWAwaN++fTp27JgePXqkDBkyqGzZsipXrlxS1IgkcvnyZTVo0EB79uwxTulErJCQEHl7e2vz5s0moVpi+d8PeYNVAa8WGRGhLctXat/2Hbp767acMrmoWv16qt+2dbzr+K2Zt0BrFyzS2kMHTI7/efyEVs+dH7s1eSorFStbRm0/7S7nf2xkAiQVzwyx/38U9PR5MleC/xWRkZFas2Sxdmzbojs3b8rFNbPqNG6i5u0/Nn7/3LP9Jy2fP1e3btyQa+Ysqt+8uRq1NN2E6uxpfy2aNVNnTp2StbW1PsifXx937a6iJRhFgbcjm0PsGskn7t36l5bAfxcZEaGtK1bpwI6dsZ89XVzkXb+u6rZpKUtLSxkMBv20Zp12b4z93po+Y0Z5li6pFl27KG2G9Mb73Lt9R0umfqfTR4/JyiqVPEuXUrvPeyqDc8bk6xz+pxTPmDnBbV8rQHvh2bNnevLkidKnT/+fFtZH8hk0aJAyZcqkPn36JHcpKcqUKVN0584djR079j/dhwANABKHAA0AXg8BGgAkXmICtNfaRODYsWNq3ry5SpQooYoVK8rT01MtWrTQoUOHXud2SEYDBw7U9u3b492E4X/V7du3tX37dg0aNCi5SwEAAAAAAClAokegnThxQu3bt1f27NlVp04dOTs7686dO/rhhx8UHBysZcuWycsr7pa2wP8iRqABQOIwAg0AXg8j0AAg8ZJ0Cmf79u1laWmpBQsWyMrKyng8JiZGnTp1koWFhRYuXJiYWwLvLQI0AEgcAjQAeD0EaACQeEk6hfP06dNq3769SXgmxe4u2bZtW/n7+7/iSgAAAAAAAODdk+gAzcHBQVFRUfGei4qK0n/YkwAAAAAAAABIcRIdoBUvXlxz587Vs2fPTI6HhYVp7ty5KlmSrboBAAAAAADw/kiV2Au++OILNW7cWFWrVlXlypXl4uKikJAQ7d27V8+fP9eYMWOSok4AAAAAAAAgWSQ6QMuZM6fWrFmj6dOna9++fXr48KHSpUun0qVLq2fPnsqbN29S1AkAAAAAAAAki0QHaJKUJ08eTZ069Q2XAgAAAAAAAKQ8rxWghYaG6tSpU3r06FG8mwY0bNjwv9YFAAAAAAAApAiJDtD279+vzz//XM+fP483PLOwsCBAAwAAAAAAwHsj0QHa5MmTlTNnTg0YMEDZsmWTpWWiN/IEAAAAAAAA3hmJDtCuXLmi6dOnq1y5cklRDwAAAAAAAJCiJHr4WJYsWfTs2bOkqAUAAAAAAABIcRIdoHXr1k3fffedAgMDk6AcAAAAAAAAIGVJ0BROb29vWVhYGF/fvHlTPj4+ypAhg+zs7EzaWlhY6Oeff36zVQIAAAAAAADJJEEBWunSpU0CNAAAAAAAAOB/RYICtHHjxiX4htHR0a9dDAAAAAAAAJDSJHoNtKpVq+rcuXPxnvP399eHH374n4sCAAAAAAAAUooEjUDbtm2boqKiJEnBwcHauXNnvCHawYMHFRkZ+WYrBAAAAAAAAJJRggK006dPa8mSJZJiNwnw8/N7ZduOHTu+mcoAAAAAAACAFMDCYDAY/q1RRESEQkJCZDAYVK1aNc2YMUMFCxY0aWNlZSVHR0c5OjomWbHAu8b/fkhylwAA7xTPDC6SpKCnz5O5EgB4t2RzsJUknbh3K5krAYB3R/GMmRPcNkEj0GxsbOTm5iZJ2r17t1xcXGRjY/N61QEAAAAAAADvkAQFaC9zc3NTaGioFixYoN9//10hISGaP3++fv75ZxUoUEDVqlVLijoBAAAAAACAZJHoXTivX7+u+vXra82aNXJ1ddW9e/cUHR2tK1euqFevXtq7d28SlAkAAAAAAAAkj0SPQBs/frwyZsyoZcuWyd7eXh4eHpKkyZMnKzw8XLNnz1blypXfdJ0AAAAAAABAskj0CLSDBw+qR48eSps2rSwsLEzOtWjRQhcuXHhjxQEAAAAAAADJLdEBmiSlShX/wLWIiIg4oRoAAAAAAADwLkt0gFayZEnNmTNHYWFhxmMWFhaKiYnR999/r+LFi7/RAgEAAAAAAIDklOg10L744gu1atVKNWrUUJkyZWRhYaEFCxbo0qVLunr1qlauXJkUdQIAAAAAAADJItEj0PLnz6/169erTJkyOnz4sKysrPT7778rR44cWrVqlQoWLJgUdQIAAAAAAADJItEj0CQpV65cmjx58puuBQAAAAAAAEhxEhSg3bhxI1E3zZo162sVAwAAAAAAAKQ0CQrQqlatmqibnj179rWKAQAAAAAAAFKaBAVoBoNBklSoUCHVqlVLLi4uSVoUAAAAAAAAkFIkKED78ccfjX+mTZum0qVLq06dOqpZs6bSpEmT1DUCAAAAAAAAycbC8GJ4WQKdO3fOGKbduXNH5cuXV7169eTt7S1bW9ukqhN4J/nfD0nuEgDgneKZIXaUe9DT58lcCQC8W7I5xP4sduLerWSuBADeHcUzZk5w20QHaC87deqUfvzxR+3YsUMPHz6Ut7e36tSpI29v79e9JfBeIUADgMQhQAOA10OABgCJ99YCtBeioqI0e/ZszZ49W9HR0WwiAPyNAA0AEocADQBeDwEaACReYgK0BK2BFp+YmBgdOnRI27dv165du3T//n0VKVJEtWvXft1bAgAAAAAAAClOogK0+EKzggULqmPHjvLx8VH27NmTqk4AAAAAAAAgWSQoQPv999+NodmDBw+UN29etWvXTrVr11auXLmSuEQAAAAAAAAg+SQoQPP19ZWVlZWKFy8uHx8f5cuXT5IUEhKikJC4azyVKlXqzVYJAAAAAAAAJJMET+GMjo7W0aNHdezYMZPjL/YgsLCwkMFgkIWFBZsIAAAAAAAA4L2RoABt6dKlSV0HAAAAAAAAkCIlKEArXbp0UtcBAAAAAAAApEiWyV0AAAAAAAAAkJIRoAEAAAAAAABmEKABAAAAAAAAZhCgAQAAAAAAAGZYGAwGQ2IumDFjhpo1ayZXV9c454KCgrRw4UINGzbsjRUIAAAAAAAAJKdEj0CbOXOmbt++He+5U6dOae3atf+5KAAAAAAAACClSJWQRi1bttSpU6ckSQaDQS1atHhl2yJFiryZyoD3gEX1bMldAgC8Uwy7giRJt59FJnMlAPBucbWzliQ9j45J5koA4N1ha5XwcWUJCtBGjx6t7du3y2AwaObMmWrSpIkyZ85s0sbS0lJp06ZVjRo1ElctAAAAAAAAkIIlKEDLmzevevbsKUmysLB45RpoAAAAAAAAwPsm0ZsIvPDw4UM9e/ZMMTFxhwhnzZr1PxcGvA+YwgkAicMUTgB4PUzhBIDEe+NTOF927do19e/f37gmWnzOnj2b2NsCAAAAAAAAKVKiA7RRo0YpMDBQPXv2VObMmWVpmeiNPAEAAAAAAIB3RqIDtKNHj2rMmDGqW7duUtQDAAAAAAAApCiJHj7m6OiodOnSJUUtAAAAAAAAQIqT6ACtQYMGWrFihV5z7wEAAAAAAADgnZLoKZx2dnY6fvy4qlevriJFisjW1tbkvIWFhb755ps3ViAAAAAAAACQnBIdoG3cuFFp0qRRTExMvDtxWlhYvJHCAAAAAAAAgJQg0QHanj17kqIOAAAAAAAAIEVK9BpoL8TExOjcuXPav3+/njx5ogcPHrzBsgAAAAAAAICUIdEj0CRp8+bNmjx5su7cuSMLCwutW7dO06dPl7W1tSZPniwbG5s3XScAAAAAAACQLBI9Au3HH3/UgAEDVLZsWU2ZMsW4G2f16tW1b98++fn5vfEiAQAAAAAAgOSS6BFos2fPVsuWLTVixAhFR0cbjzdp0kShoaFas2aNevfu/SZrBAAAAAAAAJJNokegXblyRdWrV4/3XNGiRXX79u3/XBQAAAAAAACQUiQ6QMuYMaMuXboU77lLly4pY8aM/7koAAAAAAAAIKVIdIBWu3Ztfffdd9q+fbsiIiIkSRYWFvrzzz/l5+enWrVqvfEiAQAAAAAAgORiYXixC0ACRUREqEePHjpw4IAsLS0VExMjBwcHhYWFqWTJkpo3b55sbW2Tql7gnWJRPVtylwAA7xTDriBJ0u1nkclcCQC8W1ztrCVJz6NjkrkSAHh32FolfFxZogO0F3777TcdPHhQDx8+VJo0aVS6dGlVqlRJFhYWr3M74L1EgAYAiUOABgCvhwANABLvrQRoAP4dARoAJA4BGgC8HgI0AEi8xARoqV7nATt27NCJEyf06NGjOOcsLCz0zTffvM5tAQAAAAAAgBQn0QHapEmTNH/+fDk6Oipt2rRxzjOFEwAAAAAAAO+TRAdoGzduVOvWrTVs2LCkqAcAAAAAAABIURI+2fNv4eHhqlGjRlLUAgAAAAAAAKQ4iQ7QatSooZ9//jkpagEAAAAAAABSnETvwvnkyRM1a9ZMzs7O8vT0lJ2dnekNLSz06aefvtEigXcVu3ACQOKwCycAvB524QSAxEvSXTiXLVumK1eu6MqVKzp69Gic8wRoAAAAAAAAeJ8kOkBbvny56tWrp4EDBypjxoxJURMAAAAAAACQYiR6DbSwsDA1bdqU8AwAAAAAAAD/ExIdoH344Yc6fPhwUtQCAAAAAAAApDiJnsJZv359DR06VFevXpWXl5ccHR3jtGnYsOGbqA0AAAAAAABIdonehbNAgQLmb2hhobNnz/6nooD3BbtwAkDisAsnALweduEEgMRL0l04d+/endhLAAAAAAAAgHdWogO0kydPqkaNGrKxsUmKegAAAAAAAIAUJdGbCPTv31/ly5fXiBEj5O/vnxQ1AQAAAAAAAClGogO0PXv2yNfXV4cOHVKLFi1Uu3ZtLViwQCEhIUlRHwAAAAAAAJCsEr2JwMtOnDihTZs2aefOnXry5Ik++ugjNW7cWN7e3kqVKtGzQ4H3DpsIAEDisIkAALweNhEAgMRLzCYC/ylAe+H06dOaMGGCjh49KklydnbWxx9/LF9fX1lZWf3X2wPvLAI0AEgcAjQAeD0EaACQeEm6C+cLwcHB2rx5szZv3qxr164pR44c6tu3rypXrqy9e/dq5syZunjxosaPH/+6jwAAAAAAAACSXaIDtLVr12rz5s06ceKEUqdOrVq1amnMmDEqWbKksU3+/Pl1//59rVq1igANAAAAAAAA77REB2hDhw5V0aJFNWLECNWuXVuOjo7xtnN3d1eLFi3+c4EAAAAAAABAckr0GmgXL15U3rx5k6oe4L3CGmgAkDisgQYAr4c10AAg8ZJ0DbS8efMqPDxc58+fV0REhF7kbzExMXr27JmOHTumfv36Jfa2AAAAAAAAQIqU6ADt8OHD+vzzz/Xw4cN4zzs4OBCgAQAAAAAA4L2R6ABtypQpypAhg77++mtt2bJFlpaWaty4sfbv36/vv/9e8+bNS4o6AQAAAAAAgGSR6ADt/PnzGj16tKpXr67Hjx9r1apVqlSpkipVqqTIyEjNmjVLc+fOTYpaAQAAAAAAgLcu4aul/S0mJkaurq6SpJw5c+rChQvGczVr1tRff/315qoDAAAAAAAAklmiA7QcOXLo/PnzkqTcuXPr2bNnunz5siQpKipKT58+fbMVAgAAAAAAAMko0QFavXr1NGnSJC1fvlxOTk7y8PDQ119/rT179mjmzJnKmzdvUtQJAIiHm3MW3d94RpU8y5kc/8ijtPZ/u14PN53V1RWHNbXHSDnaOZi0+brDlzLsCorz54umXY1trCytNOrjfrq24oiebr2g/d+uV+kCXm+lbwDwNsTExOj7JYvUql5tVStTQh2bN9bOH7a9sv30ieNVsZiHybHmPjVUsZhHvH+a166Z1F0AgGR1+9YtfVSmtI4eOWJ6/PZtDfryS1UsV1YfliqpT3w76uw/ZqzdCA7Wl336qPJH5VXpw3Lq3bOnrl+79jbLBxIs0Wugde7cWffv39epU6fUtm1bDR8+XF26dFGPHj3k6OioWbNmJUWd74127drpyD++sbzs4MGDcnJykre3txo1aqTPPvvsjTz3+PHjMhgMKlmy5Bu536u4u7tr7Nixaty48Ru9b1BQkKpWraqlS5eqTJkyb/TeL0yfPl0bN27Unj17kuT+wJuWzSWLdoxdofSO6UyOF8qZX7vGr9SBP4+q+ejucnPOrAldBuuDzDlUf1hHY7tieQrrlz9+16CF40yuv3o7yPj1t92Gq1Otlhq4YKwCb19X3yaf6Ofx38urey1duhGYpP0DgLdhgd8Mfb94oXx79FTBwh46eOBXjR48UJaWlqrmU9uk7R/Hj2ndyuVx7jF6yjRFRkSYHDtz6pRmTJ6gBs2aJ2n9AJCcbt28qe5duujx48cmx58+fSrf9u1kY22joSNGyia1jebOmq1unTtp3ebNcnHJpOfPn6tr506Kjo7WwMGDZZvaVn7Tp6tTh4+1btNmpU2bNpl6BcQv0QGapaWlBgwYYHxdpEgR/fzzz7p8+bI++OADOTo6vtEC30c+Pj4aPHhwvOcyZMiQJM9s3bq1xo4dm+QB2oEDB5QmTZokfQbwv87CwkLtqzfVpE+GysLCIs75NlUbyWCQGg7vpKfPwyRJqaysNKf3eOXI5KZrd4IlxQZoi3as1uGzJ+J9TjaXLOper516zRym2duWSZJ2Ht+vgEX7NaBFD30ypX8S9RAA3o7nz55p3Yplatq6rdr6dpYklShTVgF/ndH671eYBGhhYWEaN3yInDNlUsjt2yb3yV+goMnrp0+eaOTA/ipXoaLadOyU9B0BgLcsJiZGWzdv1rcTJ8hgMMQ5v3zpEj188EAbt22Ti0smSVLhwh5q2aypjh05Kp86dXTi+HFdu3pVcxcsVJlysbMpcuXOrQZ1amvvnj2q37Dh2+wS8K8SFaD5+/srODhYOXLkUOHChY3HHR0d5enp+caLe1/Z2trKxcUluctIEu9rv4CUxPODgpr9+Vj5bVmqn08e0I9jlpqct7VOrcioSIWFPzMeu/fogSQpY9oMunYnWBnTZlA2lyz649KrN36p6vWRrFNZa+Nv243HIiIjtO3wz2r4Ya032ykASAbWNjbyW7Jc6Z0ymhxPZW2tp0+emBybNWWSnDI6q0SZsloyd7bZ+y6dN0cPQkPVZ/6iN14zAKQEAefPa/TIEWreqpXKli2nnt27mZz/eedOVatRwxieSZKzi4t+3rvP+DoiPFyS5PDSIJx06dNLkh48eJB0xQOvKUFroD169EitWrVSixYt1KdPHzVt2lStW7fWzZs3k7o+/O3EiRNq06aNPD09VblyZY0cOVJPXvpgFxkZqWnTpqlKlSoqWrSoGjdurN9++01S7LRKSRo0aJAGDhyooKAgubu7a86cOSpfvryqVq2qJ0+e6MGDBxo5cqQqVaokT09PtWzZUocPHzY+Y/r06erQoYPmzp2rihUrqkiRImrbtq0uXbpkbOPu7q4NGzYYX2/ZskX169eXp6enqlatqiVLlryyjwaDQUuWLFHNmjXl6empOnXqaNs20zVITp06pWbNmsnDw0NVq1bV+vXrTc6vX79ePj4+8vT0lI+Pj5YsWaKYmBjj+bt376p///4qU6aMSpQooa5du+rq1avx1rN48WIVKVJEv/zyyytrBpLDtTs3lPfjCvpiziiFPX8W5/zCHaslxU6/dEqTXoVy5tfwdn3kf/msTl2ODcyK5Yn9JUjdslUVuPyQIn66ohOztqtWqSrG+xTMkU+Pnj7W7fshJve/GBwoN+fMcrC1T6ouAsBbYWVlpTz53ZXR2VkGg0Gh9+5q+cL5On74kBo2b2lsd/Tg79qxdasGjRod78jfl92+eVPrVi5Xy487KHPWrEndBQBIFlmyZNG27Tv05YCBsrWzMzkXGRmpy5cuKVeu3Jrx3TRVrVhBJTyLqFOHj3XxwgVju3Lly+uDD/JoyuRJCrp+XXdDQjR29Neyt7eXd9Wqb7tLwL9KUIA2depU/fXXX/rss880d+5cDRgwQJcvX9awYcOSuj5IOnfunDp27KgKFSpoy5YtmjRpks6cOSNfX1/jcNkxY8Zo1apVGjBggLZu3aoKFSqoW7duunz5sg4cOCBJ+uqrr0ymjm7cuFFLlizR1KlTZWdnJ19fXx07dkwTJ07Uhg0blD9/fnXq1En+/v7Ga44dO6bjx49r7ty5Wrlype7du6eRI0fGW/ePP/6oAQMGqEGDBtqyZYv69u2rSZMmmQRsL5s/f76mTJmizp07a9u2bWrZsqX69++vQ4cOGdssWbJE3bt3148//qgKFSpoyJAhxgBs9erVmjBhgnr27KkffvhBvXv31rx58zRp0iRJsbvE+vr66uLFi/Lz89OaNWsUExOjzp07Kzo62qSWFStW6Ntvv9WMGTNUpUoVASnJ/ccPFHz31b/AOBN4Xv3nj9FnDTrq3oY/dWb+HqWxc1CdIe2NgfKLAC1zhkzq/O2XajSis+48uKttXy9WjZKVJEnpHNLoUdiTOPd//Cx2t+W0DkzXBvD+2L39JzWsWllzv5uqsh9VUI06dSVJTx4/1viRw+Tb41Nlz5nrX++zdsUyWdvYqFmbtklcMQAkn3Tp08s1c+Z4zz169EhRUVFavnSJjh45ouFff63xkyfrfmioOn3cXnfu3JEkpU6dWiNGf62LAQGqU7OGqlaqqF9279a3332nbNmzv83uAAmSoCmcv/zyi/r27auPP/5YklSxYkW5urqqX79+CgsLk709oxASY+vWrdqxY0ec49WqVdPEiRPjHF+wYIHKly+vbt1ih8XmypVLkydPVrVq1XTkyBEVLlxY69at09ChQ1WrVuy0qj59+shgMOjJkyf64IMPJElp0qRRmjRp9PDhQ0mx66K92DV13759OnPmjLZu3ar8+fNLkkaOHKnTp09rwYIFmjZtmqTYEGrChAlKly520fKWLVvGW7MUG3bVrl1bnTp1Mtb99OlT2draxmn7YvRZ+/bt1axZM0mxGy48f/5cUVFRxnaffvqpvL29jX38/vvvdebMGeXMmVN+fn7q3r276tSpI0nKnj27njx5opEjR+rzzz/XkSNHdP78eW3fvl25c+eWJI0ePVqLFy82vieStGbNGk2YMEF+fn766KOP4u0bkJINaPGpxnUepBmbF2vDgR/lnNZJQ9v21u4Jq1WhT2PdeXBXa/Zt1bnrF/XT0V+ModqOY/t0as5OjWrfTzuP7ZOlhfnfsbw8uhMA3nUFPTz03YLFunQhQAtmzlC/T7vpu/mLNH3ieGVyzazmbdv/6z3Cw8P1w6YNqtOwsdKkTfev7QHgfRQVGWn8etacubJ3iN0JvnBhD9XzqaVVK1aoV58+Onb0iLp36aJiXsXVrsPHsrK00to1q9Xns17ymzNHxZN4/W4gsRIUoIWEhJiseSZJZcqUUXR0tG7evKk8efIkSXHvK29vb/Xr1y/O8VcFkX/99ZeuXr0qLy+vOOcuXboke3t7RUZGqmjRoibn+vbta7aOnDlzGr8OCAhQmjRpjOGZFLtQecmSJY0j2CTJ2dnZGJ5JsaFc5EvfIF8WEBBgDLNeaN48/p2o7t+/r5CQkDh96NKli6TYXTglGYMvScY6wsPDFRoaqlu3bunbb781hn1S7A/44eHhCgoKUkBAgNKlS2dyD1dXV5NNMe7cuaMRI0bI2tpabm5u8dYKpGRWllYa2uZzLf95gz6bMcR4fK//QV1a8pu+bN5NX84dreshN3Q95IbJtVHRUdp5fL+61Y0dNfHw6WOlsXeI84y09o7G8wDwvnDLnkNu2XOoWImScnBw0DdDB2vJ3NnaveMnzVuxWjExMYqJiTGO/o+KipKlpaUsLf//lw1HD/6up0+eqHrtOq96DAC8914EZiVLlzZ+LUlZsmbVBx/k0bmzZyVJ8+bMUSZXV82cM0c2NjaSYqd1tm/dShPHj9P3a9e9/eIBMxIUoEVFRRn/Qb/wcniBxHFwcDAJr/5NTEyM6tWrZxyB9jInJycFBwe/Vh0vjwSLb+eUF8dTpfr/fyb//HdgzsvX/Rtra+sEtXv5Q+oLBoPBOBJm0KBB+vDDD+O0yZIlS4LqsbCw0Lx58zR16lR99dVXWrFiRbzPBFIql/QZ5WBnr9/OHDU5HvLgns4HXVLhnLFrIvqU9padja02HPjRpJ2dja1CHoRKks4HXVI6h7RyTuekuw9DjW3yZs2lwFvX9TzieRL3BgCS1oPQUB367VeVKf+RMry0kUD+goUkScsXzFNERIQ+btowzrXeJYupVr0G+urrMcZjB/fvUxa3bCpQ2CPJaweAlCpNmjTK4OSkiIiIOOcioyKV2ja1JOnmjRsqVLiwyc+YlpaW8ipeQqu/X/nW6gUS6j8nA68KXvDm5MuXTxcvXlTOnDmNf6KiojR27FjdvHlTOXPmlLW1tU6fPm1yXfPmzbV48eIEPcPd3V2PHz9WQECA8ZjBYNDx48eN0zwTK0+ePHFqGjt2rHr16hWnbZo0aZQpU6Y47Xv16qWxY8f+67MyZswoJycnXb9+3eR9OnPmjKZOnSpJyps3rx4+fGiyaUBoaKjKlCmjP/74Q1LsLqLly5fX6NGjdfr0aS1dujSepwEp150Hd3Xv0X1VKFLG5HjGtBmU3+0DXb4V+++/aYXaWtRvsjKkSW9sY29rpzplquqXU79LknYd3/932/8fSWFjbaO6Zatp59/nAOBdFh4erm+GDtYPG03XZz16MPb74Pzv12ruilUmf+o1bipJmrtilTp262Fy3ZnTp1SkWLG3UjsApGQVKlbU4YMHdf/+feOxwCtXdDUwUMVLlJAk5c79gf48fdokaDMYDPI/9YfcsmV76zUD/ybhQ4Re4d92IkJcz58/V0hISLzn0qVLF2eUl6+vr9q0aaORI0eqbdu2evTokUaOHKnnz58rV65csrGxUdu2bTVt2jQ5OTkpX758WrdunQICAjRu3DhJsdNDL126ZPIN7GUfffSRChYsqC+++EJDhw5VxowZtXz5cgUEBGj48OGv1c9PPvlEn332mTw9PVWpUiWdOnVK33//vUaNGvXK9t9++61y584tLy8v7d27V7t379aiRf++BbyFhYW6dOmiKVOmKGvWrKpYsaLOnz+vESNGqGrVqrKxsVG5cuXk4eGhAQMG6KuvvpKdnZ0mTJggJycnFS5cWL/++qvxfu7u7urUqZOmTp0qb29v5ciR47XeA+Bti4mJ0fClkzWj52g9Cnustfu3yTmtkwa16qnomGhNXjtXkjRx7Ww1r1RPP41Zpm++ny4rKysNaN5DDrZ2Gr50siTp2p1gLd65RlO6D5ddalsFBF1W3yafKL1DWk1YMys5uwkAb4Rrliyq3bCRFs+dLatUqZS/QEGdOnFcKxctUJ1GjZUrnmVKft+/T5LijDKLjo7W1StXVK1W7bdSOwCkZF2799Avu3erW+dO6tq9hyIjIzVj2lS5Zs6sxk1j17z+pHt3dWjbRj26fqK27drLyspKmzZu0Kk//tCkvwdBAClJggO0ESNGyNHR0fj6xcizoUOHyuGlec0WFhZasmTJGyzx/fPTTz/pp59+ivfctGnTjBsBvFCsWDHNnz9f06ZNU6NGjWRvb69y5cppwIABxrCtb9++srKy0vDhw/X48WMVKFBAc+fONW4g4Ovrq/nz5+vSpUsaMmRInOdaWVlp4cKFGj9+vHr27KmIiAh5eHho8eLFKvaav0n19vbWqFGjNG/ePI0fP15ubm4aNGiQGjZsGG/7tm3b6vnz55o2bZpCQkKUK1cuTZkyRaVLlzaugWaOr6+vUqdOrWXLlmncuHFydnZW8+bNjSPeLC0t5efnp7Fjx6pjx46ysLBQ2bJlNX/+/HinkPbo0UPbt2/XV199pWXLlhEW450xc/NiPXjySF80/UQdazTX3Uf39evpw2o0orMCb12XJJ27dlEV+zbRN74DtbDfZNmkstb+04fVqW8/YxtJ6jp1oO4/fqgBLXrI0dZBxy/4q/rA1rp0IzCZegcAb9YXg4cpq1s2bV2/Trdv3lCmzJnl272nWn7cIVH3efTwgaKjopQmbdqkKRQA3iHZsmfXkhUrNfXbyRo8cICsrKxUttyH+nLgQGN+UNjDQwuWLNXM6d9p4JdfytraWvkLuGv+4sUqWap0MvcAiMvCkIA5mO3atUvUTZctW/baBQHvE4vqDD0GgMQw7Ir9hcntZ/FvUAMAiJ+rXewvhJ9Hs0s2ACSUrVXCVzZL0Ag0AjEAAAAAAAD8r2J7QQAAAAAAAMAMAjQAAAAAAADADAI0AAAAAAAAwAwCNAAAAAAAAMAMAjQAAAAAAADADAI0AAAAAAAAwAwCNAAAAAAAAMAMAjQAAAAAAADADAI0AAAAAAAAwAwCNAAAAAAAAMAMAjQAAAAAAADADAI0AAAAAAAAwAwCNAAAAAAAAMAMAjQAAAAAAADADAI0AAAAAAAAwAwCNAAAAAAAAMAMAjQAAAAAAADADAI0AAAAAAAAwAwCNAAAAAAAAMAMAjQAAAAAAADADAI0AAAAAAAAwAwCNAAAAAAAAMAMAjQAAAAAAADADAI0AAAAAAAAwAwCNAAAAAAAAMAMAjQAAAAAAADADAI0AAAAAAAAwAwCNAAAAAAAAMAMAjQAAAAAAADADAI0AAAAAAAAwAwCNAAAAAAAAMAMAjQAAAAAAADADAI0AAAAAAAAwAwCNAAAAAAAAMAMAjQAAAAAAADADAI0AAAAAAAAwAwCNAAAAAAAAMAMAjQAAAAAAADADAI0AAAAAAAAwAwCNAAAAAAAAMAMAjQAAAAAAADADAI0AAAAAAAAwAwCNAAAAAAAAMAMAjQAAAAAAADADAI0AAAAAAAAwAwCNAAAAAAAAMAMAjQAAAAAAADADAI0AAAAAAAAwAwCNAAAAAAAAMAMAjQAAAAAAADADAuDwWBI7iIAAAAAAACAlIoRaAAAAAAAAIAZqZK7AOB99vXJHcldAgC8U4Z61ZQk3XkemcyVAMC7JZOttSTpRlhEMlcCAO+OrPY2CW7LCDQAAAAAAADADAI0AAAAAAAAwAwCNAAAAAAAAMAMAjQAAAAAAADADAI0AAAAAAAAwAwCNAAAAAAAAMAMAjQAAAAAAADADAI0AAAAAAAAwAwCNAAAAAAAAMAMAjQAAAAAAADADAI0AAAAAAAAwAwCNAAAAAAAAMAMAjQAAAAAAADADAI0AAAAAAAAwAwCNAAAAAAAAMAMAjQAAAAAAADADAI0AAAAAAAAwAwCNAAAAAAAAMAMAjQAAAAAAADADAI0AAAAAAAAwAwCNAAAAAAAAMAMAjQAAAAAAADADAI0AAAAAAAAwAwCNAAAAAAAAMAMAjQAAAAAAADADAI0AAAAAAAAwAwCNAAAAAAAAMAMAjQAAAAAAADADAI0AAAAAAAAwAwCNAAAAAAAAMAMAjQAAAAAAADADAI0AAAAAAAAwAwCNAAAAAAAAMAMAjQAAAAAAADADAI0AAAAAAAAwAwCNAAAAAAAAMAMAjQAAAAAAADADAI0AAAAAAAAwAwCNAAAAAAAAMAMAjQAAAAAAADADAI0AAAAAAAAwAwCNAAAAAAAAMAMAjQAAAAAAADADAI0AAAAAAAAwAwCNAAAAAAAAMAMAjQAAAAAAADADAI0AAAAAAAAwAwCNAAAAAAAAMAMAjQAAAAAAADAjFTJXQDeDG9vbwUHB2vgwIHq2LFjnPPDhg3T6tWr1bNnT3322WcJvmejRo302Wefafr06dq4caP27Nnz2jX+l3sEBQWpatWqWrp0qcqUKfPaNZjzJvoIJKcLu3/XuZ/26klIqBwyZpB7zQrKX6OCLCwsJElBx//U6Q3bdf/aDdmmcVCOMl4q2qKOrG1TG+/x9N59nVixWbdOn1dMVJQye7jLq3V9pc2SKbm6BQBJKiYmRquXLdGWdWt15/ZtZc+ZU607+KpGnbrGNj9u3qRVSxYrOOi6XDNnUeMWLdWkdRvj91dJCrl9W7OmfqvDvx1QVFSUCnoUUY8+Xyh/wYLJ0S0ASFIxMTFau3yptq5bq5A7t5UtR0617NBR1WvX1a0bwWpVp9Yrr61Vv4EGjBwtSRozeKB+/vGHOG1GTJisStVrJFn9wOsgQHuPWFtba8eOHXECtKioKO3cudPkQ15CrFu3TqlTp/73hgCS3YU9v+vwvFVyr1VR2UoU0Z1zl3R08XpFR0apUF1vXTtySvunLJRrobyq8HlHxURF6fSGHQr5+opqjuotSysrRT0P1+4xMyVZqHSn5rKyTqXTG3Zo58jvVG/SIKV2dEjubgLAG7fAb4ZWLlqoTj16qoCHhw79+qu+/mqgLC0tVc2ntrZuWKcJI0eodQdflfrwQ/112l8zJk9U2LMwte/8iSQp7OlT9fT9WNY2Nuo3dLhsbGy0ZO4c9e3WRYvXbZSzi0sy9xIA3qxFs2Zo1eJF6tj9U7kX9tDhA7/qm8GDZGlhqQpVq2nmkuVxrtm0ZpV+2bFdtRs2Nh67eP68vGv5qEmrNiZts+XMldRdABKNAO09Uq5cOf3666+6deuWMmfObDx+6NAh2dvby87OLlH3c3JyetMlAkgil345JBf3D1SqQ1NJUpYi7np0887/tXfn0TVdCxzHfxFCEUPEEGQgSJAmIkhMbQTVa6qpZqnGXK2ifZTSokM8U40xD5GgUTONIaZOXtLGLEoITdCaiZoyyH1/pG57X+KiD0G/n7WyVu8+++yzz23sdfO7e++jo5u/VZXmATqwYqMKlympgGH9ZJ07c+gv4e6qte+OUcLOGFVsWEeJMft07dfzaj5+mIo4OkiSijiW1poBo5UYvU+VGtXNsfsDgMfh9q1b+io8TO26dFXXHj0lSTV8/XT05zitWLpEjQxNFTZvnvwbv6J+gwabjp9KTNTKZUtNAdry8DBdS05W2Op1prDMvaqHenZsr32xP6mRoWnO3CAAPAa3b93SiiXhatu5qzoHZY6dPr5+iv/5sFYtW6KGhqaq4ullds7Rw3HasXmTer7zrl70ri5JSk1J0anEX9SuS7cs9YGnEXugPUc8PT1VunRpbdq0yaw8MjJSBoMhywy0r776Si1atJCnp6eqVaumzp076+DBg6bjAQEBmjZtWrbX+v333zVy5Ej5+fnJx8dHgYGBZudKUkREhBo3bixPT0/17dtXycnJFvtvNBoVGhqqJk2ayNPTU82aNdOGDRvM6uzfv1+vv/66PDw81LBhQ61cudLs+MqVK2UwGOTp6SmDwaDQ0FBlZGSYjl+8eFFDhgyRr6+vfHx81KdPHyUmJmbbn0WLFunFF1/Ujh07LPYbeBrcSUtXnvz5zMryFiyg1Os3JEnXzpyTg6e7KTyTpBeKFFKhMqV0Zm+cJMmxpqeajB5oCs8kKdcf9TNS0x73LQDAE5fHxkYhi8PVMbC7eXnuPEpNSZEkjZs+Q28Nes/8eJ48Sk1JNb3euXWLXm7U2GymWTF7e63eup3wDMBzJ4+NjaYvClP7bm+Yl+fJo9TU1Cz1jUajpoz9XM7lXdWuSzdT+cnjx3UnPV0V3Nwee5+BR4EA7TljMBjMArTU1FRt3bpVzZo1M6sXFRWlMWPGqGfPntq4caMWLVqklJQUjRgx4r7XMBqN6tWrl06dOqXZs2dr+fLlqlatmjp16qTDhw9LkjZs2KAxY8aoe/fuWrt2rapXr64lS5ZYbHfevHn64osv1LNnT23YsEEdO3bUkCFDFB0dbaoTGhqqfv36KTIyUvXr19eIESNMAVhERITGjRunt99+W19//bUGDhyouXPnasKECZIyl7IGBQXp+PHjCgkJ0fLly5WRkaGePXvqzp07Zn1ZsmSJJk2apOnTp6tBgwb3fU+AnOZueFm/7T+iE9/9pNSbt/Tr/p914tsfVa5+TUlS3kIFdOPiFbNzMtLv6OalK7p+/pIkySb/CyruVl6SdCc9XVcSz2jXzHDltS0gp9reT/aGAOAJsLa2VoVKbipmby+j0ajLly4qfP48xcZEq1WHjpIkl/KucihTRkajUdeSk7V+1QptXr9OrTt0kCSlp6XplxMn5OTionnTp+m1hv7y96mmAT3e1Mnjx3Py9gDgsbC2tpZrJTfZ/WXsXLpgnnbHROu19h2y1N+xeZN+PnhAb/9rqKytrU3lx48ekSRFrl6lto0bqHFNbw0IekOHDx54YvcCPAyWcD5nDAaD5s+fr3PnzqlkyZL64YcfZGdnpypVqpjVK1KkiD777DO1bNlSklSmTBm1a9dOY8aMue81oqOjtW/fPkVHR6tIkSKSpMGDB2vPnj1avHixxo4dq7CwMDVt2lRdumSuZe/du7f27dunI0eOZNvm3dlngYGBev311yVJ3bp10+3bt5Wenm6q179/fwUEBEiSBg0apGXLlikuLk7Ozs4KCQlRv379TGGho6Ojrl+/rtGjR+vdd9/Vjz/+qKNHj2rTpk0qV66cJOnTTz/VokWLzGbHLV++XOPGjVNISIjq1at33/cDeBq41PXRucPHtWtGmKnMwctdNQLbSpJc/f10aPUWxa2NkmsDP91JTdO+iK+VevOWcue1ydLeznFz9NuBI7KyspJfn87KX7TwE7sXAMgJ2zZt1OgPhkiSatd/SU3+8hABSYo7sF/9ArtKktyrVjXNWvv92jXdSU/X8vAwlS5TVkM/Hq201FTND5mhd3p016KvVsm+BA9iAfB82r5poz4dPlSS5Ff/JTVu2jxLnS8XL5RHNW9Vq1HTrPx4fObfhrdu3dLI4HFKvnpVyxbO1+DePTQjNFyulZiZhqcLAdpzxsPDQ46Ojtq8ebMCAwMVGRmZZfaZJNWsWVMJCQmaMWOGTpw4ocTERB09etRsueO9xMXFyWg0ZpmZlZqaqpQ/ljvEx8dnua63t/c9A7QrV67owoUL8vIyX/veq1cvSZlP4ZRkCr4kqXDhzD/oU1JSdPnyZZ09e1aTJk3SlClTTHUyMjKUkpKi06dPKz4+XoULFzZro2TJkho6dKjp9fnz5zVq1CjlyZNHZcqUue97ATwtvhk/V+ePnpB3l9dk7+qkq0m/6cDKjfp28gK9/F5PebYzyHgnQ/uXR2rvsvXKZW2tCg1ry9HnRSWfOZulvRfbNFGVFg31yw+x+s+sJTJmZKhCQO0cuDMAeDIqe3ho2oJFSoiP17wZ0/XeW301bf5C0xYYpRxKa+r8hfrtzBnNmz5N/QK7av6Xy5WW/ucS9wkzZyt//vySMvdA69SiqVZ+uVR9BgzMiVsCgMfO3eNFTZ63UCeOxWtByHQN6d9Xk+f9OXYe2rdPx37+WZ9MmpLl3NYdO6v2S/6qVefPfXZ9fH3VtWVzhc+fq4//PeGJ3QfwIAjQnkN3l3F26NBB27Zt01dffZWlzvr16/XBBx+oRYsWql69ujp27Kj4+PgHmoGWkZGhggULatWqVVmO2djYmNX7qzx58tyzTUvH/ipXrqyrjo1Go+law4YNU506dbLUcXBwUO7c9/91t7Ky0ty5czV58mQNHz5cS5YsyfaawNPkwtET+nX/z/Lt3VEVAzJ//0tWqaiCJYtpx79n68yeOJX18ZB355bybGfQ7+cvKn/RwrIpkF9bRk2RTcH8Wdos4e4qKfNhBNcvXNahNVsI0AA818o4OqmMo5Oq+dRQgYIF9NmID7V/z25V86khSbIvUUL2JUrIu0ZNlS5bVu8EddfOrVtUzz9zZrx3jZqm8EySSjo4yLl8eR27x5eHAPA8KOPoqDKOjvLyqaH8BQpq7Ecf6sCe3fL6Y+z8ZusW2RYqJL969bOc6+RSTk4u5czKCtoWkke1akqIP/pE+g88DJKB55DBYNCePXu0cuVKOTo6ytXVNUudOXPmqF27dho7dqy6dOmimjVr6tSpU5IyAylLKlWqpOvXrystLU3Ozs6mn7lz52rbtm2SpMqVK2vPnj1m5/3vQwb+ytbWViVKlMhSZ8CAAQoODr7vPRcrVkx2dnY6deqUWZ/i4uI0efJkSVKFChWUnJxs9tCAy5cvy9fXV/v27ZMkFS9eXHXr1tWnn36qgwcPavHixfe9NpDTrv+xt1mJP/Yvu6tE5QqSpOTTv+ls3DH9uv9nWdvkUZGyDrIpkF8Zd+7o6qlfZefiKEm6mJCoxP+Y/7uVJDsXR928YvkhIADwLLpy+bI2rV+rK5cumZVXcs/c+uLcb78pKvJrnU5KMj9eOfP4xfMXVNDWVkWK2iktm42z09PSlTdv3sfUewDIGVcvX9bm9et05fL/jJ2VK0uSLl24YCqL/u5b1W0QoNzZTJjYvnmTfvrPrizlKSkpKlLU7hH3Gvj/EaA9hypXrixnZ2dNnDgx2+WbUuaMrD179iguLk5JSUlatGiRwsPDJSnbJ6f8Vf369VW5cmUNGjRI0dHRSkxMVHBwsFatWmUK63r37q2oqCjNmzdPv/zyi8LCwrR582aL7fbu3VuhoaFau3atkpKStHjxYm3btk0NGza87z1bWVmpV69eCgsLU3h4uJKSkhQVFaVRo0YpX758srGxUe3ateXh4aGhQ4fqwIEDOnbsmIYOHSo7OztVrVrVrD03Nzf16NFDkydPVtL/fGgGnjaFS2furXP+5wSz8gtHT0iSCpa0V1LMPkXP+VIZ6X8+MCNhR7RSb9ySY80XJUm/7jus76cvNnvYQEZGhs7GxauoU+nHfRsA8MSlpqTosxEfasMa81n1P/7xB12lylX079Efa9mihWbHf9r1gyTJtVIlSZJf/fqKjYnW1St/jp9Jv5zUqcRf5Fnd53HeAgA8cSkpKRr70YeKXL3arPxuGFa+YubYeC05WaeTEuXhlf3DqDas/EpffDZGaWl/LoW/cP6cDu3bm2W/NOBpwBLO55TBYNDMmTPVtGn2j04fOXKkPvroI3Xt2lU2NjZyd3fXuHHjNGjQIB08eFA1atS4Z9vW1tZasGCBxo8fr4EDB+rWrVtydXXV9OnTVbt25hIvf39/TZw4UdOmTdOUKVNUrVo1BQUFacOGDfdst2vXrrp9+7amTJmiCxcuyMXFRV988YVq1apl2gPNkqCgIOXNm1dhYWEaO3as7O3t1b59ew0YMEBS5vLPkJAQBQcH680338zcHN3PT/Pmzct2Celbb72lTZs2afjw4QoLCzOt4weeNnblHOVUy0u7w1Yr9cZNFavgouTTv+nAio2yK+8ox5qeKlympI5v36VdM8Pl6u+nK0lntG/pejnXrq6SVSpKkio2rKtjW3/QjnGz5dnOoFzW1oqP+l5XT/2qhsPfyuG7BIBHr6SDg5q1aq1Fs2cpd+7cquheWQf27NaSBfPVrHUblXN1Vdegnlowc4aK2tnJu2YtHY8/qkWzZ6qGn59pSdKbffrq+x3bNbhvb3Xv01fpaWmaO32qSpQspRZt2ubwXQLAo1XSwUGG11pr8dxZyp0ntyq4uevg3j1aunC+mrZqI5c/JlWcOBYvSXIpXz7bdrr16qP3+/bSiIHvqG3nrrp2LVmLZ89S4cJF1L7bG0/sfoAHZWW833o9AH/bJ3stz7oDHpU76ek6tGqzTnz3k25dSVYBezs51vTUi21fVZ58mcuHfjtwRHu/XK/k02f1QpFCKv9SLXm0ekW5cv/5OPHfz13U3qXrdO7n40q/nSL7Cs7yat/MtCca8LiN9G4iSTp/O+0+NYFHIy0tTcsWLdDGdet07rdfVaJUKbVo+7o6vdFduXLlktFo1NqvlmvVl8t05vQpFSlaVI0NzfRmv7fMlmeeTEjQrMmTtDf2J1lbW6uGX229868hKlGyVA7eHf5JSuTL/EL415uWV5MAj0JaWpoiQhdq8/rMsbN4qVJq3qadOgR2N+0hvWPLJo0Z+i+Frlorp3LZh2i7Y6IVOnumThyLl5WVlWrVqafe7w5SSQeHJ3k7+Acrnd/m/pX+QIAGPEYEaADwcAjQAODvIUADgIf3MAEae6ABAAAAAAAAFhCgAQAAAAAAABYQoAEAAAAAAAAWEKABAAAAAAAAFhCgAQAAAAAAABYQoAEAAAAAAAAWEKABAAAAAAAAFhCgAQAAAAAAABYQoAEAAAAAAAAWEKABAAAAAAAAFhCgAQAAAAAAABYQoAEAAAAAAAAWEKABAAAAAAAAFhCgAQAAAAAAABYQoAEAAAAAAAAWEKABAAAAAAAAFhCgAQAAAAAAABYQoAEAAAAAAAAWEKABAAAAAAAAFhCgAQAAAAAAABYQoAEAAAAAAAAWEKABAAAAAAAAFhCgAQAAAAAAABYQoAEAAAAAAAAWEKABAAAAAAAAFhCgAQAAAAAAABYQoAEAAAAAAAAWEKABAAAAAAAAFhCgAQAAAAAAABYQoAEAAAAAAAAWEKABAAAAAAAAFhCgAQAAAAAAABYQoAEAAAAAAAAWEKABAAAAAAAAFhCgAQAAAAAAABYQoAEAAAAAAAAWEKABAAAAAAAAFhCgAQAAAAAAABYQoAEAAAAAAAAWEKABAAAAAAAAFhCgAQAAAAAAABYQoAEAAAAAAAAWEKABAAAAAAAAFhCgAQAAAAAAABYQoAEAAAAAAAAWEKABAAAAAAAAFhCgAQAAAAAAABYQoAEAAAAAAAAWEKABAAAAAAAAFhCgAQAAAAAAABZYGY1GY053AgAAAAAAAHhaMQMNAAAAAAAAsIAADQAAAAAAALCAAA0AAAAAAACwgAANAAAAAAAAsIAADQAAAAAAALCAAA0AAAAAAACwgAANAAAAAAAAsIAADQAAAAAAALCAAA0AAAAAAACwgAANAAAAAAAAsIAADQAAAAAAALCAAA0AAAAAAACwgAANAAAAAAAAsIAADQAAAAAAALCAAA0A7iMgIEBubm5auHBhtsc/+ugjubm5adq0aY/smjt27NDx48clSTExMXJzc9Pp06cfqo20tDQtWrTokfXpSdu9e7diY2MlSadPn5abm5tiYmJyuFcAnhZ37tzR0qVL1a5dO3l7e6tGjRrq2LGjVqxYIaPRmNPdA4Cn0gcffCA3NzeLPwCyR4AGAA8gT5482rx5c5by9PR0bdmyRVZWVo/sWmfOnFHfvn116dKl/6udDRs2KDg4+BH16snr3LmzkpKScrobAJ5CaWlp6tevn6ZOnapWrVpp9erVioiI0KuvvqqxY8eqf//+unPnTk53EwCeOh9++KG+//57048kDR8+PEsZgKxy53QHAOBZULt2bX333Xc6e/asSpUqZSqPjo5W/vz59cILLzyyaz2qmRPMwADwvJo9e7ZiY2O1YsUKlS9f3lTu6uqqWrVqqX379po/f7569+6dg70EgKePra2tbG1ts5QVL148h3oEPDuYgQYAD8DT01OlS5fWpk2bzMojIyNlMBjMZqDt3btXgYGB8vHxka+vr4YNG6YrV66YjgcEBGj+/Pl655135O3tLV9fX3366adKT0/X6dOn1bBhQ0lSYGCg2bLQb775Rs2bN5eHh4eaNWumnTt33rO/q1at0rBhwyTJbOnjzp071b59e3l7e6tevXoKDg7W7du3Ld57QECA5syZo969e8vLy0sBAQHaunWrtm7dqiZNmqhatWrq0aOH2Yy5hIQE9e3bV76+vvLx8dGAAQN05swZ0/Fu3bppwoQJGj58uGrUqKHq1avrvffe0/Xr1019lqRhw4bpgw8+MJ23f/9+vf766/Lw8FDDhg21cuVKi30H8PzJyMhQWFiY2rRpYxae3VWlShW99tprCgsLU0ZGhmkJ+ObNm03jR0BAgCIiIszOW7lypQwGgzw9PWUwGBQaGqqMjIxs+xAaGipvb2/dunXLrF8vvfSSlixZIilzHOzVq5dpvH3vvfd04cIFU/3k5GSNGDFC9evXV9WqVVW7dm2NGDHC1GZMTIyqVKmiOXPmyNfXV23atLlnfwDgUQkLC1PNmjVNs3gzMjLk6+urPn36mOocPXpUbm5u+u233yRJa9asUcuWLeXp6amAgACFhITccxYw4yeeZQRoAPCADAaDWYCWmpqqrVu3qlmzZqayAwcOqFu3bqpYsaKWL1+uKVOmaP/+/erRo4fZB4kpU6aoZs2aWrdunYYMGaLw8HBt2LBBDg4O+uqrryRJ06ZNU1BQkOmcxYsXa+TIkVq/fr1cXFw0cOBA3bhxI9u+Nm3aVMOHD5ckff/99/L29lZUVJT69esnf39/rVq1SqNHj1ZkZKQGDx5833sPCQlR06ZNtX79erm7u2vIkCGaNWuWxo8fr1mzZungwYOaO3eupMwlqB06dJCNjY1CQ0O1YMECXbhwQV27djUFZJK0aNEi2dvba8WKFRo/fry2bdtm2rPtr0sKPvzwQ9M5oaGh6tevnyIjI1W/fn2NGDFCiYmJ9+0/gOfHyZMndfXqVVWvXv2edWrXrq3z58/r1KlTprLg4GD17dtXGzdulL+/v0aNGmU6HhERoXHjxuntt9/W119/rYEDB2ru3LmaMGFCtu23aNFCaWlp2rJli6ls165dunLlipo3b65z586pc+fOcnZ21ooVKzRr1ixdv35dHTp00M2bNyVl7kN0+PBhTZ8+XZs3b9awYcO0Zs0as2Dvzp07+uabbxQREaHPPvtMuXLx0R3A49WgQQNdu3ZNhw4dkiTFxcUpOTlZsbGxps+y33zzjapWrSoHBwctWrRII0eOVIcOHbRu3Tq9++67mj9/vsaOHZtt+4yfeJbxWwQAD8hgMGjfvn06d+6cJOmHH36QnZ2dqlSpYqqzYMECubm5aeTIkXJ1dZWfn58mTZqkuLg4sz0l6tWrp8DAQDk6Oqpt27Zyd3fXnj17ZG1tLTs7O0lS4cKFVaBAAdM5w4cPl6+vr8qVK6f+/fvr1q1bSkhIyLav+fLlM03PL168uGxsbDRnzhw1btxYb731lsqVK6eGDRvq448/1rZt20wPLLgXf39/tWrVSk5OTmrfvr1u3LihQYMGydPTU35+fqpTp46OHTsmSVq6dKny58+vCRMmyN3dXV5eXpo6daouXbqktWvXmtqsUKGCBg8eLBcXFzVs2FB169bV3r17TX2Wsi4z6N+/vwICAuTk5KRBgwYpIyNDcXFx9/k/B+B5kpycLEkqWrToPevcPXb58mVTWffu3dWwYUM5Ojqaxo/9+/dLyvySoF+/fmrWrJkcHR3VpEkTDRo0SOHh4UpJScnSvp2dnQICArRu3TpT2erVqxUQEKDChQtr2bJlKlWqlEaMGCFXV1d5eHho8uTJunTpkumLmLp16yo4OFheXl4qW7asWrZsqSpVqig+Pt7sWkFBQXJxcVHlypX/5jsGAA+ubNmyqlSpkulz665du/Tyyy8rJSXF9Jlr586dCggIkNFo1Ny5c9W1a1d16dJFLi4ueu211zRgwAAtW7ZMv//+e5b2GT/xLGMPNAB4QB4eHnJ0dNTmzZsVGBioyMhIs9lnkhQfH6+6deualbm7u8vW1lZHjx7Vyy+/LClzn56/srW1VVpamsXrlytXzvTfhQoVkiTdvn1bsbGx6tWrl+lY6dKl9fXXX2c5Pz4+Pkt/a9WqZTq2detWzZ4923SsRYsWGjNmjCTJ2dnZVH53vzcnJydTWb58+UxLOOPj4+Xh4SEbGxvT8eLFi6tcuXJmH2z+d+mVra2trl279sDvQeHChSUp2z9uATy/7oZj2f1hdtfdkO3uFxKS+bh7N5hPS0vT5cuXdfbsWU2aNElTpkwx1cnIyFBKSopOnz6dZcyWpLZt26pfv346f/688ufPr61bt2rq1KmSpMOHD+vYsWPy9vY2OyclJcX0xUfnzp21fft2rV69Wr/88ouOHz+u06dPZxkbXVxc7vueAMCjFBAQoF27dql///764YcfZDAYdOXKFUVHR8vZ2Vn79u3TRx99pMuXL+vixYvy8fExO79WrVpKS0vTiRMn5OXllaV9xk88qwjQAOAh3F3G2aFDB23bts203PKue23cbzQalSdPHtPrv4ZL9zv3ruymnhuNRnl4eGjNmjWmsty5sx/as2v/7n4QuXPnVseOHWUwGEzHChYsaLHNez159F73kZGRcd/34H7u9R4A+OdwcnJS8eLF9dNPP+mVV17Jts6PP/6o4sWLq2zZsqY9eu417t4dB4cNG6Y6depkqePg4JDtNerVqyd7e3tt2LBBRYoUUaFChVSvXj1JmeOdn5+fPv744yzn2draKiMjQ3369NGxY8fUvHlzNW3aVFWrVtXIkSOz1M+bN+893gkAeDzu7td78eJF7d27V2PGjNHZs2cVExOj0qVLq1SpUnJ3d9fFixezPf+vny+zw/iJZxUBGgA8BIPBoDlz5mjlypVydHTMMivBzc1Nu3fvNis7cuSIrl+/nu0MhuzcK5i6l3z58pnNELtXO25ubtqzZ4+6d+9uKouNjZWUOTOjSJEiKlKkyENdOztubm5at26dUlNTTX+wXrx4UYmJiercufP/3T6AfzZra2t1795dM2bMUMeOHbOMrceOHdOaNWvUt29fWVtb37e9YsWKyc7OTqdOnTIbSyMjIxUVFaV///vf9+xHq1atFBUVpUKFCum1114zXa9ixYqKjIyUg4ODaRy8evWqhg4dqjfffFO2trb69ttvtXz5ctPsjLS0NCUlJcnR0fFvvS8A8Kh4enqqcOHCmjVrlooVKyYXFxfVrl1boaGhKlCggAICAiRJ9vb2sre31+7du9WoUSPT+bGxscqTJ4/ZaoW/YvzEs4o90ADgIVSuXFnOzs6aOHFiluWQkvTmm2/q6NGj+uSTT5SQkKCYmBi9//77qlKlimrXrv1A18ifP7+kzKWQlpYoPWg7hw4d0u3bt9WzZ09t2bJFISEhOnnypHbs2KFPPvlEDRo0eOBw70F06tRJN27c0L/+9S8dOXJEBw4c0LvvvquiRYtm+55Z6n9CQoLZE0wBQMrc1+all15Sly5dtGTJEiUmJioxMVFLlixR165d5efnZ7a03RIrKyv16tVLYWFhCg8PV1JSkqKiojRq1Cjly5fP4mzZNm3aaP/+/dq1a5dat25tKu/cubN+//13vf/++zpy5IiOHDmiQYMG6eDBg6pUqZLs7e2VO3dubdy4UadOndLBgwc1cOBAXbhwQampqf/3+wMA/w8rKyv5+/srIiLC9Pm1evXqMhqNioqKMj0xXpJ69Oih8PBwLV26VImJiVq/fr2mT5+uDh06mO1j+78YP/EsYgYaADwkg8GgmTNnqmnTplmOeXl5ad68eZo8ebJatWqlggULqlGjRnrvvffMli9aUrRoUbVt21bjxo1TYmKiGjdu/Lf66efnJy8vL3Xs2FHjx4+XwWDQpEmTNHPmTIWEhMjOzk7NmzfXgAED/lb791K2bFmFh4dr/Pjxpqdx1q1bV+PHjzft3fYggoKCNG/ePCUkJGjEiBGPtI8Anm25cuXSlClTTE9d++KLL2Q0GlWxYkW9//77ateu3UPN5g0KClLevHkVFhamsWPHyt7eXu3bt7/v+Oji4iIvLy9lZGSYfRHh6Oio8PBwTZw4UZ06dZK1tbWqV6+uxYsXm/ZlGzt2rKZNm6YlS5aoePHi8vf3V/fu3bV9+/a/96YAwCPUoEEDrVixQr6+vpIyl8H7+Pjo0KFDqlmzpqleUFCQ6cnrn3/+uUqVKqVevXqpR48eFttn/MSzyMrI5jEAAADAQzMajWrUqJH69u2r119/Pae7AwDPDMZPPIuYgQYAAAA8hLS0NG3fvl3R0dG6efPmQy1PB4B/MsZPPMuYgQYAAAA8pPr160uSgoODTU+PAwDcH+MnnlUEaAAAAAAAAIAFPIUTAAAAAAAAsIAADQAAAAAAALCAAA0AAAAAAACwgAANAAAAAAAAsIAADQAAAAAAALAgd053AAAAAHjcPvjgA61evdpinVq1aiksLOwJ9QgAADxLrIxGozGnOwEAAAA8TklJSbp8+bLpdUhIiA4fPqzp06ebygoWLKgKFSrkRPcAAMBTjhloAAAAeO45OTnJycnJ9NrOzk42NjaqVq1aznUKAAA8M9gDDQAAAP94O3fulJubm77//nuz8tjYWLm5uWn37t2KiYkx1enSpYs8PT31yiuvaOnSpWbnZGRkaM6cOWrcuLE8PDzUpEkTloYCAPCMI0ADAADAP179+vVVokQJrV271qx8zZo1cnFxkY+Pj6ls0KBBqlKlimbMmKE6depo9OjRZiHaqFGjNHXqVLVs2VKzZs3Sq6++qs8//1wzZsx4YvcDAAAeLZZwAgAA4B/P2tparVu3VlhYmG7cuKECBQro9u3b2rhxo3r37m1Wt3Hjxvrwww8lZQZv58+fV0hIiDp16qRffvlFy5cv1+DBg03n1atXT1ZWVpo9e7Y6d+6sokWLPvH7AwAA/x9moAEAAACS2rZtq5s3byoqKkqSFBUVpZs3b6pVq1Zm9Vq3bm32+pVXXtGFCxd08uRJRUdHy2g0KiAgQOnp6aafgIAApaSkaPfu3U/qdgAAwCPEDDQAAABAkrOzs2rVqqU1a9aoVatWWrNmjerUqaOSJUua1fvf18WKFZMkJScn6+rVq5KkZs2aZXuNc+fOPfqOAwCAx44ADQAAAPhD27ZtNXz4cCUkJOg///mPJkyYkKXOlStXzJ7oeenSJUmZQVqhQoUkSaGhoSpQoECWc0uXLv2Yeg4AAB4nlnACAAAAf2jSpIleeOEFjRo1SgUKFFCjRo2y1Nm6davZ602bNqlMmTJycnJSjRo1JGWGbC+++KLp5/Lly5oyZYpphhoAAHi2MAMNAAAA+MMLL7ygZs2aKSIiQp06dZKNjU2WOgsXLlTevHlVrVo1bdmyRTt27NDEiRMlSW5ubmrZsqVGjhypM2fOyMPDQydPntQXX3yhsmXLysXF5QnfEQAAeBQI0AAAAIC/8Pf3V0REhNq0aZPt8eHDh2v16tWaPXu2ypcvr6lTp6pJkyam48HBwZo9e7a+/PJLnT17VsWKFVPTpk01cOBAWVtbP6nbAAAAj5CV0Wg05nQnAAAAgKfFxx9/rP3792vNmjVm5TExMQoMDNTixYvl6+ubM50DAAA5ghloAAAAgKTFixfrxIkTWr58ucaPH5/T3QEAAE8RAjQAAABAUmxsrL777ju98cYbat68eU53BwAAPEVYwgkAAAAAAABYkCunOwAAAAAAAAA8zQjQAAAAAAAAAAsI0AAAAAAAAAALCNAAAAAAAAAACwjQAAAAAAAAAAsI0AAAAAAAAAALCNAAAAAAAAAACwjQAAAAAAAAAAv+C7PfScYCAQnvAAAAAElFTkSuQmCC","text/plain":["<Figure size 1300x600 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["crosstab = pd.crosstab(contract_df['payment_method'], contract_df['contract_type'])\n","fig, ax = plt.subplots(figsize=(13, 6))\n","g = sns.heatmap(crosstab, cbar=False, cmap=\"BuGn\", linewidths=0.3, annot=True, fmt='d', ax=ax)\n","\n","g.set_ylabel('Payment Method')\n","g.set_xlabel('Type')\n","\n","ax.text(x=0.5, y=1.1, s='Contract Data', fontsize=16, weight='bold', ha='center', va='bottom', transform=ax.transAxes)\n","ax.text(x=0.5, y=1.05, s='Heatmap Analysis', fontsize=8, alpha=0.75, ha='center', va='bottom', transform=ax.transAxes)\n","\n","plt.yticks(rotation=0)\n","plt.xticks(rotation=0)\n","plt.show()"]},{"cell_type":"code","execution_count":583,"metadata":{"execution":{"iopub.execute_input":"2023-12-01T00:02:36.916012Z","iopub.status.busy":"2023-12-01T00:02:36.915540Z","iopub.status.idle":"2023-12-01T00:02:36.942607Z","shell.execute_reply":"2023-12-01T00:02:36.941607Z","shell.execute_reply.started":"2023-12-01T00:02:36.915974Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>customer_id</th>\n","      <th>begin_date</th>\n","      <th>contract_type</th>\n","      <th>paperless_billing</th>\n","      <th>payment_method</th>\n","      <th>monthly_charges</th>\n","      <th>total_charges</th>\n","      <th>churn_target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>7590-VHVEG</td>\n","      <td>2020-01-01</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>29.85</td>\n","      <td>29.85</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5575-GNVDE</td>\n","      <td>2017-04-01</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>56.95</td>\n","      <td>1889.50</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3668-QPYBK</td>\n","      <td>2019-10-01</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>53.85</td>\n","      <td>108.15</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>7795-CFOCW</td>\n","      <td>2016-05-01</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>42.30</td>\n","      <td>1840.75</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>9237-HQITU</td>\n","      <td>2019-09-01</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>70.70</td>\n","      <td>151.65</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7038</th>\n","      <td>6840-RESVB</td>\n","      <td>2018-02-01</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>84.80</td>\n","      <td>1990.50</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7039</th>\n","      <td>2234-XADUH</td>\n","      <td>2014-02-01</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>103.20</td>\n","      <td>7362.90</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7040</th>\n","      <td>4801-JZAZL</td>\n","      <td>2019-03-01</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>29.60</td>\n","      <td>346.45</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7041</th>\n","      <td>8361-LTMKD</td>\n","      <td>2019-07-01</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>74.40</td>\n","      <td>306.60</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7042</th>\n","      <td>3186-AJIEK</td>\n","      <td>2014-08-01</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>105.65</td>\n","      <td>6844.50</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7032 rows × 8 columns</p>\n","</div>"],"text/plain":["     customer_id begin_date  contract_type  paperless_billing  payment_method  \\\n","0     7590-VHVEG 2020-01-01              0                  1               2   \n","1     5575-GNVDE 2017-04-01              1                  0               3   \n","2     3668-QPYBK 2019-10-01              0                  1               3   \n","3     7795-CFOCW 2016-05-01              1                  0               0   \n","4     9237-HQITU 2019-09-01              0                  1               2   \n","...          ...        ...            ...                ...             ...   \n","7038  6840-RESVB 2018-02-01              1                  1               3   \n","7039  2234-XADUH 2014-02-01              1                  1               1   \n","7040  4801-JZAZL 2019-03-01              0                  1               2   \n","7041  8361-LTMKD 2019-07-01              0                  1               3   \n","7042  3186-AJIEK 2014-08-01              2                  1               0   \n","\n","      monthly_charges  total_charges  churn_target  \n","0               29.85          29.85             1  \n","1               56.95        1889.50             1  \n","2               53.85         108.15             0  \n","3               42.30        1840.75             1  \n","4               70.70         151.65             0  \n","...               ...            ...           ...  \n","7038            84.80        1990.50             1  \n","7039           103.20        7362.90             1  \n","7040            29.60         346.45             1  \n","7041            74.40         306.60             0  \n","7042           105.65        6844.50             1  \n","\n","[7032 rows x 8 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["# label encoding\n","contract_df = MultiColumnLabelEncoder(columns = ['contract_type','paperless_billing', 'payment_method']).fit_transform(contract_df)\n","\n","display(contract_df)"]},{"cell_type":"markdown","metadata":{},"source":["`Summary`\n","\n","Peaking into our contract data, we see issues with column naming, and column datatypes. We attempt amend those two to start and find that one of the features has empty strings in it's value range (through an iterative examination). \n","\n","Once we find the specific culprits, we replace with NaN values so we can then drop the rows themselves. Thse are small in numbers compared to the entire DF and so are more comfortable with the removal and do not expect much, if any, impact down the line. "]},{"cell_type":"markdown","metadata":{},"source":["-----------"]},{"cell_type":"markdown","metadata":{},"source":["# Personal data"]},{"cell_type":"code","execution_count":584,"metadata":{"execution":{"iopub.execute_input":"2023-12-01T00:02:39.542076Z","iopub.status.busy":"2023-12-01T00:02:39.541696Z","iopub.status.idle":"2023-12-01T00:02:39.554628Z","shell.execute_reply":"2023-12-01T00:02:39.553612Z","shell.execute_reply.started":"2023-12-01T00:02:39.542045Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 7043 entries, 0 to 7042\n","Data columns (total 5 columns):\n"," #   Column         Non-Null Count  Dtype \n","---  ------         --------------  ----- \n"," 0   customerID     7043 non-null   object\n"," 1   gender         7043 non-null   object\n"," 2   SeniorCitizen  7043 non-null   int64 \n"," 3   Partner        7043 non-null   object\n"," 4   Dependents     7043 non-null   object\n","dtypes: int64(1), object(4)\n","memory usage: 275.2+ KB\n"]}],"source":["personal_data.info()"]},{"cell_type":"code","execution_count":585,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Categorical Features: ['gender', 'Partner', 'Dependents']\n","Non-Categorical Features: ['customerID']\n","Discrete Features: ['SeniorCitizen']\n","Continuous Features: []\n"]}],"source":["categorical, non_categorical, discrete, continuous = classify_features(personal_data)\n","\n","print(\"Categorical Features:\", categorical)\n","print(\"Non-Categorical Features:\", non_categorical)\n","print(\"Discrete Features:\", discrete)\n","print(\"Continuous Features:\", continuous)"]},{"cell_type":"code","execution_count":586,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["gender\n","Male      3555\n","Female    3488\n","Name: count, dtype: int64\n","\n"]},{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"alignmentgroup":"True","hovertemplate":"variable=count<br>gender=%{x}<br>Count (#)=%{y}<extra></extra>","legendgroup":"count","marker":{"color":"darkgreen","pattern":{"shape":""}},"name":"count","offsetgroup":"count","orientation":"v","showlegend":true,"textposition":"auto","texttemplate":"%{y}","type":"bar","x":["Male","Female"],"xaxis":"x","y":[3555,3488],"yaxis":"y"}],"layout":{"autosize":false,"barmode":"relative","legend":{"title":{"text":"variable"},"tracegroupgap":0},"margin":{"t":60},"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"xaxis":{"anchor":"y","domain":[0,1],"title":{"text":"gender"}},"yaxis":{"anchor":"x","domain":[0,1],"title":{"text":"Count (#)"}}}},"text/html":["<div>                            <div id=\"6e8a0df8-57eb-43d4-a3f4-3ece64b9f7f6\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"6e8a0df8-57eb-43d4-a3f4-3ece64b9f7f6\")) {                    Plotly.newPlot(                        \"6e8a0df8-57eb-43d4-a3f4-3ece64b9f7f6\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=count\\u003cbr\\u003egender=%{x}\\u003cbr\\u003eCount (#)=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"count\",\"marker\":{\"color\":\"darkgreen\",\"pattern\":{\"shape\":\"\"}},\"name\":\"count\",\"offsetgroup\":\"count\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"texttemplate\":\"%{y}\",\"x\":[\"Male\",\"Female\"],\"xaxis\":\"x\",\"y\":[3555,3488],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"gender\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Count (#)\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\",\"showlegend\":false,\"autosize\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('6e8a0df8-57eb-43d4-a3f4-3ece64b9f7f6');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"alignmentgroup":"True","hovertemplate":"variable=count<br>gender=%{x}<br>Count (#)=%{y}<extra></extra>","legendgroup":"count","marker":{"color":"darkgreen","pattern":{"shape":""}},"name":"count","offsetgroup":"count","orientation":"v","showlegend":true,"textposition":"auto","texttemplate":"%{y}","type":"bar","x":["Male","Female"],"xaxis":"x","y":[3555,3488],"yaxis":"y"}],"layout":{"autosize":false,"barmode":"relative","legend":{"title":{"text":"variable"},"tracegroupgap":0},"margin":{"t":60},"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"xaxis":{"anchor":"y","domain":[0,1],"title":{"text":"gender"}},"yaxis":{"anchor":"x","domain":[0,1],"title":{"text":"Count (#)"}}}},"text/html":["<div>                            <div id=\"9f3785f3-d903-4e5a-8665-6b7c38aa913b\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"9f3785f3-d903-4e5a-8665-6b7c38aa913b\")) {                    Plotly.newPlot(                        \"9f3785f3-d903-4e5a-8665-6b7c38aa913b\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=count\\u003cbr\\u003egender=%{x}\\u003cbr\\u003eCount (#)=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"count\",\"marker\":{\"color\":\"darkgreen\",\"pattern\":{\"shape\":\"\"}},\"name\":\"count\",\"offsetgroup\":\"count\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"texttemplate\":\"%{y}\",\"x\":[\"Male\",\"Female\"],\"xaxis\":\"x\",\"y\":[3555,3488],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"gender\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Count (#)\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\",\"showlegend\":false,\"autosize\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('9f3785f3-d903-4e5a-8665-6b7c38aa913b');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Partner\n","No     3641\n","Yes    3402\n","Name: count, dtype: int64\n","\n"]},{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"alignmentgroup":"True","hovertemplate":"variable=count<br>Partner=%{x}<br>Count (#)=%{y}<extra></extra>","legendgroup":"count","marker":{"color":"darkgreen","pattern":{"shape":""}},"name":"count","offsetgroup":"count","orientation":"v","showlegend":true,"textposition":"auto","texttemplate":"%{y}","type":"bar","x":["No","Yes"],"xaxis":"x","y":[3641,3402],"yaxis":"y"}],"layout":{"autosize":false,"barmode":"relative","legend":{"title":{"text":"variable"},"tracegroupgap":0},"margin":{"t":60},"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"xaxis":{"anchor":"y","domain":[0,1],"title":{"text":"Partner"}},"yaxis":{"anchor":"x","domain":[0,1],"title":{"text":"Count (#)"}}}},"text/html":["<div>                            <div id=\"e31459bd-e18c-476f-b9d1-e4ec3741f0e6\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"e31459bd-e18c-476f-b9d1-e4ec3741f0e6\")) {                    Plotly.newPlot(                        \"e31459bd-e18c-476f-b9d1-e4ec3741f0e6\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=count\\u003cbr\\u003ePartner=%{x}\\u003cbr\\u003eCount (#)=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"count\",\"marker\":{\"color\":\"darkgreen\",\"pattern\":{\"shape\":\"\"}},\"name\":\"count\",\"offsetgroup\":\"count\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"texttemplate\":\"%{y}\",\"x\":[\"No\",\"Yes\"],\"xaxis\":\"x\",\"y\":[3641,3402],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Partner\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Count (#)\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\",\"showlegend\":false,\"autosize\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('e31459bd-e18c-476f-b9d1-e4ec3741f0e6');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"alignmentgroup":"True","hovertemplate":"variable=count<br>Partner=%{x}<br>Count (#)=%{y}<extra></extra>","legendgroup":"count","marker":{"color":"darkgreen","pattern":{"shape":""}},"name":"count","offsetgroup":"count","orientation":"v","showlegend":true,"textposition":"auto","texttemplate":"%{y}","type":"bar","x":["No","Yes"],"xaxis":"x","y":[3641,3402],"yaxis":"y"}],"layout":{"autosize":false,"barmode":"relative","legend":{"title":{"text":"variable"},"tracegroupgap":0},"margin":{"t":60},"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"xaxis":{"anchor":"y","domain":[0,1],"title":{"text":"Partner"}},"yaxis":{"anchor":"x","domain":[0,1],"title":{"text":"Count (#)"}}}},"text/html":["<div>                            <div id=\"20eb3889-9e51-4227-bb69-7e6780e3f3a2\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"20eb3889-9e51-4227-bb69-7e6780e3f3a2\")) {                    Plotly.newPlot(                        \"20eb3889-9e51-4227-bb69-7e6780e3f3a2\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=count\\u003cbr\\u003ePartner=%{x}\\u003cbr\\u003eCount (#)=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"count\",\"marker\":{\"color\":\"darkgreen\",\"pattern\":{\"shape\":\"\"}},\"name\":\"count\",\"offsetgroup\":\"count\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"texttemplate\":\"%{y}\",\"x\":[\"No\",\"Yes\"],\"xaxis\":\"x\",\"y\":[3641,3402],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Partner\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Count (#)\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\",\"showlegend\":false,\"autosize\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('20eb3889-9e51-4227-bb69-7e6780e3f3a2');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Dependents\n","No     4933\n","Yes    2110\n","Name: count, dtype: int64\n","\n"]},{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"alignmentgroup":"True","hovertemplate":"variable=count<br>Dependents=%{x}<br>Count (#)=%{y}<extra></extra>","legendgroup":"count","marker":{"color":"darkgreen","pattern":{"shape":""}},"name":"count","offsetgroup":"count","orientation":"v","showlegend":true,"textposition":"auto","texttemplate":"%{y}","type":"bar","x":["No","Yes"],"xaxis":"x","y":[4933,2110],"yaxis":"y"}],"layout":{"autosize":false,"barmode":"relative","legend":{"title":{"text":"variable"},"tracegroupgap":0},"margin":{"t":60},"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"xaxis":{"anchor":"y","domain":[0,1],"title":{"text":"Dependents"}},"yaxis":{"anchor":"x","domain":[0,1],"title":{"text":"Count (#)"}}}},"text/html":["<div>                            <div id=\"7b61eb6f-15de-4301-8793-3ec888f5149e\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"7b61eb6f-15de-4301-8793-3ec888f5149e\")) {                    Plotly.newPlot(                        \"7b61eb6f-15de-4301-8793-3ec888f5149e\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=count\\u003cbr\\u003eDependents=%{x}\\u003cbr\\u003eCount (#)=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"count\",\"marker\":{\"color\":\"darkgreen\",\"pattern\":{\"shape\":\"\"}},\"name\":\"count\",\"offsetgroup\":\"count\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"texttemplate\":\"%{y}\",\"x\":[\"No\",\"Yes\"],\"xaxis\":\"x\",\"y\":[4933,2110],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Dependents\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Count (#)\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\",\"showlegend\":false,\"autosize\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('7b61eb6f-15de-4301-8793-3ec888f5149e');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"alignmentgroup":"True","hovertemplate":"variable=count<br>Dependents=%{x}<br>Count (#)=%{y}<extra></extra>","legendgroup":"count","marker":{"color":"darkgreen","pattern":{"shape":""}},"name":"count","offsetgroup":"count","orientation":"v","showlegend":true,"textposition":"auto","texttemplate":"%{y}","type":"bar","x":["No","Yes"],"xaxis":"x","y":[4933,2110],"yaxis":"y"}],"layout":{"autosize":false,"barmode":"relative","legend":{"title":{"text":"variable"},"tracegroupgap":0},"margin":{"t":60},"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"xaxis":{"anchor":"y","domain":[0,1],"title":{"text":"Dependents"}},"yaxis":{"anchor":"x","domain":[0,1],"title":{"text":"Count (#)"}}}},"text/html":["<div>                            <div id=\"b02d7ac8-8515-4c79-8dd0-a286eeafa347\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"b02d7ac8-8515-4c79-8dd0-a286eeafa347\")) {                    Plotly.newPlot(                        \"b02d7ac8-8515-4c79-8dd0-a286eeafa347\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=count\\u003cbr\\u003eDependents=%{x}\\u003cbr\\u003eCount (#)=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"count\",\"marker\":{\"color\":\"darkgreen\",\"pattern\":{\"shape\":\"\"}},\"name\":\"count\",\"offsetgroup\":\"count\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"texttemplate\":\"%{y}\",\"x\":[\"No\",\"Yes\"],\"xaxis\":\"x\",\"y\":[4933,2110],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Dependents\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Count (#)\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\",\"showlegend\":false,\"autosize\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('b02d7ac8-8515-4c79-8dd0-a286eeafa347');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"}],"source":["for i in categorical:\n","    #print(i, ':')\n","    print(personal_data[i].value_counts())\n","    fig = px.bar(personal_data[i].value_counts(), labels={'value':'Count (#)'}, text_auto=True).update_layout(showlegend=False,autosize=False).update_traces(marker_color='darkgreen')\n","    print()\n","    fig.show()\n","    fig.show()"]},{"cell_type":"code","execution_count":587,"metadata":{"execution":{"iopub.execute_input":"2023-12-01T00:02:41.352220Z","iopub.status.busy":"2023-12-01T00:02:41.351772Z","iopub.status.idle":"2023-12-01T00:02:41.368592Z","shell.execute_reply":"2023-12-01T00:02:41.367394Z","shell.execute_reply.started":"2023-12-01T00:02:41.352187Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>SeniorCitizen</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>7043.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>0.162147</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.368612</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       SeniorCitizen\n","count    7043.000000\n","mean        0.162147\n","std         0.368612\n","min         0.000000\n","25%         0.000000\n","50%         0.000000\n","75%         0.000000\n","max         1.000000"]},"execution_count":587,"metadata":{},"output_type":"execute_result"}],"source":["personal_data.describe()"]},{"cell_type":"code","execution_count":588,"metadata":{"execution":{"iopub.execute_input":"2023-12-01T00:02:43.186760Z","iopub.status.busy":"2023-12-01T00:02:43.186382Z","iopub.status.idle":"2023-12-01T00:02:43.198043Z","shell.execute_reply":"2023-12-01T00:02:43.197002Z","shell.execute_reply.started":"2023-12-01T00:02:43.186729Z"},"trusted":true},"outputs":[{"data":{"text/plain":["customerID       0\n","gender           0\n","SeniorCitizen    0\n","Partner          0\n","Dependents       0\n","dtype: int64"]},"execution_count":588,"metadata":{},"output_type":"execute_result"}],"source":["personal_data.isna().sum()"]},{"cell_type":"code","execution_count":589,"metadata":{"execution":{"iopub.execute_input":"2023-12-01T00:02:44.472779Z","iopub.status.busy":"2023-12-01T00:02:44.472365Z","iopub.status.idle":"2023-12-01T00:02:44.491860Z","shell.execute_reply":"2023-12-01T00:02:44.490748Z","shell.execute_reply.started":"2023-12-01T00:02:44.472746Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>customerID</th>\n","      <th>gender</th>\n","      <th>SeniorCitizen</th>\n","      <th>Partner</th>\n","      <th>Dependents</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>7590-VHVEG</td>\n","      <td>Female</td>\n","      <td>0</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5575-GNVDE</td>\n","      <td>Male</td>\n","      <td>0</td>\n","      <td>No</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3668-QPYBK</td>\n","      <td>Male</td>\n","      <td>0</td>\n","      <td>No</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>7795-CFOCW</td>\n","      <td>Male</td>\n","      <td>0</td>\n","      <td>No</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>9237-HQITU</td>\n","      <td>Female</td>\n","      <td>0</td>\n","      <td>No</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7038</th>\n","      <td>6840-RESVB</td>\n","      <td>Male</td>\n","      <td>0</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>7039</th>\n","      <td>2234-XADUH</td>\n","      <td>Female</td>\n","      <td>0</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>7040</th>\n","      <td>4801-JZAZL</td>\n","      <td>Female</td>\n","      <td>0</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>7041</th>\n","      <td>8361-LTMKD</td>\n","      <td>Male</td>\n","      <td>1</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>7042</th>\n","      <td>3186-AJIEK</td>\n","      <td>Male</td>\n","      <td>0</td>\n","      <td>No</td>\n","      <td>No</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7043 rows × 5 columns</p>\n","</div>"],"text/plain":["      customerID  gender  SeniorCitizen Partner Dependents\n","0     7590-VHVEG  Female              0     Yes         No\n","1     5575-GNVDE    Male              0      No         No\n","2     3668-QPYBK    Male              0      No         No\n","3     7795-CFOCW    Male              0      No         No\n","4     9237-HQITU  Female              0      No         No\n","...          ...     ...            ...     ...        ...\n","7038  6840-RESVB    Male              0     Yes        Yes\n","7039  2234-XADUH  Female              0     Yes        Yes\n","7040  4801-JZAZL  Female              0     Yes        Yes\n","7041  8361-LTMKD    Male              1     Yes         No\n","7042  3186-AJIEK    Male              0      No         No\n","\n","[7043 rows x 5 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["display(personal_data)"]},{"cell_type":"markdown","metadata":{},"source":["`Preprocessing`"]},{"cell_type":"code","execution_count":590,"metadata":{"execution":{"iopub.execute_input":"2023-12-01T00:02:46.035248Z","iopub.status.busy":"2023-12-01T00:02:46.034611Z","iopub.status.idle":"2023-12-01T00:02:46.042734Z","shell.execute_reply":"2023-12-01T00:02:46.041244Z","shell.execute_reply.started":"2023-12-01T00:02:46.035215Z"},"trusted":true},"outputs":[],"source":["personal_df = personal_data.copy()\n","# column renaming\n","personal_df = personal_df.rename(columns={\"customerID\": \"customer_id\", \"SeniorCitizen\": \"senior_citizen\",\n","                                          \"Partner\": \"partner\", \"Dependents\": \"dependents\"})"]},{"cell_type":"code","execution_count":591,"metadata":{"execution":{"iopub.execute_input":"2023-12-01T00:05:45.267943Z","iopub.status.busy":"2023-12-01T00:05:45.267552Z","iopub.status.idle":"2023-12-01T00:05:45.330839Z","shell.execute_reply":"2023-12-01T00:05:45.329844Z","shell.execute_reply.started":"2023-12-01T00:05:45.267913Z"},"trusted":true},"outputs":[{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"domain":{"x":[0,1],"y":[0,1]},"hovertemplate":"label=%{label}<extra></extra>","labels":["Male","Female"],"legendgroup":"","name":"","showlegend":true,"type":"pie"}],"layout":{"autosize":false,"legend":{"orientation":"h","tracegroupgap":0,"x":1,"xanchor":"right","y":1.02,"yanchor":"bottom"},"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"title":{"text":"Gender Mix"}}},"text/html":["<div>                            <div id=\"32ebbc30-2922-4411-aceb-c337e3ba760b\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"32ebbc30-2922-4411-aceb-c337e3ba760b\")) {                    Plotly.newPlot(                        \"32ebbc30-2922-4411-aceb-c337e3ba760b\",                        [{\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"hovertemplate\":\"label=%{label}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"labels\":[\"Male\",\"Female\"],\"legendgroup\":\"\",\"name\":\"\",\"showlegend\":true,\"type\":\"pie\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"legend\":{\"tracegroupgap\":0,\"orientation\":\"h\",\"yanchor\":\"bottom\",\"y\":1.02,\"xanchor\":\"right\",\"x\":1},\"title\":{\"text\":\"Gender Mix\"},\"autosize\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('32ebbc30-2922-4411-aceb-c337e3ba760b');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"}],"source":["personal_grp = personal_df.groupby(['partner','gender']).size().reset_index().groupby('gender')[[0]].max()\n","\n","labels = ['Male', 'Female']\n","fig = px.pie(personal_grp, names=labels, title='Gender Mix')\n","fig.update_layout(legend=dict(\n","    orientation=\"h\",\n","    yanchor=\"bottom\",\n","    y=1.02,\n","    xanchor=\"right\",\n","    x=1\n","),autosize=False)\n","\n","fig.show()"]},{"cell_type":"code","execution_count":592,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 1000x600 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["crosstab = pd.crosstab(personal_df['partner'], personal_df['gender'])\n","fig, ax = plt.subplots(figsize=(10, 6))\n","g = sns.heatmap(crosstab, cbar=False, cmap=\"Blues\", linewidths=0.3, annot=True, fmt='d', ax=ax)\n","\n","g.set_ylabel('Has Partner')\n","g.set_xlabel('Gender')\n","\n","ax.text(x=0.5, y=1.1, s='Personal Data', fontsize=16, weight='bold', ha='center', va='bottom', transform=ax.transAxes)\n","ax.text(x=0.5, y=1.05, s='Heatmap Analysis', fontsize=8, alpha=0.75, ha='center', va='bottom', transform=ax.transAxes)\n","\n","plt.yticks(rotation=0)\n","plt.xticks(rotation=0)\n","plt.show()"]},{"cell_type":"code","execution_count":593,"metadata":{"execution":{"iopub.execute_input":"2023-12-01T00:04:37.551263Z","iopub.status.busy":"2023-12-01T00:04:37.550905Z","iopub.status.idle":"2023-12-01T00:04:37.573245Z","shell.execute_reply":"2023-12-01T00:04:37.572312Z","shell.execute_reply.started":"2023-12-01T00:04:37.551237Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>customer_id</th>\n","      <th>gender</th>\n","      <th>senior_citizen</th>\n","      <th>partner</th>\n","      <th>dependents</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>7590-VHVEG</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5575-GNVDE</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3668-QPYBK</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>7795-CFOCW</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>9237-HQITU</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7038</th>\n","      <td>6840-RESVB</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7039</th>\n","      <td>2234-XADUH</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7040</th>\n","      <td>4801-JZAZL</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7041</th>\n","      <td>8361-LTMKD</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7042</th>\n","      <td>3186-AJIEK</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7043 rows × 5 columns</p>\n","</div>"],"text/plain":["     customer_id  gender  senior_citizen  partner  dependents\n","0     7590-VHVEG       0               0        1           0\n","1     5575-GNVDE       1               0        0           0\n","2     3668-QPYBK       1               0        0           0\n","3     7795-CFOCW       1               0        0           0\n","4     9237-HQITU       0               0        0           0\n","...          ...     ...             ...      ...         ...\n","7038  6840-RESVB       1               0        1           1\n","7039  2234-XADUH       0               0        1           1\n","7040  4801-JZAZL       0               0        1           1\n","7041  8361-LTMKD       1               1        1           0\n","7042  3186-AJIEK       1               0        0           0\n","\n","[7043 rows x 5 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["# label encoding\n","personal_df = MultiColumnLabelEncoder(columns = ['gender','senior_citizen', 'partner', 'dependents']).fit_transform(personal_df)\n","\n","display(personal_df)"]},{"cell_type":"markdown","metadata":{},"source":["`Summary`\n","\n","Similar instances of column revisions for personal_data but we preemtively being feature encoding through a function that handles multiple column encoding. These values then become inputs the eventual models can handle and make sense of."]},{"cell_type":"markdown","metadata":{},"source":["-----------"]},{"cell_type":"markdown","metadata":{},"source":["# Internet data"]},{"cell_type":"code","execution_count":594,"metadata":{"execution":{"iopub.execute_input":"2023-12-01T00:05:49.500662Z","iopub.status.busy":"2023-12-01T00:05:49.500284Z","iopub.status.idle":"2023-12-01T00:05:49.516111Z","shell.execute_reply":"2023-12-01T00:05:49.514940Z","shell.execute_reply.started":"2023-12-01T00:05:49.500630Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 5517 entries, 0 to 5516\n","Data columns (total 8 columns):\n"," #   Column            Non-Null Count  Dtype \n","---  ------            --------------  ----- \n"," 0   customerID        5517 non-null   object\n"," 1   InternetService   5517 non-null   object\n"," 2   OnlineSecurity    5517 non-null   object\n"," 3   OnlineBackup      5517 non-null   object\n"," 4   DeviceProtection  5517 non-null   object\n"," 5   TechSupport       5517 non-null   object\n"," 6   StreamingTV       5517 non-null   object\n"," 7   StreamingMovies   5517 non-null   object\n","dtypes: object(8)\n","memory usage: 344.9+ KB\n"]}],"source":["internet_data.info()"]},{"cell_type":"code","execution_count":595,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Categorical Features: ['InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies']\n","Non-Categorical Features: ['customerID']\n","Discrete Features: []\n","Continuous Features: []\n"]}],"source":["categorical, non_categorical, discrete, continuous = classify_features(internet_data)\n","\n","print(\"Categorical Features:\", categorical)\n","print(\"Non-Categorical Features:\", non_categorical)\n","print(\"Discrete Features:\", discrete)\n","print(\"Continuous Features:\", continuous)"]},{"cell_type":"code","execution_count":596,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["InternetService\n","Fiber optic    3096\n","DSL            2421\n","Name: count, dtype: int64\n","\n"]},{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"alignmentgroup":"True","hovertemplate":"variable=count<br>InternetService=%{x}<br>Count (#)=%{y}<extra></extra>","legendgroup":"count","marker":{"color":"darkblue","pattern":{"shape":""}},"name":"count","offsetgroup":"count","orientation":"v","showlegend":true,"textposition":"auto","texttemplate":"%{y}","type":"bar","x":["Fiber optic","DSL"],"xaxis":"x","y":[3096,2421],"yaxis":"y"}],"layout":{"autosize":false,"barmode":"relative","legend":{"title":{"text":"variable"},"tracegroupgap":0},"margin":{"t":60},"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"xaxis":{"anchor":"y","domain":[0,1],"title":{"text":"InternetService"}},"yaxis":{"anchor":"x","domain":[0,1],"title":{"text":"Count (#)"}}}},"text/html":["<div>                            <div id=\"5aafcd57-c61d-44f7-92b5-97a0ff1cca27\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"5aafcd57-c61d-44f7-92b5-97a0ff1cca27\")) {                    Plotly.newPlot(                        \"5aafcd57-c61d-44f7-92b5-97a0ff1cca27\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=count\\u003cbr\\u003eInternetService=%{x}\\u003cbr\\u003eCount (#)=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"count\",\"marker\":{\"color\":\"darkblue\",\"pattern\":{\"shape\":\"\"}},\"name\":\"count\",\"offsetgroup\":\"count\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"texttemplate\":\"%{y}\",\"x\":[\"Fiber optic\",\"DSL\"],\"xaxis\":\"x\",\"y\":[3096,2421],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"InternetService\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Count (#)\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\",\"showlegend\":false,\"autosize\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('5aafcd57-c61d-44f7-92b5-97a0ff1cca27');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"alignmentgroup":"True","hovertemplate":"variable=count<br>InternetService=%{x}<br>Count (#)=%{y}<extra></extra>","legendgroup":"count","marker":{"color":"darkblue","pattern":{"shape":""}},"name":"count","offsetgroup":"count","orientation":"v","showlegend":true,"textposition":"auto","texttemplate":"%{y}","type":"bar","x":["Fiber optic","DSL"],"xaxis":"x","y":[3096,2421],"yaxis":"y"}],"layout":{"autosize":false,"barmode":"relative","legend":{"title":{"text":"variable"},"tracegroupgap":0},"margin":{"t":60},"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"xaxis":{"anchor":"y","domain":[0,1],"title":{"text":"InternetService"}},"yaxis":{"anchor":"x","domain":[0,1],"title":{"text":"Count (#)"}}}},"text/html":["<div>                            <div id=\"172d9b18-5ece-4d83-8131-6622edaea13c\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"172d9b18-5ece-4d83-8131-6622edaea13c\")) {                    Plotly.newPlot(                        \"172d9b18-5ece-4d83-8131-6622edaea13c\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=count\\u003cbr\\u003eInternetService=%{x}\\u003cbr\\u003eCount (#)=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"count\",\"marker\":{\"color\":\"darkblue\",\"pattern\":{\"shape\":\"\"}},\"name\":\"count\",\"offsetgroup\":\"count\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"texttemplate\":\"%{y}\",\"x\":[\"Fiber optic\",\"DSL\"],\"xaxis\":\"x\",\"y\":[3096,2421],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"InternetService\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Count (#)\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\",\"showlegend\":false,\"autosize\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('172d9b18-5ece-4d83-8131-6622edaea13c');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["OnlineSecurity\n","No     3498\n","Yes    2019\n","Name: count, dtype: int64\n","\n"]},{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"alignmentgroup":"True","hovertemplate":"variable=count<br>OnlineSecurity=%{x}<br>Count (#)=%{y}<extra></extra>","legendgroup":"count","marker":{"color":"darkblue","pattern":{"shape":""}},"name":"count","offsetgroup":"count","orientation":"v","showlegend":true,"textposition":"auto","texttemplate":"%{y}","type":"bar","x":["No","Yes"],"xaxis":"x","y":[3498,2019],"yaxis":"y"}],"layout":{"autosize":false,"barmode":"relative","legend":{"title":{"text":"variable"},"tracegroupgap":0},"margin":{"t":60},"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"xaxis":{"anchor":"y","domain":[0,1],"title":{"text":"OnlineSecurity"}},"yaxis":{"anchor":"x","domain":[0,1],"title":{"text":"Count (#)"}}}},"text/html":["<div>                            <div id=\"9db90697-8f5d-4829-9235-4b3f8a7f1a12\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"9db90697-8f5d-4829-9235-4b3f8a7f1a12\")) {                    Plotly.newPlot(                        \"9db90697-8f5d-4829-9235-4b3f8a7f1a12\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=count\\u003cbr\\u003eOnlineSecurity=%{x}\\u003cbr\\u003eCount (#)=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"count\",\"marker\":{\"color\":\"darkblue\",\"pattern\":{\"shape\":\"\"}},\"name\":\"count\",\"offsetgroup\":\"count\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"texttemplate\":\"%{y}\",\"x\":[\"No\",\"Yes\"],\"xaxis\":\"x\",\"y\":[3498,2019],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"OnlineSecurity\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Count (#)\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\",\"showlegend\":false,\"autosize\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('9db90697-8f5d-4829-9235-4b3f8a7f1a12');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"alignmentgroup":"True","hovertemplate":"variable=count<br>OnlineSecurity=%{x}<br>Count (#)=%{y}<extra></extra>","legendgroup":"count","marker":{"color":"darkblue","pattern":{"shape":""}},"name":"count","offsetgroup":"count","orientation":"v","showlegend":true,"textposition":"auto","texttemplate":"%{y}","type":"bar","x":["No","Yes"],"xaxis":"x","y":[3498,2019],"yaxis":"y"}],"layout":{"autosize":false,"barmode":"relative","legend":{"title":{"text":"variable"},"tracegroupgap":0},"margin":{"t":60},"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"xaxis":{"anchor":"y","domain":[0,1],"title":{"text":"OnlineSecurity"}},"yaxis":{"anchor":"x","domain":[0,1],"title":{"text":"Count (#)"}}}},"text/html":["<div>                            <div id=\"77706108-3071-4e58-a7b9-e81e7b9c687c\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"77706108-3071-4e58-a7b9-e81e7b9c687c\")) {                    Plotly.newPlot(                        \"77706108-3071-4e58-a7b9-e81e7b9c687c\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=count\\u003cbr\\u003eOnlineSecurity=%{x}\\u003cbr\\u003eCount (#)=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"count\",\"marker\":{\"color\":\"darkblue\",\"pattern\":{\"shape\":\"\"}},\"name\":\"count\",\"offsetgroup\":\"count\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"texttemplate\":\"%{y}\",\"x\":[\"No\",\"Yes\"],\"xaxis\":\"x\",\"y\":[3498,2019],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"OnlineSecurity\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Count (#)\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\",\"showlegend\":false,\"autosize\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('77706108-3071-4e58-a7b9-e81e7b9c687c');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["OnlineBackup\n","No     3088\n","Yes    2429\n","Name: count, dtype: int64\n","\n"]},{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"alignmentgroup":"True","hovertemplate":"variable=count<br>OnlineBackup=%{x}<br>Count (#)=%{y}<extra></extra>","legendgroup":"count","marker":{"color":"darkblue","pattern":{"shape":""}},"name":"count","offsetgroup":"count","orientation":"v","showlegend":true,"textposition":"auto","texttemplate":"%{y}","type":"bar","x":["No","Yes"],"xaxis":"x","y":[3088,2429],"yaxis":"y"}],"layout":{"autosize":false,"barmode":"relative","legend":{"title":{"text":"variable"},"tracegroupgap":0},"margin":{"t":60},"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"xaxis":{"anchor":"y","domain":[0,1],"title":{"text":"OnlineBackup"}},"yaxis":{"anchor":"x","domain":[0,1],"title":{"text":"Count (#)"}}}},"text/html":["<div>                            <div id=\"6e70952f-9b4a-4306-9037-09b8e2f47f71\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"6e70952f-9b4a-4306-9037-09b8e2f47f71\")) {                    Plotly.newPlot(                        \"6e70952f-9b4a-4306-9037-09b8e2f47f71\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=count\\u003cbr\\u003eOnlineBackup=%{x}\\u003cbr\\u003eCount (#)=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"count\",\"marker\":{\"color\":\"darkblue\",\"pattern\":{\"shape\":\"\"}},\"name\":\"count\",\"offsetgroup\":\"count\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"texttemplate\":\"%{y}\",\"x\":[\"No\",\"Yes\"],\"xaxis\":\"x\",\"y\":[3088,2429],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"OnlineBackup\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Count (#)\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\",\"showlegend\":false,\"autosize\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('6e70952f-9b4a-4306-9037-09b8e2f47f71');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"alignmentgroup":"True","hovertemplate":"variable=count<br>OnlineBackup=%{x}<br>Count (#)=%{y}<extra></extra>","legendgroup":"count","marker":{"color":"darkblue","pattern":{"shape":""}},"name":"count","offsetgroup":"count","orientation":"v","showlegend":true,"textposition":"auto","texttemplate":"%{y}","type":"bar","x":["No","Yes"],"xaxis":"x","y":[3088,2429],"yaxis":"y"}],"layout":{"autosize":false,"barmode":"relative","legend":{"title":{"text":"variable"},"tracegroupgap":0},"margin":{"t":60},"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"xaxis":{"anchor":"y","domain":[0,1],"title":{"text":"OnlineBackup"}},"yaxis":{"anchor":"x","domain":[0,1],"title":{"text":"Count (#)"}}}},"text/html":["<div>                            <div id=\"e9b3f474-f29d-4ba4-9e6c-f0e1cce56cb0\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"e9b3f474-f29d-4ba4-9e6c-f0e1cce56cb0\")) {                    Plotly.newPlot(                        \"e9b3f474-f29d-4ba4-9e6c-f0e1cce56cb0\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=count\\u003cbr\\u003eOnlineBackup=%{x}\\u003cbr\\u003eCount (#)=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"count\",\"marker\":{\"color\":\"darkblue\",\"pattern\":{\"shape\":\"\"}},\"name\":\"count\",\"offsetgroup\":\"count\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"texttemplate\":\"%{y}\",\"x\":[\"No\",\"Yes\"],\"xaxis\":\"x\",\"y\":[3088,2429],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"OnlineBackup\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Count (#)\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\",\"showlegend\":false,\"autosize\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('e9b3f474-f29d-4ba4-9e6c-f0e1cce56cb0');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["DeviceProtection\n","No     3095\n","Yes    2422\n","Name: count, dtype: int64\n","\n"]},{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"alignmentgroup":"True","hovertemplate":"variable=count<br>DeviceProtection=%{x}<br>Count (#)=%{y}<extra></extra>","legendgroup":"count","marker":{"color":"darkblue","pattern":{"shape":""}},"name":"count","offsetgroup":"count","orientation":"v","showlegend":true,"textposition":"auto","texttemplate":"%{y}","type":"bar","x":["No","Yes"],"xaxis":"x","y":[3095,2422],"yaxis":"y"}],"layout":{"autosize":false,"barmode":"relative","legend":{"title":{"text":"variable"},"tracegroupgap":0},"margin":{"t":60},"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"xaxis":{"anchor":"y","domain":[0,1],"title":{"text":"DeviceProtection"}},"yaxis":{"anchor":"x","domain":[0,1],"title":{"text":"Count (#)"}}}},"text/html":["<div>                            <div id=\"ee6b2b4e-6a1a-411b-a9af-16df73f2616f\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"ee6b2b4e-6a1a-411b-a9af-16df73f2616f\")) {                    Plotly.newPlot(                        \"ee6b2b4e-6a1a-411b-a9af-16df73f2616f\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=count\\u003cbr\\u003eDeviceProtection=%{x}\\u003cbr\\u003eCount (#)=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"count\",\"marker\":{\"color\":\"darkblue\",\"pattern\":{\"shape\":\"\"}},\"name\":\"count\",\"offsetgroup\":\"count\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"texttemplate\":\"%{y}\",\"x\":[\"No\",\"Yes\"],\"xaxis\":\"x\",\"y\":[3095,2422],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"DeviceProtection\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Count (#)\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\",\"showlegend\":false,\"autosize\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('ee6b2b4e-6a1a-411b-a9af-16df73f2616f');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"alignmentgroup":"True","hovertemplate":"variable=count<br>DeviceProtection=%{x}<br>Count (#)=%{y}<extra></extra>","legendgroup":"count","marker":{"color":"darkblue","pattern":{"shape":""}},"name":"count","offsetgroup":"count","orientation":"v","showlegend":true,"textposition":"auto","texttemplate":"%{y}","type":"bar","x":["No","Yes"],"xaxis":"x","y":[3095,2422],"yaxis":"y"}],"layout":{"autosize":false,"barmode":"relative","legend":{"title":{"text":"variable"},"tracegroupgap":0},"margin":{"t":60},"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"xaxis":{"anchor":"y","domain":[0,1],"title":{"text":"DeviceProtection"}},"yaxis":{"anchor":"x","domain":[0,1],"title":{"text":"Count (#)"}}}},"text/html":["<div>                            <div id=\"92bdbe07-783e-4acf-a990-6f71183a57dc\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"92bdbe07-783e-4acf-a990-6f71183a57dc\")) {                    Plotly.newPlot(                        \"92bdbe07-783e-4acf-a990-6f71183a57dc\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=count\\u003cbr\\u003eDeviceProtection=%{x}\\u003cbr\\u003eCount (#)=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"count\",\"marker\":{\"color\":\"darkblue\",\"pattern\":{\"shape\":\"\"}},\"name\":\"count\",\"offsetgroup\":\"count\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"texttemplate\":\"%{y}\",\"x\":[\"No\",\"Yes\"],\"xaxis\":\"x\",\"y\":[3095,2422],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"DeviceProtection\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Count (#)\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\",\"showlegend\":false,\"autosize\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('92bdbe07-783e-4acf-a990-6f71183a57dc');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["TechSupport\n","No     3473\n","Yes    2044\n","Name: count, dtype: int64\n","\n"]},{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"alignmentgroup":"True","hovertemplate":"variable=count<br>TechSupport=%{x}<br>Count (#)=%{y}<extra></extra>","legendgroup":"count","marker":{"color":"darkblue","pattern":{"shape":""}},"name":"count","offsetgroup":"count","orientation":"v","showlegend":true,"textposition":"auto","texttemplate":"%{y}","type":"bar","x":["No","Yes"],"xaxis":"x","y":[3473,2044],"yaxis":"y"}],"layout":{"autosize":false,"barmode":"relative","legend":{"title":{"text":"variable"},"tracegroupgap":0},"margin":{"t":60},"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"xaxis":{"anchor":"y","domain":[0,1],"title":{"text":"TechSupport"}},"yaxis":{"anchor":"x","domain":[0,1],"title":{"text":"Count (#)"}}}},"text/html":["<div>                            <div id=\"9623f765-c49f-458f-bbf2-046278113e58\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"9623f765-c49f-458f-bbf2-046278113e58\")) {                    Plotly.newPlot(                        \"9623f765-c49f-458f-bbf2-046278113e58\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=count\\u003cbr\\u003eTechSupport=%{x}\\u003cbr\\u003eCount (#)=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"count\",\"marker\":{\"color\":\"darkblue\",\"pattern\":{\"shape\":\"\"}},\"name\":\"count\",\"offsetgroup\":\"count\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"texttemplate\":\"%{y}\",\"x\":[\"No\",\"Yes\"],\"xaxis\":\"x\",\"y\":[3473,2044],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"TechSupport\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Count (#)\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\",\"showlegend\":false,\"autosize\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('9623f765-c49f-458f-bbf2-046278113e58');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"alignmentgroup":"True","hovertemplate":"variable=count<br>TechSupport=%{x}<br>Count (#)=%{y}<extra></extra>","legendgroup":"count","marker":{"color":"darkblue","pattern":{"shape":""}},"name":"count","offsetgroup":"count","orientation":"v","showlegend":true,"textposition":"auto","texttemplate":"%{y}","type":"bar","x":["No","Yes"],"xaxis":"x","y":[3473,2044],"yaxis":"y"}],"layout":{"autosize":false,"barmode":"relative","legend":{"title":{"text":"variable"},"tracegroupgap":0},"margin":{"t":60},"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"xaxis":{"anchor":"y","domain":[0,1],"title":{"text":"TechSupport"}},"yaxis":{"anchor":"x","domain":[0,1],"title":{"text":"Count (#)"}}}},"text/html":["<div>                            <div id=\"c4dcfb44-f316-4383-b34c-80a07a7c1bc0\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"c4dcfb44-f316-4383-b34c-80a07a7c1bc0\")) {                    Plotly.newPlot(                        \"c4dcfb44-f316-4383-b34c-80a07a7c1bc0\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=count\\u003cbr\\u003eTechSupport=%{x}\\u003cbr\\u003eCount (#)=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"count\",\"marker\":{\"color\":\"darkblue\",\"pattern\":{\"shape\":\"\"}},\"name\":\"count\",\"offsetgroup\":\"count\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"texttemplate\":\"%{y}\",\"x\":[\"No\",\"Yes\"],\"xaxis\":\"x\",\"y\":[3473,2044],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"TechSupport\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Count (#)\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\",\"showlegend\":false,\"autosize\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('c4dcfb44-f316-4383-b34c-80a07a7c1bc0');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["StreamingTV\n","No     2810\n","Yes    2707\n","Name: count, dtype: int64\n","\n"]},{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"alignmentgroup":"True","hovertemplate":"variable=count<br>StreamingTV=%{x}<br>Count (#)=%{y}<extra></extra>","legendgroup":"count","marker":{"color":"darkblue","pattern":{"shape":""}},"name":"count","offsetgroup":"count","orientation":"v","showlegend":true,"textposition":"auto","texttemplate":"%{y}","type":"bar","x":["No","Yes"],"xaxis":"x","y":[2810,2707],"yaxis":"y"}],"layout":{"autosize":false,"barmode":"relative","legend":{"title":{"text":"variable"},"tracegroupgap":0},"margin":{"t":60},"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"xaxis":{"anchor":"y","domain":[0,1],"title":{"text":"StreamingTV"}},"yaxis":{"anchor":"x","domain":[0,1],"title":{"text":"Count (#)"}}}},"text/html":["<div>                            <div id=\"be872240-1529-4b3b-81c9-a2ed3725d334\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"be872240-1529-4b3b-81c9-a2ed3725d334\")) {                    Plotly.newPlot(                        \"be872240-1529-4b3b-81c9-a2ed3725d334\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=count\\u003cbr\\u003eStreamingTV=%{x}\\u003cbr\\u003eCount (#)=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"count\",\"marker\":{\"color\":\"darkblue\",\"pattern\":{\"shape\":\"\"}},\"name\":\"count\",\"offsetgroup\":\"count\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"texttemplate\":\"%{y}\",\"x\":[\"No\",\"Yes\"],\"xaxis\":\"x\",\"y\":[2810,2707],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"StreamingTV\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Count (#)\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\",\"showlegend\":false,\"autosize\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('be872240-1529-4b3b-81c9-a2ed3725d334');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"alignmentgroup":"True","hovertemplate":"variable=count<br>StreamingTV=%{x}<br>Count (#)=%{y}<extra></extra>","legendgroup":"count","marker":{"color":"darkblue","pattern":{"shape":""}},"name":"count","offsetgroup":"count","orientation":"v","showlegend":true,"textposition":"auto","texttemplate":"%{y}","type":"bar","x":["No","Yes"],"xaxis":"x","y":[2810,2707],"yaxis":"y"}],"layout":{"autosize":false,"barmode":"relative","legend":{"title":{"text":"variable"},"tracegroupgap":0},"margin":{"t":60},"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"xaxis":{"anchor":"y","domain":[0,1],"title":{"text":"StreamingTV"}},"yaxis":{"anchor":"x","domain":[0,1],"title":{"text":"Count (#)"}}}},"text/html":["<div>                            <div id=\"71bc9b9b-f6cb-4073-a57c-b7af74946466\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"71bc9b9b-f6cb-4073-a57c-b7af74946466\")) {                    Plotly.newPlot(                        \"71bc9b9b-f6cb-4073-a57c-b7af74946466\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=count\\u003cbr\\u003eStreamingTV=%{x}\\u003cbr\\u003eCount (#)=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"count\",\"marker\":{\"color\":\"darkblue\",\"pattern\":{\"shape\":\"\"}},\"name\":\"count\",\"offsetgroup\":\"count\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"texttemplate\":\"%{y}\",\"x\":[\"No\",\"Yes\"],\"xaxis\":\"x\",\"y\":[2810,2707],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"StreamingTV\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Count (#)\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\",\"showlegend\":false,\"autosize\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('71bc9b9b-f6cb-4073-a57c-b7af74946466');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["StreamingMovies\n","No     2785\n","Yes    2732\n","Name: count, dtype: int64\n","\n"]},{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"alignmentgroup":"True","hovertemplate":"variable=count<br>StreamingMovies=%{x}<br>Count (#)=%{y}<extra></extra>","legendgroup":"count","marker":{"color":"darkblue","pattern":{"shape":""}},"name":"count","offsetgroup":"count","orientation":"v","showlegend":true,"textposition":"auto","texttemplate":"%{y}","type":"bar","x":["No","Yes"],"xaxis":"x","y":[2785,2732],"yaxis":"y"}],"layout":{"autosize":false,"barmode":"relative","legend":{"title":{"text":"variable"},"tracegroupgap":0},"margin":{"t":60},"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"xaxis":{"anchor":"y","domain":[0,1],"title":{"text":"StreamingMovies"}},"yaxis":{"anchor":"x","domain":[0,1],"title":{"text":"Count (#)"}}}},"text/html":["<div>                            <div id=\"fea50dc9-3544-4f94-bc52-81519f5d7df2\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"fea50dc9-3544-4f94-bc52-81519f5d7df2\")) {                    Plotly.newPlot(                        \"fea50dc9-3544-4f94-bc52-81519f5d7df2\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=count\\u003cbr\\u003eStreamingMovies=%{x}\\u003cbr\\u003eCount (#)=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"count\",\"marker\":{\"color\":\"darkblue\",\"pattern\":{\"shape\":\"\"}},\"name\":\"count\",\"offsetgroup\":\"count\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"texttemplate\":\"%{y}\",\"x\":[\"No\",\"Yes\"],\"xaxis\":\"x\",\"y\":[2785,2732],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"StreamingMovies\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Count (#)\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\",\"showlegend\":false,\"autosize\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('fea50dc9-3544-4f94-bc52-81519f5d7df2');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"alignmentgroup":"True","hovertemplate":"variable=count<br>StreamingMovies=%{x}<br>Count (#)=%{y}<extra></extra>","legendgroup":"count","marker":{"color":"darkblue","pattern":{"shape":""}},"name":"count","offsetgroup":"count","orientation":"v","showlegend":true,"textposition":"auto","texttemplate":"%{y}","type":"bar","x":["No","Yes"],"xaxis":"x","y":[2785,2732],"yaxis":"y"}],"layout":{"autosize":false,"barmode":"relative","legend":{"title":{"text":"variable"},"tracegroupgap":0},"margin":{"t":60},"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"xaxis":{"anchor":"y","domain":[0,1],"title":{"text":"StreamingMovies"}},"yaxis":{"anchor":"x","domain":[0,1],"title":{"text":"Count (#)"}}}},"text/html":["<div>                            <div id=\"4c2bbfdc-3583-4f82-b1df-cfe234f8c5b7\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"4c2bbfdc-3583-4f82-b1df-cfe234f8c5b7\")) {                    Plotly.newPlot(                        \"4c2bbfdc-3583-4f82-b1df-cfe234f8c5b7\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=count\\u003cbr\\u003eStreamingMovies=%{x}\\u003cbr\\u003eCount (#)=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"count\",\"marker\":{\"color\":\"darkblue\",\"pattern\":{\"shape\":\"\"}},\"name\":\"count\",\"offsetgroup\":\"count\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"texttemplate\":\"%{y}\",\"x\":[\"No\",\"Yes\"],\"xaxis\":\"x\",\"y\":[2785,2732],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"StreamingMovies\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Count (#)\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\",\"showlegend\":false,\"autosize\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('4c2bbfdc-3583-4f82-b1df-cfe234f8c5b7');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"}],"source":["for i in categorical:\n","    #print(i, ':')\n","    print(internet_data[i].value_counts())\n","    fig = px.bar(internet_data[i].value_counts(), labels={'value':'Count (#)'}, text_auto=True).update_layout(showlegend=False,autosize=False).update_traces(marker_color='darkblue')\n","    print()\n","    fig.show()\n","    fig.show()"]},{"cell_type":"code","execution_count":597,"metadata":{"execution":{"iopub.execute_input":"2023-12-01T00:05:51.309934Z","iopub.status.busy":"2023-12-01T00:05:51.308826Z","iopub.status.idle":"2023-12-01T00:05:51.348867Z","shell.execute_reply":"2023-12-01T00:05:51.347729Z","shell.execute_reply.started":"2023-12-01T00:05:51.309882Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>customerID</th>\n","      <th>InternetService</th>\n","      <th>OnlineSecurity</th>\n","      <th>OnlineBackup</th>\n","      <th>DeviceProtection</th>\n","      <th>TechSupport</th>\n","      <th>StreamingTV</th>\n","      <th>StreamingMovies</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>5517</td>\n","      <td>5517</td>\n","      <td>5517</td>\n","      <td>5517</td>\n","      <td>5517</td>\n","      <td>5517</td>\n","      <td>5517</td>\n","      <td>5517</td>\n","    </tr>\n","    <tr>\n","      <th>unique</th>\n","      <td>5517</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>top</th>\n","      <td>7590-VHVEG</td>\n","      <td>Fiber optic</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>freq</th>\n","      <td>1</td>\n","      <td>3096</td>\n","      <td>3498</td>\n","      <td>3088</td>\n","      <td>3095</td>\n","      <td>3473</td>\n","      <td>2810</td>\n","      <td>2785</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        customerID InternetService OnlineSecurity OnlineBackup  \\\n","count         5517            5517           5517         5517   \n","unique        5517               2              2            2   \n","top     7590-VHVEG     Fiber optic             No           No   \n","freq             1            3096           3498         3088   \n","\n","       DeviceProtection TechSupport StreamingTV StreamingMovies  \n","count              5517        5517        5517            5517  \n","unique                2           2           2               2  \n","top                  No          No          No              No  \n","freq               3095        3473        2810            2785  "]},"execution_count":597,"metadata":{},"output_type":"execute_result"}],"source":["internet_data.describe()"]},{"cell_type":"code","execution_count":598,"metadata":{"execution":{"iopub.execute_input":"2023-12-01T00:05:52.393204Z","iopub.status.busy":"2023-12-01T00:05:52.392734Z","iopub.status.idle":"2023-12-01T00:05:52.408559Z","shell.execute_reply":"2023-12-01T00:05:52.407412Z","shell.execute_reply.started":"2023-12-01T00:05:52.393168Z"},"trusted":true},"outputs":[{"data":{"text/plain":["customerID          0\n","InternetService     0\n","OnlineSecurity      0\n","OnlineBackup        0\n","DeviceProtection    0\n","TechSupport         0\n","StreamingTV         0\n","StreamingMovies     0\n","dtype: int64"]},"execution_count":598,"metadata":{},"output_type":"execute_result"}],"source":["internet_data.isna().sum()"]},{"cell_type":"code","execution_count":599,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>customerID</th>\n","      <th>InternetService</th>\n","      <th>OnlineSecurity</th>\n","      <th>OnlineBackup</th>\n","      <th>DeviceProtection</th>\n","      <th>TechSupport</th>\n","      <th>StreamingTV</th>\n","      <th>StreamingMovies</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>7590-VHVEG</td>\n","      <td>DSL</td>\n","      <td>No</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5575-GNVDE</td>\n","      <td>DSL</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3668-QPYBK</td>\n","      <td>DSL</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>7795-CFOCW</td>\n","      <td>DSL</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>9237-HQITU</td>\n","      <td>Fiber optic</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>5512</th>\n","      <td>6840-RESVB</td>\n","      <td>DSL</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>5513</th>\n","      <td>2234-XADUH</td>\n","      <td>Fiber optic</td>\n","      <td>No</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>5514</th>\n","      <td>4801-JZAZL</td>\n","      <td>DSL</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>5515</th>\n","      <td>8361-LTMKD</td>\n","      <td>Fiber optic</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>5516</th>\n","      <td>3186-AJIEK</td>\n","      <td>Fiber optic</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5517 rows × 8 columns</p>\n","</div>"],"text/plain":["      customerID InternetService OnlineSecurity OnlineBackup DeviceProtection  \\\n","0     7590-VHVEG             DSL             No          Yes               No   \n","1     5575-GNVDE             DSL            Yes           No              Yes   \n","2     3668-QPYBK             DSL            Yes          Yes               No   \n","3     7795-CFOCW             DSL            Yes           No              Yes   \n","4     9237-HQITU     Fiber optic             No           No               No   \n","...          ...             ...            ...          ...              ...   \n","5512  6840-RESVB             DSL            Yes           No              Yes   \n","5513  2234-XADUH     Fiber optic             No          Yes              Yes   \n","5514  4801-JZAZL             DSL            Yes           No               No   \n","5515  8361-LTMKD     Fiber optic             No           No               No   \n","5516  3186-AJIEK     Fiber optic            Yes           No              Yes   \n","\n","     TechSupport StreamingTV StreamingMovies  \n","0             No          No              No  \n","1             No          No              No  \n","2             No          No              No  \n","3            Yes          No              No  \n","4             No          No              No  \n","...          ...         ...             ...  \n","5512         Yes         Yes             Yes  \n","5513          No         Yes             Yes  \n","5514          No          No              No  \n","5515          No          No              No  \n","5516         Yes         Yes             Yes  \n","\n","[5517 rows x 8 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["display(internet_data)"]},{"cell_type":"markdown","metadata":{},"source":["`Preprocessing`"]},{"cell_type":"code","execution_count":600,"metadata":{"execution":{"iopub.execute_input":"2023-12-01T00:07:35.879986Z","iopub.status.busy":"2023-12-01T00:07:35.879598Z","iopub.status.idle":"2023-12-01T00:07:35.899097Z","shell.execute_reply":"2023-12-01T00:07:35.898124Z","shell.execute_reply.started":"2023-12-01T00:07:35.879954Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>customer_id</th>\n","      <th>internet_service</th>\n","      <th>online_security</th>\n","      <th>online_backup</th>\n","      <th>device_protection</th>\n","      <th>tech_support</th>\n","      <th>streaming_tv</th>\n","      <th>streaming_movies</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>7590-VHVEG</td>\n","      <td>DSL</td>\n","      <td>No</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5575-GNVDE</td>\n","      <td>DSL</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3668-QPYBK</td>\n","      <td>DSL</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>7795-CFOCW</td>\n","      <td>DSL</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>9237-HQITU</td>\n","      <td>Fiber optic</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>5512</th>\n","      <td>6840-RESVB</td>\n","      <td>DSL</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>5513</th>\n","      <td>2234-XADUH</td>\n","      <td>Fiber optic</td>\n","      <td>No</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>5514</th>\n","      <td>4801-JZAZL</td>\n","      <td>DSL</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>5515</th>\n","      <td>8361-LTMKD</td>\n","      <td>Fiber optic</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>5516</th>\n","      <td>3186-AJIEK</td>\n","      <td>Fiber optic</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5517 rows × 8 columns</p>\n","</div>"],"text/plain":["     customer_id internet_service online_security online_backup  \\\n","0     7590-VHVEG              DSL              No           Yes   \n","1     5575-GNVDE              DSL             Yes            No   \n","2     3668-QPYBK              DSL             Yes           Yes   \n","3     7795-CFOCW              DSL             Yes            No   \n","4     9237-HQITU      Fiber optic              No            No   \n","...          ...              ...             ...           ...   \n","5512  6840-RESVB              DSL             Yes            No   \n","5513  2234-XADUH      Fiber optic              No           Yes   \n","5514  4801-JZAZL              DSL             Yes            No   \n","5515  8361-LTMKD      Fiber optic              No            No   \n","5516  3186-AJIEK      Fiber optic             Yes            No   \n","\n","     device_protection tech_support streaming_tv streaming_movies  \n","0                   No           No           No               No  \n","1                  Yes           No           No               No  \n","2                   No           No           No               No  \n","3                  Yes          Yes           No               No  \n","4                   No           No           No               No  \n","...                ...          ...          ...              ...  \n","5512               Yes          Yes          Yes              Yes  \n","5513               Yes           No          Yes              Yes  \n","5514                No           No           No               No  \n","5515                No           No           No               No  \n","5516               Yes          Yes          Yes              Yes  \n","\n","[5517 rows x 8 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["internet_df = internet_data.copy()\n","# column renaming\n","internet_df = internet_df.rename(columns={\"customerID\": \"customer_id\", \"InternetService\": \"internet_service\", \"OnlineSecurity\": \"online_security\", \"OnlineBackup\": \"online_backup\",\n","                                         \"DeviceProtection\": \"device_protection\", \"TechSupport\": \"tech_support\", \"StreamingTV\": \"streaming_tv\",\n","                                         \"StreamingMovies\": \"streaming_movies\"})\n","\n","display(internet_df)"]},{"cell_type":"code","execution_count":601,"metadata":{"execution":{"iopub.execute_input":"2023-12-01T00:07:37.945942Z","iopub.status.busy":"2023-12-01T00:07:37.945531Z","iopub.status.idle":"2023-12-01T00:07:38.030203Z","shell.execute_reply":"2023-12-01T00:07:38.029209Z","shell.execute_reply.started":"2023-12-01T00:07:37.945894Z"},"trusted":true},"outputs":[{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"alignmentgroup":"True","hovertemplate":"variable=0<br>internet_service=%{x}<br>value=%{y}<extra></extra>","legendgroup":"0","marker":{"color":"#636efa","pattern":{"shape":""}},"name":"0","offsetgroup":"0","orientation":"v","showlegend":true,"textposition":"auto","texttemplate":"%{y}","type":"bar","x":["DSL","Fiber optic"],"xaxis":"x","y":[1241,2257],"yaxis":"y"}],"layout":{"autosize":false,"barmode":"relative","legend":{"title":{"text":"variable"},"tracegroupgap":0},"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"title":{"text":"Customer Internet Service Type"},"xaxis":{"anchor":"y","domain":[0,1],"title":{"text":"internet_service"}},"yaxis":{"anchor":"x","domain":[0,1],"title":{"text":"value"}}}},"text/html":["<div>                            <div id=\"749c03ff-bacc-4b36-95cc-92a6f5eb4646\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"749c03ff-bacc-4b36-95cc-92a6f5eb4646\")) {                    Plotly.newPlot(                        \"749c03ff-bacc-4b36-95cc-92a6f5eb4646\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=0\\u003cbr\\u003einternet_service=%{x}\\u003cbr\\u003evalue=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"0\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"0\",\"offsetgroup\":\"0\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"texttemplate\":\"%{y}\",\"x\":[\"DSL\",\"Fiber optic\"],\"xaxis\":\"x\",\"y\":[1241,2257],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"internet_service\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"value\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Customer Internet Service Type\"},\"barmode\":\"relative\",\"showlegend\":false,\"autosize\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('749c03ff-bacc-4b36-95cc-92a6f5eb4646');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"}],"source":["internet_grp = internet_df.groupby(['online_security','internet_service']).size().reset_index().groupby('internet_service')[[0]].max()\n","\n","fig = px.bar(internet_grp, title=\"Customer Internet Service Type\",text_auto = True)\n","fig.update_layout(showlegend=False, autosize=False)\n","fig.show()"]},{"cell_type":"code","execution_count":602,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 1000x600 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["crosstab = pd.crosstab(internet_df['online_security'], internet_df['internet_service'])\n","fig, ax = plt.subplots(figsize=(10, 6))\n","g = sns.heatmap(crosstab, cbar=False, cmap=\"Grays\", linewidths=0.0029, annot=True, fmt='d', linecolor='lightgray', ax=ax)\n","\n","g.set_ylabel('Selected Online Security')\n","g.set_xlabel('Service Type')\n","\n","ax.text(x=0.5, y=1.1, s='Internet Data', fontsize=16, weight='bold', ha='center', va='bottom', transform=ax.transAxes)\n","ax.text(x=0.5, y=1.05, s='Heatmap Analysis', fontsize=8, alpha=0.75, ha='center', va='bottom', transform=ax.transAxes)\n","\n","plt.yticks(rotation=0)\n","plt.xticks(rotation=0)\n","plt.show()"]},{"cell_type":"code","execution_count":603,"metadata":{"execution":{"iopub.execute_input":"2023-12-01T00:08:00.452624Z","iopub.status.busy":"2023-12-01T00:08:00.452241Z","iopub.status.idle":"2023-12-01T00:08:00.485532Z","shell.execute_reply":"2023-12-01T00:08:00.484493Z","shell.execute_reply.started":"2023-12-01T00:08:00.452593Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>customer_id</th>\n","      <th>internet_service</th>\n","      <th>online_security</th>\n","      <th>online_backup</th>\n","      <th>device_protection</th>\n","      <th>tech_support</th>\n","      <th>streaming_tv</th>\n","      <th>streaming_movies</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>7590-VHVEG</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5575-GNVDE</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3668-QPYBK</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>7795-CFOCW</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>9237-HQITU</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>5512</th>\n","      <td>6840-RESVB</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5513</th>\n","      <td>2234-XADUH</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5514</th>\n","      <td>4801-JZAZL</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5515</th>\n","      <td>8361-LTMKD</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5516</th>\n","      <td>3186-AJIEK</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5517 rows × 8 columns</p>\n","</div>"],"text/plain":["     customer_id  internet_service  online_security  online_backup  \\\n","0     7590-VHVEG                 0                0              1   \n","1     5575-GNVDE                 0                1              0   \n","2     3668-QPYBK                 0                1              1   \n","3     7795-CFOCW                 0                1              0   \n","4     9237-HQITU                 1                0              0   \n","...          ...               ...              ...            ...   \n","5512  6840-RESVB                 0                1              0   \n","5513  2234-XADUH                 1                0              1   \n","5514  4801-JZAZL                 0                1              0   \n","5515  8361-LTMKD                 1                0              0   \n","5516  3186-AJIEK                 1                1              0   \n","\n","      device_protection  tech_support  streaming_tv  streaming_movies  \n","0                     0             0             0                 0  \n","1                     1             0             0                 0  \n","2                     0             0             0                 0  \n","3                     1             1             0                 0  \n","4                     0             0             0                 0  \n","...                 ...           ...           ...               ...  \n","5512                  1             1             1                 1  \n","5513                  1             0             1                 1  \n","5514                  0             0             0                 0  \n","5515                  0             0             0                 0  \n","5516                  1             1             1                 1  \n","\n","[5517 rows x 8 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["# label encoding\n","internet_df = MultiColumnLabelEncoder(columns = ['internet_service','online_security', 'online_backup', 'device_protection','tech_support', 'streaming_tv', 'streaming_movies']).fit_transform(internet_df)\n","\n","display(internet_df)"]},{"cell_type":"markdown","metadata":{},"source":["`Summary`\n","\n","Looking into our internet_data, we see a smaller number of rows and therefore have a smaller number of customer_ids (compared to all the other sets). \n","\n","We perform some renaming and label encoding to the columns. After doing so, we are making the assumption that those customer_ids that are not included in this dataset did not sign up for the internet services therefore we will also make the assumption that where we find NaNs in our final, merged set we can replace those with 'No' or 'Not subscribed'."]},{"cell_type":"markdown","metadata":{},"source":["-----------"]},{"cell_type":"markdown","metadata":{},"source":["# Phone data"]},{"cell_type":"code","execution_count":604,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T17:45:14.722976Z","iopub.status.busy":"2023-11-30T17:45:14.722603Z","iopub.status.idle":"2023-11-30T17:45:14.734147Z","shell.execute_reply":"2023-11-30T17:45:14.733169Z","shell.execute_reply.started":"2023-11-30T17:45:14.722944Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 6361 entries, 0 to 6360\n","Data columns (total 2 columns):\n"," #   Column         Non-Null Count  Dtype \n","---  ------         --------------  ----- \n"," 0   customerID     6361 non-null   object\n"," 1   MultipleLines  6361 non-null   object\n","dtypes: object(2)\n","memory usage: 99.5+ KB\n"]}],"source":["phone_data.info()"]},{"cell_type":"code","execution_count":605,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Categorical Features: ['MultipleLines']\n","Non-Categorical Features: ['customerID']\n","Discrete Features: []\n","Continuous Features: []\n"]}],"source":["categorical, non_categorical, discrete, continuous = classify_features(phone_data)\n","\n","print(\"Categorical Features:\", categorical)\n","print(\"Non-Categorical Features:\", non_categorical)\n","print(\"Discrete Features:\", discrete)\n","print(\"Continuous Features:\", continuous)"]},{"cell_type":"code","execution_count":606,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T17:45:14.736282Z","iopub.status.busy":"2023-11-30T17:45:14.735380Z","iopub.status.idle":"2023-11-30T17:45:14.754870Z","shell.execute_reply":"2023-11-30T17:45:14.754005Z","shell.execute_reply.started":"2023-11-30T17:45:14.736256Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>customerID</th>\n","      <th>MultipleLines</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>6361</td>\n","      <td>6361</td>\n","    </tr>\n","    <tr>\n","      <th>unique</th>\n","      <td>6361</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>top</th>\n","      <td>5575-GNVDE</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>freq</th>\n","      <td>1</td>\n","      <td>3390</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        customerID MultipleLines\n","count         6361          6361\n","unique        6361             2\n","top     5575-GNVDE            No\n","freq             1          3390"]},"execution_count":606,"metadata":{},"output_type":"execute_result"}],"source":["phone_data.describe()"]},{"cell_type":"code","execution_count":607,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T17:45:14.756310Z","iopub.status.busy":"2023-11-30T17:45:14.755987Z","iopub.status.idle":"2023-11-30T17:45:14.764593Z","shell.execute_reply":"2023-11-30T17:45:14.763774Z","shell.execute_reply.started":"2023-11-30T17:45:14.756278Z"},"trusted":true},"outputs":[{"data":{"text/plain":["customerID       0\n","MultipleLines    0\n","dtype: int64"]},"execution_count":607,"metadata":{},"output_type":"execute_result"}],"source":["phone_data.isna().sum()"]},{"cell_type":"code","execution_count":608,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T17:45:14.766178Z","iopub.status.busy":"2023-11-30T17:45:14.765825Z","iopub.status.idle":"2023-11-30T17:45:14.778487Z","shell.execute_reply":"2023-11-30T17:45:14.777532Z","shell.execute_reply.started":"2023-11-30T17:45:14.766147Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>customerID</th>\n","      <th>MultipleLines</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5575-GNVDE</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3668-QPYBK</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>9237-HQITU</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9305-CDSKC</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1452-KIOVK</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>6356</th>\n","      <td>2569-WGERO</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>6357</th>\n","      <td>6840-RESVB</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>6358</th>\n","      <td>2234-XADUH</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>6359</th>\n","      <td>8361-LTMKD</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>6360</th>\n","      <td>3186-AJIEK</td>\n","      <td>No</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>6361 rows × 2 columns</p>\n","</div>"],"text/plain":["      customerID MultipleLines\n","0     5575-GNVDE            No\n","1     3668-QPYBK            No\n","2     9237-HQITU            No\n","3     9305-CDSKC           Yes\n","4     1452-KIOVK           Yes\n","...          ...           ...\n","6356  2569-WGERO            No\n","6357  6840-RESVB           Yes\n","6358  2234-XADUH           Yes\n","6359  8361-LTMKD           Yes\n","6360  3186-AJIEK            No\n","\n","[6361 rows x 2 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["display(phone_data)"]},{"cell_type":"markdown","metadata":{},"source":["`Preprocessing`"]},{"cell_type":"code","execution_count":609,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T17:45:14.780406Z","iopub.status.busy":"2023-11-30T17:45:14.779800Z","iopub.status.idle":"2023-11-30T17:45:14.793297Z","shell.execute_reply":"2023-11-30T17:45:14.792451Z","shell.execute_reply.started":"2023-11-30T17:45:14.780345Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>customer_id</th>\n","      <th>multiple_lines</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5575-GNVDE</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3668-QPYBK</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>9237-HQITU</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9305-CDSKC</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1452-KIOVK</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>6356</th>\n","      <td>2569-WGERO</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>6357</th>\n","      <td>6840-RESVB</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>6358</th>\n","      <td>2234-XADUH</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>6359</th>\n","      <td>8361-LTMKD</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>6360</th>\n","      <td>3186-AJIEK</td>\n","      <td>No</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>6361 rows × 2 columns</p>\n","</div>"],"text/plain":["     customer_id multiple_lines\n","0     5575-GNVDE             No\n","1     3668-QPYBK             No\n","2     9237-HQITU             No\n","3     9305-CDSKC            Yes\n","4     1452-KIOVK            Yes\n","...          ...            ...\n","6356  2569-WGERO             No\n","6357  6840-RESVB            Yes\n","6358  2234-XADUH            Yes\n","6359  8361-LTMKD            Yes\n","6360  3186-AJIEK             No\n","\n","[6361 rows x 2 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["phone_df = phone_data.copy()\n","# column renaming\n","phone_df = phone_df.rename(columns={\"customerID\": \"customer_id\", \"MultipleLines\": \"multiple_lines\"})\n","\n","display(phone_df)"]},{"cell_type":"code","execution_count":610,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T17:45:14.794678Z","iopub.status.busy":"2023-11-30T17:45:14.794395Z","iopub.status.idle":"2023-11-30T17:45:14.811233Z","shell.execute_reply":"2023-11-30T17:45:14.810336Z","shell.execute_reply.started":"2023-11-30T17:45:14.794633Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>customer_id</th>\n","      <th>multiple_lines</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5575-GNVDE</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3668-QPYBK</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>9237-HQITU</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9305-CDSKC</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1452-KIOVK</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>6356</th>\n","      <td>2569-WGERO</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6357</th>\n","      <td>6840-RESVB</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6358</th>\n","      <td>2234-XADUH</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6359</th>\n","      <td>8361-LTMKD</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6360</th>\n","      <td>3186-AJIEK</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>6361 rows × 2 columns</p>\n","</div>"],"text/plain":["     customer_id  multiple_lines\n","0     5575-GNVDE               0\n","1     3668-QPYBK               0\n","2     9237-HQITU               0\n","3     9305-CDSKC               1\n","4     1452-KIOVK               1\n","...          ...             ...\n","6356  2569-WGERO               0\n","6357  6840-RESVB               1\n","6358  2234-XADUH               1\n","6359  8361-LTMKD               1\n","6360  3186-AJIEK               0\n","\n","[6361 rows x 2 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["# label encoding\n","phone_df.multiple_lines = encoder.fit_transform(phone_df.multiple_lines.values)\n","display(phone_df)"]},{"cell_type":"markdown","metadata":{},"source":["`Summary`\n","\n","Our last DF in question, phone_data, has a smaller subset of data and one feature we are insterested in called 'multiple_lines'. We fix the column naming convention to mirror the edits we made to the other DFs and we encode our selected feature using label encoding. "]},{"cell_type":"markdown","metadata":{},"source":["-----------"]},{"cell_type":"markdown","metadata":{},"source":["# Merging"]},{"cell_type":"code","execution_count":611,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T17:45:14.812782Z","iopub.status.busy":"2023-11-30T17:45:14.812442Z","iopub.status.idle":"2023-11-30T17:45:14.867926Z","shell.execute_reply":"2023-11-30T17:45:14.867055Z","shell.execute_reply.started":"2023-11-30T17:45:14.812756Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>customer_id</th>\n","      <th>begin_date</th>\n","      <th>contract_type</th>\n","      <th>paperless_billing</th>\n","      <th>payment_method</th>\n","      <th>monthly_charges</th>\n","      <th>total_charges</th>\n","      <th>churn_target</th>\n","      <th>gender</th>\n","      <th>senior_citizen</th>\n","      <th>partner</th>\n","      <th>dependents</th>\n","      <th>internet_service</th>\n","      <th>online_security</th>\n","      <th>online_backup</th>\n","      <th>device_protection</th>\n","      <th>tech_support</th>\n","      <th>streaming_tv</th>\n","      <th>streaming_movies</th>\n","      <th>multiple_lines</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>7590-VHVEG</td>\n","      <td>2020-01-01</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>29.85</td>\n","      <td>29.85</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5575-GNVDE</td>\n","      <td>2017-04-01</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>56.95</td>\n","      <td>1889.50</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3668-QPYBK</td>\n","      <td>2019-10-01</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>53.85</td>\n","      <td>108.15</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>7795-CFOCW</td>\n","      <td>2016-05-01</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>42.30</td>\n","      <td>1840.75</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>9237-HQITU</td>\n","      <td>2019-09-01</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>70.70</td>\n","      <td>151.65</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7027</th>\n","      <td>6840-RESVB</td>\n","      <td>2018-02-01</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>84.80</td>\n","      <td>1990.50</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>7028</th>\n","      <td>2234-XADUH</td>\n","      <td>2014-02-01</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>103.20</td>\n","      <td>7362.90</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>7029</th>\n","      <td>4801-JZAZL</td>\n","      <td>2019-03-01</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>29.60</td>\n","      <td>346.45</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>7030</th>\n","      <td>8361-LTMKD</td>\n","      <td>2019-07-01</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>74.40</td>\n","      <td>306.60</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>7031</th>\n","      <td>3186-AJIEK</td>\n","      <td>2014-08-01</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>105.65</td>\n","      <td>6844.50</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7032 rows × 20 columns</p>\n","</div>"],"text/plain":["     customer_id begin_date  contract_type  paperless_billing  payment_method  \\\n","0     7590-VHVEG 2020-01-01              0                  1               2   \n","1     5575-GNVDE 2017-04-01              1                  0               3   \n","2     3668-QPYBK 2019-10-01              0                  1               3   \n","3     7795-CFOCW 2016-05-01              1                  0               0   \n","4     9237-HQITU 2019-09-01              0                  1               2   \n","...          ...        ...            ...                ...             ...   \n","7027  6840-RESVB 2018-02-01              1                  1               3   \n","7028  2234-XADUH 2014-02-01              1                  1               1   \n","7029  4801-JZAZL 2019-03-01              0                  1               2   \n","7030  8361-LTMKD 2019-07-01              0                  1               3   \n","7031  3186-AJIEK 2014-08-01              2                  1               0   \n","\n","      monthly_charges  total_charges  churn_target  gender  senior_citizen  \\\n","0               29.85          29.85             1       0               0   \n","1               56.95        1889.50             1       1               0   \n","2               53.85         108.15             0       1               0   \n","3               42.30        1840.75             1       1               0   \n","4               70.70         151.65             0       0               0   \n","...               ...            ...           ...     ...             ...   \n","7027            84.80        1990.50             1       1               0   \n","7028           103.20        7362.90             1       0               0   \n","7029            29.60         346.45             1       0               0   \n","7030            74.40         306.60             0       1               1   \n","7031           105.65        6844.50             1       1               0   \n","\n","      partner  dependents  internet_service  online_security  online_backup  \\\n","0           1           0               0.0              0.0            1.0   \n","1           0           0               0.0              1.0            0.0   \n","2           0           0               0.0              1.0            1.0   \n","3           0           0               0.0              1.0            0.0   \n","4           0           0               1.0              0.0            0.0   \n","...       ...         ...               ...              ...            ...   \n","7027        1           1               0.0              1.0            0.0   \n","7028        1           1               1.0              0.0            1.0   \n","7029        1           1               0.0              1.0            0.0   \n","7030        1           0               1.0              0.0            0.0   \n","7031        0           0               1.0              1.0            0.0   \n","\n","      device_protection  tech_support  streaming_tv  streaming_movies  \\\n","0                   0.0           0.0           0.0               0.0   \n","1                   1.0           0.0           0.0               0.0   \n","2                   0.0           0.0           0.0               0.0   \n","3                   1.0           1.0           0.0               0.0   \n","4                   0.0           0.0           0.0               0.0   \n","...                 ...           ...           ...               ...   \n","7027                1.0           1.0           1.0               1.0   \n","7028                1.0           0.0           1.0               1.0   \n","7029                0.0           0.0           0.0               0.0   \n","7030                0.0           0.0           0.0               0.0   \n","7031                1.0           1.0           1.0               1.0   \n","\n","      multiple_lines  \n","0                NaN  \n","1                0.0  \n","2                0.0  \n","3                NaN  \n","4                0.0  \n","...              ...  \n","7027             1.0  \n","7028             1.0  \n","7029             NaN  \n","7030             1.0  \n","7031             0.0  \n","\n","[7032 rows x 20 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["# merge data based off of customer_id, main DF should be contract_df\n","# contract, personal, phone merge to start\n","# null values from phone_df will need to be monitored with options to 1) remove (if small impact), 2) replace (average,std) or, 3) keep in place\n","\n","# merged_df = contract_df.merge(personal_df,\n","#                              on='customer_id',\n","#                              ).merge(phone_df, on='customer_id', how='left')\n","\n","# display(merged_df)\n","\n","# display(merged_df.query('multiple_lines.isna()')) # attempting to find commonality for NaN values under 'multiple_lines' -- nothing in common \n","\n","data_frames = [contract_df, personal_df, internet_df, phone_df]\n","\n","merged_df = reduce(lambda  left, right: pd.merge(left, right, on=['customer_id'],\n","                                            how='left'), data_frames)\n","\n","display(merged_df) # should include most of our 'customer_id' instances"]},{"cell_type":"code","execution_count":612,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T17:45:14.869214Z","iopub.status.busy":"2023-11-30T17:45:14.868956Z","iopub.status.idle":"2023-11-30T17:45:14.874991Z","shell.execute_reply":"2023-11-30T17:45:14.874103Z","shell.execute_reply.started":"2023-11-30T17:45:14.869192Z"},"trusted":true},"outputs":[],"source":["# dropping columns that don't impact analysis \n","merged_df = merged_df.drop('customer_id', axis=1)"]},{"cell_type":"code","execution_count":613,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T17:45:14.876580Z","iopub.status.busy":"2023-11-30T17:45:14.876261Z","iopub.status.idle":"2023-11-30T17:45:14.911323Z","shell.execute_reply":"2023-11-30T17:45:14.910491Z","shell.execute_reply.started":"2023-11-30T17:45:14.876522Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>begin_date</th>\n","      <th>contract_type</th>\n","      <th>paperless_billing</th>\n","      <th>payment_method</th>\n","      <th>monthly_charges</th>\n","      <th>total_charges</th>\n","      <th>churn_target</th>\n","      <th>gender</th>\n","      <th>senior_citizen</th>\n","      <th>partner</th>\n","      <th>dependents</th>\n","      <th>internet_service</th>\n","      <th>online_security</th>\n","      <th>online_backup</th>\n","      <th>device_protection</th>\n","      <th>tech_support</th>\n","      <th>streaming_tv</th>\n","      <th>streaming_movies</th>\n","      <th>multiple_lines</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2020-01-01</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>29.85</td>\n","      <td>29.85</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2017-04-01</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>56.95</td>\n","      <td>1889.50</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2019-10-01</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>53.85</td>\n","      <td>108.15</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2016-05-01</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>42.30</td>\n","      <td>1840.75</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2019-09-01</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>70.70</td>\n","      <td>151.65</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7027</th>\n","      <td>2018-02-01</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>84.80</td>\n","      <td>1990.50</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>7028</th>\n","      <td>2014-02-01</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>103.20</td>\n","      <td>7362.90</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>7029</th>\n","      <td>2019-03-01</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>29.60</td>\n","      <td>346.45</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>7030</th>\n","      <td>2019-07-01</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>74.40</td>\n","      <td>306.60</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>7031</th>\n","      <td>2014-08-01</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>105.65</td>\n","      <td>6844.50</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7032 rows × 19 columns</p>\n","</div>"],"text/plain":["     begin_date  contract_type  paperless_billing  payment_method  \\\n","0    2020-01-01              0                  1               2   \n","1    2017-04-01              1                  0               3   \n","2    2019-10-01              0                  1               3   \n","3    2016-05-01              1                  0               0   \n","4    2019-09-01              0                  1               2   \n","...         ...            ...                ...             ...   \n","7027 2018-02-01              1                  1               3   \n","7028 2014-02-01              1                  1               1   \n","7029 2019-03-01              0                  1               2   \n","7030 2019-07-01              0                  1               3   \n","7031 2014-08-01              2                  1               0   \n","\n","      monthly_charges  total_charges  churn_target  gender  senior_citizen  \\\n","0               29.85          29.85             1       0               0   \n","1               56.95        1889.50             1       1               0   \n","2               53.85         108.15             0       1               0   \n","3               42.30        1840.75             1       1               0   \n","4               70.70         151.65             0       0               0   \n","...               ...            ...           ...     ...             ...   \n","7027            84.80        1990.50             1       1               0   \n","7028           103.20        7362.90             1       0               0   \n","7029            29.60         346.45             1       0               0   \n","7030            74.40         306.60             0       1               1   \n","7031           105.65        6844.50             1       1               0   \n","\n","      partner  dependents  internet_service  online_security  online_backup  \\\n","0           1           0               0.0              0.0            1.0   \n","1           0           0               0.0              1.0            0.0   \n","2           0           0               0.0              1.0            1.0   \n","3           0           0               0.0              1.0            0.0   \n","4           0           0               1.0              0.0            0.0   \n","...       ...         ...               ...              ...            ...   \n","7027        1           1               0.0              1.0            0.0   \n","7028        1           1               1.0              0.0            1.0   \n","7029        1           1               0.0              1.0            0.0   \n","7030        1           0               1.0              0.0            0.0   \n","7031        0           0               1.0              1.0            0.0   \n","\n","      device_protection  tech_support  streaming_tv  streaming_movies  \\\n","0                   0.0           0.0           0.0               0.0   \n","1                   1.0           0.0           0.0               0.0   \n","2                   0.0           0.0           0.0               0.0   \n","3                   1.0           1.0           0.0               0.0   \n","4                   0.0           0.0           0.0               0.0   \n","...                 ...           ...           ...               ...   \n","7027                1.0           1.0           1.0               1.0   \n","7028                1.0           0.0           1.0               1.0   \n","7029                0.0           0.0           0.0               0.0   \n","7030                0.0           0.0           0.0               0.0   \n","7031                1.0           1.0           1.0               1.0   \n","\n","      multiple_lines  \n","0                0.0  \n","1                0.0  \n","2                0.0  \n","3                0.0  \n","4                0.0  \n","...              ...  \n","7027             1.0  \n","7028             1.0  \n","7029             0.0  \n","7030             1.0  \n","7031             0.0  \n","\n","[7032 rows x 19 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["# dropping rows with NaNs under 'multiple_lines' as a test, reverting back to this and filling in if there are score issues with models\n","# lines_filter = merged_df.query('multiple_lines.isna()')\n","# merged_df.drop(merged_df[merged_df['multiple_lines'].isna()].index, inplace=True)\n","\n","# dropping rows with NaNs under 'internet_service' as a test, reverting back to this and filling in if there are score issues with models\n","# service_filter = merged_df.query('internet_service.isna()') #1520 rows with NaNs, removal might be required \n","\n","# we are making the assumption that NaN under multiple_lines == No and NaN under the internet_df means they did not sign up, so == No as well\n","merged_df = merged_df.fillna(0)\n","\n","display(merged_df)"]},{"cell_type":"code","execution_count":614,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 1300x800 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["fig, ax = plt.subplots(figsize=(13, 8))\n","g = sns.regplot(data=merged_df, x=merged_df['begin_date'].dt.year,y='total_charges', order=2,\n","                x_jitter=.05\n","                #x_estimator=np.mean\n","                )\n","\n","g.set_ylabel('Total Charges')\n","g.set_xlabel('Beginning Year of Service')\n","\n","sns.despine()\n","\n","ax.text(x=0.5, y=1.1, s='Merged Data', fontsize=16, weight='bold', ha='center', va='bottom', transform=ax.transAxes)\n","ax.text(x=0.5, y=1.05, s='Regression Analysis', fontsize=8, alpha=0.75, ha='center', va='bottom', transform=ax.transAxes)\n","\n","plt.yticks(rotation=0)\n","plt.xticks(rotation=0)\n","plt.show()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["`Summary`\n","\n","We merged all but one of our DFs in our project with our 'contract_data' being the lead DF given the substantial information included. \n","We decide to keep all the matches on the DFs which, knowingly, gives us some NaNs based off of our 'phone_data' -- we keep in our merged DF for now to see how our models react to seeing such values. \n","\n","If issues arise, we will revisit this section and run through a few options for our NaNs. This includes removing the rows or replacing them."]},{"cell_type":"markdown","metadata":{},"source":["-----------"]},{"cell_type":"markdown","metadata":{},"source":["# Target Frequency"]},{"cell_type":"code","execution_count":615,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T17:45:14.912507Z","iopub.status.busy":"2023-11-30T17:45:14.912265Z","iopub.status.idle":"2023-11-30T17:45:14.970784Z","shell.execute_reply":"2023-11-30T17:45:14.969840Z","shell.execute_reply.started":"2023-11-30T17:45:14.912486Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Checking frequency:\n","churn_target\n","1    5163\n","0    1869\n","Name: count, dtype: int64\n"]},{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"domain":{"x":[0,1],"y":[0,1]},"hovertemplate":"label=%{label}<br>count=%{value}<extra></extra>","labels":["No Churn","Churn"],"legendgroup":"","name":"","showlegend":true,"type":"pie","values":[5163,1869]}],"layout":{"autosize":false,"legend":{"orientation":"h","tracegroupgap":0,"x":1,"xanchor":"right","y":1.02,"yanchor":"bottom"},"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"title":{"text":"Class Frequency"}}},"text/html":["<div>                            <div id=\"68a476de-096d-4dbc-af01-6af2a68282a9\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"68a476de-096d-4dbc-af01-6af2a68282a9\")) {                    Plotly.newPlot(                        \"68a476de-096d-4dbc-af01-6af2a68282a9\",                        [{\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"hovertemplate\":\"label=%{label}\\u003cbr\\u003ecount=%{value}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"labels\":[\"No Churn\",\"Churn\"],\"legendgroup\":\"\",\"name\":\"\",\"showlegend\":true,\"values\":[5163,1869],\"type\":\"pie\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"legend\":{\"tracegroupgap\":0,\"orientation\":\"h\",\"yanchor\":\"bottom\",\"y\":1.02,\"xanchor\":\"right\",\"x\":1},\"title\":{\"text\":\"Class Frequency\"},\"autosize\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('68a476de-096d-4dbc-af01-6af2a68282a9');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"}],"source":["class_frequency = merged_df['churn_target'].value_counts()\n","print('Checking frequency:')\n","print(class_frequency)\n","\n","#class_frequency.plot.pie(autopct='%.2f',textprops={'fontsize':12}, colors=['cyan', 'teal']) # calls for upsampling 'rare' or churn target values (26.58%)\n","\n","labels = ['No Churn', 'Churn']\n","fig = px.pie(class_frequency, values='count', names=labels, title='Class Frequency')\n","fig.update_layout(legend=dict(\n","    orientation=\"h\",\n","    yanchor=\"bottom\",\n","    y=1.02,\n","    xanchor=\"right\",\n","    x=1\n","), autosize=False)\n","\n","fig.show()"]},{"cell_type":"markdown","metadata":{},"source":["-----------"]},{"cell_type":"markdown","metadata":{},"source":["# Model Preparation"]},{"cell_type":"markdown","metadata":{},"source":["`Fixed Parameter`"]},{"cell_type":"code","execution_count":616,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T17:45:14.972240Z","iopub.status.busy":"2023-11-30T17:45:14.971954Z","iopub.status.idle":"2023-11-30T17:45:14.976422Z","shell.execute_reply":"2023-11-30T17:45:14.975545Z","shell.execute_reply.started":"2023-11-30T17:45:14.972215Z"},"trusted":true},"outputs":[],"source":["# random_state parameter for all models\n","random_state = 12345"]},{"cell_type":"markdown","metadata":{},"source":["`CV`"]},{"cell_type":"markdown","metadata":{},"source":["Rearranging the data so as to ensure that each fold is a good representative of the whole"]},{"cell_type":"code","execution_count":617,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T17:45:14.977975Z","iopub.status.busy":"2023-11-30T17:45:14.977635Z","iopub.status.idle":"2023-11-30T17:45:14.985544Z","shell.execute_reply":"2023-11-30T17:45:14.984645Z","shell.execute_reply.started":"2023-11-30T17:45:14.977949Z"},"trusted":true},"outputs":[],"source":["cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=5, random_state=random_state)"]},{"cell_type":"markdown","metadata":{},"source":["`Feature Engineering`"]},{"cell_type":"code","execution_count":618,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T17:45:14.986987Z","iopub.status.busy":"2023-11-30T17:45:14.986721Z","iopub.status.idle":"2023-11-30T17:45:15.026035Z","shell.execute_reply":"2023-11-30T17:45:15.025164Z","shell.execute_reply.started":"2023-11-30T17:45:14.986966Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>contract_type</th>\n","      <th>paperless_billing</th>\n","      <th>payment_method</th>\n","      <th>monthly_charges</th>\n","      <th>total_charges</th>\n","      <th>churn_target</th>\n","      <th>gender</th>\n","      <th>senior_citizen</th>\n","      <th>partner</th>\n","      <th>dependents</th>\n","      <th>...</th>\n","      <th>online_security</th>\n","      <th>online_backup</th>\n","      <th>device_protection</th>\n","      <th>tech_support</th>\n","      <th>streaming_tv</th>\n","      <th>streaming_movies</th>\n","      <th>multiple_lines</th>\n","      <th>begin_year</th>\n","      <th>begin_month</th>\n","      <th>begin_dayofweek</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>29.85</td>\n","      <td>29.85</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2020</td>\n","      <td>1</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>56.95</td>\n","      <td>1889.50</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2017</td>\n","      <td>4</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>53.85</td>\n","      <td>108.15</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2019</td>\n","      <td>10</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>42.30</td>\n","      <td>1840.75</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2016</td>\n","      <td>5</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>70.70</td>\n","      <td>151.65</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2019</td>\n","      <td>9</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7027</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>84.80</td>\n","      <td>1990.50</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>2018</td>\n","      <td>2</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>7028</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>103.20</td>\n","      <td>7362.90</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>2014</td>\n","      <td>2</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>7029</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>29.60</td>\n","      <td>346.45</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2019</td>\n","      <td>3</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>7030</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>74.40</td>\n","      <td>306.60</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>2019</td>\n","      <td>7</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7031</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>105.65</td>\n","      <td>6844.50</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>2014</td>\n","      <td>8</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7032 rows × 21 columns</p>\n","</div>"],"text/plain":["      contract_type  paperless_billing  payment_method  monthly_charges  \\\n","0                 0                  1               2            29.85   \n","1                 1                  0               3            56.95   \n","2                 0                  1               3            53.85   \n","3                 1                  0               0            42.30   \n","4                 0                  1               2            70.70   \n","...             ...                ...             ...              ...   \n","7027              1                  1               3            84.80   \n","7028              1                  1               1           103.20   \n","7029              0                  1               2            29.60   \n","7030              0                  1               3            74.40   \n","7031              2                  1               0           105.65   \n","\n","      total_charges  churn_target  gender  senior_citizen  partner  \\\n","0             29.85             1       0               0        1   \n","1           1889.50             1       1               0        0   \n","2            108.15             0       1               0        0   \n","3           1840.75             1       1               0        0   \n","4            151.65             0       0               0        0   \n","...             ...           ...     ...             ...      ...   \n","7027        1990.50             1       1               0        1   \n","7028        7362.90             1       0               0        1   \n","7029         346.45             1       0               0        1   \n","7030         306.60             0       1               1        1   \n","7031        6844.50             1       1               0        0   \n","\n","      dependents  ...  online_security  online_backup  device_protection  \\\n","0              0  ...              0.0            1.0                0.0   \n","1              0  ...              1.0            0.0                1.0   \n","2              0  ...              1.0            1.0                0.0   \n","3              0  ...              1.0            0.0                1.0   \n","4              0  ...              0.0            0.0                0.0   \n","...          ...  ...              ...            ...                ...   \n","7027           1  ...              1.0            0.0                1.0   \n","7028           1  ...              0.0            1.0                1.0   \n","7029           1  ...              1.0            0.0                0.0   \n","7030           0  ...              0.0            0.0                0.0   \n","7031           0  ...              1.0            0.0                1.0   \n","\n","      tech_support  streaming_tv  streaming_movies  multiple_lines  \\\n","0              0.0           0.0               0.0             0.0   \n","1              0.0           0.0               0.0             0.0   \n","2              0.0           0.0               0.0             0.0   \n","3              1.0           0.0               0.0             0.0   \n","4              0.0           0.0               0.0             0.0   \n","...            ...           ...               ...             ...   \n","7027           1.0           1.0               1.0             1.0   \n","7028           0.0           1.0               1.0             1.0   \n","7029           0.0           0.0               0.0             0.0   \n","7030           0.0           0.0               0.0             1.0   \n","7031           1.0           1.0               1.0             0.0   \n","\n","      begin_year  begin_month  begin_dayofweek  \n","0           2020            1                2  \n","1           2017            4                5  \n","2           2019           10                1  \n","3           2016            5                6  \n","4           2019            9                6  \n","...          ...          ...              ...  \n","7027        2018            2                3  \n","7028        2014            2                5  \n","7029        2019            3                4  \n","7030        2019            7                0  \n","7031        2014            8                4  \n","\n","[7032 rows x 21 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["# extracting date features from datetime column\n","def make_features(data, col):\n","    data['begin_year'] = data[col].dt.year\n","    data['begin_month'] = data[col].dt.month\n","    # data['begin_day'] = data[col].dt.day # no impact to model outputs\n","    data['begin_dayofweek'] = data[col].dt.dayofweek\n","    \n","#     for lag in range(1, max_lag + 1):\n","#         data['lag_{}'.format(lag)] = data['PJME_MW'].shift(lag)\n","\n","#     data['rolling_mean'] = data['PJME_MW'].shift().rolling(rolling_mean_size).mean()\n","#     #data['rolling_mean'] = data['PJME_MW'].rolling(rolling_mean_size).mean()\n","\n","make_features(merged_df, 'begin_date')\n","merged_df = merged_df.drop('begin_date', axis = 1) # removing as this has been replaced by the newly created features\n","\n","display(merged_df)"]},{"cell_type":"markdown","metadata":{},"source":["`Features and Target`"]},{"cell_type":"code","execution_count":619,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T17:45:15.027635Z","iopub.status.busy":"2023-11-30T17:45:15.027289Z","iopub.status.idle":"2023-11-30T17:45:15.033636Z","shell.execute_reply":"2023-11-30T17:45:15.032692Z","shell.execute_reply.started":"2023-11-30T17:45:15.027603Z"},"trusted":true},"outputs":[],"source":["features = merged_df.drop('churn_target', axis=1)\n","target = merged_df['churn_target']"]},{"cell_type":"markdown","metadata":{},"source":["`Data Splitting`"]},{"cell_type":"code","execution_count":620,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T17:45:15.035612Z","iopub.status.busy":"2023-11-30T17:45:15.035009Z","iopub.status.idle":"2023-11-30T17:45:15.053330Z","shell.execute_reply":"2023-11-30T17:45:15.052375Z","shell.execute_reply.started":"2023-11-30T17:45:15.035580Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(4218, 20)\n","(4218,)\n","(1407, 20)\n","(1407, 20)\n"]}],"source":["# splitting the data into a training, validation and test dataset\n","features_train, features_test, target_train, target_test = train_test_split(features, target, \n","                                                                            test_size=0.2, random_state=12345, stratify=target)\n","\n","features_train, features_valid, target_train, target_valid = train_test_split(features_train, target_train, \n","                                                                          test_size=0.25, random_state=12345, stratify=target_train)\n","\n","print(features_train.shape)\n","print(target_train.shape)\n","print(features_valid.shape)\n","print(features_test.shape)"]},{"cell_type":"code","execution_count":621,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T17:45:15.054620Z","iopub.status.busy":"2023-11-30T17:45:15.054353Z","iopub.status.idle":"2023-11-30T17:45:15.061776Z","shell.execute_reply":"2023-11-30T17:45:15.060865Z","shell.execute_reply.started":"2023-11-30T17:45:15.054597Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["> Class = 0 : 1121/4218 (26.6%)\n","> Class = 1 : 3097/4218 (73.4%)\n"]}],"source":["# target_train summary\n","classes = unique(target_train)\n","total = len(target_train)\n","for c in classes:\n","    n_examples = len(target_train[target_train==c])\n","    percent = n_examples / total * 100\n","    print('> Class = %d : %d/%d (%.1f%%)' % (c, n_examples, total, percent))"]},{"cell_type":"code","execution_count":622,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T17:45:15.063304Z","iopub.status.busy":"2023-11-30T17:45:15.063022Z","iopub.status.idle":"2023-11-30T17:45:15.072464Z","shell.execute_reply":"2023-11-30T17:45:15.071457Z","shell.execute_reply.started":"2023-11-30T17:45:15.063279Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Train: 0=1121, 1=3097, \n","Valid: 0=374, 1=1033, \n","Test: 0=374, 1=1033\n"]}],"source":["# summarize by set\n","train_0, train_1 = len(target_train[target_train==0]), len(target_train[target_train==1])\n","valid_0, valid_1 = len(target_valid[target_valid==0]), len(target_valid[target_valid==1])\n","test_0, test_1 = len(target_test[target_test==0]), len(target_test[target_test==1])\n","print('Train: 0=%d, 1=%d, \\nValid: 0=%d, 1=%d, \\nTest: 0=%d, 1=%d' % (train_0, train_1, valid_0, valid_1 , test_0, test_1))"]},{"cell_type":"markdown","metadata":{},"source":["`Scaling`"]},{"cell_type":"code","execution_count":623,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T17:45:15.073894Z","iopub.status.busy":"2023-11-30T17:45:15.073571Z","iopub.status.idle":"2023-11-30T17:45:15.128923Z","shell.execute_reply":"2023-11-30T17:45:15.127933Z","shell.execute_reply.started":"2023-11-30T17:45:15.073863Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(      contract_type  paperless_billing  payment_method  monthly_charges  \\\n"," 95                0                  1               2         0.604582   \n"," 4644              1                  1               1         0.013944   \n"," 5562              1                  1               2         0.613048   \n"," 320               1                  0               0         0.639442   \n"," 303               2                  0               1         0.418825   \n"," ...             ...                ...             ...              ...   \n"," 5421              0                  1               1         0.536853   \n"," 5945              0                  1               1         0.366036   \n"," 945               0                  1               2         0.804781   \n"," 6246              1                  1               3         0.919323   \n"," 6745              0                  1               0         0.712151   \n"," \n","       total_charges  gender  senior_citizen  partner  dependents  \\\n"," 95         0.104836       0               0        0           0   \n"," 4644       0.052995       0               0        0           0   \n"," 5562       0.564964       1               0        1           0   \n"," 320        0.499801       0               1        0           0   \n"," 303        0.471979       0               0        1           1   \n"," ...             ...     ...             ...      ...         ...   \n"," 5421       0.089477       1               0        0           0   \n"," 5945       0.132322       1               0        0           0   \n"," 945        0.389680       1               1        0           0   \n"," 6246       0.875986       1               1        1           0   \n"," 6745       0.221563       1               1        1           0   \n"," \n","       internet_service  online_security  online_backup  device_protection  \\\n"," 95                 1.0              1.0            0.0                0.0   \n"," 4644               0.0              0.0            0.0                0.0   \n"," 5562               0.0              0.0            1.0                1.0   \n"," 320                0.0              1.0            1.0                0.0   \n"," 303                0.0              0.0            1.0                1.0   \n"," ...                ...              ...            ...                ...   \n"," 5421               0.0              0.0            0.0                0.0   \n"," 5945               0.0              1.0            1.0                1.0   \n"," 945                1.0              0.0            0.0                1.0   \n"," 6246               1.0              1.0            0.0                1.0   \n"," 6745               1.0              0.0            0.0                0.0   \n"," \n","       tech_support  streaming_tv  streaming_movies  multiple_lines  \\\n"," 95             0.0           0.0               0.0             1.0   \n"," 4644           0.0           0.0               0.0             0.0   \n"," 5562           0.0           1.0               1.0             1.0   \n"," 320            1.0           1.0               1.0             1.0   \n"," 303            1.0           1.0               1.0             0.0   \n"," ...            ...           ...               ...             ...   \n"," 5421           0.0           1.0               1.0             1.0   \n"," 5945           1.0           1.0               0.0             0.0   \n"," 945            0.0           1.0               1.0             1.0   \n"," 6246           1.0           1.0               1.0             1.0   \n"," 6745           0.0           1.0               1.0             0.0   \n"," \n","       begin_year  begin_month  begin_dayofweek  \n"," 95      0.714286     1.000000         0.833333  \n"," 4644    0.714286     0.181818         0.500000  \n"," 5562    0.285714     0.000000         0.500000  \n"," 320     0.285714     0.363636         0.666667  \n"," 303     0.142857     0.454545         1.000000  \n"," ...          ...          ...              ...  \n"," 5421    0.857143     0.090909         0.666667  \n"," 5945    0.714286     0.454545         0.666667  \n"," 945     0.571429     0.090909         0.333333  \n"," 6246    0.142857     0.363636         0.500000  \n"," 6745    0.714286     0.272727         1.000000  \n"," \n"," [4218 rows x 20 columns],\n","       contract_type  paperless_billing  payment_method  monthly_charges  \\\n"," 469               0                  0               2         0.375498   \n"," 4590              0                  0               3         0.378486   \n"," 5822              0                  1               0         0.722610   \n"," 5084              0                  0               3         0.021912   \n"," 2003              0                  1               3         0.685757   \n"," ...             ...                ...             ...              ...   \n"," 1386              0                  1               2         0.672809   \n"," 1597              0                  1               2         0.717131   \n"," 4111              0                  0               1         0.563247   \n"," 6510              1                  1               2         0.728088   \n"," 6387              0                  1               1         0.734064   \n"," \n","       total_charges  gender  senior_citizen  partner  dependents  \\\n"," 469        0.082565       0               0        1           1   \n"," 4590       0.109740       1               0        0           0   \n"," 5822       0.091265       0               0        0           0   \n"," 5084       0.015220       0               0        1           1   \n"," 2003       0.037226       0               0        0           1   \n"," ...             ...     ...             ...      ...         ...   \n"," 1386       0.279415       1               0        1           0   \n"," 1597       0.315776       1               0        0           0   \n"," 4111       0.340742       0               0        0           0   \n"," 6510       0.663038       1               0        1           1   \n"," 6387       0.378747       0               1        1           0   \n"," \n","       internet_service  online_security  online_backup  device_protection  \\\n"," 469                0.0              0.0            0.0                0.0   \n"," 4590               0.0              1.0            0.0                0.0   \n"," 5822               1.0              0.0            0.0                0.0   \n"," 5084               0.0              0.0            0.0                0.0   \n"," 2003               1.0              0.0            0.0                1.0   \n"," ...                ...              ...            ...                ...   \n"," 1386               1.0              0.0            1.0                1.0   \n"," 1597               1.0              0.0            0.0                0.0   \n"," 4111               1.0              0.0            1.0                0.0   \n"," 6510               1.0              0.0            1.0                0.0   \n"," 6387               1.0              0.0            1.0                0.0   \n"," \n","       tech_support  streaming_tv  streaming_movies  multiple_lines  \\\n"," 469            0.0           0.0               1.0             0.0   \n"," 4590           0.0           0.0               0.0             1.0   \n"," 5822           0.0           1.0               1.0             0.0   \n"," 5084           0.0           0.0               0.0             0.0   \n"," 2003           1.0           0.0               0.0             1.0   \n"," ...            ...           ...               ...             ...   \n"," 1386           0.0           0.0               0.0             1.0   \n"," 1597           0.0           1.0               1.0             0.0   \n"," 4111           0.0           0.0               0.0             0.0   \n"," 6510           0.0           0.0               1.0             1.0   \n"," 6387           0.0           1.0               0.0             1.0   \n"," \n","       begin_year  begin_month  begin_dayofweek  \n"," 469     0.714286     1.000000         0.833333  \n"," 4590    0.714286     0.636364         0.333333  \n"," 5822    0.857143     0.181818         0.666667  \n"," 5084    0.857143     0.545455         0.000000  \n"," 2003    0.857143     0.454545         0.833333  \n"," ...          ...          ...              ...  \n"," 1386    0.571429     0.727273         0.666667  \n"," 1597    0.571429     0.272727         0.833333  \n"," 4111    0.428571     0.818182         0.833333  \n"," 6510    0.142857     0.909091         0.833333  \n"," 6387    0.571429     0.090909         0.333333  \n"," \n"," [1407 rows x 20 columns],\n","       contract_type  paperless_billing  payment_method  monthly_charges  \\\n"," 3307              0                  0               3         0.020418   \n"," 679               0                  0               2         0.615040   \n"," 4724              2                  0               1         0.016434   \n"," 569               2                  1               1         0.009960   \n"," 2928              2                  1               0         0.057271   \n"," ...             ...                ...             ...              ...   \n"," 2991              0                  1               3         0.421813   \n"," 6725              2                  0               1         0.687251   \n"," 5068              1                  1               2         0.752490   \n"," 4212              1                  0               2         0.566733   \n"," 205               1                  1               0         0.614542   \n"," \n","       total_charges  gender  senior_citizen  partner  dependents  \\\n"," 3307       0.000167       1               0        0           0   \n"," 679        0.007056       1               0        1           1   \n"," 4724       0.159065       0               0        1           1   \n"," 569        0.125133       0               0        1           1   \n"," 2928       0.189875       1               0        1           1   \n"," ...             ...     ...             ...      ...         ...   \n"," 2991       0.131261       0               0        0           0   \n"," 6725       0.728120       0               0        1           1   \n"," 5068       0.358374       0               0        1           1   \n"," 4212       0.433167       0               0        0           0   \n"," 205        0.307641       0               0        0           0   \n"," \n","       internet_service  online_security  online_backup  device_protection  \\\n"," 3307               0.0              0.0            0.0                0.0   \n"," 679                1.0              0.0            0.0                0.0   \n"," 4724               0.0              0.0            0.0                0.0   \n"," 569                0.0              0.0            0.0                0.0   \n"," 2928               0.0              0.0            0.0                0.0   \n"," ...                ...              ...            ...                ...   \n"," 2991               0.0              1.0            0.0                1.0   \n"," 6725               0.0              1.0            1.0                1.0   \n"," 5068               1.0              0.0            0.0                1.0   \n"," 4212               1.0              0.0            1.0                0.0   \n"," 205                1.0              0.0            1.0                0.0   \n"," \n","       tech_support  streaming_tv  streaming_movies  multiple_lines  \\\n"," 3307           0.0           0.0               0.0             0.0   \n"," 679            0.0           0.0               1.0             0.0   \n"," 4724           0.0           0.0               0.0             0.0   \n"," 569            0.0           0.0               0.0             0.0   \n"," 2928           0.0           0.0               0.0             1.0   \n"," ...            ...           ...               ...             ...   \n"," 2991           0.0           0.0               0.0             1.0   \n"," 6725           1.0           1.0               1.0             0.0   \n"," 5068           0.0           1.0               1.0             0.0   \n"," 4212           0.0           0.0               0.0             0.0   \n"," 205            1.0           0.0               0.0             0.0   \n"," \n","       begin_year  begin_month  begin_dayofweek  \n"," 3307    1.000000     0.000000         0.333333  \n"," 679     0.857143     1.000000         1.000000  \n"," 4724    0.142857     0.181818         0.833333  \n"," 569     0.285714     0.090909         1.000000  \n"," 2928    0.142857     0.454545         1.000000  \n"," ...          ...          ...              ...  \n"," 2991    0.714286     0.636364         0.333333  \n"," 6725    0.142857     0.181818         0.833333  \n"," 5068    0.571429     0.000000         1.000000  \n"," 4212    0.428571     0.090909         0.000000  \n"," 205     0.571429     0.363636         0.000000  \n"," \n"," [1407 rows x 20 columns])"]},"execution_count":623,"metadata":{},"output_type":"execute_result"}],"source":["numeric = ['monthly_charges', 'total_charges', 'begin_year','begin_month', 'begin_dayofweek']\n","\n","def scaling(x_train, x_valid, x_test):\n","    scaler = MinMaxScaler()\n","    scaler.fit(x_train[numeric])\n","    x_train[numeric] = scaler.transform(x_train[numeric])\n","    x_valid[numeric] = scaler.transform(x_valid[numeric])\n","    x_test[numeric] = scaler.transform(x_test[numeric])\n","    return x_train, x_valid, x_test\n","\n","scaling(features_train, features_valid, features_test)"]},{"cell_type":"markdown","metadata":{},"source":["`Summary`\n","\n","After taking into account class imbalancing, we've split the data into Train, Validation and Test datasets where each has been scaled in order to take value magnitute into account and create good inputs for our model training."]},{"cell_type":"markdown","metadata":{},"source":["# Dummy Model"]},{"cell_type":"code","execution_count":624,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T17:45:15.130534Z","iopub.status.busy":"2023-11-30T17:45:15.130173Z","iopub.status.idle":"2023-11-30T17:45:15.139236Z","shell.execute_reply":"2023-11-30T17:45:15.138270Z","shell.execute_reply.started":"2023-11-30T17:45:15.130498Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Dummy Model Score: 0.7341862117981521\n"]}],"source":["dummy = DummyClassifier(random_state=random_state,strategy=\"most_frequent\")\n","dummy.fit(features_train, target_train)\n","DummyClassifier(strategy='most_frequent')\n","dummy.predict(features_valid)\n","print('Dummy Model Score:', dummy.score(features_valid, target_valid))"]},{"cell_type":"markdown","metadata":{},"source":["# Random Forest"]},{"cell_type":"code","execution_count":625,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T17:47:07.682082Z","iopub.status.busy":"2023-11-30T17:47:07.681288Z","iopub.status.idle":"2023-11-30T17:47:21.988070Z","shell.execute_reply":"2023-11-30T17:47:21.987028Z","shell.execute_reply.started":"2023-11-30T17:47:07.682047Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Runtime:\n","CPU times: user 998 ms, sys: 555 ms, total: 1.55 s\n","Wall time: 22.8 s\n"]}],"source":["%%time\n","forest_model = RandomForestClassifier(random_state=random_state)\n","forest_parameters = [{'max_depth': [2,6,12,18,30],\n","                     'min_samples_split': [2,6,12],\n","                     \"criterion\": ['gini', 'entropy', 'log_loss'],\n","                     \"warm_start\": [True, False],\n","                     'n_estimators': [50,100,200]}]\n","\n","forest_clf = RandomizedSearchCV(forest_model, forest_parameters, scoring='roc_auc', n_jobs=-1, cv=cv)\n","forest_clf.fit(features_train, target_train)\n","# create a variable for the best model\n","best_for = forest_clf.best_estimator_\n","for_pred = best_for.predict(features_valid)\n","print('Runtime:')"]},{"cell_type":"code","execution_count":670,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 1000x500 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["sns.set(style=\"white\", color_codes=True)\n","plt.rcParams['axes.linewidth'] = 0.1\n","\n","fig, ax = plt.subplots(figsize = (10,5))\n","disp = CalibrationDisplay.from_estimator(forest_clf, features_valid, target_valid, ax=ax)\n","plt.title('Calibration Chart - Random Forest Classifier', fontsize=10)\n","ax.set_xlabel('Mean predicted probability (Positive class: 1)', fontsize=10)\n","ax.set_ylabel('Fraction of positives (Positive class: 1)',fontsize=10)\n","\n","ax.tick_params(color='gray', labelcolor='gray')\n","for spine in ax.spines.values():\n","    spine.set_edgecolor('gray')\n","\n","\n","fig.tight_layout()\n","plt.legend(fontsize=8)\n","plt.show()"]},{"cell_type":"code","execution_count":627,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T16:51:02.675236Z","iopub.status.busy":"2023-11-30T16:51:02.674939Z","iopub.status.idle":"2023-11-30T16:51:28.806061Z","shell.execute_reply":"2023-11-30T16:51:28.805200Z","shell.execute_reply.started":"2023-11-30T16:51:02.675211Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Cross Validation Scores: [0.88701779 0.86640265 0.88940092 0.84344758 0.87862903 0.87919067\n"," 0.86424251 0.84251152 0.89613673 0.88196371 0.83515193 0.86029666\n"," 0.89203629 0.87079493 0.88859447 0.87049251 0.89919355 0.86601382\n"," 0.90471856 0.87202381 0.84351462 0.896803   0.8889977  0.8749424\n"," 0.87351671 0.90600518 0.88781682 0.88974654 0.87455213 0.83183079\n"," 0.87531861 0.85427707 0.87151498 0.89668779 0.89811348 0.8905962\n"," 0.865625   0.865553   0.87138812 0.87749942 0.87534725 0.88326613\n"," 0.85733007 0.84854551 0.87587846 0.8812212  0.88701037 0.90756048\n"," 0.8802589  0.884911  ]\n"]}],"source":["forest_scores = cross_val_score(forest_model, features_train, target_train, cv=cv, scoring='roc_auc')\n","print('Cross Validation Scores: {}'.format(forest_scores))"]},{"cell_type":"code","execution_count":628,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T16:51:28.815144Z","iopub.status.busy":"2023-11-30T16:51:28.814760Z","iopub.status.idle":"2023-11-30T16:51:28.886083Z","shell.execute_reply":"2023-11-30T16:51:28.885261Z","shell.execute_reply.started":"2023-11-30T16:51:28.815112Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Best hyperparameters: {'warm_start': True, 'n_estimators': 100, 'min_samples_split': 12, 'max_depth': 18, 'criterion': 'log_loss'}\n","\n","Best score: 0.8746264764110123\n","\n","Average Cross Validation Score: 0.8760777711552042\n","\n","ROC AUC Score - Validation Dataset: 0.898504433895357\n"]}],"source":["# summary\n","print('Best hyperparameters:',  forest_clf.best_params_)\n","print()\n","print('Best score:', forest_clf.best_score_)\n","print()\n","print('Average Cross Validation Score: {}'.format(forest_scores.mean()))\n","print()\n","print('ROC AUC Score - Validation Dataset:',  roc_auc_score(target_valid, forest_clf.predict_proba(features_valid)[:, 1]))"]},{"cell_type":"markdown","metadata":{},"source":["# ROC AUC Curve - RandomForestClassifier"]},{"cell_type":"code","execution_count":629,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T16:51:28.887485Z","iopub.status.busy":"2023-11-30T16:51:28.887134Z","iopub.status.idle":"2023-11-30T16:51:29.109214Z","shell.execute_reply":"2023-11-30T16:51:29.108341Z","shell.execute_reply.started":"2023-11-30T16:51:28.887453Z"},"trusted":true},"outputs":[{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"fillpattern":{"shape":""},"hovertemplate":"False Positive Rate=%{x}<br>True Positive Rate=%{y}<extra></extra>","legendgroup":"","line":{"color":"#636efa"},"marker":{"symbol":"circle"},"mode":"lines","name":"","orientation":"v","showlegend":false,"stackgroup":"1","type":"scatter","x":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.00267379679144385,0.00267379679144385,0.00267379679144385,0.00267379679144385,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.008021390374331552,0.008021390374331552,0.0106951871657754,0.0106951871657754,0.013368983957219251,0.013368983957219251,0.016042780748663103,0.016042780748663103,0.01871657754010695,0.01871657754010695,0.0213903743315508,0.0213903743315508,0.02406417112299465,0.02406417112299465,0.026737967914438502,0.026737967914438502,0.029411764705882353,0.029411764705882353,0.03208556149732621,0.03208556149732621,0.034759358288770054,0.034759358288770054,0.0374331550802139,0.0374331550802139,0.0427807486631016,0.0427807486631016,0.045454545454545456,0.045454545454545456,0.0481283422459893,0.0481283422459893,0.05080213903743316,0.05080213903743316,0.053475935828877004,0.053475935828877004,0.05614973262032086,0.05614973262032086,0.058823529411764705,0.058823529411764705,0.06149732620320856,0.06149732620320856,0.06417112299465241,0.06417112299465241,0.06684491978609626,0.06684491978609626,0.06951871657754011,0.06951871657754011,0.07219251336898395,0.07219251336898395,0.0748663101604278,0.0748663101604278,0.07754010695187166,0.07754010695187166,0.08288770053475936,0.08288770053475936,0.0855614973262032,0.0855614973262032,0.09090909090909091,0.09090909090909091,0.09358288770053476,0.09358288770053476,0.0962566844919786,0.0962566844919786,0.09893048128342247,0.09893048128342247,0.10160427807486631,0.10160427807486631,0.10427807486631016,0.10427807486631016,0.10695187165775401,0.10695187165775401,0.10962566844919786,0.10962566844919786,0.11229946524064172,0.11229946524064172,0.11497326203208556,0.11497326203208556,0.11764705882352941,0.11764705882352941,0.12299465240641712,0.12299465240641712,0.12566844919786097,0.12566844919786097,0.12834224598930483,0.12834224598930483,0.13101604278074866,0.13101604278074866,0.13368983957219252,0.13368983957219252,0.13636363636363635,0.13636363636363635,0.13903743315508021,0.13903743315508021,0.14171122994652408,0.14171122994652408,0.1443850267379679,0.1443850267379679,0.14705882352941177,0.14705882352941177,0.15508021390374332,0.15508021390374332,0.16042780748663102,0.16042780748663102,0.16310160427807488,0.16310160427807488,0.16844919786096257,0.16844919786096257,0.1711229946524064,0.1711229946524064,0.17379679144385027,0.17379679144385027,0.17647058823529413,0.17647058823529413,0.17914438502673796,0.17914438502673796,0.18449197860962566,0.18449197860962566,0.18716577540106952,0.18716577540106952,0.18983957219251338,0.18983957219251338,0.1925133689839572,0.1925133689839572,0.19518716577540107,0.19518716577540107,0.20053475935828877,0.20053475935828877,0.20588235294117646,0.20588235294117646,0.20855614973262032,0.20855614973262032,0.21122994652406418,0.21122994652406418,0.21657754010695188,0.21657754010695188,0.2192513368983957,0.2192513368983957,0.22459893048128343,0.22459893048128343,0.22727272727272727,0.22727272727272727,0.22994652406417113,0.22994652406417113,0.232620320855615,0.232620320855615,0.23529411764705882,0.23529411764705882,0.23796791443850268,0.23796791443850268,0.24064171122994651,0.24064171122994651,0.24331550802139038,0.24331550802139038,0.24598930481283424,0.24598930481283424,0.24866310160427807,0.24866310160427807,0.25133689839572193,0.25133689839572193,0.2540106951871658,0.2540106951871658,0.25668449197860965,0.25668449197860965,0.25935828877005346,0.25935828877005346,0.2647058823529412,0.2647058823529412,0.27807486631016043,0.27807486631016043,0.2807486631016043,0.2807486631016043,0.28342245989304815,0.28342245989304815,0.28609625668449196,0.28609625668449196,0.2914438502673797,0.2914438502673797,0.29411764705882354,0.29411764705882354,0.2994652406417112,0.2994652406417112,0.30213903743315507,0.30213903743315507,0.3048128342245989,0.3048128342245989,0.3074866310160428,0.3074866310160428,0.31016042780748665,0.31016042780748665,0.3155080213903743,0.3155080213903743,0.32085561497326204,0.32085561497326204,0.32620320855614976,0.32620320855614976,0.32887700534759357,0.32887700534759357,0.3315508021390374,0.3315508021390374,0.3342245989304813,0.3342245989304813,0.339572192513369,0.339572192513369,0.3422459893048128,0.3422459893048128,0.3449197860962567,0.3449197860962567,0.34759358288770054,0.34759358288770054,0.35294117647058826,0.35294117647058826,0.35561497326203206,0.35561497326203206,0.3582887700534759,0.3582887700534759,0.36363636363636365,0.36363636363636365,0.3770053475935829,0.3770053475935829,0.3850267379679144,0.3850267379679144,0.3877005347593583,0.3877005347593583,0.39037433155080214,0.39037433155080214,0.393048128342246,0.393048128342246,0.3983957219251337,0.3983957219251337,0.40106951871657753,0.40106951871657753,0.4037433155080214,0.4037433155080214,0.40641711229946526,0.40641711229946526,0.4090909090909091,0.4090909090909091,0.41711229946524064,0.41711229946524064,0.4304812834224599,0.4304812834224599,0.45454545454545453,0.45454545454545453,0.4572192513368984,0.4572192513368984,0.4625668449197861,0.4625668449197861,0.48128342245989303,0.48128342245989303,0.4839572192513369,0.4839572192513369,0.4893048128342246,0.4893048128342246,0.4919786096256685,0.4919786096256685,0.4946524064171123,0.4946524064171123,0.49732620320855614,0.49732620320855614,0.5320855614973262,0.5320855614973262,0.5347593582887701,0.5347593582887701,0.5374331550802139,0.5374331550802139,0.5427807486631016,0.5427807486631016,0.5454545454545454,0.5454545454545454,0.5481283422459893,0.5481283422459893,0.5588235294117647,0.5588235294117647,0.5962566844919787,0.5962566844919787,0.6042780748663101,0.6042780748663101,0.6310160427807486,0.6310160427807486,0.6898395721925134,0.6898395721925134,0.7192513368983957,0.7192513368983957,0.7272727272727273,0.7272727272727273,0.7299465240641712,0.7299465240641712,0.7754010695187166,0.7754010695187166,1],"xaxis":"x","y":[0,0.01452081316553727,0.015488867376573089,0.017424975798644726,0.021297192642787996,0.02420135527589545,0.026137463697967087,0.028073572120038724,0.03581800580832527,0.03969022265246854,0.04259438528557599,0.04549854791868345,0.04743465634075508,0.049370764762826716,0.05517909002904162,0.057115198451113264,0.061955469506292354,0.06389157792836399,0.06582768635043562,0.06776379477250725,0.08131655372700872,0.08422071636011616,0.08615682478218781,0.08615682478218781,0.08809293320425944,0.09002904162633107,0.10067763794772508,0.10067763794772508,0.10454985479186835,0.10648596321393998,0.14714424007744434,0.14714424007744434,0.1665053242981607,0.1665053242981607,0.19748305905130686,0.19748305905130686,0.2758954501452081,0.2758954501452081,0.29235237173281703,0.29235237173281703,0.33494675701839305,0.33494675701839305,0.39496611810261373,0.39496611810261373,0.41045498547918685,0.41045498547918685,0.42884801548886736,0.42884801548886736,0.43852855759922554,0.43852855759922554,0.5004840271055179,0.5004840271055179,0.5033881897386253,0.5033881897386253,0.5198451113262342,0.5198451113262342,0.5217812197483059,0.5217812197483059,0.5401742497579864,0.5401742497579864,0.5430784123910939,0.5430784123910939,0.5498547918683446,0.5498547918683446,0.5595353339787028,0.5595353339787028,0.5614714424007744,0.5614714424007744,0.57405614714424,0.57405614714424,0.5759922555663117,0.5759922555663117,0.5769603097773476,0.5769603097773476,0.5934172313649564,0.5934172313649564,0.5943852855759922,0.5943852855759922,0.5982575024201355,0.5982575024201355,0.6224588576960309,0.6224588576960309,0.6282671829622459,0.6282671829622459,0.6321393998063891,0.6321393998063891,0.6418199419167473,0.6418199419167473,0.643756050338819,0.643756050338819,0.6544046466602129,0.6544046466602129,0.6592449177153921,0.6592449177153921,0.6621490803484995,0.6621490803484995,0.6698935140367861,0.6698935140367861,0.6737657308809293,0.6737657308809293,0.6776379477250726,0.6776379477250726,0.6969990319457889,0.6969990319457889,0.6989351403678606,0.6989351403678606,0.7018393030009681,0.7018393030009681,0.718296224588577,0.718296224588577,0.7270087124878993,0.7270087124878993,0.7299128751210068,0.7299128751210068,0.7308809293320426,0.7308809293320426,0.7318489835430784,0.7318489835430784,0.739593417231365,0.739593417231365,0.7405614714424008,0.7405614714424008,0.7483059051306873,0.7483059051306873,0.7521781219748306,0.7521781219748306,0.7792836398838335,0.7792836398838335,0.7850919651500484,0.7850919651500484,0.7860600193610843,0.7860600193610843,0.78702807357212,0.78702807357212,0.7899322362052275,0.7899322362052275,0.7909002904162633,0.7909002904162633,0.7918683446272992,0.7918683446272992,0.7967086156824782,0.7967086156824782,0.7986447241045499,0.7986447241045499,0.8034849951597289,0.8034849951597289,0.8063891577928364,0.8063891577928364,0.8083252662149081,0.8083252662149081,0.8092933204259438,0.8092933204259438,0.8102613746369797,0.8102613746369797,0.8228460793804453,0.8228460793804453,0.829622458857696,0.829622458857696,0.8354307841239109,0.8354307841239109,0.8373668925459826,0.8373668925459826,0.8393030009680542,0.8393030009680542,0.8402710551790901,0.8402710551790901,0.8422071636011617,0.8422071636011617,0.8431752178121975,0.8431752178121975,0.8441432720232332,0.8441432720232332,0.8451113262342691,0.8451113262342691,0.846079380445305,0.846079380445305,0.8470474346563408,0.8470474346563408,0.850919651500484,0.850919651500484,0.8538238141335914,0.8538238141335914,0.8596321393998064,0.8596321393998064,0.8606001936108422,0.8606001936108422,0.8625363020329139,0.8625363020329139,0.8644724104549855,0.8644724104549855,0.8654404646660213,0.8654404646660213,0.8664085188770572,0.8664085188770572,0.8731848983543078,0.8731848983543078,0.8760890609874153,0.8760890609874153,0.8780251694094869,0.8780251694094869,0.8809293320425944,0.8809293320425944,0.8857696030977735,0.8857696030977735,0.8877057115198451,0.8877057115198451,0.888673765730881,0.888673765730881,0.8915779283639884,0.8915779283639884,0.8944820909970959,0.8944820909970959,0.8954501452081317,0.8954501452081317,0.8973862536302033,0.8973862536302033,0.8993223620522749,0.8993223620522749,0.9031945788964182,0.9031945788964182,0.9119070667957405,0.9119070667957405,0.9138431752178122,0.9138431752178122,0.9167473378509197,0.9167473378509197,0.9196515004840271,0.9196515004840271,0.920619554695063,0.920619554695063,0.9273959341723137,0.9273959341723137,0.9283639883833494,0.9283639883833494,0.9293320425943853,0.9293320425943853,0.9312681510164569,0.9312681510164569,0.9341723136495643,0.9341723136495643,0.9390125847047435,0.9390125847047435,0.9399806389157793,0.9399806389157793,0.9428848015488868,0.9428848015488868,0.9438528557599225,0.9438528557599225,0.9477250726040658,0.9477250726040658,0.9496611810261375,0.9496611810261375,0.952565343659245,0.952565343659245,0.9545014520813165,0.9545014520813165,0.9554695062923524,0.9554695062923524,0.9564375605033882,0.9564375605033882,0.9583736689254598,0.9583736689254598,0.9593417231364957,0.9593417231364957,0.9603097773475314,0.9603097773475314,0.9612778315585673,0.9612778315585673,0.9641819941916747,0.9641819941916747,0.9670861568247822,0.9670861568247822,0.968054211035818,0.968054211035818,0.9690222652468539,0.9690222652468539,0.9719264278799613,0.9719264278799613,0.9738625363020329,0.9738625363020329,0.9748305905130688,0.9748305905130688,0.9757986447241046,0.9757986447241046,0.9767666989351403,0.9767666989351403,0.9777347531461762,0.9777347531461762,0.9806389157792836,0.9806389157792836,0.9816069699903195,0.9816069699903195,0.9825750242013552,0.9825750242013552,0.9874152952565344,0.9874152952565344,0.9883833494675702,0.9883833494675702,0.989351403678606,0.989351403678606,0.9903194578896418,0.9903194578896418,0.9912875121006777,0.9912875121006777,0.9922555663117134,0.9922555663117134,0.9941916747337851,0.9941916747337851,0.995159728944821,0.995159728944821,0.9961277831558567,0.9961277831558567,0.9970958373668926,0.9970958373668926,0.9980638915779284,0.9980638915779284,0.9990319457889641,0.9990319457889641,1,1],"yaxis":"y"}],"layout":{"height":600,"legend":{"tracegroupgap":0},"shapes":[{"line":{"dash":"dash"},"type":"line","x0":0,"x1":1,"y0":0,"y1":1}],"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"title":{"text":"ROC Curve (AUC=0.8985)"},"width":800,"xaxis":{"anchor":"y","constrain":"domain","domain":[0,1],"title":{"text":"False Positive Rate"}},"yaxis":{"anchor":"x","domain":[0,1],"scaleanchor":"x","scaleratio":1,"title":{"text":"True Positive Rate"}}}},"text/html":["<div>                            <div id=\"c50e4567-5f46-4fb5-85d6-48aff7491ea7\" class=\"plotly-graph-div\" style=\"height:600px; width:800px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"c50e4567-5f46-4fb5-85d6-48aff7491ea7\")) {                    Plotly.newPlot(                        \"c50e4567-5f46-4fb5-85d6-48aff7491ea7\",                        [{\"fillpattern\":{\"shape\":\"\"},\"hovertemplate\":\"False Positive Rate=%{x}\\u003cbr\\u003eTrue Positive Rate=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"stackgroup\":\"1\",\"x\":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.00267379679144385,0.00267379679144385,0.00267379679144385,0.00267379679144385,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.008021390374331552,0.008021390374331552,0.0106951871657754,0.0106951871657754,0.013368983957219251,0.013368983957219251,0.016042780748663103,0.016042780748663103,0.01871657754010695,0.01871657754010695,0.0213903743315508,0.0213903743315508,0.02406417112299465,0.02406417112299465,0.026737967914438502,0.026737967914438502,0.029411764705882353,0.029411764705882353,0.03208556149732621,0.03208556149732621,0.034759358288770054,0.034759358288770054,0.0374331550802139,0.0374331550802139,0.0427807486631016,0.0427807486631016,0.045454545454545456,0.045454545454545456,0.0481283422459893,0.0481283422459893,0.05080213903743316,0.05080213903743316,0.053475935828877004,0.053475935828877004,0.05614973262032086,0.05614973262032086,0.058823529411764705,0.058823529411764705,0.06149732620320856,0.06149732620320856,0.06417112299465241,0.06417112299465241,0.06684491978609626,0.06684491978609626,0.06951871657754011,0.06951871657754011,0.07219251336898395,0.07219251336898395,0.0748663101604278,0.0748663101604278,0.07754010695187166,0.07754010695187166,0.08288770053475936,0.08288770053475936,0.0855614973262032,0.0855614973262032,0.09090909090909091,0.09090909090909091,0.09358288770053476,0.09358288770053476,0.0962566844919786,0.0962566844919786,0.09893048128342247,0.09893048128342247,0.10160427807486631,0.10160427807486631,0.10427807486631016,0.10427807486631016,0.10695187165775401,0.10695187165775401,0.10962566844919786,0.10962566844919786,0.11229946524064172,0.11229946524064172,0.11497326203208556,0.11497326203208556,0.11764705882352941,0.11764705882352941,0.12299465240641712,0.12299465240641712,0.12566844919786097,0.12566844919786097,0.12834224598930483,0.12834224598930483,0.13101604278074866,0.13101604278074866,0.13368983957219252,0.13368983957219252,0.13636363636363635,0.13636363636363635,0.13903743315508021,0.13903743315508021,0.14171122994652408,0.14171122994652408,0.1443850267379679,0.1443850267379679,0.14705882352941177,0.14705882352941177,0.15508021390374332,0.15508021390374332,0.16042780748663102,0.16042780748663102,0.16310160427807488,0.16310160427807488,0.16844919786096257,0.16844919786096257,0.1711229946524064,0.1711229946524064,0.17379679144385027,0.17379679144385027,0.17647058823529413,0.17647058823529413,0.17914438502673796,0.17914438502673796,0.18449197860962566,0.18449197860962566,0.18716577540106952,0.18716577540106952,0.18983957219251338,0.18983957219251338,0.1925133689839572,0.1925133689839572,0.19518716577540107,0.19518716577540107,0.20053475935828877,0.20053475935828877,0.20588235294117646,0.20588235294117646,0.20855614973262032,0.20855614973262032,0.21122994652406418,0.21122994652406418,0.21657754010695188,0.21657754010695188,0.2192513368983957,0.2192513368983957,0.22459893048128343,0.22459893048128343,0.22727272727272727,0.22727272727272727,0.22994652406417113,0.22994652406417113,0.232620320855615,0.232620320855615,0.23529411764705882,0.23529411764705882,0.23796791443850268,0.23796791443850268,0.24064171122994651,0.24064171122994651,0.24331550802139038,0.24331550802139038,0.24598930481283424,0.24598930481283424,0.24866310160427807,0.24866310160427807,0.25133689839572193,0.25133689839572193,0.2540106951871658,0.2540106951871658,0.25668449197860965,0.25668449197860965,0.25935828877005346,0.25935828877005346,0.2647058823529412,0.2647058823529412,0.27807486631016043,0.27807486631016043,0.2807486631016043,0.2807486631016043,0.28342245989304815,0.28342245989304815,0.28609625668449196,0.28609625668449196,0.2914438502673797,0.2914438502673797,0.29411764705882354,0.29411764705882354,0.2994652406417112,0.2994652406417112,0.30213903743315507,0.30213903743315507,0.3048128342245989,0.3048128342245989,0.3074866310160428,0.3074866310160428,0.31016042780748665,0.31016042780748665,0.3155080213903743,0.3155080213903743,0.32085561497326204,0.32085561497326204,0.32620320855614976,0.32620320855614976,0.32887700534759357,0.32887700534759357,0.3315508021390374,0.3315508021390374,0.3342245989304813,0.3342245989304813,0.339572192513369,0.339572192513369,0.3422459893048128,0.3422459893048128,0.3449197860962567,0.3449197860962567,0.34759358288770054,0.34759358288770054,0.35294117647058826,0.35294117647058826,0.35561497326203206,0.35561497326203206,0.3582887700534759,0.3582887700534759,0.36363636363636365,0.36363636363636365,0.3770053475935829,0.3770053475935829,0.3850267379679144,0.3850267379679144,0.3877005347593583,0.3877005347593583,0.39037433155080214,0.39037433155080214,0.393048128342246,0.393048128342246,0.3983957219251337,0.3983957219251337,0.40106951871657753,0.40106951871657753,0.4037433155080214,0.4037433155080214,0.40641711229946526,0.40641711229946526,0.4090909090909091,0.4090909090909091,0.41711229946524064,0.41711229946524064,0.4304812834224599,0.4304812834224599,0.45454545454545453,0.45454545454545453,0.4572192513368984,0.4572192513368984,0.4625668449197861,0.4625668449197861,0.48128342245989303,0.48128342245989303,0.4839572192513369,0.4839572192513369,0.4893048128342246,0.4893048128342246,0.4919786096256685,0.4919786096256685,0.4946524064171123,0.4946524064171123,0.49732620320855614,0.49732620320855614,0.5320855614973262,0.5320855614973262,0.5347593582887701,0.5347593582887701,0.5374331550802139,0.5374331550802139,0.5427807486631016,0.5427807486631016,0.5454545454545454,0.5454545454545454,0.5481283422459893,0.5481283422459893,0.5588235294117647,0.5588235294117647,0.5962566844919787,0.5962566844919787,0.6042780748663101,0.6042780748663101,0.6310160427807486,0.6310160427807486,0.6898395721925134,0.6898395721925134,0.7192513368983957,0.7192513368983957,0.7272727272727273,0.7272727272727273,0.7299465240641712,0.7299465240641712,0.7754010695187166,0.7754010695187166,1.0],\"xaxis\":\"x\",\"y\":[0.0,0.01452081316553727,0.015488867376573089,0.017424975798644726,0.021297192642787996,0.02420135527589545,0.026137463697967087,0.028073572120038724,0.03581800580832527,0.03969022265246854,0.04259438528557599,0.04549854791868345,0.04743465634075508,0.049370764762826716,0.05517909002904162,0.057115198451113264,0.061955469506292354,0.06389157792836399,0.06582768635043562,0.06776379477250725,0.08131655372700872,0.08422071636011616,0.08615682478218781,0.08615682478218781,0.08809293320425944,0.09002904162633107,0.10067763794772508,0.10067763794772508,0.10454985479186835,0.10648596321393998,0.14714424007744434,0.14714424007744434,0.1665053242981607,0.1665053242981607,0.19748305905130686,0.19748305905130686,0.2758954501452081,0.2758954501452081,0.29235237173281703,0.29235237173281703,0.33494675701839305,0.33494675701839305,0.39496611810261373,0.39496611810261373,0.41045498547918685,0.41045498547918685,0.42884801548886736,0.42884801548886736,0.43852855759922554,0.43852855759922554,0.5004840271055179,0.5004840271055179,0.5033881897386253,0.5033881897386253,0.5198451113262342,0.5198451113262342,0.5217812197483059,0.5217812197483059,0.5401742497579864,0.5401742497579864,0.5430784123910939,0.5430784123910939,0.5498547918683446,0.5498547918683446,0.5595353339787028,0.5595353339787028,0.5614714424007744,0.5614714424007744,0.57405614714424,0.57405614714424,0.5759922555663117,0.5759922555663117,0.5769603097773476,0.5769603097773476,0.5934172313649564,0.5934172313649564,0.5943852855759922,0.5943852855759922,0.5982575024201355,0.5982575024201355,0.6224588576960309,0.6224588576960309,0.6282671829622459,0.6282671829622459,0.6321393998063891,0.6321393998063891,0.6418199419167473,0.6418199419167473,0.643756050338819,0.643756050338819,0.6544046466602129,0.6544046466602129,0.6592449177153921,0.6592449177153921,0.6621490803484995,0.6621490803484995,0.6698935140367861,0.6698935140367861,0.6737657308809293,0.6737657308809293,0.6776379477250726,0.6776379477250726,0.6969990319457889,0.6969990319457889,0.6989351403678606,0.6989351403678606,0.7018393030009681,0.7018393030009681,0.718296224588577,0.718296224588577,0.7270087124878993,0.7270087124878993,0.7299128751210068,0.7299128751210068,0.7308809293320426,0.7308809293320426,0.7318489835430784,0.7318489835430784,0.739593417231365,0.739593417231365,0.7405614714424008,0.7405614714424008,0.7483059051306873,0.7483059051306873,0.7521781219748306,0.7521781219748306,0.7792836398838335,0.7792836398838335,0.7850919651500484,0.7850919651500484,0.7860600193610843,0.7860600193610843,0.78702807357212,0.78702807357212,0.7899322362052275,0.7899322362052275,0.7909002904162633,0.7909002904162633,0.7918683446272992,0.7918683446272992,0.7967086156824782,0.7967086156824782,0.7986447241045499,0.7986447241045499,0.8034849951597289,0.8034849951597289,0.8063891577928364,0.8063891577928364,0.8083252662149081,0.8083252662149081,0.8092933204259438,0.8092933204259438,0.8102613746369797,0.8102613746369797,0.8228460793804453,0.8228460793804453,0.829622458857696,0.829622458857696,0.8354307841239109,0.8354307841239109,0.8373668925459826,0.8373668925459826,0.8393030009680542,0.8393030009680542,0.8402710551790901,0.8402710551790901,0.8422071636011617,0.8422071636011617,0.8431752178121975,0.8431752178121975,0.8441432720232332,0.8441432720232332,0.8451113262342691,0.8451113262342691,0.846079380445305,0.846079380445305,0.8470474346563408,0.8470474346563408,0.850919651500484,0.850919651500484,0.8538238141335914,0.8538238141335914,0.8596321393998064,0.8596321393998064,0.8606001936108422,0.8606001936108422,0.8625363020329139,0.8625363020329139,0.8644724104549855,0.8644724104549855,0.8654404646660213,0.8654404646660213,0.8664085188770572,0.8664085188770572,0.8731848983543078,0.8731848983543078,0.8760890609874153,0.8760890609874153,0.8780251694094869,0.8780251694094869,0.8809293320425944,0.8809293320425944,0.8857696030977735,0.8857696030977735,0.8877057115198451,0.8877057115198451,0.888673765730881,0.888673765730881,0.8915779283639884,0.8915779283639884,0.8944820909970959,0.8944820909970959,0.8954501452081317,0.8954501452081317,0.8973862536302033,0.8973862536302033,0.8993223620522749,0.8993223620522749,0.9031945788964182,0.9031945788964182,0.9119070667957405,0.9119070667957405,0.9138431752178122,0.9138431752178122,0.9167473378509197,0.9167473378509197,0.9196515004840271,0.9196515004840271,0.920619554695063,0.920619554695063,0.9273959341723137,0.9273959341723137,0.9283639883833494,0.9283639883833494,0.9293320425943853,0.9293320425943853,0.9312681510164569,0.9312681510164569,0.9341723136495643,0.9341723136495643,0.9390125847047435,0.9390125847047435,0.9399806389157793,0.9399806389157793,0.9428848015488868,0.9428848015488868,0.9438528557599225,0.9438528557599225,0.9477250726040658,0.9477250726040658,0.9496611810261375,0.9496611810261375,0.952565343659245,0.952565343659245,0.9545014520813165,0.9545014520813165,0.9554695062923524,0.9554695062923524,0.9564375605033882,0.9564375605033882,0.9583736689254598,0.9583736689254598,0.9593417231364957,0.9593417231364957,0.9603097773475314,0.9603097773475314,0.9612778315585673,0.9612778315585673,0.9641819941916747,0.9641819941916747,0.9670861568247822,0.9670861568247822,0.968054211035818,0.968054211035818,0.9690222652468539,0.9690222652468539,0.9719264278799613,0.9719264278799613,0.9738625363020329,0.9738625363020329,0.9748305905130688,0.9748305905130688,0.9757986447241046,0.9757986447241046,0.9767666989351403,0.9767666989351403,0.9777347531461762,0.9777347531461762,0.9806389157792836,0.9806389157792836,0.9816069699903195,0.9816069699903195,0.9825750242013552,0.9825750242013552,0.9874152952565344,0.9874152952565344,0.9883833494675702,0.9883833494675702,0.989351403678606,0.989351403678606,0.9903194578896418,0.9903194578896418,0.9912875121006777,0.9912875121006777,0.9922555663117134,0.9922555663117134,0.9941916747337851,0.9941916747337851,0.995159728944821,0.995159728944821,0.9961277831558567,0.9961277831558567,0.9970958373668926,0.9970958373668926,0.9980638915779284,0.9980638915779284,0.9990319457889641,0.9990319457889641,1.0,1.0],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"False Positive Rate\"},\"constrain\":\"domain\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"True Positive Rate\"},\"scaleanchor\":\"x\",\"scaleratio\":1},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"ROC Curve (AUC=0.8985)\"},\"height\":600,\"width\":800,\"shapes\":[{\"line\":{\"dash\":\"dash\"},\"type\":\"line\",\"x0\":0,\"x1\":1,\"y0\":0,\"y1\":1}],\"showlegend\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('c50e4567-5f46-4fb5-85d6-48aff7491ea7');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"fillpattern":{"shape":""},"hovertemplate":"Recall=%{x}<br>Precision=%{y}<extra></extra>","legendgroup":"","line":{"color":"#636efa"},"marker":{"symbol":"circle"},"mode":"lines","name":"","orientation":"v","showlegend":false,"stackgroup":"1","type":"scatter","x":[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9980638915779284,0.9980638915779284,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9932236205227493,0.9922555663117134,0.9922555663117134,0.9922555663117134,0.9922555663117134,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.989351403678606,0.989351403678606,0.9883833494675702,0.9883833494675702,0.9874152952565344,0.9874152952565344,0.9874152952565344,0.9864472410454985,0.9854791868344628,0.9845111326234269,0.9835430784123911,0.9825750242013552,0.9825750242013552,0.9816069699903195,0.9816069699903195,0.9806389157792836,0.9806389157792836,0.9806389157792836,0.9806389157792836,0.9806389157792836,0.9806389157792836,0.9806389157792836,0.9806389157792836,0.9806389157792836,0.9806389157792836,0.9806389157792836,0.9806389157792836,0.9806389157792836,0.9806389157792836,0.9796708615682478,0.978702807357212,0.9777347531461762,0.9777347531461762,0.9767666989351403,0.9767666989351403,0.9757986447241046,0.9757986447241046,0.9748305905130688,0.9748305905130688,0.9748305905130688,0.9738625363020329,0.9738625363020329,0.972894482090997,0.9719264278799613,0.9719264278799613,0.9719264278799613,0.9719264278799613,0.9719264278799613,0.9719264278799613,0.9719264278799613,0.9719264278799613,0.9709583736689255,0.9699903194578896,0.9690222652468539,0.9690222652468539,0.9690222652468539,0.968054211035818,0.968054211035818,0.9670861568247822,0.9670861568247822,0.9670861568247822,0.9670861568247822,0.9670861568247822,0.9670861568247822,0.9670861568247822,0.9670861568247822,0.9670861568247822,0.9670861568247822,0.9661181026137464,0.9651500484027106,0.9641819941916747,0.9641819941916747,0.9641819941916747,0.9641819941916747,0.9641819941916747,0.9641819941916747,0.9632139399806389,0.9622458857696031,0.9612778315585673,0.9612778315585673,0.9612778315585673,0.9612778315585673,0.9603097773475314,0.9603097773475314,0.9593417231364957,0.9593417231364957,0.9583736689254598,0.9583736689254598,0.957405614714424,0.9564375605033882,0.9564375605033882,0.9554695062923524,0.9554695062923524,0.9554695062923524,0.9545014520813165,0.9545014520813165,0.9535333978702807,0.952565343659245,0.952565343659245,0.9515972894482091,0.9506292352371732,0.9496611810261375,0.9496611810261375,0.9486931268151017,0.9477250726040658,0.9477250726040658,0.9477250726040658,0.9477250726040658,0.9467570183930301,0.9457889641819942,0.9448209099709584,0.9438528557599225,0.9438528557599225,0.9438528557599225,0.9438528557599225,0.9438528557599225,0.9438528557599225,0.9428848015488868,0.9428848015488868,0.9428848015488868,0.9419167473378509,0.9409486931268151,0.9399806389157793,0.9399806389157793,0.9390125847047435,0.9390125847047435,0.9380445304937076,0.9370764762826719,0.936108422071636,0.9351403678606002,0.9341723136495643,0.9341723136495643,0.9341723136495643,0.9332042594385286,0.9322362052274927,0.9312681510164569,0.9312681510164569,0.9303000968054211,0.9293320425943853,0.9293320425943853,0.9283639883833494,0.9283639883833494,0.9273959341723137,0.9273959341723137,0.9273959341723137,0.9264278799612778,0.925459825750242,0.9244917715392061,0.9235237173281704,0.9225556631171346,0.9215876089060987,0.920619554695063,0.920619554695063,0.9196515004840271,0.9196515004840271,0.9186834462729913,0.9177153920619555,0.9167473378509197,0.9167473378509197,0.9157792836398838,0.914811229428848,0.9138431752178122,0.9138431752178122,0.9138431752178122,0.9128751210067764,0.9119070667957405,0.9119070667957405,0.9119070667957405,0.9109390125847048,0.9099709583736689,0.9090029041626331,0.9080348499515973,0.9070667957405615,0.9060987415295256,0.9051306873184899,0.904162633107454,0.9031945788964182,0.9031945788964182,0.9031945788964182,0.9022265246853823,0.9012584704743466,0.9002904162633107,0.8993223620522749,0.8993223620522749,0.8983543078412392,0.8973862536302033,0.8973862536302033,0.8964181994191674,0.8954501452081317,0.8954501452081317,0.8944820909970959,0.8944820909970959,0.89351403678606,0.8925459825750242,0.8915779283639884,0.8915779283639884,0.8915779283639884,0.8906098741529526,0.8896418199419167,0.888673765730881,0.888673765730881,0.8877057115198451,0.8877057115198451,0.8877057115198451,0.8867376573088093,0.8857696030977735,0.8857696030977735,0.8848015488867377,0.8838334946757018,0.882865440464666,0.8818973862536302,0.8809293320425944,0.8809293320425944,0.8799612778315585,0.8789932236205228,0.8780251694094869,0.8780251694094869,0.8770571151984511,0.8760890609874153,0.8760890609874153,0.8760890609874153,0.8760890609874153,0.8760890609874153,0.8760890609874153,0.8751210067763795,0.8741529525653436,0.8731848983543078,0.8731848983543078,0.8731848983543078,0.872216844143272,0.8712487899322362,0.8702807357212003,0.8693126815101646,0.8683446272991288,0.8673765730880929,0.8664085188770572,0.8664085188770572,0.8654404646660213,0.8654404646660213,0.8644724104549855,0.8644724104549855,0.8635043562439496,0.8625363020329139,0.8625363020329139,0.861568247821878,0.8606001936108422,0.8606001936108422,0.8596321393998064,0.8596321393998064,0.8586640851887706,0.8576960309777347,0.856727976766699,0.8557599225556631,0.8547918683446273,0.8538238141335914,0.8538238141335914,0.8528557599225557,0.8518877057115198,0.850919651500484,0.850919651500484,0.8499515972894482,0.8489835430784124,0.8480154888673765,0.8470474346563408,0.8470474346563408,0.846079380445305,0.846079380445305,0.8451113262342691,0.8451113262342691,0.8441432720232332,0.8441432720232332,0.8431752178121975,0.8431752178121975,0.8422071636011617,0.8422071636011617,0.8422071636011617,0.8412391093901258,0.8402710551790901,0.8402710551790901,0.8393030009680542,0.8393030009680542,0.8393030009680542,0.8383349467570184,0.8373668925459826,0.8373668925459826,0.8363988383349468,0.8354307841239109,0.8354307841239109,0.8344627299128751,0.8334946757018393,0.8325266214908035,0.8315585672797676,0.8305905130687319,0.829622458857696,0.829622458857696,0.829622458857696,0.8286544046466602,0.8276863504356244,0.8267182962245886,0.8257502420135527,0.8247821878025169,0.8238141335914811,0.8228460793804453,0.8228460793804453,0.8228460793804453,0.8218780251694094,0.8209099709583737,0.8199419167473379,0.818973862536302,0.8180058083252663,0.8170377541142304,0.8160696999031946,0.8151016456921588,0.814133591481123,0.8131655372700871,0.8121974830590513,0.8112294288480155,0.8102613746369797,0.8102613746369797,0.8092933204259438,0.8092933204259438,0.8083252662149081,0.8083252662149081,0.8073572120038722,0.8063891577928364,0.8063891577928364,0.8054211035818006,0.8044530493707648,0.8034849951597289,0.8034849951597289,0.8034849951597289,0.8025169409486931,0.8015488867376573,0.8005808325266215,0.7996127783155856,0.7986447241045499,0.7986447241045499,0.797676669893514,0.7967086156824782,0.7967086156824782,0.7957405614714425,0.7947725072604066,0.7938044530493708,0.7928363988383349,0.7918683446272992,0.7918683446272992,0.7909002904162633,0.7909002904162633,0.7899322362052275,0.7899322362052275,0.7899322362052275,0.7889641819941917,0.7879961277831559,0.78702807357212,0.78702807357212,0.7860600193610843,0.7860600193610843,0.7860600193610843,0.7850919651500484,0.7850919651500484,0.7850919651500484,0.7850919651500484,0.7841239109390126,0.7831558567279767,0.782187802516941,0.7812197483059051,0.7802516940948693,0.7792836398838335,0.7792836398838335,0.7783155856727977,0.7773475314617618,0.7763794772507261,0.7754114230396902,0.7744433688286544,0.7734753146176185,0.7725072604065828,0.771539206195547,0.7705711519845111,0.7696030977734754,0.7686350435624395,0.7676669893514037,0.7666989351403679,0.7657308809293321,0.7647628267182962,0.7637947725072604,0.7628267182962246,0.7618586640851888,0.7608906098741529,0.7599225556631172,0.7589545014520813,0.7579864472410455,0.7570183930300097,0.7560503388189739,0.755082284607938,0.7541142303969022,0.7531461761858664,0.7521781219748306,0.7521781219748306,0.7512100677637947,0.750242013552759,0.7492739593417231,0.7483059051306873,0.7483059051306873,0.7473378509196515,0.7463697967086157,0.7454017424975798,0.744433688286544,0.7434656340755083,0.7424975798644724,0.7415295256534365,0.7405614714424008,0.7405614714424008,0.739593417231365,0.739593417231365,0.7386253630203291,0.7376573088092934,0.7366892545982575,0.7357212003872217,0.7347531461761858,0.7337850919651501,0.7328170377541142,0.7318489835430784,0.7318489835430784,0.7308809293320426,0.7308809293320426,0.7299128751210068,0.7299128751210068,0.7289448209099709,0.7279767666989352,0.7270087124878993,0.7270087124878993,0.7260406582768635,0.7250726040658277,0.7241045498547919,0.723136495643756,0.7221684414327202,0.7212003872216844,0.7202323330106486,0.7192642787996127,0.718296224588577,0.718296224588577,0.718296224588577,0.7173281703775412,0.7163601161665053,0.7153920619554696,0.7144240077444337,0.7134559535333979,0.712487899322362,0.7115198451113263,0.7105517909002904,0.7095837366892546,0.7086156824782188,0.707647628267183,0.7066795740561471,0.7057115198451114,0.7047434656340755,0.7037754114230397,0.7028073572120038,0.7018393030009681,0.7018393030009681,0.7008712487899322,0.6999031945788964,0.6989351403678606,0.6989351403678606,0.6979670861568248,0.6969990319457889,0.6969990319457889,0.6960309777347532,0.6950629235237173,0.6940948693126815,0.6931268151016456,0.6921587608906099,0.691190706679574,0.6902226524685382,0.6892545982575025,0.6882865440464666,0.6873184898354308,0.686350435624395,0.6853823814133592,0.6844143272023233,0.6834462729912875,0.6824782187802517,0.6815101645692159,0.68054211035818,0.6795740561471443,0.6786060019361084,0.6776379477250726,0.6776379477250726,0.6766698935140368,0.675701839303001,0.6747337850919651,0.6737657308809293,0.6737657308809293,0.6727976766698935,0.6718296224588577,0.6708615682478218,0.6698935140367861,0.6698935140367861,0.6689254598257502,0.6679574056147144,0.6669893514036787,0.6660212971926428,0.665053242981607,0.6640851887705711,0.6631171345595354,0.6621490803484995,0.6621490803484995,0.6611810261374637,0.6602129719264279,0.6592449177153921,0.6592449177153921,0.6582768635043562,0.6573088092933205,0.6563407550822846,0.6553727008712488,0.6544046466602129,0.6544046466602129,0.6534365924491772,0.6524685382381413,0.6515004840271055,0.6505324298160697,0.6495643756050339,0.648596321393998,0.6476282671829623,0.6466602129719264,0.6456921587608906,0.6447241045498547,0.643756050338819,0.643756050338819,0.6427879961277831,0.6418199419167473,0.6418199419167473,0.6418199419167473,0.6408518877057116,0.6398838334946757,0.6389157792836399,0.6379477250726041,0.6369796708615683,0.6360116166505324,0.6350435624394967,0.6340755082284608,0.633107454017425,0.6321393998063891,0.6321393998063891,0.6311713455953534,0.6302032913843175,0.6292352371732817,0.6282671829622459,0.6282671829622459,0.6282671829622459,0.6272991287512101,0.6263310745401742,0.6253630203291385,0.6243949661181026,0.6234269119070668,0.6224588576960309,0.6224588576960309,0.6214908034849952,0.6205227492739593,0.6195546950629235,0.6185866408518877,0.6176185866408519,0.616650532429816,0.6156824782187803,0.6147144240077445,0.6137463697967086,0.6127783155856728,0.611810261374637,0.6108422071636012,0.6098741529525653,0.6089060987415296,0.6079380445304937,0.6069699903194579,0.6060019361084221,0.6050338818973863,0.6040658276863504,0.6030977734753146,0.6021297192642788,0.601161665053243,0.6001936108422071,0.5992255566311714,0.5982575024201355,0.5982575024201355,0.5972894482090997,0.5963213939980639,0.5953533397870281,0.5943852855759922,0.5943852855759922,0.5934172313649564,0.5934172313649564,0.5924491771539206,0.5914811229428848,0.590513068731849,0.5895450145208132,0.5885769603097774,0.5876089060987415,0.5866408518877058,0.5856727976766699,0.5847047434656341,0.5837366892545982,0.5827686350435625,0.5818005808325266,0.5808325266214908,0.579864472410455,0.5788964181994192,0.5779283639883833,0.5769603097773476,0.5769603097773476,0.5759922555663117,0.5759922555663117,0.5750242013552759,0.57405614714424,0.57405614714424,0.5730880929332043,0.5721200387221684,0.5711519845111326,0.5701839303000968,0.569215876089061,0.5682478218780251,0.5672797676669894,0.5663117134559535,0.5653436592449177,0.5643756050338818,0.5634075508228461,0.5624394966118103,0.5614714424007744,0.5614714424007744,0.5605033881897387,0.5595353339787028,0.5595353339787028,0.558567279767667,0.5575992255566312,0.5566311713455954,0.5556631171345595,0.5546950629235237,0.5537270087124879,0.5527589545014521,0.5517909002904162,0.5508228460793805,0.5498547918683446,0.5498547918683446,0.5488867376573088,0.547918683446273,0.5469506292352372,0.5459825750242013,0.5450145208131656,0.5440464666021297,0.5430784123910939,0.5430784123910939,0.542110358180058,0.5411423039690223,0.5401742497579864,0.5401742497579864,0.5392061955469506,0.5382381413359149,0.537270087124879,0.5363020329138432,0.5353339787028074,0.5343659244917716,0.5333978702807357,0.5324298160696999,0.5314617618586641,0.5304937076476283,0.5295256534365924,0.5285575992255567,0.5275895450145208,0.526621490803485,0.5256534365924492,0.5246853823814134,0.5237173281703775,0.5227492739593417,0.5217812197483059,0.5217812197483059,0.5208131655372701,0.5198451113262342,0.5198451113262342,0.5198451113262342,0.5188770571151985,0.5179090029041626,0.5169409486931268,0.515972894482091,0.5150048402710552,0.5140367860600193,0.5130687318489835,0.5121006776379478,0.5111326234269119,0.510164569215876,0.5091965150048403,0.5082284607938045,0.5072604065827686,0.5062923523717329,0.505324298160697,0.5043562439496612,0.5033881897386253,0.5033881897386253,0.5024201355275896,0.5014520813165537,0.5004840271055179,0.5004840271055179,0.4995159728944821,0.4985479186834463,0.4975798644724105,0.49661181026137463,0.49564375605033884,0.494675701839303,0.4937076476282672,0.4927395934172314,0.49177153920619554,0.49080348499515974,0.4898354307841239,0.4888673765730881,0.4878993223620523,0.48693126815101645,0.48596321393998065,0.4849951597289448,0.484027105517909,0.4830590513068732,0.48209099709583736,0.48112294288480156,0.4801548886737657,0.4791868344627299,0.4782187802516941,0.47725072604065827,0.4762826718296225,0.4753146176185866,0.4743465634075508,0.47337850919651503,0.4724104549854792,0.4714424007744434,0.47047434656340753,0.46950629235237173,0.46853823814133594,0.4675701839303001,0.4666021297192643,0.46563407550822844,0.46466602129719264,0.46369796708615685,0.462729912875121,0.4617618586640852,0.46079380445304935,0.45982575024201355,0.45885769603097776,0.4578896418199419,0.4569215876089061,0.45595353339787026,0.45498547918683446,0.45401742497579867,0.4530493707647628,0.452081316553727,0.45111326234269117,0.45014520813165537,0.4491771539206196,0.4482090997095837,0.44724104549854793,0.4462729912875121,0.4453049370764763,0.4443368828654405,0.44336882865440463,0.44240077444336884,0.441432720232333,0.4404646660212972,0.4394966118102614,0.43852855759922554,0.43852855759922554,0.43756050338818975,0.4365924491771539,0.4356243949661181,0.4346563407550823,0.43368828654404645,0.43272023233301066,0.4317521781219748,0.430784123910939,0.4298160696999032,0.42884801548886736,0.42884801548886736,0.42787996127783157,0.4269119070667957,0.4259438528557599,0.4249757986447241,0.42400774443368827,0.4230396902226525,0.4220716360116166,0.42110358180058083,0.42013552758954503,0.4191674733785092,0.4181994191674734,0.41723136495643753,0.41626331074540174,0.41529525653436594,0.4143272023233301,0.4133591481122943,0.41239109390125844,0.41142303969022265,0.41045498547918685,0.41045498547918685,0.409486931268151,0.4085188770571152,0.4075508228460794,0.40658276863504356,0.40561471442400776,0.4046466602129719,0.4036786060019361,0.4027105517909003,0.40174249757986447,0.40077444336882867,0.3998063891577928,0.398838334946757,0.3978702807357212,0.3969022265246854,0.3959341723136496,0.39496611810261373,0.39496611810261373,0.39399806389157793,0.39303000968054214,0.3920619554695063,0.3910939012584705,0.39012584704743464,0.38915779283639884,0.38818973862536305,0.3872216844143272,0.3862536302032914,0.38528557599225555,0.38431752178121975,0.38334946757018395,0.3823814133591481,0.3814133591481123,0.38044530493707646,0.37947725072604066,0.37850919651500486,0.377541142303969,0.3765730880929332,0.37560503388189737,0.37463697967086157,0.3736689254598258,0.3727008712487899,0.3717328170377541,0.3707647628267183,0.3697967086156825,0.3688286544046467,0.36786060019361083,0.36689254598257504,0.3659244917715392,0.3649564375605034,0.3639883833494676,0.36302032913843174,0.36205227492739595,0.3610842207163601,0.3601161665053243,0.3591481122942885,0.35818005808325265,0.35721200387221685,0.356243949661181,0.3552758954501452,0.3543078412391094,0.35333978702807356,0.35237173281703776,0.3514036786060019,0.3504356243949661,0.3494675701839303,0.34849951597289447,0.3475314617618587,0.3465634075508228,0.345595353339787,0.34462729912875123,0.3436592449177154,0.3426911907066796,0.34172313649564373,0.34075508228460794,0.33978702807357214,0.3388189738625363,0.3378509196515005,0.33688286544046464,0.33591481122942884,0.33494675701839305,0.33494675701839305,0.3339787028073572,0.3330106485963214,0.33204259438528555,0.33107454017424975,0.33010648596321396,0.3291384317521781,0.3281703775411423,0.32720232333010646,0.32623426911907066,0.32526621490803487,0.324298160696999,0.3233301064859632,0.32236205227492737,0.3213939980638916,0.3204259438528558,0.3194578896418199,0.31848983543078413,0.31752178121974833,0.3165537270087125,0.3155856727976767,0.31461761858664083,0.31364956437560504,0.31268151016456924,0.3117134559535334,0.3107454017424976,0.30977734753146174,0.30880929332042595,0.30784123910939015,0.3068731848983543,0.3059051306873185,0.30493707647628265,0.30396902226524686,0.30300096805421106,0.3020329138431752,0.3010648596321394,0.30009680542110356,0.29912875121006777,0.29816069699903197,0.2971926427879961,0.2962245885769603,0.2952565343659245,0.2942884801548887,0.2933204259438529,0.29235237173281703,0.29235237173281703,0.29138431752178123,0.2904162633107454,0.2894482090997096,0.2884801548886738,0.28751210067763794,0.28654404646660214,0.2855759922555663,0.2846079380445305,0.2836398838334947,0.28267182962245885,0.28170377541142305,0.2807357212003872,0.2797676669893514,0.2787996127783156,0.27783155856727976,0.27686350435624396,0.2758954501452081,0.2758954501452081,0.2749273959341723,0.2739593417231365,0.27299128751210067,0.27202323330106487,0.271055179090029,0.2700871248789932,0.2691190706679574,0.2681510164569216,0.2671829622458858,0.26621490803484993,0.26524685382381413,0.26427879961277834,0.2633107454017425,0.2623426911907067,0.26137463697967084,0.26040658276863504,0.25943852855759925,0.2584704743465634,0.2575024201355276,0.25653436592449175,0.25556631171345595,0.25459825750242016,0.2536302032913843,0.2526621490803485,0.25169409486931266,0.25072604065827686,0.24975798644724104,0.24878993223620524,0.24782187802516942,0.2468538238141336,0.24588576960309777,0.24491771539206195,0.24394966118102615,0.24298160696999033,0.2420135527589545,0.24104549854791868,0.24007744433688286,0.23910939012584706,0.23814133591481124,0.2371732817037754,0.2362052274927396,0.23523717328170377,0.23426911907066797,0.23330106485963215,0.23233301064859632,0.2313649564375605,0.23039690222652467,0.22942884801548888,0.22846079380445306,0.22749273959341723,0.2265246853823814,0.22555663117134558,0.2245885769603098,0.22362052274927396,0.22265246853823814,0.22168441432720232,0.2207163601161665,0.2197483059051307,0.21878025169409487,0.21781219748305905,0.21684414327202323,0.2158760890609874,0.2149080348499516,0.21393998063891578,0.21297192642787996,0.21200387221684414,0.2110358180058083,0.21006776379477252,0.2090997095837367,0.20813165537270087,0.20716360116166505,0.20619554695062922,0.20522749273959343,0.2042594385285576,0.20329138431752178,0.20232333010648595,0.20135527589545016,0.20038722168441434,0.1994191674733785,0.1984511132623427,0.19748305905130686,0.19748305905130686,0.19651500484027107,0.19554695062923524,0.19457889641819942,0.1936108422071636,0.19264278799612777,0.19167473378509198,0.19070667957405615,0.18973862536302033,0.1887705711519845,0.18780251694094868,0.1868344627299129,0.18586640851887706,0.18489835430784124,0.18393030009680542,0.1829622458857696,0.1819941916747338,0.18102613746369797,0.18005808325266215,0.17909002904162633,0.1781219748305905,0.1771539206195547,0.17618586640851888,0.17521781219748306,0.17424975798644723,0.1732817037754114,0.17231364956437561,0.1713455953533398,0.17037754114230397,0.16940948693126814,0.16844143272023232,0.16747337850919652,0.1665053242981607,0.1665053242981607,0.16553727008712488,0.16456921587608905,0.16360116166505323,0.16263310745401743,0.1616650532429816,0.1606969990319458,0.15972894482090996,0.15876089060987417,0.15779283639883834,0.15682478218780252,0.1558567279767667,0.15488867376573087,0.15392061955469508,0.15295256534365925,0.15198451113262343,0.1510164569215876,0.15004840271055178,0.14908034849951599,0.14811229428848016,0.14714424007744434,0.14714424007744434,0.14617618586640851,0.1452081316553727,0.1442400774443369,0.14327202323330107,0.14230396902226525,0.14133591481122942,0.1403678606001936,0.1393998063891578,0.13843175217812198,0.13746369796708616,0.13649564375605033,0.1355275895450145,0.1345595353339787,0.1335914811229429,0.13262342691190707,0.13165537270087124,0.13068731848983542,0.12971926427879962,0.1287512100677638,0.12778315585672798,0.12681510164569215,0.12584704743465633,0.12487899322362052,0.12391093901258471,0.12294288480154889,0.12197483059051308,0.12100677637947725,0.12003872216844143,0.11907066795740562,0.1181026137463698,0.11713455953533398,0.11616650532429816,0.11519845111326234,0.11423039690222653,0.1132623426911907,0.1122942884801549,0.11132623426911907,0.11035818005808325,0.10939012584704744,0.10842207163601161,0.1074540174249758,0.10648596321393998,0.10454985479186835,0.10358180058083252,0.10261374636979671,0.10164569215876089,0.10067763794772508,0.10067763794772508,0.09970958373668926,0.09874152952565343,0.09777347531461762,0.0968054211035818,0.09583736689254599,0.09486931268151017,0.09390125847047434,0.09293320425943853,0.09196515004840271,0.0909970958373669,0.09002904162633107,0.08809293320425944,0.08712487899322362,0.08615682478218781,0.08615682478218781,0.08518877057115198,0.08422071636011616,0.08131655372700872,0.0803484995159729,0.07938044530493708,0.07841239109390126,0.07744433688286544,0.07647628267182963,0.0755082284607938,0.07454017424975799,0.07357212003872217,0.07260406582768635,0.07163601161665054,0.07066795740561471,0.0696999031945789,0.06873184898354308,0.06776379477250725,0.06582768635043562,0.06485963213939981,0.06389157792836399,0.061955469506292354,0.06098741529525654,0.060019361084220714,0.0590513068731849,0.05808325266214908,0.057115198451113264,0.05517909002904162,0.05421103581800581,0.05324298160696999,0.05227492739593417,0.051306873184898356,0.05033881897386254,0.049370764762826716,0.04743465634075508,0.046466602129719266,0.04549854791868345,0.04259438528557599,0.041626331074540175,0.04065827686350436,0.03969022265246854,0.0377541142303969,0.03581800580832527,0.03484995159728945,0.03388189738625363,0.03291384317521781,0.031945788964181994,0.030977734753146177,0.030009680542110357,0.02904162633107454,0.028073572120038724,0.026137463697967087,0.02516940948693127,0.02420135527589545,0.021297192642787996,0.02032913843175218,0.01936108422071636,0.018393030009680542,0.017424975798644726,0.015488867376573089,0.01452081316553727,0],"xaxis":"x","y":[0.7341862117981521,0.7347083926031295,0.7352313167259786,0.7357549857549858,0.7362794012829651,0.7368045649072753,0.7373304782298359,0.7378571428571429,0.7383845604002859,0.7389127324749643,0.7394416607015032,0.7399713467048711,0.7405017921146954,0.7410329985652798,0.741564967695621,0.7420977011494253,0.7426312005751258,0.7431654676258993,0.7437005039596832,0.7442363112391931,0.7447728911319395,0.7453102453102453,0.7458483754512636,0.7463872832369942,0.7469269703543022,0.7474674384949349,0.7480086893555394,0.7485507246376811,0.7490935460478607,0.7496371552975326,0.7501815541031227,0.7507267441860465,0.7512727272727273,0.7518195050946143,0.752367079388201,0.7529154518950437,0.7534646243617797,0.754014598540146,0.7545653761869978,0.7551169590643275,0.7556693489392831,0.7562225475841874,0.7567765567765568,0.7573313782991202,0.7578870139398386,0.7584434654919237,0.7590007347538574,0.7595588235294117,0.7601177336276674,0.7606774668630338,0.7612380250552689,0.7617994100294986,0.7623616236162362,0.7629246676514032,0.7634885439763488,0.7640532544378699,0.764618800888231,0.7651851851851852,0.765752409191994,0.766320474777448,0.7668893838158871,0.7674591381872214,0.7680297397769517,0.7686011904761905,0.7691734921816828,0.7697466467958272,0.7703206562266965,0.7708955223880597,0.7714712471994025,0.7720478325859492,0.7726252804786836,0.7732035928143712,0.7737827715355805,0.7743628185907047,0.7749437359339835,0.7755255255255256,0.7761081893313299,0.7766917293233083,0.7772761474793077,0.7778614457831325,0.7784476262245666,0.7790346907993967,0.779622641509434,0.7802114803625377,0.780801209372638,0.7806354009077155,0.781226343679031,0.7818181818181819,0.7824109173616376,0.7830045523520486,0.7835990888382688,0.78419452887538,0.7847908745247149,0.7853881278538812,0.785986290936786,0.7865853658536586,0.7871853546910755,0.7877862595419848,0.7883880825057296,0.7889908256880734,0.7895944912012242,0.7901990811638591,0.7908045977011494,0.7906441717791411,0.7912509593246354,0.7910906298003072,0.7916986933128363,0.7923076923076923,0.7929176289453426,0.7927580893682589,0.7933693138010794,0.7939814814814815,0.7945945945945946,0.7952086553323029,0.7958236658932715,0.7964396284829721,0.7970565453137103,0.7976744186046512,0.7982932505818464,0.7989130434782609,0.7995337995337995,0.7993779160186625,0.8,0.8006230529595015,0.8012470771628994,0.8018720748829953,0.8024980483996877,0.803125,0.8037529319781079,0.8043818466353677,0.8050117462803446,0.8056426332288401,0.8062745098039216,0.8069073783359497,0.8075412411626081,0.8081761006289309,0.8088119590873328,0.8094488188976378,0.8100866824271079,0.8107255520504731,0.8113654301499605,0.8120063191153238,0.8126482213438735,0.8132911392405063,0.8131433095803642,0.8137876386687797,0.8144329896907216,0.8150793650793651,0.8157267672756155,0.8163751987281399,0.817024661893397,0.8176751592356688,0.8183266932270916,0.8189792663476874,0.819632881085395,0.8194888178913738,0.8193445243804957,0.82,0.8206565252201762,0.8213141025641025,0.8211708099438653,0.8218298555377207,0.8224899598393575,0.8231511254019293,0.8238133547868061,0.8244766505636071,0.8251410153102336,0.8258064516129032,0.8264729620661824,0.827140549273021,0.8278092158447857,0.8284789644012945,0.8291497975708502,0.8298217179902755,0.8304947283049473,0.8303571428571429,0.8310316815597075,0.8317073170731707,0.8323840520748577,0.8330618892508144,0.8329258353708231,0.833605220228385,0.833469387755102,0.8341503267973857,0.8340147179067866,0.8346972176759411,0.8353808353808354,0.8352459016393443,0.8351107465135357,0.8349753694581281,0.8348397699260477,0.834703947368421,0.8353909465020576,0.8352553542009885,0.8359439406430338,0.8358085808580858,0.8364987613542527,0.8371900826446281,0.8378825475599669,0.8385761589403974,0.8392709196354599,0.8399668325041459,0.8406639004149378,0.8413621262458472,0.8420615128844555,0.8427620632279534,0.8434637801831807,0.8441666666666666,0.8448707256046706,0.8447412353923205,0.8446115288220551,0.8444816053511706,0.8451882845188284,0.8450586264656617,0.845766974015088,0.8456375838926175,0.8463476070528967,0.846218487394958,0.8469301934398654,0.8476430976430976,0.8475147430497051,0.8482293423271501,0.8481012658227848,0.847972972972973,0.8486897717666948,0.8494077834179357,0.8501270110076207,0.8508474576271187,0.8515691263782866,0.8522920203735145,0.8530161427357689,0.8528911564625851,0.8527659574468085,0.8526405451448041,0.8533674339300937,0.8540955631399317,0.8539709649871904,0.8547008547008547,0.8545765611633875,0.8553082191780822,0.8560411311053985,0.8567753001715266,0.8575107296137339,0.8582474226804123,0.8589853826311264,0.8597246127366609,0.8604651162790697,0.8612068965517241,0.8610871440897325,0.8609671848013817,0.8608470181503889,0.8615916955017301,0.8623376623376623,0.8630849220103987,0.8638334778837814,0.8645833333333334,0.8644656820156386,0.8643478260869565,0.8642297650130548,0.8649825783972126,0.8657367044463818,0.8664921465968587,0.8663755458515284,0.8671328671328671,0.8670166229221348,0.8677758318739054,0.8676599474145487,0.868421052631579,0.8683055311676909,0.8681898066783831,0.8689533861037819,0.8688380281690141,0.8696035242290749,0.8703703703703703,0.8702559576345984,0.8710247349823321,0.8709106984969054,0.8707964601769912,0.8715677590788308,0.8714539007092199,0.8713398402839396,0.8712255772646537,0.872,0.8718861209964412,0.8717720391807658,0.8725490196078431,0.8733273862622658,0.8741071428571429,0.8739946380697051,0.8738819320214669,0.873769024171889,0.8736559139784946,0.874439461883408,0.8752244165170556,0.876010781671159,0.8767985611510791,0.8775877587758776,0.8774774774774775,0.8782687105500451,0.8790613718411552,0.8789521228545619,0.8788426763110307,0.8787330316742081,0.8795289855072463,0.8794197642792384,0.8802177858439202,0.8801089918256131,0.88,0.8798908098271155,0.8797814207650273,0.8796718322698268,0.8804744525547445,0.8812785388127854,0.8811700182815356,0.8810612991765783,0.8809523809523809,0.8817598533455545,0.881651376146789,0.8815426997245179,0.8823529411764706,0.8822447102115916,0.8830570902394107,0.8829493087557604,0.8837638376383764,0.8845798707294552,0.8844731977818854,0.8843663274745606,0.8842592592592593,0.8841519925857275,0.8840445269016698,0.8839368616527391,0.8838289962825279,0.8846511627906977,0.8845437616387337,0.8853681267474371,0.8852611940298507,0.8851540616246498,0.8850467289719626,0.8858746492048644,0.8857677902621723,0.8856607310215557,0.8855534709193246,0.8863849765258216,0.8872180451127819,0.8871119473189087,0.8870056497175142,0.8878416588124411,0.8886792452830189,0.8885741265344664,0.888468809073724,0.8883632923368022,0.8882575757575758,0.8881516587677725,0.888045540796964,0.8879392212725546,0.8878326996197718,0.8877259752616555,0.8885714285714286,0.8894184938036225,0.8893129770992366,0.889207258834766,0.8891013384321224,0.8889952153110048,0.8898467432950191,0.8897411313518696,0.8896353166986565,0.8904899135446686,0.8903846153846153,0.890279114533205,0.8911368015414258,0.8910318225650916,0.8918918918918919,0.8917874396135266,0.8916827852998066,0.8915779283639884,0.8924418604651163,0.8933074684772065,0.8932038834951457,0.8931000971817298,0.8929961089494164,0.8938656280428432,0.8937621832358674,0.8946341463414634,0.8955078125,0.895405669599218,0.8953033268101761,0.8961802154750245,0.8960784313725491,0.8959764474975466,0.8958742632612967,0.895771878072763,0.8956692913385826,0.896551724137931,0.8964497041420119,0.8963474827245804,0.8962450592885376,0.897131552917903,0.897029702970297,0.8969276511397423,0.8978174603174603,0.8987090367428004,0.8996023856858847,0.900497512437811,0.901394422310757,0.901296111665005,0.9011976047904192,0.9010989010989011,0.902,0.9029029029029029,0.9028056112224448,0.9027081243731193,0.9026104417670683,0.9025125628140703,0.9024144869215291,0.9023162134944612,0.9022177419354839,0.9031281533804238,0.9030303030303031,0.9039433771486349,0.9038461538461539,0.9047619047619048,0.9046653144016227,0.9045685279187817,0.9054878048780488,0.9053916581892166,0.905295315682281,0.9062181447502549,0.9061224489795918,0.9070480081716037,0.9069529652351738,0.9068577277379734,0.9067622950819673,0.9066666666666666,0.9065708418891171,0.9064748201438849,0.9074074074074074,0.9073120494335737,0.9072164948453608,0.9071207430340558,0.9080578512396694,0.9079627714581179,0.9078674948240165,0.9077720207253887,0.9076763485477178,0.9086188992731049,0.9085239085239085,0.9094693028095734,0.909375,0.9103232533889468,0.9102296450939458,0.9111807732497388,0.9110878661087866,0.912041884816754,0.9119496855345912,0.912906610703043,0.9138655462184874,0.9137749737118822,0.9136842105263158,0.9146469968387777,0.9145569620253164,0.9155227032734953,0.9164904862579282,0.9164021164021164,0.9163135593220338,0.9172852598091198,0.9171974522292994,0.9171094580233794,0.9180851063829787,0.9179978700745474,0.917910447761194,0.9178228388473852,0.9177350427350427,0.9176470588235294,0.917558886509636,0.9185423365487674,0.9195278969957081,0.9194414607948442,0.9193548387096774,0.9192680301399354,0.9191810344827587,0.919093851132686,0.9190064794816415,0.918918918918919,0.9199134199134199,0.9209100758396533,0.920824295010846,0.9207383279044516,0.9206521739130434,0.9205658324265505,0.920479302832244,0.920392584514722,0.9203056768558951,0.9202185792349726,0.9201312910284464,0.9200438116100766,0.9199561403508771,0.9198682766190999,0.9197802197802197,0.9207920792079208,0.920704845814978,0.9217199558985667,0.9216335540838853,0.9226519337016574,0.922566371681416,0.9224806201550387,0.9235033259423503,0.9234184239733629,0.9233333333333333,0.9232480533926585,0.9242761692650334,0.9253065774804905,0.9252232142857143,0.9251396648044693,0.9250559284116331,0.9249720044792833,0.9248878923766816,0.9259259259259259,0.9258426966292135,0.9257592800899888,0.9268018018018018,0.9267192784667418,0.9266365688487584,0.9265536723163842,0.9264705882352942,0.9263873159682899,0.927437641723356,0.927355278093076,0.928409090909091,0.9283276450511946,0.929384965831435,0.9304446978335233,0.930365296803653,0.9302857142857143,0.9302059496567505,0.9312714776632303,0.9311926605504587,0.9322617680826636,0.9333333333333333,0.9332566168009206,0.934331797235023,0.9354094579008074,0.9364896073903002,0.9364161849710982,0.9363425925925926,0.936268829663963,0.9361948955916474,0.9361207897793263,0.936046511627907,0.9371362048894063,0.9370629370629371,0.9369894982497082,0.9369158878504673,0.9368421052631579,0.936768149882904,0.936694021101993,0.9366197183098591,0.936545240893067,0.9364705882352942,0.9363957597173145,0.9363207547169812,0.9362455726092089,0.9361702127659575,0.936094674556213,0.9360189573459715,0.9359430604982206,0.9358669833729216,0.9357907253269917,0.9357142857142857,0.9356376638855781,0.9355608591885441,0.9354838709677419,0.9354066985645934,0.9353293413173652,0.935251798561151,0.9351740696278511,0.9350961538461539,0.9350180505415162,0.936144578313253,0.9360675512665863,0.9359903381642513,0.9359129383313181,0.9358353510895884,0.936969696969697,0.9368932038834952,0.93681652490887,0.9367396593673966,0.9366626065773447,0.9365853658536586,0.9365079365079365,0.9364303178484108,0.9363525091799265,0.9375,0.9374233128834356,0.9385749385749386,0.9384993849938499,0.9384236453201971,0.938347718865598,0.9382716049382716,0.9381953028430161,0.9381188118811881,0.9380421313506815,0.9379652605459057,0.9391304347826087,0.9390547263681592,0.9402241594022416,0.940149625935162,0.9413233458177278,0.94125,0.9411764705882353,0.9411027568922306,0.9422835633626098,0.9422110552763819,0.9421383647798742,0.9420654911838791,0.9419924337957125,0.9419191919191919,0.9418457648546145,0.9417721518987342,0.9416983523447402,0.9416243654822335,0.9428208386277002,0.9440203562340967,0.9439490445859873,0.9438775510204082,0.9438058748403576,0.9437340153452686,0.9436619718309859,0.9435897435897436,0.9435173299101413,0.9434447300771208,0.9433719433719434,0.9432989690721649,0.9432258064516129,0.9431524547803618,0.943078913324709,0.9430051813471503,0.9429312581063554,0.9428571428571428,0.9427828348504551,0.9440104166666666,0.9439374185136897,0.943864229765013,0.9437908496732026,0.9450261780104712,0.944954128440367,0.9448818897637795,0.9461235216819974,0.9460526315789474,0.9459815546772069,0.945910290237467,0.9458388375165125,0.9457671957671958,0.9456953642384106,0.9456233421750663,0.9455511288180611,0.9454787234042553,0.9454061251664447,0.9453333333333334,0.945260347129506,0.9451871657754011,0.9451137884872824,0.9450402144772118,0.9449664429530201,0.9448924731182796,0.9448183041722745,0.944743935309973,0.9446693657219973,0.9459459459459459,0.945872801082544,0.94579945799458,0.9457259158751696,0.9456521739130435,0.9469387755102041,0.946866485013624,0.946793997271487,0.9467213114754098,0.9466484268125855,0.947945205479452,0.9478737997256516,0.9478021978021978,0.9477303988995873,0.9476584022038568,0.9475862068965517,0.9475138121546961,0.9474412171507607,0.9473684210526315,0.9486823855755895,0.9486111111111111,0.9485396383866481,0.9484679665738162,0.9497907949790795,0.9497206703910615,0.9496503496503497,0.9495798319327731,0.9495091164095372,0.949438202247191,0.9507735583684951,0.9507042253521126,0.9506346967559943,0.9505649717514124,0.9504950495049505,0.9504249291784702,0.950354609929078,0.9502840909090909,0.9502133712660028,0.9501424501424501,0.9500713266761769,0.95,0.9513590844062947,0.9512893982808023,0.9512195121951219,0.9525862068965517,0.9539568345323741,0.9538904899135446,0.9538239538239538,0.953757225433526,0.9536903039073806,0.9536231884057971,0.95355587808418,0.9534883720930233,0.9534206695778749,0.9533527696793003,0.9532846715328467,0.9546783625730995,0.9546120058565154,0.9545454545454546,0.9544787077826725,0.9544117647058824,0.9558173784977909,0.9572271386430679,0.9571639586410635,0.9571005917159763,0.957037037037037,0.956973293768546,0.9569093610698366,0.9568452380952381,0.9582712369597616,0.9582089552238806,0.9581464872944694,0.9580838323353293,0.9580209895052474,0.9579579579579579,0.9578947368421052,0.9578313253012049,0.9577677224736049,0.9577039274924471,0.9576399394856279,0.9575757575757575,0.9575113808801214,0.9574468085106383,0.9573820395738204,0.9573170731707317,0.9572519083969465,0.9571865443425076,0.9571209800918836,0.9570552147239264,0.956989247311828,0.9569230769230769,0.9568567026194145,0.9567901234567902,0.9567233384853169,0.9566563467492261,0.958139534883721,0.9580745341614907,0.9580093312597201,0.9579439252336449,0.9578783151326054,0.959375,0.9593114241001565,0.9608150470219435,0.9607535321821036,0.960691823899371,0.9606299212598425,0.9605678233438486,0.9605055292259084,0.9604430379746836,0.9603803486529319,0.9603174603174603,0.9602543720190779,0.9601910828025477,0.960127591706539,0.9600638977635783,0.96,0.9599358974358975,0.9598715890850722,0.9598070739549839,0.9597423510466989,0.9612903225806452,0.9612277867528272,0.9627831715210357,0.9627228525121556,0.9626623376623377,0.9642276422764228,0.9641693811074918,0.964110929853181,0.9640522875816994,0.9639934533551555,0.9639344262295082,0.9638752052545156,0.9638157894736842,0.9637561779242174,0.9636963696369637,0.9636363636363636,0.9635761589403974,0.9635157545605307,0.9634551495016611,0.9650582362728786,0.965,0.9649415692821369,0.9665551839464883,0.966499162479062,0.9664429530201343,0.9663865546218487,0.9663299663299664,0.9662731871838112,0.9662162162162162,0.9661590524534687,0.9661016949152542,0.966044142614601,0.9659863945578231,0.9676320272572402,0.9675767918088737,0.9675213675213675,0.9674657534246576,0.967409948542024,0.9673539518900344,0.9672977624784854,0.9672413793103448,0.9689119170984456,0.9688581314878892,0.9688041594454073,0.96875,0.9704347826086956,0.9703832752613241,0.9703315881326352,0.9702797202797203,0.9702276707530648,0.9701754385964912,0.9701230228471002,0.9700704225352113,0.9700176366843033,0.9699646643109541,0.9699115044247788,0.9698581560283688,0.9698046181172292,0.9697508896797153,0.9696969696969697,0.9696428571428571,0.9695885509838998,0.9695340501792115,0.9694793536804309,0.9694244604316546,0.9711711711711711,0.9711191335740073,0.9710669077757685,0.9728260869565217,0.9745916515426497,0.9745454545454545,0.9744990892531876,0.9744525547445255,0.9744058500914077,0.9743589743589743,0.9743119266055046,0.9742647058823529,0.9742173112338858,0.974169741697417,0.9741219963031423,0.9740740740740741,0.974025974025974,0.9739776951672863,0.9739292364990689,0.9738805970149254,0.9738317757009346,0.9737827715355806,0.975609756097561,0.9755639097744361,0.975517890772128,0.9754716981132076,0.9773156899810964,0.9772727272727273,0.9772296015180265,0.9771863117870723,0.9771428571428571,0.9770992366412213,0.9770554493307839,0.9770114942528736,0.9769673704414588,0.9769230769230769,0.976878612716763,0.9768339768339769,0.97678916827853,0.9767441860465116,0.9766990291262136,0.9766536964980544,0.9766081871345029,0.9765625,0.9765166340508806,0.9764705882352941,0.9764243614931237,0.9763779527559056,0.9763313609467456,0.9762845849802372,0.9762376237623762,0.9761904761904762,0.9761431411530815,0.9760956175298805,0.9760479041916168,0.976,0.9759519038076152,0.9759036144578314,0.9758551307847082,0.9758064516129032,0.9757575757575757,0.9757085020242915,0.9756592292089249,0.975609756097561,0.9755600814663951,0.9755102040816327,0.9754601226993865,0.9754098360655737,0.9753593429158111,0.9753086419753086,0.9752577319587629,0.9752066115702479,0.9751552795031055,0.975103734439834,0.975051975051975,0.975,0.9749478079331941,0.9748953974895398,0.9748427672955975,0.9747899159663865,0.9747368421052631,0.9746835443037974,0.9746300211416491,0.9745762711864406,0.9745222929936306,0.9744680851063829,0.9744136460554371,0.9743589743589743,0.974304068522484,0.9742489270386266,0.9741935483870968,0.9762931034482759,0.9762419006479481,0.9761904761904762,0.9761388286334056,0.9760869565217392,0.9760348583877996,0.9759825327510917,0.975929978118162,0.9758771929824561,0.9758241758241758,0.9757709251101322,0.977924944812362,0.9778761061946902,0.9778270509977827,0.9777777777777777,0.977728285077951,0.9776785714285714,0.9776286353467561,0.9775784753363229,0.9775280898876404,0.9774774774774775,0.9774266365688488,0.9773755656108597,0.9773242630385488,0.9772727272727273,0.9772209567198178,0.9771689497716894,0.977116704805492,0.9770642201834863,0.9770114942528736,0.9769585253456221,0.9792147806004619,0.9791666666666666,0.9791183294663574,0.9790697674418605,0.9790209790209791,0.9789719626168224,0.9789227166276346,0.9788732394366197,0.9788235294117648,0.9787735849056604,0.9787234042553191,0.9786729857819905,0.9786223277909739,0.9785714285714285,0.9785202863961814,0.9784688995215312,0.9784172661870504,0.9807692307692307,0.980722891566265,0.9806763285024155,0.9806295399515739,0.9805825242718447,0.9805352798053528,0.9804878048780488,0.980440097799511,0.9803921568627451,0.9803439803439803,0.9802955665024631,0.980246913580247,0.9801980198019802,0.9801488833746899,0.9800995024875622,0.9800498753117207,0.98,0.9799498746867168,0.9798994974874372,0.9798488664987406,0.9797979797979798,0.979746835443038,0.9796954314720813,0.9796437659033079,0.9795918367346939,0.979539641943734,0.9794871794871794,0.9794344473007712,0.979381443298969,0.979328165374677,0.9792746113989638,0.9792207792207792,0.9791666666666666,0.97911227154047,0.9790575916230366,0.979002624671916,0.9789473684210527,0.978891820580475,0.9788359788359788,0.9787798408488063,0.9787234042553191,0.9786666666666667,0.9786096256684492,0.9785522788203753,0.978494623655914,0.9784366576819407,0.9783783783783784,0.978319783197832,0.9782608695652174,0.9782016348773842,0.9781420765027322,0.9780821917808219,0.978021978021978,0.977961432506887,0.9779005524861878,0.9778393351800554,0.9777777777777777,0.9777158774373259,0.9776536312849162,0.9775910364145658,0.9775280898876404,0.9774647887323944,0.9774011299435028,0.9801699716713881,0.9801136363636364,0.98005698005698,0.98,0.9799426934097422,0.9798850574712644,0.9798270893371758,0.9797687861271677,0.9797101449275363,0.9796511627906976,0.9795918367346939,0.97953216374269,0.9794721407624634,0.9794117647058823,0.9793510324483776,0.9792899408284024,0.9792284866468842,0.9791666666666666,0.9791044776119403,0.9790419161676647,0.978978978978979,0.9789156626506024,0.9788519637462235,0.9787878787878788,0.9787234042553191,0.9786585365853658,0.9785932721712538,0.9785276073619632,0.9784615384615385,0.9783950617283951,0.978328173374613,0.9782608695652174,0.9781931464174455,0.978125,0.9780564263322884,0.9779874213836478,0.9779179810725552,0.9778481012658228,0.9777777777777777,0.9777070063694268,0.9776357827476039,0.9775641025641025,0.977491961414791,0.9774193548387097,0.9773462783171522,0.9805194805194806,0.9804560260586319,0.9803921568627451,0.980327868852459,0.9802631578947368,0.9801980198019802,0.9801324503311258,0.9800664451827242,0.98,0.979933110367893,0.9798657718120806,0.9797979797979798,0.9797297297297297,0.9796610169491525,0.9795918367346939,0.9795221843003413,0.9794520547945206,0.979381443298969,0.9827586206896551,0.9826989619377162,0.9826388888888888,0.9825783972125436,0.9825174825174825,0.9824561403508771,0.9823943661971831,0.9823321554770318,0.9822695035460993,0.9822064056939501,0.9821428571428571,0.982078853046595,0.9820143884892086,0.9819494584837545,0.9818840579710145,0.9818181818181818,0.9817518248175182,0.9816849816849816,0.9816176470588235,0.981549815498155,0.9814814814814815,0.9814126394052045,0.9813432835820896,0.9812734082397003,0.981203007518797,0.9811320754716981,0.9810606060606061,0.9809885931558935,0.9809160305343512,0.9808429118773946,0.9807692307692307,0.9806949806949807,0.9806201550387597,0.980544747081712,0.98046875,0.9803921568627451,0.9803149606299213,0.9802371541501976,0.9801587301587301,0.9800796812749004,0.98,0.9799196787148594,0.9798387096774194,0.979757085020243,0.9796747967479674,0.9795918367346939,0.9795081967213115,0.9794238683127572,0.9793388429752066,0.979253112033195,0.9791666666666666,0.9790794979079498,0.9789915966386554,0.9789029535864979,0.9788135593220338,0.9787234042553191,0.9786324786324786,0.9785407725321889,0.978448275862069,0.9783549783549783,0.9782608695652174,0.9781659388646288,0.9780701754385965,0.9779735682819384,0.9778761061946902,0.9777777777777777,0.9776785714285714,0.9775784753363229,0.9774774774774775,0.9773755656108597,0.9772727272727273,0.9771689497716894,0.9770642201834863,0.9769585253456221,0.9768518518518519,0.9767441860465116,0.9766355140186916,0.9765258215962441,0.9764150943396226,0.976303317535545,0.9761904761904762,0.9760765550239234,0.9807692307692307,0.9806763285024155,0.9805825242718447,0.9804878048780488,0.9803921568627451,0.9802955665024631,0.9801980198019802,0.9800995024875622,0.98,0.9798994974874372,0.9797979797979798,0.9796954314720813,0.9795918367346939,0.9794871794871794,0.979381443298969,0.9792746113989638,0.9791666666666666,0.9790575916230366,0.9789473684210527,0.9788359788359788,0.9787234042553191,0.9786096256684492,0.978494623655914,0.9783783783783784,0.9782608695652174,0.9781420765027322,0.978021978021978,0.9779005524861878,0.9777777777777777,0.9776536312849162,0.9775280898876404,0.9774011299435028,0.9772727272727273,0.9828571428571429,0.9827586206896551,0.9826589595375722,0.9825581395348837,0.9824561403508771,0.9823529411764705,0.9822485207100592,0.9821428571428571,0.9820359281437125,0.9819277108433735,0.9818181818181818,0.9817073170731707,0.9815950920245399,0.9814814814814815,0.9813664596273292,0.98125,0.9811320754716981,0.9810126582278481,0.9808917197452229,0.9807692307692307,0.9806451612903225,0.987012987012987,0.9869281045751634,0.9868421052631579,0.9867549668874173,0.9866666666666667,0.9865771812080537,0.9864864864864865,0.9863945578231292,0.9863013698630136,0.9862068965517241,0.9861111111111112,0.986013986013986,0.9859154929577465,0.9858156028368794,0.9857142857142858,0.9856115107913669,0.9855072463768116,0.9854014598540146,0.9852941176470589,0.9851851851851852,0.9850746268656716,0.9849624060150376,0.9848484848484849,0.9847328244274809,0.9846153846153847,0.9844961240310077,0.984375,0.984251968503937,0.9841269841269841,0.984,0.9838709677419355,0.983739837398374,0.9836065573770492,0.9834710743801653,0.9833333333333333,0.9831932773109243,0.9830508474576272,0.9829059829059829,0.9827586206896551,0.9826086956521739,0.9824561403508771,0.9823008849557522,0.9821428571428571,0.9818181818181818,0.981651376146789,0.9814814814814815,0.9813084112149533,0.9811320754716981,0.9904761904761905,0.9903846153846154,0.9902912621359223,0.9901960784313726,0.9900990099009901,0.99,0.98989898989899,0.9897959183673469,0.9896907216494846,0.9895833333333334,0.9894736842105263,0.9893617021276596,0.9891304347826086,0.989010989010989,0.9888888888888889,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],"yaxis":"y"}],"layout":{"height":600,"legend":{"tracegroupgap":0},"shapes":[{"line":{"dash":"dash"},"type":"line","x0":0,"x1":1,"y0":1,"y1":0}],"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"title":{"text":"Precision-Recall Curve (AUC=0.8985)"},"width":800,"xaxis":{"anchor":"y","constrain":"domain","domain":[0,1],"title":{"text":"Recall"}},"yaxis":{"anchor":"x","domain":[0,1],"scaleanchor":"x","scaleratio":1,"title":{"text":"Precision"}}}},"text/html":["<div>                            <div id=\"1a7f326e-e78e-4209-be6c-ffaa43fec570\" class=\"plotly-graph-div\" style=\"height:600px; width:800px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"1a7f326e-e78e-4209-be6c-ffaa43fec570\")) {                    Plotly.newPlot(                        \"1a7f326e-e78e-4209-be6c-ffaa43fec570\",                        [{\"fillpattern\":{\"shape\":\"\"},\"hovertemplate\":\"Recall=%{x}\\u003cbr\\u003ePrecision=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"stackgroup\":\"1\",\"x\":[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9980638915779284,0.9980638915779284,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9932236205227493,0.9922555663117134,0.9922555663117134,0.9922555663117134,0.9922555663117134,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.989351403678606,0.989351403678606,0.9883833494675702,0.9883833494675702,0.9874152952565344,0.9874152952565344,0.9874152952565344,0.9864472410454985,0.9854791868344628,0.9845111326234269,0.9835430784123911,0.9825750242013552,0.9825750242013552,0.9816069699903195,0.9816069699903195,0.9806389157792836,0.9806389157792836,0.9806389157792836,0.9806389157792836,0.9806389157792836,0.9806389157792836,0.9806389157792836,0.9806389157792836,0.9806389157792836,0.9806389157792836,0.9806389157792836,0.9806389157792836,0.9806389157792836,0.9806389157792836,0.9796708615682478,0.978702807357212,0.9777347531461762,0.9777347531461762,0.9767666989351403,0.9767666989351403,0.9757986447241046,0.9757986447241046,0.9748305905130688,0.9748305905130688,0.9748305905130688,0.9738625363020329,0.9738625363020329,0.972894482090997,0.9719264278799613,0.9719264278799613,0.9719264278799613,0.9719264278799613,0.9719264278799613,0.9719264278799613,0.9719264278799613,0.9719264278799613,0.9709583736689255,0.9699903194578896,0.9690222652468539,0.9690222652468539,0.9690222652468539,0.968054211035818,0.968054211035818,0.9670861568247822,0.9670861568247822,0.9670861568247822,0.9670861568247822,0.9670861568247822,0.9670861568247822,0.9670861568247822,0.9670861568247822,0.9670861568247822,0.9670861568247822,0.9661181026137464,0.9651500484027106,0.9641819941916747,0.9641819941916747,0.9641819941916747,0.9641819941916747,0.9641819941916747,0.9641819941916747,0.9632139399806389,0.9622458857696031,0.9612778315585673,0.9612778315585673,0.9612778315585673,0.9612778315585673,0.9603097773475314,0.9603097773475314,0.9593417231364957,0.9593417231364957,0.9583736689254598,0.9583736689254598,0.957405614714424,0.9564375605033882,0.9564375605033882,0.9554695062923524,0.9554695062923524,0.9554695062923524,0.9545014520813165,0.9545014520813165,0.9535333978702807,0.952565343659245,0.952565343659245,0.9515972894482091,0.9506292352371732,0.9496611810261375,0.9496611810261375,0.9486931268151017,0.9477250726040658,0.9477250726040658,0.9477250726040658,0.9477250726040658,0.9467570183930301,0.9457889641819942,0.9448209099709584,0.9438528557599225,0.9438528557599225,0.9438528557599225,0.9438528557599225,0.9438528557599225,0.9438528557599225,0.9428848015488868,0.9428848015488868,0.9428848015488868,0.9419167473378509,0.9409486931268151,0.9399806389157793,0.9399806389157793,0.9390125847047435,0.9390125847047435,0.9380445304937076,0.9370764762826719,0.936108422071636,0.9351403678606002,0.9341723136495643,0.9341723136495643,0.9341723136495643,0.9332042594385286,0.9322362052274927,0.9312681510164569,0.9312681510164569,0.9303000968054211,0.9293320425943853,0.9293320425943853,0.9283639883833494,0.9283639883833494,0.9273959341723137,0.9273959341723137,0.9273959341723137,0.9264278799612778,0.925459825750242,0.9244917715392061,0.9235237173281704,0.9225556631171346,0.9215876089060987,0.920619554695063,0.920619554695063,0.9196515004840271,0.9196515004840271,0.9186834462729913,0.9177153920619555,0.9167473378509197,0.9167473378509197,0.9157792836398838,0.914811229428848,0.9138431752178122,0.9138431752178122,0.9138431752178122,0.9128751210067764,0.9119070667957405,0.9119070667957405,0.9119070667957405,0.9109390125847048,0.9099709583736689,0.9090029041626331,0.9080348499515973,0.9070667957405615,0.9060987415295256,0.9051306873184899,0.904162633107454,0.9031945788964182,0.9031945788964182,0.9031945788964182,0.9022265246853823,0.9012584704743466,0.9002904162633107,0.8993223620522749,0.8993223620522749,0.8983543078412392,0.8973862536302033,0.8973862536302033,0.8964181994191674,0.8954501452081317,0.8954501452081317,0.8944820909970959,0.8944820909970959,0.89351403678606,0.8925459825750242,0.8915779283639884,0.8915779283639884,0.8915779283639884,0.8906098741529526,0.8896418199419167,0.888673765730881,0.888673765730881,0.8877057115198451,0.8877057115198451,0.8877057115198451,0.8867376573088093,0.8857696030977735,0.8857696030977735,0.8848015488867377,0.8838334946757018,0.882865440464666,0.8818973862536302,0.8809293320425944,0.8809293320425944,0.8799612778315585,0.8789932236205228,0.8780251694094869,0.8780251694094869,0.8770571151984511,0.8760890609874153,0.8760890609874153,0.8760890609874153,0.8760890609874153,0.8760890609874153,0.8760890609874153,0.8751210067763795,0.8741529525653436,0.8731848983543078,0.8731848983543078,0.8731848983543078,0.872216844143272,0.8712487899322362,0.8702807357212003,0.8693126815101646,0.8683446272991288,0.8673765730880929,0.8664085188770572,0.8664085188770572,0.8654404646660213,0.8654404646660213,0.8644724104549855,0.8644724104549855,0.8635043562439496,0.8625363020329139,0.8625363020329139,0.861568247821878,0.8606001936108422,0.8606001936108422,0.8596321393998064,0.8596321393998064,0.8586640851887706,0.8576960309777347,0.856727976766699,0.8557599225556631,0.8547918683446273,0.8538238141335914,0.8538238141335914,0.8528557599225557,0.8518877057115198,0.850919651500484,0.850919651500484,0.8499515972894482,0.8489835430784124,0.8480154888673765,0.8470474346563408,0.8470474346563408,0.846079380445305,0.846079380445305,0.8451113262342691,0.8451113262342691,0.8441432720232332,0.8441432720232332,0.8431752178121975,0.8431752178121975,0.8422071636011617,0.8422071636011617,0.8422071636011617,0.8412391093901258,0.8402710551790901,0.8402710551790901,0.8393030009680542,0.8393030009680542,0.8393030009680542,0.8383349467570184,0.8373668925459826,0.8373668925459826,0.8363988383349468,0.8354307841239109,0.8354307841239109,0.8344627299128751,0.8334946757018393,0.8325266214908035,0.8315585672797676,0.8305905130687319,0.829622458857696,0.829622458857696,0.829622458857696,0.8286544046466602,0.8276863504356244,0.8267182962245886,0.8257502420135527,0.8247821878025169,0.8238141335914811,0.8228460793804453,0.8228460793804453,0.8228460793804453,0.8218780251694094,0.8209099709583737,0.8199419167473379,0.818973862536302,0.8180058083252663,0.8170377541142304,0.8160696999031946,0.8151016456921588,0.814133591481123,0.8131655372700871,0.8121974830590513,0.8112294288480155,0.8102613746369797,0.8102613746369797,0.8092933204259438,0.8092933204259438,0.8083252662149081,0.8083252662149081,0.8073572120038722,0.8063891577928364,0.8063891577928364,0.8054211035818006,0.8044530493707648,0.8034849951597289,0.8034849951597289,0.8034849951597289,0.8025169409486931,0.8015488867376573,0.8005808325266215,0.7996127783155856,0.7986447241045499,0.7986447241045499,0.797676669893514,0.7967086156824782,0.7967086156824782,0.7957405614714425,0.7947725072604066,0.7938044530493708,0.7928363988383349,0.7918683446272992,0.7918683446272992,0.7909002904162633,0.7909002904162633,0.7899322362052275,0.7899322362052275,0.7899322362052275,0.7889641819941917,0.7879961277831559,0.78702807357212,0.78702807357212,0.7860600193610843,0.7860600193610843,0.7860600193610843,0.7850919651500484,0.7850919651500484,0.7850919651500484,0.7850919651500484,0.7841239109390126,0.7831558567279767,0.782187802516941,0.7812197483059051,0.7802516940948693,0.7792836398838335,0.7792836398838335,0.7783155856727977,0.7773475314617618,0.7763794772507261,0.7754114230396902,0.7744433688286544,0.7734753146176185,0.7725072604065828,0.771539206195547,0.7705711519845111,0.7696030977734754,0.7686350435624395,0.7676669893514037,0.7666989351403679,0.7657308809293321,0.7647628267182962,0.7637947725072604,0.7628267182962246,0.7618586640851888,0.7608906098741529,0.7599225556631172,0.7589545014520813,0.7579864472410455,0.7570183930300097,0.7560503388189739,0.755082284607938,0.7541142303969022,0.7531461761858664,0.7521781219748306,0.7521781219748306,0.7512100677637947,0.750242013552759,0.7492739593417231,0.7483059051306873,0.7483059051306873,0.7473378509196515,0.7463697967086157,0.7454017424975798,0.744433688286544,0.7434656340755083,0.7424975798644724,0.7415295256534365,0.7405614714424008,0.7405614714424008,0.739593417231365,0.739593417231365,0.7386253630203291,0.7376573088092934,0.7366892545982575,0.7357212003872217,0.7347531461761858,0.7337850919651501,0.7328170377541142,0.7318489835430784,0.7318489835430784,0.7308809293320426,0.7308809293320426,0.7299128751210068,0.7299128751210068,0.7289448209099709,0.7279767666989352,0.7270087124878993,0.7270087124878993,0.7260406582768635,0.7250726040658277,0.7241045498547919,0.723136495643756,0.7221684414327202,0.7212003872216844,0.7202323330106486,0.7192642787996127,0.718296224588577,0.718296224588577,0.718296224588577,0.7173281703775412,0.7163601161665053,0.7153920619554696,0.7144240077444337,0.7134559535333979,0.712487899322362,0.7115198451113263,0.7105517909002904,0.7095837366892546,0.7086156824782188,0.707647628267183,0.7066795740561471,0.7057115198451114,0.7047434656340755,0.7037754114230397,0.7028073572120038,0.7018393030009681,0.7018393030009681,0.7008712487899322,0.6999031945788964,0.6989351403678606,0.6989351403678606,0.6979670861568248,0.6969990319457889,0.6969990319457889,0.6960309777347532,0.6950629235237173,0.6940948693126815,0.6931268151016456,0.6921587608906099,0.691190706679574,0.6902226524685382,0.6892545982575025,0.6882865440464666,0.6873184898354308,0.686350435624395,0.6853823814133592,0.6844143272023233,0.6834462729912875,0.6824782187802517,0.6815101645692159,0.68054211035818,0.6795740561471443,0.6786060019361084,0.6776379477250726,0.6776379477250726,0.6766698935140368,0.675701839303001,0.6747337850919651,0.6737657308809293,0.6737657308809293,0.6727976766698935,0.6718296224588577,0.6708615682478218,0.6698935140367861,0.6698935140367861,0.6689254598257502,0.6679574056147144,0.6669893514036787,0.6660212971926428,0.665053242981607,0.6640851887705711,0.6631171345595354,0.6621490803484995,0.6621490803484995,0.6611810261374637,0.6602129719264279,0.6592449177153921,0.6592449177153921,0.6582768635043562,0.6573088092933205,0.6563407550822846,0.6553727008712488,0.6544046466602129,0.6544046466602129,0.6534365924491772,0.6524685382381413,0.6515004840271055,0.6505324298160697,0.6495643756050339,0.648596321393998,0.6476282671829623,0.6466602129719264,0.6456921587608906,0.6447241045498547,0.643756050338819,0.643756050338819,0.6427879961277831,0.6418199419167473,0.6418199419167473,0.6418199419167473,0.6408518877057116,0.6398838334946757,0.6389157792836399,0.6379477250726041,0.6369796708615683,0.6360116166505324,0.6350435624394967,0.6340755082284608,0.633107454017425,0.6321393998063891,0.6321393998063891,0.6311713455953534,0.6302032913843175,0.6292352371732817,0.6282671829622459,0.6282671829622459,0.6282671829622459,0.6272991287512101,0.6263310745401742,0.6253630203291385,0.6243949661181026,0.6234269119070668,0.6224588576960309,0.6224588576960309,0.6214908034849952,0.6205227492739593,0.6195546950629235,0.6185866408518877,0.6176185866408519,0.616650532429816,0.6156824782187803,0.6147144240077445,0.6137463697967086,0.6127783155856728,0.611810261374637,0.6108422071636012,0.6098741529525653,0.6089060987415296,0.6079380445304937,0.6069699903194579,0.6060019361084221,0.6050338818973863,0.6040658276863504,0.6030977734753146,0.6021297192642788,0.601161665053243,0.6001936108422071,0.5992255566311714,0.5982575024201355,0.5982575024201355,0.5972894482090997,0.5963213939980639,0.5953533397870281,0.5943852855759922,0.5943852855759922,0.5934172313649564,0.5934172313649564,0.5924491771539206,0.5914811229428848,0.590513068731849,0.5895450145208132,0.5885769603097774,0.5876089060987415,0.5866408518877058,0.5856727976766699,0.5847047434656341,0.5837366892545982,0.5827686350435625,0.5818005808325266,0.5808325266214908,0.579864472410455,0.5788964181994192,0.5779283639883833,0.5769603097773476,0.5769603097773476,0.5759922555663117,0.5759922555663117,0.5750242013552759,0.57405614714424,0.57405614714424,0.5730880929332043,0.5721200387221684,0.5711519845111326,0.5701839303000968,0.569215876089061,0.5682478218780251,0.5672797676669894,0.5663117134559535,0.5653436592449177,0.5643756050338818,0.5634075508228461,0.5624394966118103,0.5614714424007744,0.5614714424007744,0.5605033881897387,0.5595353339787028,0.5595353339787028,0.558567279767667,0.5575992255566312,0.5566311713455954,0.5556631171345595,0.5546950629235237,0.5537270087124879,0.5527589545014521,0.5517909002904162,0.5508228460793805,0.5498547918683446,0.5498547918683446,0.5488867376573088,0.547918683446273,0.5469506292352372,0.5459825750242013,0.5450145208131656,0.5440464666021297,0.5430784123910939,0.5430784123910939,0.542110358180058,0.5411423039690223,0.5401742497579864,0.5401742497579864,0.5392061955469506,0.5382381413359149,0.537270087124879,0.5363020329138432,0.5353339787028074,0.5343659244917716,0.5333978702807357,0.5324298160696999,0.5314617618586641,0.5304937076476283,0.5295256534365924,0.5285575992255567,0.5275895450145208,0.526621490803485,0.5256534365924492,0.5246853823814134,0.5237173281703775,0.5227492739593417,0.5217812197483059,0.5217812197483059,0.5208131655372701,0.5198451113262342,0.5198451113262342,0.5198451113262342,0.5188770571151985,0.5179090029041626,0.5169409486931268,0.515972894482091,0.5150048402710552,0.5140367860600193,0.5130687318489835,0.5121006776379478,0.5111326234269119,0.510164569215876,0.5091965150048403,0.5082284607938045,0.5072604065827686,0.5062923523717329,0.505324298160697,0.5043562439496612,0.5033881897386253,0.5033881897386253,0.5024201355275896,0.5014520813165537,0.5004840271055179,0.5004840271055179,0.4995159728944821,0.4985479186834463,0.4975798644724105,0.49661181026137463,0.49564375605033884,0.494675701839303,0.4937076476282672,0.4927395934172314,0.49177153920619554,0.49080348499515974,0.4898354307841239,0.4888673765730881,0.4878993223620523,0.48693126815101645,0.48596321393998065,0.4849951597289448,0.484027105517909,0.4830590513068732,0.48209099709583736,0.48112294288480156,0.4801548886737657,0.4791868344627299,0.4782187802516941,0.47725072604065827,0.4762826718296225,0.4753146176185866,0.4743465634075508,0.47337850919651503,0.4724104549854792,0.4714424007744434,0.47047434656340753,0.46950629235237173,0.46853823814133594,0.4675701839303001,0.4666021297192643,0.46563407550822844,0.46466602129719264,0.46369796708615685,0.462729912875121,0.4617618586640852,0.46079380445304935,0.45982575024201355,0.45885769603097776,0.4578896418199419,0.4569215876089061,0.45595353339787026,0.45498547918683446,0.45401742497579867,0.4530493707647628,0.452081316553727,0.45111326234269117,0.45014520813165537,0.4491771539206196,0.4482090997095837,0.44724104549854793,0.4462729912875121,0.4453049370764763,0.4443368828654405,0.44336882865440463,0.44240077444336884,0.441432720232333,0.4404646660212972,0.4394966118102614,0.43852855759922554,0.43852855759922554,0.43756050338818975,0.4365924491771539,0.4356243949661181,0.4346563407550823,0.43368828654404645,0.43272023233301066,0.4317521781219748,0.430784123910939,0.4298160696999032,0.42884801548886736,0.42884801548886736,0.42787996127783157,0.4269119070667957,0.4259438528557599,0.4249757986447241,0.42400774443368827,0.4230396902226525,0.4220716360116166,0.42110358180058083,0.42013552758954503,0.4191674733785092,0.4181994191674734,0.41723136495643753,0.41626331074540174,0.41529525653436594,0.4143272023233301,0.4133591481122943,0.41239109390125844,0.41142303969022265,0.41045498547918685,0.41045498547918685,0.409486931268151,0.4085188770571152,0.4075508228460794,0.40658276863504356,0.40561471442400776,0.4046466602129719,0.4036786060019361,0.4027105517909003,0.40174249757986447,0.40077444336882867,0.3998063891577928,0.398838334946757,0.3978702807357212,0.3969022265246854,0.3959341723136496,0.39496611810261373,0.39496611810261373,0.39399806389157793,0.39303000968054214,0.3920619554695063,0.3910939012584705,0.39012584704743464,0.38915779283639884,0.38818973862536305,0.3872216844143272,0.3862536302032914,0.38528557599225555,0.38431752178121975,0.38334946757018395,0.3823814133591481,0.3814133591481123,0.38044530493707646,0.37947725072604066,0.37850919651500486,0.377541142303969,0.3765730880929332,0.37560503388189737,0.37463697967086157,0.3736689254598258,0.3727008712487899,0.3717328170377541,0.3707647628267183,0.3697967086156825,0.3688286544046467,0.36786060019361083,0.36689254598257504,0.3659244917715392,0.3649564375605034,0.3639883833494676,0.36302032913843174,0.36205227492739595,0.3610842207163601,0.3601161665053243,0.3591481122942885,0.35818005808325265,0.35721200387221685,0.356243949661181,0.3552758954501452,0.3543078412391094,0.35333978702807356,0.35237173281703776,0.3514036786060019,0.3504356243949661,0.3494675701839303,0.34849951597289447,0.3475314617618587,0.3465634075508228,0.345595353339787,0.34462729912875123,0.3436592449177154,0.3426911907066796,0.34172313649564373,0.34075508228460794,0.33978702807357214,0.3388189738625363,0.3378509196515005,0.33688286544046464,0.33591481122942884,0.33494675701839305,0.33494675701839305,0.3339787028073572,0.3330106485963214,0.33204259438528555,0.33107454017424975,0.33010648596321396,0.3291384317521781,0.3281703775411423,0.32720232333010646,0.32623426911907066,0.32526621490803487,0.324298160696999,0.3233301064859632,0.32236205227492737,0.3213939980638916,0.3204259438528558,0.3194578896418199,0.31848983543078413,0.31752178121974833,0.3165537270087125,0.3155856727976767,0.31461761858664083,0.31364956437560504,0.31268151016456924,0.3117134559535334,0.3107454017424976,0.30977734753146174,0.30880929332042595,0.30784123910939015,0.3068731848983543,0.3059051306873185,0.30493707647628265,0.30396902226524686,0.30300096805421106,0.3020329138431752,0.3010648596321394,0.30009680542110356,0.29912875121006777,0.29816069699903197,0.2971926427879961,0.2962245885769603,0.2952565343659245,0.2942884801548887,0.2933204259438529,0.29235237173281703,0.29235237173281703,0.29138431752178123,0.2904162633107454,0.2894482090997096,0.2884801548886738,0.28751210067763794,0.28654404646660214,0.2855759922555663,0.2846079380445305,0.2836398838334947,0.28267182962245885,0.28170377541142305,0.2807357212003872,0.2797676669893514,0.2787996127783156,0.27783155856727976,0.27686350435624396,0.2758954501452081,0.2758954501452081,0.2749273959341723,0.2739593417231365,0.27299128751210067,0.27202323330106487,0.271055179090029,0.2700871248789932,0.2691190706679574,0.2681510164569216,0.2671829622458858,0.26621490803484993,0.26524685382381413,0.26427879961277834,0.2633107454017425,0.2623426911907067,0.26137463697967084,0.26040658276863504,0.25943852855759925,0.2584704743465634,0.2575024201355276,0.25653436592449175,0.25556631171345595,0.25459825750242016,0.2536302032913843,0.2526621490803485,0.25169409486931266,0.25072604065827686,0.24975798644724104,0.24878993223620524,0.24782187802516942,0.2468538238141336,0.24588576960309777,0.24491771539206195,0.24394966118102615,0.24298160696999033,0.2420135527589545,0.24104549854791868,0.24007744433688286,0.23910939012584706,0.23814133591481124,0.2371732817037754,0.2362052274927396,0.23523717328170377,0.23426911907066797,0.23330106485963215,0.23233301064859632,0.2313649564375605,0.23039690222652467,0.22942884801548888,0.22846079380445306,0.22749273959341723,0.2265246853823814,0.22555663117134558,0.2245885769603098,0.22362052274927396,0.22265246853823814,0.22168441432720232,0.2207163601161665,0.2197483059051307,0.21878025169409487,0.21781219748305905,0.21684414327202323,0.2158760890609874,0.2149080348499516,0.21393998063891578,0.21297192642787996,0.21200387221684414,0.2110358180058083,0.21006776379477252,0.2090997095837367,0.20813165537270087,0.20716360116166505,0.20619554695062922,0.20522749273959343,0.2042594385285576,0.20329138431752178,0.20232333010648595,0.20135527589545016,0.20038722168441434,0.1994191674733785,0.1984511132623427,0.19748305905130686,0.19748305905130686,0.19651500484027107,0.19554695062923524,0.19457889641819942,0.1936108422071636,0.19264278799612777,0.19167473378509198,0.19070667957405615,0.18973862536302033,0.1887705711519845,0.18780251694094868,0.1868344627299129,0.18586640851887706,0.18489835430784124,0.18393030009680542,0.1829622458857696,0.1819941916747338,0.18102613746369797,0.18005808325266215,0.17909002904162633,0.1781219748305905,0.1771539206195547,0.17618586640851888,0.17521781219748306,0.17424975798644723,0.1732817037754114,0.17231364956437561,0.1713455953533398,0.17037754114230397,0.16940948693126814,0.16844143272023232,0.16747337850919652,0.1665053242981607,0.1665053242981607,0.16553727008712488,0.16456921587608905,0.16360116166505323,0.16263310745401743,0.1616650532429816,0.1606969990319458,0.15972894482090996,0.15876089060987417,0.15779283639883834,0.15682478218780252,0.1558567279767667,0.15488867376573087,0.15392061955469508,0.15295256534365925,0.15198451113262343,0.1510164569215876,0.15004840271055178,0.14908034849951599,0.14811229428848016,0.14714424007744434,0.14714424007744434,0.14617618586640851,0.1452081316553727,0.1442400774443369,0.14327202323330107,0.14230396902226525,0.14133591481122942,0.1403678606001936,0.1393998063891578,0.13843175217812198,0.13746369796708616,0.13649564375605033,0.1355275895450145,0.1345595353339787,0.1335914811229429,0.13262342691190707,0.13165537270087124,0.13068731848983542,0.12971926427879962,0.1287512100677638,0.12778315585672798,0.12681510164569215,0.12584704743465633,0.12487899322362052,0.12391093901258471,0.12294288480154889,0.12197483059051308,0.12100677637947725,0.12003872216844143,0.11907066795740562,0.1181026137463698,0.11713455953533398,0.11616650532429816,0.11519845111326234,0.11423039690222653,0.1132623426911907,0.1122942884801549,0.11132623426911907,0.11035818005808325,0.10939012584704744,0.10842207163601161,0.1074540174249758,0.10648596321393998,0.10454985479186835,0.10358180058083252,0.10261374636979671,0.10164569215876089,0.10067763794772508,0.10067763794772508,0.09970958373668926,0.09874152952565343,0.09777347531461762,0.0968054211035818,0.09583736689254599,0.09486931268151017,0.09390125847047434,0.09293320425943853,0.09196515004840271,0.0909970958373669,0.09002904162633107,0.08809293320425944,0.08712487899322362,0.08615682478218781,0.08615682478218781,0.08518877057115198,0.08422071636011616,0.08131655372700872,0.0803484995159729,0.07938044530493708,0.07841239109390126,0.07744433688286544,0.07647628267182963,0.0755082284607938,0.07454017424975799,0.07357212003872217,0.07260406582768635,0.07163601161665054,0.07066795740561471,0.0696999031945789,0.06873184898354308,0.06776379477250725,0.06582768635043562,0.06485963213939981,0.06389157792836399,0.061955469506292354,0.06098741529525654,0.060019361084220714,0.0590513068731849,0.05808325266214908,0.057115198451113264,0.05517909002904162,0.05421103581800581,0.05324298160696999,0.05227492739593417,0.051306873184898356,0.05033881897386254,0.049370764762826716,0.04743465634075508,0.046466602129719266,0.04549854791868345,0.04259438528557599,0.041626331074540175,0.04065827686350436,0.03969022265246854,0.0377541142303969,0.03581800580832527,0.03484995159728945,0.03388189738625363,0.03291384317521781,0.031945788964181994,0.030977734753146177,0.030009680542110357,0.02904162633107454,0.028073572120038724,0.026137463697967087,0.02516940948693127,0.02420135527589545,0.021297192642787996,0.02032913843175218,0.01936108422071636,0.018393030009680542,0.017424975798644726,0.015488867376573089,0.01452081316553727,0.0],\"xaxis\":\"x\",\"y\":[0.7341862117981521,0.7347083926031295,0.7352313167259786,0.7357549857549858,0.7362794012829651,0.7368045649072753,0.7373304782298359,0.7378571428571429,0.7383845604002859,0.7389127324749643,0.7394416607015032,0.7399713467048711,0.7405017921146954,0.7410329985652798,0.741564967695621,0.7420977011494253,0.7426312005751258,0.7431654676258993,0.7437005039596832,0.7442363112391931,0.7447728911319395,0.7453102453102453,0.7458483754512636,0.7463872832369942,0.7469269703543022,0.7474674384949349,0.7480086893555394,0.7485507246376811,0.7490935460478607,0.7496371552975326,0.7501815541031227,0.7507267441860465,0.7512727272727273,0.7518195050946143,0.752367079388201,0.7529154518950437,0.7534646243617797,0.754014598540146,0.7545653761869978,0.7551169590643275,0.7556693489392831,0.7562225475841874,0.7567765567765568,0.7573313782991202,0.7578870139398386,0.7584434654919237,0.7590007347538574,0.7595588235294117,0.7601177336276674,0.7606774668630338,0.7612380250552689,0.7617994100294986,0.7623616236162362,0.7629246676514032,0.7634885439763488,0.7640532544378699,0.764618800888231,0.7651851851851852,0.765752409191994,0.766320474777448,0.7668893838158871,0.7674591381872214,0.7680297397769517,0.7686011904761905,0.7691734921816828,0.7697466467958272,0.7703206562266965,0.7708955223880597,0.7714712471994025,0.7720478325859492,0.7726252804786836,0.7732035928143712,0.7737827715355805,0.7743628185907047,0.7749437359339835,0.7755255255255256,0.7761081893313299,0.7766917293233083,0.7772761474793077,0.7778614457831325,0.7784476262245666,0.7790346907993967,0.779622641509434,0.7802114803625377,0.780801209372638,0.7806354009077155,0.781226343679031,0.7818181818181819,0.7824109173616376,0.7830045523520486,0.7835990888382688,0.78419452887538,0.7847908745247149,0.7853881278538812,0.785986290936786,0.7865853658536586,0.7871853546910755,0.7877862595419848,0.7883880825057296,0.7889908256880734,0.7895944912012242,0.7901990811638591,0.7908045977011494,0.7906441717791411,0.7912509593246354,0.7910906298003072,0.7916986933128363,0.7923076923076923,0.7929176289453426,0.7927580893682589,0.7933693138010794,0.7939814814814815,0.7945945945945946,0.7952086553323029,0.7958236658932715,0.7964396284829721,0.7970565453137103,0.7976744186046512,0.7982932505818464,0.7989130434782609,0.7995337995337995,0.7993779160186625,0.8,0.8006230529595015,0.8012470771628994,0.8018720748829953,0.8024980483996877,0.803125,0.8037529319781079,0.8043818466353677,0.8050117462803446,0.8056426332288401,0.8062745098039216,0.8069073783359497,0.8075412411626081,0.8081761006289309,0.8088119590873328,0.8094488188976378,0.8100866824271079,0.8107255520504731,0.8113654301499605,0.8120063191153238,0.8126482213438735,0.8132911392405063,0.8131433095803642,0.8137876386687797,0.8144329896907216,0.8150793650793651,0.8157267672756155,0.8163751987281399,0.817024661893397,0.8176751592356688,0.8183266932270916,0.8189792663476874,0.819632881085395,0.8194888178913738,0.8193445243804957,0.82,0.8206565252201762,0.8213141025641025,0.8211708099438653,0.8218298555377207,0.8224899598393575,0.8231511254019293,0.8238133547868061,0.8244766505636071,0.8251410153102336,0.8258064516129032,0.8264729620661824,0.827140549273021,0.8278092158447857,0.8284789644012945,0.8291497975708502,0.8298217179902755,0.8304947283049473,0.8303571428571429,0.8310316815597075,0.8317073170731707,0.8323840520748577,0.8330618892508144,0.8329258353708231,0.833605220228385,0.833469387755102,0.8341503267973857,0.8340147179067866,0.8346972176759411,0.8353808353808354,0.8352459016393443,0.8351107465135357,0.8349753694581281,0.8348397699260477,0.834703947368421,0.8353909465020576,0.8352553542009885,0.8359439406430338,0.8358085808580858,0.8364987613542527,0.8371900826446281,0.8378825475599669,0.8385761589403974,0.8392709196354599,0.8399668325041459,0.8406639004149378,0.8413621262458472,0.8420615128844555,0.8427620632279534,0.8434637801831807,0.8441666666666666,0.8448707256046706,0.8447412353923205,0.8446115288220551,0.8444816053511706,0.8451882845188284,0.8450586264656617,0.845766974015088,0.8456375838926175,0.8463476070528967,0.846218487394958,0.8469301934398654,0.8476430976430976,0.8475147430497051,0.8482293423271501,0.8481012658227848,0.847972972972973,0.8486897717666948,0.8494077834179357,0.8501270110076207,0.8508474576271187,0.8515691263782866,0.8522920203735145,0.8530161427357689,0.8528911564625851,0.8527659574468085,0.8526405451448041,0.8533674339300937,0.8540955631399317,0.8539709649871904,0.8547008547008547,0.8545765611633875,0.8553082191780822,0.8560411311053985,0.8567753001715266,0.8575107296137339,0.8582474226804123,0.8589853826311264,0.8597246127366609,0.8604651162790697,0.8612068965517241,0.8610871440897325,0.8609671848013817,0.8608470181503889,0.8615916955017301,0.8623376623376623,0.8630849220103987,0.8638334778837814,0.8645833333333334,0.8644656820156386,0.8643478260869565,0.8642297650130548,0.8649825783972126,0.8657367044463818,0.8664921465968587,0.8663755458515284,0.8671328671328671,0.8670166229221348,0.8677758318739054,0.8676599474145487,0.868421052631579,0.8683055311676909,0.8681898066783831,0.8689533861037819,0.8688380281690141,0.8696035242290749,0.8703703703703703,0.8702559576345984,0.8710247349823321,0.8709106984969054,0.8707964601769912,0.8715677590788308,0.8714539007092199,0.8713398402839396,0.8712255772646537,0.872,0.8718861209964412,0.8717720391807658,0.8725490196078431,0.8733273862622658,0.8741071428571429,0.8739946380697051,0.8738819320214669,0.873769024171889,0.8736559139784946,0.874439461883408,0.8752244165170556,0.876010781671159,0.8767985611510791,0.8775877587758776,0.8774774774774775,0.8782687105500451,0.8790613718411552,0.8789521228545619,0.8788426763110307,0.8787330316742081,0.8795289855072463,0.8794197642792384,0.8802177858439202,0.8801089918256131,0.88,0.8798908098271155,0.8797814207650273,0.8796718322698268,0.8804744525547445,0.8812785388127854,0.8811700182815356,0.8810612991765783,0.8809523809523809,0.8817598533455545,0.881651376146789,0.8815426997245179,0.8823529411764706,0.8822447102115916,0.8830570902394107,0.8829493087557604,0.8837638376383764,0.8845798707294552,0.8844731977818854,0.8843663274745606,0.8842592592592593,0.8841519925857275,0.8840445269016698,0.8839368616527391,0.8838289962825279,0.8846511627906977,0.8845437616387337,0.8853681267474371,0.8852611940298507,0.8851540616246498,0.8850467289719626,0.8858746492048644,0.8857677902621723,0.8856607310215557,0.8855534709193246,0.8863849765258216,0.8872180451127819,0.8871119473189087,0.8870056497175142,0.8878416588124411,0.8886792452830189,0.8885741265344664,0.888468809073724,0.8883632923368022,0.8882575757575758,0.8881516587677725,0.888045540796964,0.8879392212725546,0.8878326996197718,0.8877259752616555,0.8885714285714286,0.8894184938036225,0.8893129770992366,0.889207258834766,0.8891013384321224,0.8889952153110048,0.8898467432950191,0.8897411313518696,0.8896353166986565,0.8904899135446686,0.8903846153846153,0.890279114533205,0.8911368015414258,0.8910318225650916,0.8918918918918919,0.8917874396135266,0.8916827852998066,0.8915779283639884,0.8924418604651163,0.8933074684772065,0.8932038834951457,0.8931000971817298,0.8929961089494164,0.8938656280428432,0.8937621832358674,0.8946341463414634,0.8955078125,0.895405669599218,0.8953033268101761,0.8961802154750245,0.8960784313725491,0.8959764474975466,0.8958742632612967,0.895771878072763,0.8956692913385826,0.896551724137931,0.8964497041420119,0.8963474827245804,0.8962450592885376,0.897131552917903,0.897029702970297,0.8969276511397423,0.8978174603174603,0.8987090367428004,0.8996023856858847,0.900497512437811,0.901394422310757,0.901296111665005,0.9011976047904192,0.9010989010989011,0.902,0.9029029029029029,0.9028056112224448,0.9027081243731193,0.9026104417670683,0.9025125628140703,0.9024144869215291,0.9023162134944612,0.9022177419354839,0.9031281533804238,0.9030303030303031,0.9039433771486349,0.9038461538461539,0.9047619047619048,0.9046653144016227,0.9045685279187817,0.9054878048780488,0.9053916581892166,0.905295315682281,0.9062181447502549,0.9061224489795918,0.9070480081716037,0.9069529652351738,0.9068577277379734,0.9067622950819673,0.9066666666666666,0.9065708418891171,0.9064748201438849,0.9074074074074074,0.9073120494335737,0.9072164948453608,0.9071207430340558,0.9080578512396694,0.9079627714581179,0.9078674948240165,0.9077720207253887,0.9076763485477178,0.9086188992731049,0.9085239085239085,0.9094693028095734,0.909375,0.9103232533889468,0.9102296450939458,0.9111807732497388,0.9110878661087866,0.912041884816754,0.9119496855345912,0.912906610703043,0.9138655462184874,0.9137749737118822,0.9136842105263158,0.9146469968387777,0.9145569620253164,0.9155227032734953,0.9164904862579282,0.9164021164021164,0.9163135593220338,0.9172852598091198,0.9171974522292994,0.9171094580233794,0.9180851063829787,0.9179978700745474,0.917910447761194,0.9178228388473852,0.9177350427350427,0.9176470588235294,0.917558886509636,0.9185423365487674,0.9195278969957081,0.9194414607948442,0.9193548387096774,0.9192680301399354,0.9191810344827587,0.919093851132686,0.9190064794816415,0.918918918918919,0.9199134199134199,0.9209100758396533,0.920824295010846,0.9207383279044516,0.9206521739130434,0.9205658324265505,0.920479302832244,0.920392584514722,0.9203056768558951,0.9202185792349726,0.9201312910284464,0.9200438116100766,0.9199561403508771,0.9198682766190999,0.9197802197802197,0.9207920792079208,0.920704845814978,0.9217199558985667,0.9216335540838853,0.9226519337016574,0.922566371681416,0.9224806201550387,0.9235033259423503,0.9234184239733629,0.9233333333333333,0.9232480533926585,0.9242761692650334,0.9253065774804905,0.9252232142857143,0.9251396648044693,0.9250559284116331,0.9249720044792833,0.9248878923766816,0.9259259259259259,0.9258426966292135,0.9257592800899888,0.9268018018018018,0.9267192784667418,0.9266365688487584,0.9265536723163842,0.9264705882352942,0.9263873159682899,0.927437641723356,0.927355278093076,0.928409090909091,0.9283276450511946,0.929384965831435,0.9304446978335233,0.930365296803653,0.9302857142857143,0.9302059496567505,0.9312714776632303,0.9311926605504587,0.9322617680826636,0.9333333333333333,0.9332566168009206,0.934331797235023,0.9354094579008074,0.9364896073903002,0.9364161849710982,0.9363425925925926,0.936268829663963,0.9361948955916474,0.9361207897793263,0.936046511627907,0.9371362048894063,0.9370629370629371,0.9369894982497082,0.9369158878504673,0.9368421052631579,0.936768149882904,0.936694021101993,0.9366197183098591,0.936545240893067,0.9364705882352942,0.9363957597173145,0.9363207547169812,0.9362455726092089,0.9361702127659575,0.936094674556213,0.9360189573459715,0.9359430604982206,0.9358669833729216,0.9357907253269917,0.9357142857142857,0.9356376638855781,0.9355608591885441,0.9354838709677419,0.9354066985645934,0.9353293413173652,0.935251798561151,0.9351740696278511,0.9350961538461539,0.9350180505415162,0.936144578313253,0.9360675512665863,0.9359903381642513,0.9359129383313181,0.9358353510895884,0.936969696969697,0.9368932038834952,0.93681652490887,0.9367396593673966,0.9366626065773447,0.9365853658536586,0.9365079365079365,0.9364303178484108,0.9363525091799265,0.9375,0.9374233128834356,0.9385749385749386,0.9384993849938499,0.9384236453201971,0.938347718865598,0.9382716049382716,0.9381953028430161,0.9381188118811881,0.9380421313506815,0.9379652605459057,0.9391304347826087,0.9390547263681592,0.9402241594022416,0.940149625935162,0.9413233458177278,0.94125,0.9411764705882353,0.9411027568922306,0.9422835633626098,0.9422110552763819,0.9421383647798742,0.9420654911838791,0.9419924337957125,0.9419191919191919,0.9418457648546145,0.9417721518987342,0.9416983523447402,0.9416243654822335,0.9428208386277002,0.9440203562340967,0.9439490445859873,0.9438775510204082,0.9438058748403576,0.9437340153452686,0.9436619718309859,0.9435897435897436,0.9435173299101413,0.9434447300771208,0.9433719433719434,0.9432989690721649,0.9432258064516129,0.9431524547803618,0.943078913324709,0.9430051813471503,0.9429312581063554,0.9428571428571428,0.9427828348504551,0.9440104166666666,0.9439374185136897,0.943864229765013,0.9437908496732026,0.9450261780104712,0.944954128440367,0.9448818897637795,0.9461235216819974,0.9460526315789474,0.9459815546772069,0.945910290237467,0.9458388375165125,0.9457671957671958,0.9456953642384106,0.9456233421750663,0.9455511288180611,0.9454787234042553,0.9454061251664447,0.9453333333333334,0.945260347129506,0.9451871657754011,0.9451137884872824,0.9450402144772118,0.9449664429530201,0.9448924731182796,0.9448183041722745,0.944743935309973,0.9446693657219973,0.9459459459459459,0.945872801082544,0.94579945799458,0.9457259158751696,0.9456521739130435,0.9469387755102041,0.946866485013624,0.946793997271487,0.9467213114754098,0.9466484268125855,0.947945205479452,0.9478737997256516,0.9478021978021978,0.9477303988995873,0.9476584022038568,0.9475862068965517,0.9475138121546961,0.9474412171507607,0.9473684210526315,0.9486823855755895,0.9486111111111111,0.9485396383866481,0.9484679665738162,0.9497907949790795,0.9497206703910615,0.9496503496503497,0.9495798319327731,0.9495091164095372,0.949438202247191,0.9507735583684951,0.9507042253521126,0.9506346967559943,0.9505649717514124,0.9504950495049505,0.9504249291784702,0.950354609929078,0.9502840909090909,0.9502133712660028,0.9501424501424501,0.9500713266761769,0.95,0.9513590844062947,0.9512893982808023,0.9512195121951219,0.9525862068965517,0.9539568345323741,0.9538904899135446,0.9538239538239538,0.953757225433526,0.9536903039073806,0.9536231884057971,0.95355587808418,0.9534883720930233,0.9534206695778749,0.9533527696793003,0.9532846715328467,0.9546783625730995,0.9546120058565154,0.9545454545454546,0.9544787077826725,0.9544117647058824,0.9558173784977909,0.9572271386430679,0.9571639586410635,0.9571005917159763,0.957037037037037,0.956973293768546,0.9569093610698366,0.9568452380952381,0.9582712369597616,0.9582089552238806,0.9581464872944694,0.9580838323353293,0.9580209895052474,0.9579579579579579,0.9578947368421052,0.9578313253012049,0.9577677224736049,0.9577039274924471,0.9576399394856279,0.9575757575757575,0.9575113808801214,0.9574468085106383,0.9573820395738204,0.9573170731707317,0.9572519083969465,0.9571865443425076,0.9571209800918836,0.9570552147239264,0.956989247311828,0.9569230769230769,0.9568567026194145,0.9567901234567902,0.9567233384853169,0.9566563467492261,0.958139534883721,0.9580745341614907,0.9580093312597201,0.9579439252336449,0.9578783151326054,0.959375,0.9593114241001565,0.9608150470219435,0.9607535321821036,0.960691823899371,0.9606299212598425,0.9605678233438486,0.9605055292259084,0.9604430379746836,0.9603803486529319,0.9603174603174603,0.9602543720190779,0.9601910828025477,0.960127591706539,0.9600638977635783,0.96,0.9599358974358975,0.9598715890850722,0.9598070739549839,0.9597423510466989,0.9612903225806452,0.9612277867528272,0.9627831715210357,0.9627228525121556,0.9626623376623377,0.9642276422764228,0.9641693811074918,0.964110929853181,0.9640522875816994,0.9639934533551555,0.9639344262295082,0.9638752052545156,0.9638157894736842,0.9637561779242174,0.9636963696369637,0.9636363636363636,0.9635761589403974,0.9635157545605307,0.9634551495016611,0.9650582362728786,0.965,0.9649415692821369,0.9665551839464883,0.966499162479062,0.9664429530201343,0.9663865546218487,0.9663299663299664,0.9662731871838112,0.9662162162162162,0.9661590524534687,0.9661016949152542,0.966044142614601,0.9659863945578231,0.9676320272572402,0.9675767918088737,0.9675213675213675,0.9674657534246576,0.967409948542024,0.9673539518900344,0.9672977624784854,0.9672413793103448,0.9689119170984456,0.9688581314878892,0.9688041594454073,0.96875,0.9704347826086956,0.9703832752613241,0.9703315881326352,0.9702797202797203,0.9702276707530648,0.9701754385964912,0.9701230228471002,0.9700704225352113,0.9700176366843033,0.9699646643109541,0.9699115044247788,0.9698581560283688,0.9698046181172292,0.9697508896797153,0.9696969696969697,0.9696428571428571,0.9695885509838998,0.9695340501792115,0.9694793536804309,0.9694244604316546,0.9711711711711711,0.9711191335740073,0.9710669077757685,0.9728260869565217,0.9745916515426497,0.9745454545454545,0.9744990892531876,0.9744525547445255,0.9744058500914077,0.9743589743589743,0.9743119266055046,0.9742647058823529,0.9742173112338858,0.974169741697417,0.9741219963031423,0.9740740740740741,0.974025974025974,0.9739776951672863,0.9739292364990689,0.9738805970149254,0.9738317757009346,0.9737827715355806,0.975609756097561,0.9755639097744361,0.975517890772128,0.9754716981132076,0.9773156899810964,0.9772727272727273,0.9772296015180265,0.9771863117870723,0.9771428571428571,0.9770992366412213,0.9770554493307839,0.9770114942528736,0.9769673704414588,0.9769230769230769,0.976878612716763,0.9768339768339769,0.97678916827853,0.9767441860465116,0.9766990291262136,0.9766536964980544,0.9766081871345029,0.9765625,0.9765166340508806,0.9764705882352941,0.9764243614931237,0.9763779527559056,0.9763313609467456,0.9762845849802372,0.9762376237623762,0.9761904761904762,0.9761431411530815,0.9760956175298805,0.9760479041916168,0.976,0.9759519038076152,0.9759036144578314,0.9758551307847082,0.9758064516129032,0.9757575757575757,0.9757085020242915,0.9756592292089249,0.975609756097561,0.9755600814663951,0.9755102040816327,0.9754601226993865,0.9754098360655737,0.9753593429158111,0.9753086419753086,0.9752577319587629,0.9752066115702479,0.9751552795031055,0.975103734439834,0.975051975051975,0.975,0.9749478079331941,0.9748953974895398,0.9748427672955975,0.9747899159663865,0.9747368421052631,0.9746835443037974,0.9746300211416491,0.9745762711864406,0.9745222929936306,0.9744680851063829,0.9744136460554371,0.9743589743589743,0.974304068522484,0.9742489270386266,0.9741935483870968,0.9762931034482759,0.9762419006479481,0.9761904761904762,0.9761388286334056,0.9760869565217392,0.9760348583877996,0.9759825327510917,0.975929978118162,0.9758771929824561,0.9758241758241758,0.9757709251101322,0.977924944812362,0.9778761061946902,0.9778270509977827,0.9777777777777777,0.977728285077951,0.9776785714285714,0.9776286353467561,0.9775784753363229,0.9775280898876404,0.9774774774774775,0.9774266365688488,0.9773755656108597,0.9773242630385488,0.9772727272727273,0.9772209567198178,0.9771689497716894,0.977116704805492,0.9770642201834863,0.9770114942528736,0.9769585253456221,0.9792147806004619,0.9791666666666666,0.9791183294663574,0.9790697674418605,0.9790209790209791,0.9789719626168224,0.9789227166276346,0.9788732394366197,0.9788235294117648,0.9787735849056604,0.9787234042553191,0.9786729857819905,0.9786223277909739,0.9785714285714285,0.9785202863961814,0.9784688995215312,0.9784172661870504,0.9807692307692307,0.980722891566265,0.9806763285024155,0.9806295399515739,0.9805825242718447,0.9805352798053528,0.9804878048780488,0.980440097799511,0.9803921568627451,0.9803439803439803,0.9802955665024631,0.980246913580247,0.9801980198019802,0.9801488833746899,0.9800995024875622,0.9800498753117207,0.98,0.9799498746867168,0.9798994974874372,0.9798488664987406,0.9797979797979798,0.979746835443038,0.9796954314720813,0.9796437659033079,0.9795918367346939,0.979539641943734,0.9794871794871794,0.9794344473007712,0.979381443298969,0.979328165374677,0.9792746113989638,0.9792207792207792,0.9791666666666666,0.97911227154047,0.9790575916230366,0.979002624671916,0.9789473684210527,0.978891820580475,0.9788359788359788,0.9787798408488063,0.9787234042553191,0.9786666666666667,0.9786096256684492,0.9785522788203753,0.978494623655914,0.9784366576819407,0.9783783783783784,0.978319783197832,0.9782608695652174,0.9782016348773842,0.9781420765027322,0.9780821917808219,0.978021978021978,0.977961432506887,0.9779005524861878,0.9778393351800554,0.9777777777777777,0.9777158774373259,0.9776536312849162,0.9775910364145658,0.9775280898876404,0.9774647887323944,0.9774011299435028,0.9801699716713881,0.9801136363636364,0.98005698005698,0.98,0.9799426934097422,0.9798850574712644,0.9798270893371758,0.9797687861271677,0.9797101449275363,0.9796511627906976,0.9795918367346939,0.97953216374269,0.9794721407624634,0.9794117647058823,0.9793510324483776,0.9792899408284024,0.9792284866468842,0.9791666666666666,0.9791044776119403,0.9790419161676647,0.978978978978979,0.9789156626506024,0.9788519637462235,0.9787878787878788,0.9787234042553191,0.9786585365853658,0.9785932721712538,0.9785276073619632,0.9784615384615385,0.9783950617283951,0.978328173374613,0.9782608695652174,0.9781931464174455,0.978125,0.9780564263322884,0.9779874213836478,0.9779179810725552,0.9778481012658228,0.9777777777777777,0.9777070063694268,0.9776357827476039,0.9775641025641025,0.977491961414791,0.9774193548387097,0.9773462783171522,0.9805194805194806,0.9804560260586319,0.9803921568627451,0.980327868852459,0.9802631578947368,0.9801980198019802,0.9801324503311258,0.9800664451827242,0.98,0.979933110367893,0.9798657718120806,0.9797979797979798,0.9797297297297297,0.9796610169491525,0.9795918367346939,0.9795221843003413,0.9794520547945206,0.979381443298969,0.9827586206896551,0.9826989619377162,0.9826388888888888,0.9825783972125436,0.9825174825174825,0.9824561403508771,0.9823943661971831,0.9823321554770318,0.9822695035460993,0.9822064056939501,0.9821428571428571,0.982078853046595,0.9820143884892086,0.9819494584837545,0.9818840579710145,0.9818181818181818,0.9817518248175182,0.9816849816849816,0.9816176470588235,0.981549815498155,0.9814814814814815,0.9814126394052045,0.9813432835820896,0.9812734082397003,0.981203007518797,0.9811320754716981,0.9810606060606061,0.9809885931558935,0.9809160305343512,0.9808429118773946,0.9807692307692307,0.9806949806949807,0.9806201550387597,0.980544747081712,0.98046875,0.9803921568627451,0.9803149606299213,0.9802371541501976,0.9801587301587301,0.9800796812749004,0.98,0.9799196787148594,0.9798387096774194,0.979757085020243,0.9796747967479674,0.9795918367346939,0.9795081967213115,0.9794238683127572,0.9793388429752066,0.979253112033195,0.9791666666666666,0.9790794979079498,0.9789915966386554,0.9789029535864979,0.9788135593220338,0.9787234042553191,0.9786324786324786,0.9785407725321889,0.978448275862069,0.9783549783549783,0.9782608695652174,0.9781659388646288,0.9780701754385965,0.9779735682819384,0.9778761061946902,0.9777777777777777,0.9776785714285714,0.9775784753363229,0.9774774774774775,0.9773755656108597,0.9772727272727273,0.9771689497716894,0.9770642201834863,0.9769585253456221,0.9768518518518519,0.9767441860465116,0.9766355140186916,0.9765258215962441,0.9764150943396226,0.976303317535545,0.9761904761904762,0.9760765550239234,0.9807692307692307,0.9806763285024155,0.9805825242718447,0.9804878048780488,0.9803921568627451,0.9802955665024631,0.9801980198019802,0.9800995024875622,0.98,0.9798994974874372,0.9797979797979798,0.9796954314720813,0.9795918367346939,0.9794871794871794,0.979381443298969,0.9792746113989638,0.9791666666666666,0.9790575916230366,0.9789473684210527,0.9788359788359788,0.9787234042553191,0.9786096256684492,0.978494623655914,0.9783783783783784,0.9782608695652174,0.9781420765027322,0.978021978021978,0.9779005524861878,0.9777777777777777,0.9776536312849162,0.9775280898876404,0.9774011299435028,0.9772727272727273,0.9828571428571429,0.9827586206896551,0.9826589595375722,0.9825581395348837,0.9824561403508771,0.9823529411764705,0.9822485207100592,0.9821428571428571,0.9820359281437125,0.9819277108433735,0.9818181818181818,0.9817073170731707,0.9815950920245399,0.9814814814814815,0.9813664596273292,0.98125,0.9811320754716981,0.9810126582278481,0.9808917197452229,0.9807692307692307,0.9806451612903225,0.987012987012987,0.9869281045751634,0.9868421052631579,0.9867549668874173,0.9866666666666667,0.9865771812080537,0.9864864864864865,0.9863945578231292,0.9863013698630136,0.9862068965517241,0.9861111111111112,0.986013986013986,0.9859154929577465,0.9858156028368794,0.9857142857142858,0.9856115107913669,0.9855072463768116,0.9854014598540146,0.9852941176470589,0.9851851851851852,0.9850746268656716,0.9849624060150376,0.9848484848484849,0.9847328244274809,0.9846153846153847,0.9844961240310077,0.984375,0.984251968503937,0.9841269841269841,0.984,0.9838709677419355,0.983739837398374,0.9836065573770492,0.9834710743801653,0.9833333333333333,0.9831932773109243,0.9830508474576272,0.9829059829059829,0.9827586206896551,0.9826086956521739,0.9824561403508771,0.9823008849557522,0.9821428571428571,0.9818181818181818,0.981651376146789,0.9814814814814815,0.9813084112149533,0.9811320754716981,0.9904761904761905,0.9903846153846154,0.9902912621359223,0.9901960784313726,0.9900990099009901,0.99,0.98989898989899,0.9897959183673469,0.9896907216494846,0.9895833333333334,0.9894736842105263,0.9893617021276596,0.9891304347826086,0.989010989010989,0.9888888888888889,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Recall\"},\"constrain\":\"domain\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Precision\"},\"scaleanchor\":\"x\",\"scaleratio\":1},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Precision-Recall Curve (AUC=0.8985)\"},\"height\":600,\"width\":800,\"shapes\":[{\"line\":{\"dash\":\"dash\"},\"type\":\"line\",\"x0\":0,\"x1\":1,\"y0\":1,\"y1\":0}],\"showlegend\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('1a7f326e-e78e-4209-be6c-ffaa43fec570');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"}],"source":["target_score = forest_clf.predict_proba(features_valid)[:, 1]\n","\n","fpr, tpr, thresholds = roc_curve(target_valid, target_score)\n","\n","fig = px.area(\n","    x=fpr, y=tpr,\n","    title=f'ROC Curve (AUC={auc(fpr, tpr):.4f})',\n","    labels=dict(x='False Positive Rate', y='True Positive Rate'),\n","    width=800, height=600\n",")\n","fig.add_shape(\n","    type='line', line=dict(dash='dash'),\n","    x0=0, x1=1, y0=0, y1=1\n",")\n","\n","fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n","fig.update_xaxes(constrain='domain')\n","fig.update_layout(showlegend=False)\n","fig.show()\n","\n","precision, recall, thresholds = precision_recall_curve(target_valid, target_score)\n","\n","fig = px.area(\n","    x=recall, y=precision,\n","    title=f'Precision-Recall Curve (AUC={auc(fpr, tpr):.4f})',\n","    labels=dict(x='Recall', y='Precision'),\n","    width=800, height=600\n",")\n","fig.add_shape(\n","    type='line', line=dict(dash='dash'),\n","    x0=0, x1=1, y0=1, y1=0\n",")\n","fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n","fig.update_xaxes(constrain='domain')\n","fig.update_layout(showlegend=False)\n","fig.show()"]},{"cell_type":"markdown","metadata":{},"source":["-----------"]},{"cell_type":"markdown","metadata":{},"source":["# Decision Tree"]},{"cell_type":"code","execution_count":630,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T16:51:29.110557Z","iopub.status.busy":"2023-11-30T16:51:29.110290Z","iopub.status.idle":"2023-11-30T16:51:33.787645Z","shell.execute_reply":"2023-11-30T16:51:33.786705Z","shell.execute_reply.started":"2023-11-30T16:51:29.110532Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Runtime:\n","CPU times: user 216 ms, sys: 95.6 ms, total: 311 ms\n","Wall time: 1.87 s\n"]}],"source":["%%time\n","tree_model = DecisionTreeClassifier(random_state=random_state)\n","tree_parameters = [{'max_depth': [2,6,12,18,22,35],\n","                     'min_samples_split': [2,6,12],\n","                     \"criterion\": ['gini', 'entropy', 'log_loss'],\n","                     \"splitter\": ['best', 'random'],\n","                   }]\n","\n","tree_clf = RandomizedSearchCV(tree_model, tree_parameters, scoring='roc_auc', n_jobs=-1, cv=cv)\n","tree_clf.fit(features_train, target_train)\n","# create a variable for the best model\n","best_tree = tree_clf.best_estimator_\n","tree_pred = best_tree.predict(features_valid)\n","print('Runtime:')"]},{"cell_type":"code","execution_count":674,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 1000x500 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["sns.set(style=\"white\", color_codes=True)\n","plt.rcParams['axes.linewidth'] = 0.1\n","\n","fig, ax = plt.subplots(figsize = (10,5))\n","disp = CalibrationDisplay.from_estimator(tree_clf, features_valid, target_valid, ax=ax)\n","plt.title('Calibration Chart - Decision Tree Classifier', fontsize=10)\n","ax.set_xlabel('Mean predicted probability (Positive class: 1)', fontsize=10)\n","ax.set_ylabel('Fraction of positives (Positive class: 1)',fontsize=10)\n","\n","ax.tick_params(color='gray', labelcolor='gray')\n","for spine in ax.spines.values():\n","    spine.set_edgecolor('gray')\n","\n","\n","fig.tight_layout()\n","plt.legend(fontsize=8)\n","plt.show()"]},{"cell_type":"code","execution_count":632,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T16:51:33.789028Z","iopub.status.busy":"2023-11-30T16:51:33.788754Z","iopub.status.idle":"2023-11-30T16:51:35.084919Z","shell.execute_reply":"2023-11-30T16:51:35.083993Z","shell.execute_reply.started":"2023-11-30T16:51:33.789006Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Cross Validation Scores: [0.76152018 0.74971198 0.77724654 0.72453917 0.77750576 0.78245968\n"," 0.74115783 0.74190668 0.79236015 0.72746186 0.74220294 0.7484735\n"," 0.76621544 0.69415323 0.75256336 0.74637097 0.73545507 0.74104263\n"," 0.8058108  0.75062124 0.73454191 0.78245968 0.76794355 0.73459101\n"," 0.75207373 0.79585253 0.73185484 0.78493664 0.76518435 0.74007455\n"," 0.7264513  0.74104263 0.75368664 0.72404954 0.79014977 0.75889977\n"," 0.78332373 0.74003456 0.72344545 0.74576687 0.73530086 0.76422811\n"," 0.72690092 0.70259217 0.71362327 0.78741359 0.76782834 0.79634217\n"," 0.75307732 0.77009651]\n"]}],"source":["tree_scores = cross_val_score(tree_model, features_train, target_train, cv=cv, scoring='roc_auc')\n","print('Cross Validation Scores: {}'.format(tree_scores))"]},{"cell_type":"code","execution_count":633,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T16:51:35.086379Z","iopub.status.busy":"2023-11-30T16:51:35.086103Z","iopub.status.idle":"2023-11-30T16:51:35.097642Z","shell.execute_reply":"2023-11-30T16:51:35.096722Z","shell.execute_reply.started":"2023-11-30T16:51:35.086355Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Best hyperparameters: {'splitter': 'best', 'min_samples_split': 12, 'max_depth': 6, 'criterion': 'entropy'}\n","\n","Best score: 0.8518398809127874\n","\n","Average Cross Validation Score: 0.7530509062867848\n","\n","ROC AUC Score - Validation Dataset: 0.8719981260127038\n"]}],"source":["# summary\n","print('Best hyperparameters:',  tree_clf.best_params_)\n","print()\n","print('Best score:',  tree_clf.best_score_)\n","print()\n","print('Average Cross Validation Score: {}'.format(tree_scores.mean()))\n","print()\n","print('ROC AUC Score - Validation Dataset:',  roc_auc_score(target_valid, tree_clf.predict_proba(features_valid)[:, 1]))"]},{"cell_type":"markdown","metadata":{},"source":["# ROC AUC Curve - DecisionTreeClassifier"]},{"cell_type":"code","execution_count":634,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T16:51:35.099923Z","iopub.status.busy":"2023-11-30T16:51:35.099527Z","iopub.status.idle":"2023-11-30T16:51:35.224449Z","shell.execute_reply":"2023-11-30T16:51:35.223687Z","shell.execute_reply.started":"2023-11-30T16:51:35.099892Z"},"trusted":true},"outputs":[{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"fillpattern":{"shape":""},"hovertemplate":"False Positive Rate=%{x}<br>True Positive Rate=%{y}<extra></extra>","legendgroup":"","line":{"color":"#636efa"},"marker":{"symbol":"circle"},"mode":"lines","name":"","orientation":"v","showlegend":false,"stackgroup":"1","type":"scatter","x":[0,0.013368983957219251,0.026737967914438502,0.034759358288770054,0.040106951871657755,0.05080213903743316,0.053475935828877004,0.058823529411764705,0.06149732620320856,0.0748663101604278,0.08021390374331551,0.08021390374331551,0.1443850267379679,0.14705882352941177,0.15775401069518716,0.20855614973262032,0.23529411764705882,0.23529411764705882,0.28609625668449196,0.31016042780748665,0.4037433155080214,0.4732620320855615,0.679144385026738,0.6818181818181818,0.7727272727272727,0.7727272727272727,0.8368983957219251,1],"xaxis":"x","y":[0,0.1771539206195547,0.356243949661181,0.4482090997095837,0.46369796708615685,0.47047434656340753,0.4975798644724105,0.5091965150048403,0.5430784123910939,0.5721200387221684,0.5837366892545982,0.5866408518877058,0.6882865440464666,0.6979670861568248,0.7289448209099709,0.7986447241045499,0.8276863504356244,0.829622458857696,0.8673765730880929,0.8857696030977735,0.9196515004840271,0.9390125847047435,0.978702807357212,0.978702807357212,0.989351403678606,0.9932236205227493,0.9990319457889641,1],"yaxis":"y"}],"layout":{"height":600,"legend":{"tracegroupgap":0},"shapes":[{"line":{"dash":"dash"},"type":"line","x0":0,"x1":1,"y0":0,"y1":1}],"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"title":{"text":"ROC Curve (AUC=0.8720)"},"width":800,"xaxis":{"anchor":"y","constrain":"domain","domain":[0,1],"title":{"text":"False Positive Rate"}},"yaxis":{"anchor":"x","domain":[0,1],"scaleanchor":"x","scaleratio":1,"title":{"text":"True Positive Rate"}}}},"text/html":["<div>                            <div id=\"3a29f11c-f21f-4b43-afd1-b0b0d6255e21\" class=\"plotly-graph-div\" style=\"height:600px; width:800px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"3a29f11c-f21f-4b43-afd1-b0b0d6255e21\")) {                    Plotly.newPlot(                        \"3a29f11c-f21f-4b43-afd1-b0b0d6255e21\",                        [{\"fillpattern\":{\"shape\":\"\"},\"hovertemplate\":\"False Positive Rate=%{x}\\u003cbr\\u003eTrue Positive Rate=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"stackgroup\":\"1\",\"x\":[0.0,0.013368983957219251,0.026737967914438502,0.034759358288770054,0.040106951871657755,0.05080213903743316,0.053475935828877004,0.058823529411764705,0.06149732620320856,0.0748663101604278,0.08021390374331551,0.08021390374331551,0.1443850267379679,0.14705882352941177,0.15775401069518716,0.20855614973262032,0.23529411764705882,0.23529411764705882,0.28609625668449196,0.31016042780748665,0.4037433155080214,0.4732620320855615,0.679144385026738,0.6818181818181818,0.7727272727272727,0.7727272727272727,0.8368983957219251,1.0],\"xaxis\":\"x\",\"y\":[0.0,0.1771539206195547,0.356243949661181,0.4482090997095837,0.46369796708615685,0.47047434656340753,0.4975798644724105,0.5091965150048403,0.5430784123910939,0.5721200387221684,0.5837366892545982,0.5866408518877058,0.6882865440464666,0.6979670861568248,0.7289448209099709,0.7986447241045499,0.8276863504356244,0.829622458857696,0.8673765730880929,0.8857696030977735,0.9196515004840271,0.9390125847047435,0.978702807357212,0.978702807357212,0.989351403678606,0.9932236205227493,0.9990319457889641,1.0],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"False Positive Rate\"},\"constrain\":\"domain\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"True Positive Rate\"},\"scaleanchor\":\"x\",\"scaleratio\":1},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"ROC Curve (AUC=0.8720)\"},\"height\":600,\"width\":800,\"shapes\":[{\"line\":{\"dash\":\"dash\"},\"type\":\"line\",\"x0\":0,\"x1\":1,\"y0\":0,\"y1\":1}],\"showlegend\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('3a29f11c-f21f-4b43-afd1-b0b0d6255e21');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"fillpattern":{"shape":""},"hovertemplate":"Recall=%{x}<br>Precision=%{y}<extra></extra>","legendgroup":"","line":{"color":"#636efa"},"marker":{"symbol":"circle"},"mode":"lines","name":"","orientation":"v","showlegend":false,"stackgroup":"1","type":"scatter","x":[1,0.9990319457889641,0.9932236205227493,0.989351403678606,0.978702807357212,0.978702807357212,0.9390125847047435,0.9196515004840271,0.8857696030977735,0.8673765730880929,0.829622458857696,0.8276863504356244,0.7986447241045499,0.7289448209099709,0.6979670861568248,0.6882865440464666,0.5866408518877058,0.5837366892545982,0.5721200387221684,0.5430784123910939,0.5091965150048403,0.4975798644724105,0.47047434656340753,0.46369796708615685,0.4482090997095837,0.356243949661181,0.1771539206195547,0],"xaxis":"x","y":[0.7341862117981521,0.7672862453531598,0.7802281368821293,0.7795575896262396,0.7985781990521327,0.799209486166008,0.8456843940714909,0.8628519527702089,0.8874878758486906,0.8933200398803589,0.9068783068783068,0.9066808059384942,0.9136212624584718,0.9273399014778325,0.9291237113402062,0.9294117647058824,0.9528301886792453,0.95260663507109,0.9547657512116317,0.9606164383561644,0.9598540145985401,0.9625468164794008,0.9623762376237623,0.9696356275303644,0.9726890756302521,0.9735449735449735,0.973404255319149,1],"yaxis":"y"}],"layout":{"height":600,"legend":{"tracegroupgap":0},"shapes":[{"line":{"dash":"dash"},"type":"line","x0":0,"x1":1,"y0":1,"y1":0}],"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"title":{"text":"Precision-Recall Curve (AUC=0.8720)"},"width":800,"xaxis":{"anchor":"y","constrain":"domain","domain":[0,1],"title":{"text":"Recall"}},"yaxis":{"anchor":"x","domain":[0,1],"scaleanchor":"x","scaleratio":1,"title":{"text":"Precision"}}}},"text/html":["<div>                            <div id=\"bbcc67d6-5ee2-442c-b341-457f441063d8\" class=\"plotly-graph-div\" style=\"height:600px; width:800px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"bbcc67d6-5ee2-442c-b341-457f441063d8\")) {                    Plotly.newPlot(                        \"bbcc67d6-5ee2-442c-b341-457f441063d8\",                        [{\"fillpattern\":{\"shape\":\"\"},\"hovertemplate\":\"Recall=%{x}\\u003cbr\\u003ePrecision=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"stackgroup\":\"1\",\"x\":[1.0,0.9990319457889641,0.9932236205227493,0.989351403678606,0.978702807357212,0.978702807357212,0.9390125847047435,0.9196515004840271,0.8857696030977735,0.8673765730880929,0.829622458857696,0.8276863504356244,0.7986447241045499,0.7289448209099709,0.6979670861568248,0.6882865440464666,0.5866408518877058,0.5837366892545982,0.5721200387221684,0.5430784123910939,0.5091965150048403,0.4975798644724105,0.47047434656340753,0.46369796708615685,0.4482090997095837,0.356243949661181,0.1771539206195547,0.0],\"xaxis\":\"x\",\"y\":[0.7341862117981521,0.7672862453531598,0.7802281368821293,0.7795575896262396,0.7985781990521327,0.799209486166008,0.8456843940714909,0.8628519527702089,0.8874878758486906,0.8933200398803589,0.9068783068783068,0.9066808059384942,0.9136212624584718,0.9273399014778325,0.9291237113402062,0.9294117647058824,0.9528301886792453,0.95260663507109,0.9547657512116317,0.9606164383561644,0.9598540145985401,0.9625468164794008,0.9623762376237623,0.9696356275303644,0.9726890756302521,0.9735449735449735,0.973404255319149,1.0],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Recall\"},\"constrain\":\"domain\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Precision\"},\"scaleanchor\":\"x\",\"scaleratio\":1},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Precision-Recall Curve (AUC=0.8720)\"},\"height\":600,\"width\":800,\"shapes\":[{\"line\":{\"dash\":\"dash\"},\"type\":\"line\",\"x0\":0,\"x1\":1,\"y0\":1,\"y1\":0}],\"showlegend\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('bbcc67d6-5ee2-442c-b341-457f441063d8');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"}],"source":["target_score = tree_clf.predict_proba(features_valid)[:, 1]\n","\n","fpr, tpr, thresholds = roc_curve(target_valid, target_score)\n","\n","fig = px.area(\n","    x=fpr, y=tpr,\n","    title=f'ROC Curve (AUC={auc(fpr, tpr):.4f})',\n","    labels=dict(x='False Positive Rate', y='True Positive Rate'),\n","    width=800, height=600\n",")\n","fig.add_shape(\n","    type='line', line=dict(dash='dash'),\n","    x0=0, x1=1, y0=0, y1=1\n",")\n","\n","fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n","fig.update_xaxes(constrain='domain')\n","fig.update_layout(showlegend=False)\n","fig.show()\n","\n","precision, recall, thresholds = precision_recall_curve(target_valid, target_score)\n","\n","fig = px.area(\n","    x=recall, y=precision,\n","    title=f'Precision-Recall Curve (AUC={auc(fpr, tpr):.4f})',\n","    labels=dict(x='Recall', y='Precision'),\n","    width=800, height=600\n",")\n","fig.add_shape(\n","    type='line', line=dict(dash='dash'),\n","    x0=0, x1=1, y0=1, y1=0\n",")\n","fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n","fig.update_xaxes(constrain='domain')\n","fig.update_layout(showlegend=False)\n","fig.show()"]},{"cell_type":"markdown","metadata":{},"source":["-----------"]},{"cell_type":"markdown","metadata":{},"source":["# Extra Trees"]},{"cell_type":"code","execution_count":635,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T16:51:35.225674Z","iopub.status.busy":"2023-11-30T16:51:35.225423Z","iopub.status.idle":"2023-11-30T16:52:58.400487Z","shell.execute_reply":"2023-11-30T16:52:58.399533Z","shell.execute_reply.started":"2023-11-30T16:51:35.225641Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Runtime:\n","CPU times: user 1 s, sys: 369 ms, total: 1.37 s\n","Wall time: 22.1 s\n"]}],"source":["%%time\n","extra_trees_model = ExtraTreesClassifier(random_state=random_state)\n","extra_trees_parameters = [{'max_depth': [2,6,8,12,18,30],\n","                     'min_samples_split': [2,6,8,12],\n","                     \"criterion\": ['gini', 'entropy', 'log_loss'],\n","                     \"warm_start\": [True, False],\n","                     'n_estimators': [50,100,200]}]\n","\n","extra_trees_clf = RandomizedSearchCV(extra_trees_model, extra_trees_parameters, scoring='roc_auc', n_jobs=-1, cv=cv)\n","extra_trees_clf.fit(features_train, target_train)\n","# create a variable for the best model\n","best_ext = extra_trees_clf.best_estimator_\n","ext_pred = best_ext.predict(features_valid)\n","print('Runtime:')"]},{"cell_type":"code","execution_count":675,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 1000x500 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["sns.set(style=\"white\", color_codes=True)\n","plt.rcParams['axes.linewidth'] = 0.1\n","\n","fig, ax = plt.subplots(figsize = (10,5))\n","disp = CalibrationDisplay.from_estimator(extra_trees_clf, features_valid, target_valid, ax=ax)\n","plt.title('Calibration Chart - Extra Trees Classifier', fontsize=10)\n","ax.set_xlabel('Mean predicted probability (Positive class: 1)', fontsize=10)\n","ax.set_ylabel('Fraction of positives (Positive class: 1)',fontsize=10)\n","\n","ax.tick_params(color='gray', labelcolor='gray')\n","for spine in ax.spines.values():\n","    spine.set_edgecolor('gray')\n","\n","\n","fig.tight_layout()\n","plt.legend(fontsize=8)\n","plt.show()"]},{"cell_type":"code","execution_count":637,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T16:52:58.402048Z","iopub.status.busy":"2023-11-30T16:52:58.401764Z","iopub.status.idle":"2023-11-30T16:53:23.273446Z","shell.execute_reply":"2023-11-30T16:53:23.272464Z","shell.execute_reply.started":"2023-11-30T16:52:58.402022Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Cross Validation Scores: [0.86500845 0.83686636 0.85711406 0.82880184 0.84677419 0.84474366\n"," 0.8422235  0.8139977  0.87829404 0.86738615 0.8049947  0.83702477\n"," 0.86673387 0.8265553  0.86496256 0.83313652 0.86828917 0.83366935\n"," 0.8825994  0.83418574 0.83532377 0.86350806 0.86647465 0.85596198\n"," 0.83706797 0.87138537 0.86238479 0.8671803  0.83862113 0.79510518\n"," 0.84864106 0.82436636 0.8405962  0.86353687 0.86965726 0.85709965\n"," 0.84448445 0.85020161 0.85273636 0.85234628 0.85839276 0.85734447\n"," 0.82521601 0.82070853 0.83175403 0.84179147 0.85817972 0.86784274\n"," 0.8469718  0.86162159]\n"]}],"source":["extra_trees_scores = cross_val_score(extra_trees_model, features_train, target_train, cv=cv, scoring='roc_auc')\n","print('Cross Validation Scores: {}'.format(extra_trees_scores))"]},{"cell_type":"code","execution_count":638,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T16:53:23.274951Z","iopub.status.busy":"2023-11-30T16:53:23.274646Z","iopub.status.idle":"2023-11-30T16:53:23.354259Z","shell.execute_reply":"2023-11-30T16:53:23.353326Z","shell.execute_reply.started":"2023-11-30T16:53:23.274927Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Best hyperparameters: {'warm_start': False, 'n_estimators': 200, 'min_samples_split': 6, 'max_depth': 30, 'criterion': 'log_loss'}\n","\n","Best score: 0.8551217437510469\n","\n","Average Cross Validation Score: 0.8479972754101266\n","\n","ROC AUC Score - Validation Dataset: 0.88399915101128\n"]}],"source":["# summary\n","print('Best hyperparameters:',  extra_trees_clf.best_params_)\n","print()\n","print('Best score:',  extra_trees_clf.best_score_)\n","print()\n","print('Average Cross Validation Score: {}'.format(extra_trees_scores.mean()))\n","print()\n","print('ROC AUC Score - Validation Dataset:',  roc_auc_score(target_valid, extra_trees_clf.predict_proba(features_valid)[:, 1]))"]},{"cell_type":"markdown","metadata":{},"source":["# ROC AUC Curve - ExtraTreesClassifier"]},{"cell_type":"code","execution_count":639,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T16:53:23.356396Z","iopub.status.busy":"2023-11-30T16:53:23.356005Z","iopub.status.idle":"2023-11-30T16:53:23.560598Z","shell.execute_reply":"2023-11-30T16:53:23.559701Z","shell.execute_reply.started":"2023-11-30T16:53:23.356359Z"},"trusted":true},"outputs":[{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"fillpattern":{"shape":""},"hovertemplate":"False Positive Rate=%{x}<br>True Positive Rate=%{y}<extra></extra>","legendgroup":"","line":{"color":"#636efa"},"marker":{"symbol":"circle"},"mode":"lines","name":"","orientation":"v","showlegend":false,"stackgroup":"1","type":"scatter","x":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.00267379679144385,0.00267379679144385,0.00267379679144385,0.00267379679144385,0.00267379679144385,0.00267379679144385,0.00267379679144385,0.00267379679144385,0.00267379679144385,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.008021390374331552,0.008021390374331552,0.008021390374331552,0.008021390374331552,0.008021390374331552,0.008021390374331552,0.0106951871657754,0.0106951871657754,0.013368983957219251,0.013368983957219251,0.013368983957219251,0.013368983957219251,0.013368983957219251,0.013368983957219251,0.013368983957219251,0.013368983957219251,0.013368983957219251,0.013368983957219251,0.013368983957219251,0.013368983957219251,0.013368983957219251,0.013368983957219251,0.013368983957219251,0.013368983957219251,0.013368983957219251,0.013368983957219251,0.013368983957219251,0.013368983957219251,0.016042780748663103,0.016042780748663103,0.01871657754010695,0.01871657754010695,0.01871657754010695,0.01871657754010695,0.01871657754010695,0.01871657754010695,0.01871657754010695,0.01871657754010695,0.01871657754010695,0.01871657754010695,0.01871657754010695,0.01871657754010695,0.0213903743315508,0.0213903743315508,0.02406417112299465,0.02406417112299465,0.026737967914438502,0.026737967914438502,0.029411764705882353,0.029411764705882353,0.03208556149732621,0.03208556149732621,0.034759358288770054,0.034759358288770054,0.0374331550802139,0.0374331550802139,0.040106951871657755,0.040106951871657755,0.040106951871657755,0.040106951871657755,0.0427807486631016,0.0427807486631016,0.045454545454545456,0.045454545454545456,0.0481283422459893,0.0481283422459893,0.05080213903743316,0.05080213903743316,0.053475935828877004,0.053475935828877004,0.05614973262032086,0.05614973262032086,0.05614973262032086,0.05614973262032086,0.058823529411764705,0.058823529411764705,0.06417112299465241,0.06417112299465241,0.06684491978609626,0.06684491978609626,0.07219251336898395,0.07219251336898395,0.0748663101604278,0.0748663101604278,0.07754010695187166,0.07754010695187166,0.08021390374331551,0.08021390374331551,0.08288770053475936,0.08288770053475936,0.0855614973262032,0.0855614973262032,0.08823529411764706,0.08823529411764706,0.08823529411764706,0.08823529411764706,0.09090909090909091,0.09090909090909091,0.09358288770053476,0.09358288770053476,0.0962566844919786,0.0962566844919786,0.09893048128342247,0.09893048128342247,0.09893048128342247,0.09893048128342247,0.10160427807486631,0.10160427807486631,0.10695187165775401,0.10695187165775401,0.10962566844919786,0.10962566844919786,0.11229946524064172,0.11229946524064172,0.11497326203208556,0.11497326203208556,0.11764705882352941,0.11764705882352941,0.11764705882352941,0.11764705882352941,0.12299465240641712,0.12299465240641712,0.12566844919786097,0.12566844919786097,0.12834224598930483,0.12834224598930483,0.13101604278074866,0.13101604278074866,0.13368983957219252,0.13368983957219252,0.13636363636363635,0.13636363636363635,0.13903743315508021,0.13903743315508021,0.14171122994652408,0.14171122994652408,0.14171122994652408,0.14171122994652408,0.1443850267379679,0.1443850267379679,0.14705882352941177,0.14705882352941177,0.1497326203208556,0.1497326203208556,0.15240641711229946,0.15240641711229946,0.15508021390374332,0.15508021390374332,0.15775401069518716,0.15775401069518716,0.16042780748663102,0.16042780748663102,0.16310160427807488,0.16310160427807488,0.16844919786096257,0.16844919786096257,0.1711229946524064,0.1711229946524064,0.17379679144385027,0.17379679144385027,0.17647058823529413,0.17647058823529413,0.17914438502673796,0.17914438502673796,0.18181818181818182,0.18716577540106952,0.18716577540106952,0.18983957219251338,0.18983957219251338,0.1925133689839572,0.1925133689839572,0.19518716577540107,0.19518716577540107,0.19786096256684493,0.19786096256684493,0.19786096256684493,0.19786096256684493,0.20320855614973263,0.20320855614973263,0.20588235294117646,0.20588235294117646,0.20588235294117646,0.20588235294117646,0.20855614973262032,0.20855614973262032,0.21122994652406418,0.21122994652406418,0.21657754010695188,0.21657754010695188,0.2192513368983957,0.2192513368983957,0.22192513368983957,0.22192513368983957,0.22459893048128343,0.22459893048128343,0.22727272727272727,0.22727272727272727,0.22994652406417113,0.22994652406417113,0.22994652406417113,0.22994652406417113,0.232620320855615,0.232620320855615,0.24064171122994651,0.24064171122994651,0.24866310160427807,0.24866310160427807,0.25133689839572193,0.25133689839572193,0.2620320855614973,0.2620320855614973,0.2647058823529412,0.2647058823529412,0.26737967914438504,0.26737967914438504,0.2727272727272727,0.2727272727272727,0.2727272727272727,0.2727272727272727,0.27540106951871657,0.27540106951871657,0.27807486631016043,0.27807486631016043,0.28342245989304815,0.28342245989304815,0.28609625668449196,0.28609625668449196,0.2887700534759358,0.2887700534759358,0.2914438502673797,0.2914438502673797,0.29411764705882354,0.29411764705882354,0.2967914438502674,0.2967914438502674,0.30213903743315507,0.30213903743315507,0.3074866310160428,0.3074866310160428,0.31016042780748665,0.31016042780748665,0.31283422459893045,0.31283422459893045,0.3155080213903743,0.3155080213903743,0.3235294117647059,0.3235294117647059,0.3315508021390374,0.3315508021390374,0.3342245989304813,0.3342245989304813,0.339572192513369,0.339572192513369,0.3422459893048128,0.3422459893048128,0.3449197860962567,0.3449197860962567,0.3502673796791444,0.3502673796791444,0.35561497326203206,0.35561497326203206,0.37433155080213903,0.37433155080213903,0.37967914438502676,0.37967914438502676,0.38235294117647056,0.38235294117647056,0.3850267379679144,0.3850267379679144,0.393048128342246,0.393048128342246,0.40106951871657753,0.40106951871657753,0.4090909090909091,0.4090909090909091,0.4117647058823529,0.4117647058823529,0.4144385026737968,0.4144385026737968,0.41711229946524064,0.41711229946524064,0.42245989304812837,0.42245989304812837,0.42513368983957217,0.42513368983957217,0.4304812834224599,0.4304812834224599,0.43315508021390375,0.43315508021390375,0.4358288770053476,0.4358288770053476,0.4411764705882353,0.4411764705882353,0.45454545454545453,0.45454545454545453,0.4572192513368984,0.4572192513368984,0.46524064171123,0.46524064171123,0.47593582887700536,0.47593582887700536,0.48128342245989303,0.48128342245989303,0.4839572192513369,0.4839572192513369,0.4893048128342246,0.4893048128342246,0.5053475935828877,0.5053475935828877,0.5213903743315508,0.5213903743315508,0.5267379679144385,0.5267379679144385,0.5320855614973262,0.5320855614973262,0.5374331550802139,0.5374331550802139,0.5427807486631016,0.5427807486631016,0.5454545454545454,0.5454545454545454,0.5481283422459893,0.5481283422459893,0.5508021390374331,0.5508021390374331,0.553475935828877,0.553475935828877,0.56951871657754,0.56951871657754,0.5855614973262032,0.5855614973262032,0.5909090909090909,0.5909090909090909,0.5962566844919787,0.5962566844919787,0.5989304812834224,0.5989304812834224,0.606951871657754,0.606951871657754,0.6096256684491979,0.6096256684491979,0.6283422459893048,0.6283422459893048,0.6417112299465241,0.6443850267379679,0.6497326203208557,0.6497326203208557,0.660427807486631,0.660427807486631,0.6764705882352942,0.6764705882352942,0.6898395721925134,0.6898395721925134,0.6951871657754011,0.6951871657754011,0.7005347593582888,0.7005347593582888,0.7647058823529411,0.7647058823529411,0.7754010695187166,0.7754010695187166,0.786096256684492,0.786096256684492,0.7887700534759359,0.7887700534759359,0.7914438502673797,0.7914438502673797,0.7967914438502673,0.7967914438502673,0.8021390374331551,0.8021390374331551,0.820855614973262,0.820855614973262,0.8850267379679144,0.8850267379679144,0.8903743315508021,0.8903743315508021,1],"xaxis":"x","y":[0,0.046466602129719266,0.05614714424007745,0.06098741529525654,0.06679574056147145,0.06873184898354308,0.07163601161665054,0.07938044530493708,0.08422071636011616,0.08615682478218781,0.08906098741529525,0.09196515004840271,0.09390125847047434,0.09583736689254599,0.09777347531461762,0.10164569215876089,0.10358180058083252,0.10551790900290416,0.1074540174249758,0.10939012584704744,0.11132623426911907,0.11423039690222653,0.11519845111326234,0.11907066795740562,0.12100677637947725,0.12197483059051308,0.12584704743465633,0.12971926427879962,0.13165537270087124,0.1335914811229429,0.1393998063891578,0.1403678606001936,0.1558567279767667,0.15779283639883834,0.15972894482090996,0.1616650532429816,0.16553727008712488,0.16747337850919652,0.16940948693126814,0.1713455953533398,0.17231364956437561,0.17424975798644723,0.17521781219748306,0.1781219748305905,0.18005808325266215,0.1819941916747338,0.18393030009680542,0.19070667957405615,0.19070667957405615,0.19457889641819942,0.19554695062923524,0.20329138431752178,0.20522749273959343,0.20619554695062922,0.20813165537270087,0.21006776379477252,0.21200387221684414,0.2207163601161665,0.22362052274927396,0.25169409486931266,0.2536302032913843,0.26427879961277834,0.26621490803484993,0.2691190706679574,0.271055179090029,0.27202323330106487,0.2749273959341723,0.2836398838334947,0.2855759922555663,0.2894482090997096,0.2894482090997096,0.29816069699903197,0.29816069699903197,0.30396902226524686,0.3059051306873185,0.31364956437560504,0.3155856727976767,0.3194578896418199,0.3213939980638916,0.33591481122942884,0.3378509196515005,0.38431752178121975,0.3872216844143272,0.39399806389157793,0.39399806389157793,0.3998063891577928,0.3998063891577928,0.4027105517909003,0.4027105517909003,0.4133591481122943,0.4133591481122943,0.42013552758954503,0.42110358180058083,0.4259438528557599,0.4259438528557599,0.4269119070667957,0.4269119070667957,0.42884801548886736,0.42884801548886736,0.45885769603097776,0.46079380445304935,0.47047434656340753,0.47047434656340753,0.48112294288480156,0.48112294288480156,0.484027105517909,0.484027105517909,0.48596321393998065,0.48596321393998065,0.5072604065827686,0.5072604065827686,0.5091965150048403,0.5091965150048403,0.5440464666021297,0.5459825750242013,0.5488867376573088,0.5488867376573088,0.5517909002904162,0.5517909002904162,0.5546950629235237,0.5546950629235237,0.5575992255566312,0.5575992255566312,0.5682478218780251,0.5682478218780251,0.5711519845111326,0.5711519845111326,0.5769603097773476,0.5779283639883833,0.5818005808325266,0.5818005808325266,0.5827686350435625,0.5827686350435625,0.5876089060987415,0.5876089060987415,0.5972894482090997,0.5992255566311714,0.6021297192642788,0.6021297192642788,0.6040658276863504,0.6040658276863504,0.6108422071636012,0.6108422071636012,0.6185866408518877,0.6185866408518877,0.6205227492739593,0.6224588576960309,0.633107454017425,0.633107454017425,0.6418199419167473,0.6418199419167473,0.643756050338819,0.643756050338819,0.6515004840271055,0.6515004840271055,0.6524685382381413,0.6524685382381413,0.6563407550822846,0.6563407550822846,0.6573088092933205,0.6592449177153921,0.6631171345595354,0.6631171345595354,0.6640851887705711,0.6640851887705711,0.6698935140367861,0.6698935140367861,0.6718296224588577,0.6718296224588577,0.6902226524685382,0.6902226524685382,0.6999031945788964,0.6999031945788964,0.7057115198451114,0.7057115198451114,0.7134559535333979,0.7134559535333979,0.7153920619554696,0.7173281703775412,0.7202323330106486,0.7202323330106486,0.723136495643756,0.723136495643756,0.7250726040658277,0.7250726040658277,0.7260406582768635,0.7260406582768635,0.7289448209099709,0.7289448209099709,0.7347531461761858,0.7347531461761858,0.7415295256534365,0.7415295256534365,0.7473378509196515,0.7473378509196515,0.7483059051306873,0.7483059051306873,0.7512100677637947,0.7512100677637947,0.7589545014520813,0.7589545014520813,0.7628267182962246,0.7628267182962246,0.7637947725072604,0.7637947725072604,0.7725072604065828,0.7725072604065828,0.7725072604065828,0.7744433688286544,0.7744433688286544,0.7763794772507261,0.7763794772507261,0.7783155856727977,0.7783155856727977,0.7802516940948693,0.7802516940948693,0.782187802516941,0.7841239109390126,0.7889641819941917,0.7889641819941917,0.8025169409486931,0.8025169409486931,0.8054211035818006,0.8073572120038722,0.8112294288480155,0.8112294288480155,0.8160696999031946,0.8160696999031946,0.8170377541142304,0.8170377541142304,0.818973862536302,0.818973862536302,0.8199419167473379,0.8199419167473379,0.8276863504356244,0.8276863504356244,0.8325266214908035,0.8325266214908035,0.8344627299128751,0.8344627299128751,0.8354307841239109,0.8373668925459826,0.8441432720232332,0.8441432720232332,0.8480154888673765,0.8480154888673765,0.8489835430784124,0.8489835430784124,0.8538238141335914,0.8538238141335914,0.8596321393998064,0.8596321393998064,0.8606001936108422,0.8606001936108422,0.8625363020329139,0.8625363020329139,0.8664085188770572,0.8664085188770572,0.8702807357212003,0.872216844143272,0.8818973862536302,0.8818973862536302,0.8838334946757018,0.8838334946757018,0.8848015488867377,0.8848015488867377,0.8877057115198451,0.8877057115198451,0.89351403678606,0.89351403678606,0.8944820909970959,0.8944820909970959,0.8964181994191674,0.8964181994191674,0.8983543078412392,0.8983543078412392,0.8993223620522749,0.8993223620522749,0.9022265246853823,0.9022265246853823,0.904162633107454,0.904162633107454,0.9051306873184899,0.9060987415295256,0.9070667957405615,0.9070667957405615,0.9090029041626331,0.9090029041626331,0.9109390125847048,0.9109390125847048,0.9119070667957405,0.9119070667957405,0.9128751210067764,0.9128751210067764,0.9138431752178122,0.9138431752178122,0.914811229428848,0.914811229428848,0.9186834462729913,0.9186834462729913,0.9196515004840271,0.9196515004840271,0.9215876089060987,0.9215876089060987,0.9225556631171346,0.9225556631171346,0.9312681510164569,0.9312681510164569,0.9322362052274927,0.9322362052274927,0.936108422071636,0.936108422071636,0.9390125847047435,0.9390125847047435,0.9399806389157793,0.9399806389157793,0.9409486931268151,0.9409486931268151,0.9419167473378509,0.9419167473378509,0.9428848015488868,0.9428848015488868,0.9438528557599225,0.9438528557599225,0.9448209099709584,0.9448209099709584,0.9457889641819942,0.9457889641819942,0.9477250726040658,0.9477250726040658,0.9486931268151017,0.9486931268151017,0.9496611810261375,0.9496611810261375,0.9506292352371732,0.9506292352371732,0.9515972894482091,0.9515972894482091,0.952565343659245,0.952565343659245,0.9535333978702807,0.9535333978702807,0.9545014520813165,0.9545014520813165,0.9564375605033882,0.9564375605033882,0.9603097773475314,0.9603097773475314,0.9622458857696031,0.9622458857696031,0.9632139399806389,0.9632139399806389,0.9641819941916747,0.9641819941916747,0.9651500484027106,0.9651500484027106,0.9661181026137464,0.9661181026137464,0.9670861568247822,0.9670861568247822,0.9690222652468539,0.9690222652468539,0.9699903194578896,0.9699903194578896,0.9709583736689255,0.9709583736689255,0.9719264278799613,0.9719264278799613,0.972894482090997,0.972894482090997,0.9738625363020329,0.9738625363020329,0.9748305905130688,0.9748305905130688,0.9757986447241046,0.9757986447241046,0.9777347531461762,0.9777347531461762,0.978702807357212,0.978702807357212,0.9796708615682478,0.9796708615682478,0.9806389157792836,0.9806389157792836,0.9816069699903195,0.9816069699903195,0.9825750242013552,0.9825750242013552,0.9835430784123911,0.9835430784123911,0.9854791868344628,0.9854791868344628,0.9864472410454985,0.9864472410454985,0.9874152952565344,0.9874152952565344,0.9883833494675702,0.9883833494675702,0.989351403678606,0.989351403678606,0.9912875121006777,0.9912875121006777,0.9922555663117134,0.9922555663117134,0.9932236205227493,0.9932236205227493,0.9941916747337851,0.9941916747337851,0.995159728944821,0.995159728944821,0.9961277831558567,0.9961277831558567,0.9970958373668926,0.9970958373668926,0.9980638915779284,0.9980638915779284,0.9990319457889641,0.9990319457889641,1,1],"yaxis":"y"}],"layout":{"height":600,"legend":{"tracegroupgap":0},"shapes":[{"line":{"dash":"dash"},"type":"line","x0":0,"x1":1,"y0":0,"y1":1}],"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"title":{"text":"ROC Curve (AUC=0.8840)"},"width":800,"xaxis":{"anchor":"y","constrain":"domain","domain":[0,1],"title":{"text":"False Positive Rate"}},"yaxis":{"anchor":"x","domain":[0,1],"scaleanchor":"x","scaleratio":1,"title":{"text":"True Positive Rate"}}}},"text/html":["<div>                            <div id=\"a5ba148a-0ea1-46ff-802e-b1cd24321ca3\" class=\"plotly-graph-div\" style=\"height:600px; width:800px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"a5ba148a-0ea1-46ff-802e-b1cd24321ca3\")) {                    Plotly.newPlot(                        \"a5ba148a-0ea1-46ff-802e-b1cd24321ca3\",                        [{\"fillpattern\":{\"shape\":\"\"},\"hovertemplate\":\"False Positive Rate=%{x}\\u003cbr\\u003eTrue Positive Rate=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"stackgroup\":\"1\",\"x\":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.00267379679144385,0.00267379679144385,0.00267379679144385,0.00267379679144385,0.00267379679144385,0.00267379679144385,0.00267379679144385,0.00267379679144385,0.00267379679144385,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.008021390374331552,0.008021390374331552,0.008021390374331552,0.008021390374331552,0.008021390374331552,0.008021390374331552,0.0106951871657754,0.0106951871657754,0.013368983957219251,0.013368983957219251,0.013368983957219251,0.013368983957219251,0.013368983957219251,0.013368983957219251,0.013368983957219251,0.013368983957219251,0.013368983957219251,0.013368983957219251,0.013368983957219251,0.013368983957219251,0.013368983957219251,0.013368983957219251,0.013368983957219251,0.013368983957219251,0.013368983957219251,0.013368983957219251,0.013368983957219251,0.013368983957219251,0.016042780748663103,0.016042780748663103,0.01871657754010695,0.01871657754010695,0.01871657754010695,0.01871657754010695,0.01871657754010695,0.01871657754010695,0.01871657754010695,0.01871657754010695,0.01871657754010695,0.01871657754010695,0.01871657754010695,0.01871657754010695,0.0213903743315508,0.0213903743315508,0.02406417112299465,0.02406417112299465,0.026737967914438502,0.026737967914438502,0.029411764705882353,0.029411764705882353,0.03208556149732621,0.03208556149732621,0.034759358288770054,0.034759358288770054,0.0374331550802139,0.0374331550802139,0.040106951871657755,0.040106951871657755,0.040106951871657755,0.040106951871657755,0.0427807486631016,0.0427807486631016,0.045454545454545456,0.045454545454545456,0.0481283422459893,0.0481283422459893,0.05080213903743316,0.05080213903743316,0.053475935828877004,0.053475935828877004,0.05614973262032086,0.05614973262032086,0.05614973262032086,0.05614973262032086,0.058823529411764705,0.058823529411764705,0.06417112299465241,0.06417112299465241,0.06684491978609626,0.06684491978609626,0.07219251336898395,0.07219251336898395,0.0748663101604278,0.0748663101604278,0.07754010695187166,0.07754010695187166,0.08021390374331551,0.08021390374331551,0.08288770053475936,0.08288770053475936,0.0855614973262032,0.0855614973262032,0.08823529411764706,0.08823529411764706,0.08823529411764706,0.08823529411764706,0.09090909090909091,0.09090909090909091,0.09358288770053476,0.09358288770053476,0.0962566844919786,0.0962566844919786,0.09893048128342247,0.09893048128342247,0.09893048128342247,0.09893048128342247,0.10160427807486631,0.10160427807486631,0.10695187165775401,0.10695187165775401,0.10962566844919786,0.10962566844919786,0.11229946524064172,0.11229946524064172,0.11497326203208556,0.11497326203208556,0.11764705882352941,0.11764705882352941,0.11764705882352941,0.11764705882352941,0.12299465240641712,0.12299465240641712,0.12566844919786097,0.12566844919786097,0.12834224598930483,0.12834224598930483,0.13101604278074866,0.13101604278074866,0.13368983957219252,0.13368983957219252,0.13636363636363635,0.13636363636363635,0.13903743315508021,0.13903743315508021,0.14171122994652408,0.14171122994652408,0.14171122994652408,0.14171122994652408,0.1443850267379679,0.1443850267379679,0.14705882352941177,0.14705882352941177,0.1497326203208556,0.1497326203208556,0.15240641711229946,0.15240641711229946,0.15508021390374332,0.15508021390374332,0.15775401069518716,0.15775401069518716,0.16042780748663102,0.16042780748663102,0.16310160427807488,0.16310160427807488,0.16844919786096257,0.16844919786096257,0.1711229946524064,0.1711229946524064,0.17379679144385027,0.17379679144385027,0.17647058823529413,0.17647058823529413,0.17914438502673796,0.17914438502673796,0.18181818181818182,0.18716577540106952,0.18716577540106952,0.18983957219251338,0.18983957219251338,0.1925133689839572,0.1925133689839572,0.19518716577540107,0.19518716577540107,0.19786096256684493,0.19786096256684493,0.19786096256684493,0.19786096256684493,0.20320855614973263,0.20320855614973263,0.20588235294117646,0.20588235294117646,0.20588235294117646,0.20588235294117646,0.20855614973262032,0.20855614973262032,0.21122994652406418,0.21122994652406418,0.21657754010695188,0.21657754010695188,0.2192513368983957,0.2192513368983957,0.22192513368983957,0.22192513368983957,0.22459893048128343,0.22459893048128343,0.22727272727272727,0.22727272727272727,0.22994652406417113,0.22994652406417113,0.22994652406417113,0.22994652406417113,0.232620320855615,0.232620320855615,0.24064171122994651,0.24064171122994651,0.24866310160427807,0.24866310160427807,0.25133689839572193,0.25133689839572193,0.2620320855614973,0.2620320855614973,0.2647058823529412,0.2647058823529412,0.26737967914438504,0.26737967914438504,0.2727272727272727,0.2727272727272727,0.2727272727272727,0.2727272727272727,0.27540106951871657,0.27540106951871657,0.27807486631016043,0.27807486631016043,0.28342245989304815,0.28342245989304815,0.28609625668449196,0.28609625668449196,0.2887700534759358,0.2887700534759358,0.2914438502673797,0.2914438502673797,0.29411764705882354,0.29411764705882354,0.2967914438502674,0.2967914438502674,0.30213903743315507,0.30213903743315507,0.3074866310160428,0.3074866310160428,0.31016042780748665,0.31016042780748665,0.31283422459893045,0.31283422459893045,0.3155080213903743,0.3155080213903743,0.3235294117647059,0.3235294117647059,0.3315508021390374,0.3315508021390374,0.3342245989304813,0.3342245989304813,0.339572192513369,0.339572192513369,0.3422459893048128,0.3422459893048128,0.3449197860962567,0.3449197860962567,0.3502673796791444,0.3502673796791444,0.35561497326203206,0.35561497326203206,0.37433155080213903,0.37433155080213903,0.37967914438502676,0.37967914438502676,0.38235294117647056,0.38235294117647056,0.3850267379679144,0.3850267379679144,0.393048128342246,0.393048128342246,0.40106951871657753,0.40106951871657753,0.4090909090909091,0.4090909090909091,0.4117647058823529,0.4117647058823529,0.4144385026737968,0.4144385026737968,0.41711229946524064,0.41711229946524064,0.42245989304812837,0.42245989304812837,0.42513368983957217,0.42513368983957217,0.4304812834224599,0.4304812834224599,0.43315508021390375,0.43315508021390375,0.4358288770053476,0.4358288770053476,0.4411764705882353,0.4411764705882353,0.45454545454545453,0.45454545454545453,0.4572192513368984,0.4572192513368984,0.46524064171123,0.46524064171123,0.47593582887700536,0.47593582887700536,0.48128342245989303,0.48128342245989303,0.4839572192513369,0.4839572192513369,0.4893048128342246,0.4893048128342246,0.5053475935828877,0.5053475935828877,0.5213903743315508,0.5213903743315508,0.5267379679144385,0.5267379679144385,0.5320855614973262,0.5320855614973262,0.5374331550802139,0.5374331550802139,0.5427807486631016,0.5427807486631016,0.5454545454545454,0.5454545454545454,0.5481283422459893,0.5481283422459893,0.5508021390374331,0.5508021390374331,0.553475935828877,0.553475935828877,0.56951871657754,0.56951871657754,0.5855614973262032,0.5855614973262032,0.5909090909090909,0.5909090909090909,0.5962566844919787,0.5962566844919787,0.5989304812834224,0.5989304812834224,0.606951871657754,0.606951871657754,0.6096256684491979,0.6096256684491979,0.6283422459893048,0.6283422459893048,0.6417112299465241,0.6443850267379679,0.6497326203208557,0.6497326203208557,0.660427807486631,0.660427807486631,0.6764705882352942,0.6764705882352942,0.6898395721925134,0.6898395721925134,0.6951871657754011,0.6951871657754011,0.7005347593582888,0.7005347593582888,0.7647058823529411,0.7647058823529411,0.7754010695187166,0.7754010695187166,0.786096256684492,0.786096256684492,0.7887700534759359,0.7887700534759359,0.7914438502673797,0.7914438502673797,0.7967914438502673,0.7967914438502673,0.8021390374331551,0.8021390374331551,0.820855614973262,0.820855614973262,0.8850267379679144,0.8850267379679144,0.8903743315508021,0.8903743315508021,1.0],\"xaxis\":\"x\",\"y\":[0.0,0.046466602129719266,0.05614714424007745,0.06098741529525654,0.06679574056147145,0.06873184898354308,0.07163601161665054,0.07938044530493708,0.08422071636011616,0.08615682478218781,0.08906098741529525,0.09196515004840271,0.09390125847047434,0.09583736689254599,0.09777347531461762,0.10164569215876089,0.10358180058083252,0.10551790900290416,0.1074540174249758,0.10939012584704744,0.11132623426911907,0.11423039690222653,0.11519845111326234,0.11907066795740562,0.12100677637947725,0.12197483059051308,0.12584704743465633,0.12971926427879962,0.13165537270087124,0.1335914811229429,0.1393998063891578,0.1403678606001936,0.1558567279767667,0.15779283639883834,0.15972894482090996,0.1616650532429816,0.16553727008712488,0.16747337850919652,0.16940948693126814,0.1713455953533398,0.17231364956437561,0.17424975798644723,0.17521781219748306,0.1781219748305905,0.18005808325266215,0.1819941916747338,0.18393030009680542,0.19070667957405615,0.19070667957405615,0.19457889641819942,0.19554695062923524,0.20329138431752178,0.20522749273959343,0.20619554695062922,0.20813165537270087,0.21006776379477252,0.21200387221684414,0.2207163601161665,0.22362052274927396,0.25169409486931266,0.2536302032913843,0.26427879961277834,0.26621490803484993,0.2691190706679574,0.271055179090029,0.27202323330106487,0.2749273959341723,0.2836398838334947,0.2855759922555663,0.2894482090997096,0.2894482090997096,0.29816069699903197,0.29816069699903197,0.30396902226524686,0.3059051306873185,0.31364956437560504,0.3155856727976767,0.3194578896418199,0.3213939980638916,0.33591481122942884,0.3378509196515005,0.38431752178121975,0.3872216844143272,0.39399806389157793,0.39399806389157793,0.3998063891577928,0.3998063891577928,0.4027105517909003,0.4027105517909003,0.4133591481122943,0.4133591481122943,0.42013552758954503,0.42110358180058083,0.4259438528557599,0.4259438528557599,0.4269119070667957,0.4269119070667957,0.42884801548886736,0.42884801548886736,0.45885769603097776,0.46079380445304935,0.47047434656340753,0.47047434656340753,0.48112294288480156,0.48112294288480156,0.484027105517909,0.484027105517909,0.48596321393998065,0.48596321393998065,0.5072604065827686,0.5072604065827686,0.5091965150048403,0.5091965150048403,0.5440464666021297,0.5459825750242013,0.5488867376573088,0.5488867376573088,0.5517909002904162,0.5517909002904162,0.5546950629235237,0.5546950629235237,0.5575992255566312,0.5575992255566312,0.5682478218780251,0.5682478218780251,0.5711519845111326,0.5711519845111326,0.5769603097773476,0.5779283639883833,0.5818005808325266,0.5818005808325266,0.5827686350435625,0.5827686350435625,0.5876089060987415,0.5876089060987415,0.5972894482090997,0.5992255566311714,0.6021297192642788,0.6021297192642788,0.6040658276863504,0.6040658276863504,0.6108422071636012,0.6108422071636012,0.6185866408518877,0.6185866408518877,0.6205227492739593,0.6224588576960309,0.633107454017425,0.633107454017425,0.6418199419167473,0.6418199419167473,0.643756050338819,0.643756050338819,0.6515004840271055,0.6515004840271055,0.6524685382381413,0.6524685382381413,0.6563407550822846,0.6563407550822846,0.6573088092933205,0.6592449177153921,0.6631171345595354,0.6631171345595354,0.6640851887705711,0.6640851887705711,0.6698935140367861,0.6698935140367861,0.6718296224588577,0.6718296224588577,0.6902226524685382,0.6902226524685382,0.6999031945788964,0.6999031945788964,0.7057115198451114,0.7057115198451114,0.7134559535333979,0.7134559535333979,0.7153920619554696,0.7173281703775412,0.7202323330106486,0.7202323330106486,0.723136495643756,0.723136495643756,0.7250726040658277,0.7250726040658277,0.7260406582768635,0.7260406582768635,0.7289448209099709,0.7289448209099709,0.7347531461761858,0.7347531461761858,0.7415295256534365,0.7415295256534365,0.7473378509196515,0.7473378509196515,0.7483059051306873,0.7483059051306873,0.7512100677637947,0.7512100677637947,0.7589545014520813,0.7589545014520813,0.7628267182962246,0.7628267182962246,0.7637947725072604,0.7637947725072604,0.7725072604065828,0.7725072604065828,0.7725072604065828,0.7744433688286544,0.7744433688286544,0.7763794772507261,0.7763794772507261,0.7783155856727977,0.7783155856727977,0.7802516940948693,0.7802516940948693,0.782187802516941,0.7841239109390126,0.7889641819941917,0.7889641819941917,0.8025169409486931,0.8025169409486931,0.8054211035818006,0.8073572120038722,0.8112294288480155,0.8112294288480155,0.8160696999031946,0.8160696999031946,0.8170377541142304,0.8170377541142304,0.818973862536302,0.818973862536302,0.8199419167473379,0.8199419167473379,0.8276863504356244,0.8276863504356244,0.8325266214908035,0.8325266214908035,0.8344627299128751,0.8344627299128751,0.8354307841239109,0.8373668925459826,0.8441432720232332,0.8441432720232332,0.8480154888673765,0.8480154888673765,0.8489835430784124,0.8489835430784124,0.8538238141335914,0.8538238141335914,0.8596321393998064,0.8596321393998064,0.8606001936108422,0.8606001936108422,0.8625363020329139,0.8625363020329139,0.8664085188770572,0.8664085188770572,0.8702807357212003,0.872216844143272,0.8818973862536302,0.8818973862536302,0.8838334946757018,0.8838334946757018,0.8848015488867377,0.8848015488867377,0.8877057115198451,0.8877057115198451,0.89351403678606,0.89351403678606,0.8944820909970959,0.8944820909970959,0.8964181994191674,0.8964181994191674,0.8983543078412392,0.8983543078412392,0.8993223620522749,0.8993223620522749,0.9022265246853823,0.9022265246853823,0.904162633107454,0.904162633107454,0.9051306873184899,0.9060987415295256,0.9070667957405615,0.9070667957405615,0.9090029041626331,0.9090029041626331,0.9109390125847048,0.9109390125847048,0.9119070667957405,0.9119070667957405,0.9128751210067764,0.9128751210067764,0.9138431752178122,0.9138431752178122,0.914811229428848,0.914811229428848,0.9186834462729913,0.9186834462729913,0.9196515004840271,0.9196515004840271,0.9215876089060987,0.9215876089060987,0.9225556631171346,0.9225556631171346,0.9312681510164569,0.9312681510164569,0.9322362052274927,0.9322362052274927,0.936108422071636,0.936108422071636,0.9390125847047435,0.9390125847047435,0.9399806389157793,0.9399806389157793,0.9409486931268151,0.9409486931268151,0.9419167473378509,0.9419167473378509,0.9428848015488868,0.9428848015488868,0.9438528557599225,0.9438528557599225,0.9448209099709584,0.9448209099709584,0.9457889641819942,0.9457889641819942,0.9477250726040658,0.9477250726040658,0.9486931268151017,0.9486931268151017,0.9496611810261375,0.9496611810261375,0.9506292352371732,0.9506292352371732,0.9515972894482091,0.9515972894482091,0.952565343659245,0.952565343659245,0.9535333978702807,0.9535333978702807,0.9545014520813165,0.9545014520813165,0.9564375605033882,0.9564375605033882,0.9603097773475314,0.9603097773475314,0.9622458857696031,0.9622458857696031,0.9632139399806389,0.9632139399806389,0.9641819941916747,0.9641819941916747,0.9651500484027106,0.9651500484027106,0.9661181026137464,0.9661181026137464,0.9670861568247822,0.9670861568247822,0.9690222652468539,0.9690222652468539,0.9699903194578896,0.9699903194578896,0.9709583736689255,0.9709583736689255,0.9719264278799613,0.9719264278799613,0.972894482090997,0.972894482090997,0.9738625363020329,0.9738625363020329,0.9748305905130688,0.9748305905130688,0.9757986447241046,0.9757986447241046,0.9777347531461762,0.9777347531461762,0.978702807357212,0.978702807357212,0.9796708615682478,0.9796708615682478,0.9806389157792836,0.9806389157792836,0.9816069699903195,0.9816069699903195,0.9825750242013552,0.9825750242013552,0.9835430784123911,0.9835430784123911,0.9854791868344628,0.9854791868344628,0.9864472410454985,0.9864472410454985,0.9874152952565344,0.9874152952565344,0.9883833494675702,0.9883833494675702,0.989351403678606,0.989351403678606,0.9912875121006777,0.9912875121006777,0.9922555663117134,0.9922555663117134,0.9932236205227493,0.9932236205227493,0.9941916747337851,0.9941916747337851,0.995159728944821,0.995159728944821,0.9961277831558567,0.9961277831558567,0.9970958373668926,0.9970958373668926,0.9980638915779284,0.9980638915779284,0.9990319457889641,0.9990319457889641,1.0,1.0],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"False Positive Rate\"},\"constrain\":\"domain\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"True Positive Rate\"},\"scaleanchor\":\"x\",\"scaleratio\":1},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"ROC Curve (AUC=0.8840)\"},\"height\":600,\"width\":800,\"shapes\":[{\"line\":{\"dash\":\"dash\"},\"type\":\"line\",\"x0\":0,\"x1\":1,\"y0\":0,\"y1\":1}],\"showlegend\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('a5ba148a-0ea1-46ff-802e-b1cd24321ca3');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"fillpattern":{"shape":""},"hovertemplate":"Recall=%{x}<br>Precision=%{y}<extra></extra>","legendgroup":"","line":{"color":"#636efa"},"marker":{"symbol":"circle"},"mode":"lines","name":"","orientation":"v","showlegend":false,"stackgroup":"1","type":"scatter","x":[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.995159728944821,0.995159728944821,0.995159728944821,0.9941916747337851,0.9941916747337851,0.9932236205227493,0.9932236205227493,0.9922555663117134,0.9922555663117134,0.9922555663117134,0.9922555663117134,0.9922555663117134,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9903194578896418,0.989351403678606,0.989351403678606,0.989351403678606,0.989351403678606,0.989351403678606,0.989351403678606,0.989351403678606,0.989351403678606,0.989351403678606,0.989351403678606,0.989351403678606,0.989351403678606,0.989351403678606,0.989351403678606,0.989351403678606,0.989351403678606,0.989351403678606,0.989351403678606,0.989351403678606,0.989351403678606,0.989351403678606,0.989351403678606,0.989351403678606,0.989351403678606,0.989351403678606,0.9883833494675702,0.9883833494675702,0.9883833494675702,0.9874152952565344,0.9874152952565344,0.9874152952565344,0.9864472410454985,0.9864472410454985,0.9864472410454985,0.9864472410454985,0.9864472410454985,0.9864472410454985,0.9854791868344628,0.9854791868344628,0.9854791868344628,0.9854791868344628,0.9854791868344628,0.9854791868344628,0.9854791868344628,0.9845111326234269,0.9835430784123911,0.9835430784123911,0.9835430784123911,0.9835430784123911,0.9835430784123911,0.9825750242013552,0.9825750242013552,0.9825750242013552,0.9816069699903195,0.9816069699903195,0.9816069699903195,0.9816069699903195,0.9816069699903195,0.9816069699903195,0.9806389157792836,0.9806389157792836,0.9806389157792836,0.9806389157792836,0.9806389157792836,0.9806389157792836,0.9806389157792836,0.9806389157792836,0.9796708615682478,0.9796708615682478,0.978702807357212,0.978702807357212,0.978702807357212,0.978702807357212,0.9777347531461762,0.9777347531461762,0.9767666989351403,0.9757986447241046,0.9757986447241046,0.9757986447241046,0.9748305905130688,0.9748305905130688,0.9748305905130688,0.9738625363020329,0.9738625363020329,0.9738625363020329,0.9738625363020329,0.9738625363020329,0.9738625363020329,0.9738625363020329,0.972894482090997,0.972894482090997,0.972894482090997,0.972894482090997,0.972894482090997,0.972894482090997,0.972894482090997,0.9719264278799613,0.9719264278799613,0.9709583736689255,0.9709583736689255,0.9699903194578896,0.9699903194578896,0.9690222652468539,0.9690222652468539,0.968054211035818,0.9670861568247822,0.9670861568247822,0.9670861568247822,0.9661181026137464,0.9661181026137464,0.9661181026137464,0.9651500484027106,0.9651500484027106,0.9651500484027106,0.9641819941916747,0.9641819941916747,0.9641819941916747,0.9632139399806389,0.9632139399806389,0.9632139399806389,0.9632139399806389,0.9632139399806389,0.9632139399806389,0.9632139399806389,0.9622458857696031,0.9622458857696031,0.9622458857696031,0.9622458857696031,0.9622458857696031,0.9622458857696031,0.9622458857696031,0.9612778315585673,0.9603097773475314,0.9603097773475314,0.9603097773475314,0.9593417231364957,0.9583736689254598,0.957405614714424,0.9564375605033882,0.9564375605033882,0.9554695062923524,0.9545014520813165,0.9545014520813165,0.9545014520813165,0.9535333978702807,0.9535333978702807,0.9535333978702807,0.9535333978702807,0.9535333978702807,0.952565343659245,0.952565343659245,0.952565343659245,0.952565343659245,0.9515972894482091,0.9515972894482091,0.9506292352371732,0.9506292352371732,0.9506292352371732,0.9506292352371732,0.9506292352371732,0.9506292352371732,0.9496611810261375,0.9496611810261375,0.9496611810261375,0.9486931268151017,0.9486931268151017,0.9477250726040658,0.9477250726040658,0.9467570183930301,0.9457889641819942,0.9457889641819942,0.9457889641819942,0.9448209099709584,0.9448209099709584,0.9438528557599225,0.9438528557599225,0.9438528557599225,0.9428848015488868,0.9428848015488868,0.9419167473378509,0.9419167473378509,0.9409486931268151,0.9409486931268151,0.9399806389157793,0.9399806389157793,0.9399806389157793,0.9399806389157793,0.9390125847047435,0.9390125847047435,0.9390125847047435,0.9390125847047435,0.9380445304937076,0.9370764762826719,0.936108422071636,0.936108422071636,0.936108422071636,0.936108422071636,0.9351403678606002,0.9341723136495643,0.9332042594385286,0.9322362052274927,0.9322362052274927,0.9312681510164569,0.9312681510164569,0.9303000968054211,0.9293320425943853,0.9283639883833494,0.9273959341723137,0.9264278799612778,0.925459825750242,0.9244917715392061,0.9235237173281704,0.9225556631171346,0.9225556631171346,0.9225556631171346,0.9215876089060987,0.9215876089060987,0.9215876089060987,0.9215876089060987,0.9215876089060987,0.9215876089060987,0.9215876089060987,0.9215876089060987,0.920619554695063,0.9196515004840271,0.9196515004840271,0.9196515004840271,0.9186834462729913,0.9186834462729913,0.9186834462729913,0.9177153920619555,0.9167473378509197,0.9157792836398838,0.914811229428848,0.914811229428848,0.9138431752178122,0.9138431752178122,0.9128751210067764,0.9128751210067764,0.9128751210067764,0.9119070667957405,0.9119070667957405,0.9109390125847048,0.9109390125847048,0.9109390125847048,0.9109390125847048,0.9099709583736689,0.9090029041626331,0.9090029041626331,0.9090029041626331,0.9090029041626331,0.9080348499515973,0.9070667957405615,0.9070667957405615,0.9060987415295256,0.9051306873184899,0.904162633107454,0.904162633107454,0.9031945788964182,0.9022265246853823,0.9022265246853823,0.9022265246853823,0.9012584704743466,0.9002904162633107,0.8993223620522749,0.8993223620522749,0.8993223620522749,0.8983543078412392,0.8983543078412392,0.8973862536302033,0.8964181994191674,0.8964181994191674,0.8954501452081317,0.8944820909970959,0.8944820909970959,0.89351403678606,0.89351403678606,0.8925459825750242,0.8915779283639884,0.8906098741529526,0.8896418199419167,0.888673765730881,0.8877057115198451,0.8877057115198451,0.8867376573088093,0.8857696030977735,0.8848015488867377,0.8848015488867377,0.8848015488867377,0.8838334946757018,0.8838334946757018,0.882865440464666,0.8818973862536302,0.8818973862536302,0.8809293320425944,0.8799612778315585,0.8789932236205228,0.8780251694094869,0.8770571151984511,0.8760890609874153,0.8751210067763795,0.8741529525653436,0.8731848983543078,0.872216844143272,0.8702807357212003,0.8693126815101646,0.8683446272991288,0.8673765730880929,0.8664085188770572,0.8664085188770572,0.8664085188770572,0.8654404646660213,0.8644724104549855,0.8635043562439496,0.8625363020329139,0.8625363020329139,0.861568247821878,0.8606001936108422,0.8606001936108422,0.8596321393998064,0.8596321393998064,0.8596321393998064,0.8596321393998064,0.8596321393998064,0.8586640851887706,0.8576960309777347,0.856727976766699,0.8557599225556631,0.8547918683446273,0.8538238141335914,0.8538238141335914,0.8528557599225557,0.8518877057115198,0.850919651500484,0.8499515972894482,0.8489835430784124,0.8489835430784124,0.8489835430784124,0.8489835430784124,0.8480154888673765,0.8480154888673765,0.8480154888673765,0.8480154888673765,0.8470474346563408,0.846079380445305,0.8451113262342691,0.8441432720232332,0.8441432720232332,0.8431752178121975,0.8422071636011617,0.8412391093901258,0.8402710551790901,0.8393030009680542,0.8383349467570184,0.8373668925459826,0.8354307841239109,0.8344627299128751,0.8344627299128751,0.8334946757018393,0.8325266214908035,0.8325266214908035,0.8315585672797676,0.8305905130687319,0.829622458857696,0.8286544046466602,0.8276863504356244,0.8276863504356244,0.8267182962245886,0.8257502420135527,0.8247821878025169,0.8238141335914811,0.8228460793804453,0.8218780251694094,0.8209099709583737,0.8199419167473379,0.8199419167473379,0.818973862536302,0.818973862536302,0.8180058083252663,0.8170377541142304,0.8170377541142304,0.8170377541142304,0.8160696999031946,0.8160696999031946,0.8151016456921588,0.814133591481123,0.8131655372700871,0.8121974830590513,0.8112294288480155,0.8112294288480155,0.8102613746369797,0.8092933204259438,0.8083252662149081,0.8073572120038722,0.8054211035818006,0.8044530493707648,0.8034849951597289,0.8025169409486931,0.8025169409486931,0.8015488867376573,0.8005808325266215,0.7996127783155856,0.7986447241045499,0.797676669893514,0.7967086156824782,0.7957405614714425,0.7947725072604066,0.7938044530493708,0.7928363988383349,0.7918683446272992,0.7909002904162633,0.7899322362052275,0.7889641819941917,0.7889641819941917,0.7889641819941917,0.7879961277831559,0.78702807357212,0.7860600193610843,0.7850919651500484,0.7841239109390126,0.782187802516941,0.7812197483059051,0.7802516940948693,0.7802516940948693,0.7792836398838335,0.7783155856727977,0.7783155856727977,0.7773475314617618,0.7763794772507261,0.7763794772507261,0.7754114230396902,0.7744433688286544,0.7744433688286544,0.7734753146176185,0.7725072604065828,0.7725072604065828,0.7725072604065828,0.771539206195547,0.7705711519845111,0.7696030977734754,0.7686350435624395,0.7676669893514037,0.7666989351403679,0.7657308809293321,0.7647628267182962,0.7637947725072604,0.7637947725072604,0.7628267182962246,0.7628267182962246,0.7618586640851888,0.7608906098741529,0.7599225556631172,0.7589545014520813,0.7589545014520813,0.7579864472410455,0.7570183930300097,0.7560503388189739,0.755082284607938,0.7541142303969022,0.7531461761858664,0.7521781219748306,0.7512100677637947,0.7512100677637947,0.750242013552759,0.7492739593417231,0.7483059051306873,0.7483059051306873,0.7483059051306873,0.7473378509196515,0.7473378509196515,0.7463697967086157,0.7454017424975798,0.744433688286544,0.7434656340755083,0.7424975798644724,0.7415295256534365,0.7415295256534365,0.7405614714424008,0.739593417231365,0.7386253630203291,0.7376573088092934,0.7366892545982575,0.7357212003872217,0.7347531461761858,0.7347531461761858,0.7337850919651501,0.7328170377541142,0.7318489835430784,0.7308809293320426,0.7299128751210068,0.7289448209099709,0.7289448209099709,0.7279767666989352,0.7270087124878993,0.7260406582768635,0.7260406582768635,0.7250726040658277,0.7250726040658277,0.7241045498547919,0.723136495643756,0.723136495643756,0.7221684414327202,0.7212003872216844,0.7202323330106486,0.7202323330106486,0.7192642787996127,0.718296224588577,0.7173281703775412,0.7153920619554696,0.7144240077444337,0.7134559535333979,0.7134559535333979,0.712487899322362,0.7115198451113263,0.7105517909002904,0.7095837366892546,0.7086156824782188,0.707647628267183,0.7066795740561471,0.7057115198451114,0.7057115198451114,0.7047434656340755,0.7037754114230397,0.7028073572120038,0.7018393030009681,0.7008712487899322,0.6999031945788964,0.6999031945788964,0.6989351403678606,0.6979670861568248,0.6969990319457889,0.6960309777347532,0.6950629235237173,0.6940948693126815,0.6931268151016456,0.6921587608906099,0.691190706679574,0.6902226524685382,0.6902226524685382,0.6892545982575025,0.6882865440464666,0.6873184898354308,0.686350435624395,0.6853823814133592,0.6844143272023233,0.6834462729912875,0.6824782187802517,0.6815101645692159,0.68054211035818,0.6795740561471443,0.6786060019361084,0.6776379477250726,0.6766698935140368,0.675701839303001,0.6747337850919651,0.6737657308809293,0.6727976766698935,0.6718296224588577,0.6718296224588577,0.6708615682478218,0.6698935140367861,0.6698935140367861,0.6689254598257502,0.6679574056147144,0.6669893514036787,0.6660212971926428,0.665053242981607,0.6640851887705711,0.6640851887705711,0.6631171345595354,0.6631171345595354,0.6631171345595354,0.6621490803484995,0.6611810261374637,0.6602129719264279,0.6592449177153921,0.6573088092933205,0.6563407550822846,0.6563407550822846,0.6553727008712488,0.6544046466602129,0.6534365924491772,0.6524685382381413,0.6524685382381413,0.6515004840271055,0.6515004840271055,0.6505324298160697,0.6495643756050339,0.648596321393998,0.6476282671829623,0.6466602129719264,0.6456921587608906,0.6447241045498547,0.643756050338819,0.643756050338819,0.6427879961277831,0.6418199419167473,0.6418199419167473,0.6418199419167473,0.6408518877057116,0.6398838334946757,0.6389157792836399,0.6379477250726041,0.6369796708615683,0.6360116166505324,0.6350435624394967,0.6340755082284608,0.633107454017425,0.633107454017425,0.6321393998063891,0.6311713455953534,0.6302032913843175,0.6292352371732817,0.6282671829622459,0.6272991287512101,0.6263310745401742,0.6253630203291385,0.6243949661181026,0.6234269119070668,0.6224588576960309,0.6205227492739593,0.6195546950629235,0.6185866408518877,0.6185866408518877,0.6176185866408519,0.616650532429816,0.6156824782187803,0.6147144240077445,0.6137463697967086,0.6127783155856728,0.611810261374637,0.6108422071636012,0.6108422071636012,0.6098741529525653,0.6089060987415296,0.6079380445304937,0.6069699903194579,0.6060019361084221,0.6050338818973863,0.6040658276863504,0.6040658276863504,0.6030977734753146,0.6021297192642788,0.6021297192642788,0.601161665053243,0.6001936108422071,0.5992255566311714,0.5972894482090997,0.5963213939980639,0.5953533397870281,0.5943852855759922,0.5934172313649564,0.5924491771539206,0.5914811229428848,0.590513068731849,0.5895450145208132,0.5885769603097774,0.5876089060987415,0.5876089060987415,0.5866408518877058,0.5856727976766699,0.5847047434656341,0.5837366892545982,0.5827686350435625,0.5827686350435625,0.5818005808325266,0.5818005808325266,0.5808325266214908,0.579864472410455,0.5788964181994192,0.5779283639883833,0.5769603097773476,0.5759922555663117,0.5750242013552759,0.57405614714424,0.5730880929332043,0.5721200387221684,0.5711519845111326,0.5711519845111326,0.5701839303000968,0.569215876089061,0.5682478218780251,0.5682478218780251,0.5672797676669894,0.5663117134559535,0.5653436592449177,0.5643756050338818,0.5634075508228461,0.5624394966118103,0.5614714424007744,0.5605033881897387,0.5595353339787028,0.558567279767667,0.5575992255566312,0.5575992255566312,0.5575992255566312,0.5566311713455954,0.5556631171345595,0.5546950629235237,0.5546950629235237,0.5537270087124879,0.5527589545014521,0.5517909002904162,0.5517909002904162,0.5517909002904162,0.5508228460793805,0.5498547918683446,0.5488867376573088,0.5488867376573088,0.547918683446273,0.5469506292352372,0.5459825750242013,0.5440464666021297,0.5430784123910939,0.542110358180058,0.5411423039690223,0.5401742497579864,0.5392061955469506,0.5382381413359149,0.537270087124879,0.5363020329138432,0.5353339787028074,0.5343659244917716,0.5333978702807357,0.5324298160696999,0.5314617618586641,0.5304937076476283,0.5295256534365924,0.5285575992255567,0.5275895450145208,0.526621490803485,0.5256534365924492,0.5246853823814134,0.5237173281703775,0.5227492739593417,0.5217812197483059,0.5208131655372701,0.5198451113262342,0.5188770571151985,0.5179090029041626,0.5169409486931268,0.515972894482091,0.5150048402710552,0.5140367860600193,0.5130687318489835,0.5121006776379478,0.5111326234269119,0.510164569215876,0.5091965150048403,0.5091965150048403,0.5082284607938045,0.5072604065827686,0.5072604065827686,0.5062923523717329,0.505324298160697,0.5043562439496612,0.5033881897386253,0.5024201355275896,0.5014520813165537,0.5004840271055179,0.4995159728944821,0.4985479186834463,0.4975798644724105,0.49661181026137463,0.49564375605033884,0.494675701839303,0.4937076476282672,0.4927395934172314,0.49177153920619554,0.49080348499515974,0.4898354307841239,0.4888673765730881,0.4878993223620523,0.48693126815101645,0.48596321393998065,0.48596321393998065,0.4849951597289448,0.484027105517909,0.484027105517909,0.4830590513068732,0.48209099709583736,0.48112294288480156,0.48112294288480156,0.4801548886737657,0.4791868344627299,0.4782187802516941,0.47725072604065827,0.4762826718296225,0.4753146176185866,0.4743465634075508,0.47337850919651503,0.4724104549854792,0.4714424007744434,0.47047434656340753,0.47047434656340753,0.46950629235237173,0.46853823814133594,0.4675701839303001,0.4666021297192643,0.46563407550822844,0.46466602129719264,0.46369796708615685,0.462729912875121,0.4617618586640852,0.46079380445304935,0.45885769603097776,0.4578896418199419,0.4569215876089061,0.45595353339787026,0.45498547918683446,0.45401742497579867,0.4530493707647628,0.452081316553727,0.45111326234269117,0.45014520813165537,0.4491771539206196,0.4482090997095837,0.44724104549854793,0.4462729912875121,0.4453049370764763,0.4443368828654405,0.44336882865440463,0.44240077444336884,0.441432720232333,0.4404646660212972,0.4394966118102614,0.43852855759922554,0.43756050338818975,0.4365924491771539,0.4356243949661181,0.4346563407550823,0.43368828654404645,0.43272023233301066,0.4317521781219748,0.430784123910939,0.4298160696999032,0.42884801548886736,0.42884801548886736,0.42787996127783157,0.4269119070667957,0.4269119070667957,0.4259438528557599,0.4259438528557599,0.4249757986447241,0.42400774443368827,0.4230396902226525,0.4220716360116166,0.42110358180058083,0.42013552758954503,0.4191674733785092,0.4181994191674734,0.41723136495643753,0.41626331074540174,0.41529525653436594,0.4143272023233301,0.4133591481122943,0.4133591481122943,0.41239109390125844,0.41142303969022265,0.41045498547918685,0.409486931268151,0.4085188770571152,0.4075508228460794,0.40658276863504356,0.40561471442400776,0.4046466602129719,0.4036786060019361,0.4027105517909003,0.4027105517909003,0.40174249757986447,0.40077444336882867,0.3998063891577928,0.3998063891577928,0.398838334946757,0.3978702807357212,0.3969022265246854,0.3959341723136496,0.39496611810261373,0.39399806389157793,0.39399806389157793,0.39303000968054214,0.3920619554695063,0.3910939012584705,0.39012584704743464,0.38915779283639884,0.38818973862536305,0.3872216844143272,0.38431752178121975,0.38334946757018395,0.3823814133591481,0.3814133591481123,0.38044530493707646,0.37947725072604066,0.37850919651500486,0.377541142303969,0.3765730880929332,0.37560503388189737,0.37463697967086157,0.3736689254598258,0.3727008712487899,0.3717328170377541,0.3707647628267183,0.3697967086156825,0.3688286544046467,0.36786060019361083,0.36689254598257504,0.3659244917715392,0.3649564375605034,0.3639883833494676,0.36302032913843174,0.36205227492739595,0.3610842207163601,0.3601161665053243,0.3591481122942885,0.35818005808325265,0.35721200387221685,0.356243949661181,0.3552758954501452,0.3543078412391094,0.35333978702807356,0.35237173281703776,0.3514036786060019,0.3504356243949661,0.3494675701839303,0.34849951597289447,0.3475314617618587,0.3465634075508228,0.345595353339787,0.34462729912875123,0.3436592449177154,0.3426911907066796,0.34172313649564373,0.34075508228460794,0.33978702807357214,0.3388189738625363,0.3378509196515005,0.33591481122942884,0.33494675701839305,0.3339787028073572,0.3330106485963214,0.33204259438528555,0.33107454017424975,0.33010648596321396,0.3291384317521781,0.3281703775411423,0.32720232333010646,0.32623426911907066,0.32526621490803487,0.324298160696999,0.3233301064859632,0.32236205227492737,0.3213939980638916,0.3194578896418199,0.31848983543078413,0.31752178121974833,0.3165537270087125,0.3155856727976767,0.31364956437560504,0.31268151016456924,0.3117134559535334,0.3107454017424976,0.30977734753146174,0.30880929332042595,0.30784123910939015,0.3068731848983543,0.3059051306873185,0.30396902226524686,0.30300096805421106,0.3020329138431752,0.3010648596321394,0.30009680542110356,0.29912875121006777,0.29816069699903197,0.29816069699903197,0.2971926427879961,0.2962245885769603,0.2952565343659245,0.2942884801548887,0.2933204259438529,0.29235237173281703,0.29138431752178123,0.2904162633107454,0.2894482090997096,0.2894482090997096,0.2884801548886738,0.28751210067763794,0.28654404646660214,0.2855759922555663,0.2836398838334947,0.28267182962245885,0.28170377541142305,0.2807357212003872,0.2797676669893514,0.2787996127783156,0.27783155856727976,0.27686350435624396,0.2758954501452081,0.2749273959341723,0.27202323330106487,0.271055179090029,0.2691190706679574,0.2681510164569216,0.2671829622458858,0.26621490803484993,0.26427879961277834,0.2633107454017425,0.2623426911907067,0.26137463697967084,0.26040658276863504,0.25943852855759925,0.2584704743465634,0.2575024201355276,0.25653436592449175,0.25556631171345595,0.25459825750242016,0.2536302032913843,0.25169409486931266,0.25072604065827686,0.24975798644724104,0.24878993223620524,0.24782187802516942,0.2468538238141336,0.24588576960309777,0.24491771539206195,0.24394966118102615,0.24298160696999033,0.2420135527589545,0.24104549854791868,0.24007744433688286,0.23910939012584706,0.23814133591481124,0.2371732817037754,0.2362052274927396,0.23523717328170377,0.23426911907066797,0.23330106485963215,0.23233301064859632,0.2313649564375605,0.23039690222652467,0.22942884801548888,0.22846079380445306,0.22749273959341723,0.2265246853823814,0.22555663117134558,0.2245885769603098,0.22362052274927396,0.2207163601161665,0.2197483059051307,0.21878025169409487,0.21781219748305905,0.21684414327202323,0.2158760890609874,0.2149080348499516,0.21393998063891578,0.21297192642787996,0.21200387221684414,0.21006776379477252,0.2090997095837367,0.20813165537270087,0.20619554695062922,0.20522749273959343,0.20329138431752178,0.20232333010648595,0.20135527589545016,0.20038722168441434,0.1994191674733785,0.1984511132623427,0.19748305905130686,0.19651500484027107,0.19554695062923524,0.19457889641819942,0.1936108422071636,0.19264278799612777,0.19167473378509198,0.19070667957405615,0.19070667957405615,0.18973862536302033,0.1887705711519845,0.18780251694094868,0.1868344627299129,0.18586640851887706,0.18489835430784124,0.18393030009680542,0.1819941916747338,0.18102613746369797,0.18005808325266215,0.1781219748305905,0.1771539206195547,0.17618586640851888,0.17521781219748306,0.17424975798644723,0.17231364956437561,0.1713455953533398,0.16940948693126814,0.16844143272023232,0.16747337850919652,0.16553727008712488,0.16456921587608905,0.16360116166505323,0.16263310745401743,0.1616650532429816,0.15972894482090996,0.15876089060987417,0.15779283639883834,0.1558567279767667,0.15488867376573087,0.15392061955469508,0.15295256534365925,0.15198451113262343,0.1510164569215876,0.15004840271055178,0.14908034849951599,0.14811229428848016,0.14714424007744434,0.14617618586640851,0.1452081316553727,0.1442400774443369,0.14327202323330107,0.14230396902226525,0.14133591481122942,0.1403678606001936,0.1393998063891578,0.13843175217812198,0.13746369796708616,0.13649564375605033,0.1355275895450145,0.1345595353339787,0.1335914811229429,0.13165537270087124,0.13068731848983542,0.12971926427879962,0.12584704743465633,0.12391093901258471,0.12197483059051308,0.12100677637947725,0.11907066795740562,0.1181026137463698,0.11713455953533398,0.11616650532429816,0.11519845111326234,0.11423039690222653,0.1132623426911907,0.1122942884801549,0.11132623426911907,0.10939012584704744,0.10842207163601161,0.1074540174249758,0.10551790900290416,0.10454985479186835,0.10358180058083252,0.10164569215876089,0.10067763794772508,0.09970958373668926,0.09874152952565343,0.09777347531461762,0.09583736689254599,0.09486931268151017,0.09390125847047434,0.09196515004840271,0.0909970958373669,0.09002904162633107,0.08906098741529525,0.08615682478218781,0.08422071636011616,0.07938044530493708,0.07163601161665054,0.06873184898354308,0.06679574056147145,0.06389157792836399,0.06098741529525654,0.05614714424007745,0.046466602129719266,0],"xaxis":"x","y":[0.7341862117981521,0.7347083926031295,0.7352313167259786,0.7357549857549858,0.7362794012829651,0.7368045649072753,0.7373304782298359,0.7378571428571429,0.7383845604002859,0.7389127324749643,0.7394416607015032,0.7399713467048711,0.7405017921146954,0.7410329985652798,0.741564967695621,0.7420977011494253,0.7426312005751258,0.7431654676258993,0.7437005039596832,0.7442363112391931,0.7447728911319395,0.7453102453102453,0.7458483754512636,0.7463872832369942,0.7469269703543022,0.7474674384949349,0.7480086893555394,0.7485507246376811,0.7490935460478607,0.7496371552975326,0.7501815541031227,0.7507267441860465,0.7512727272727273,0.7518195050946143,0.752367079388201,0.7529154518950437,0.7534646243617797,0.754014598540146,0.7545653761869978,0.7551169590643275,0.7556693489392831,0.7562225475841874,0.756043956043956,0.7565982404692082,0.7571533382245048,0.7569750367107195,0.7575312270389419,0.7580882352941176,0.7586460632818248,0.7592047128129602,0.7597641857037583,0.7603244837758112,0.7608856088560886,0.7614475627769571,0.762010347376201,0.7625739644970414,0.7631384159881569,0.7637037037037037,0.7642698295033358,0.7648367952522255,0.7654046028210839,0.7659732540861813,0.7665427509293681,0.7671130952380952,0.7676842889054356,0.7682563338301043,0.7688292319164802,0.7694029850746269,0.7699775952203136,0.7705530642750373,0.7703814510097232,0.7709580838323353,0.7715355805243446,0.7721139430284858,0.7726931732933233,0.7732732732732732,0.7738542449286251,0.7744360902255639,0.7742663656884876,0.7748493975903614,0.7754333082140166,0.77526395173454,0.7758490566037736,0.7764350453172205,0.7762660619803476,0.7768532526475038,0.7766843300529902,0.7772727272727272,0.77710386656558,0.7776934749620638,0.7782839787395596,0.7788753799392097,0.779467680608365,0.7792998477929984,0.7798933739527799,0.7804878048780488,0.7810831426392068,0.7816793893129771,0.7815126050420168,0.7813455657492355,0.7819433817903596,0.7825421133231241,0.7831417624521073,0.7837423312883436,0.7843438219493477,0.7849462365591398,0.7855495772482706,0.7861538461538462,0.7867590454195535,0.7873651771956857,0.7879722436391673,0.7885802469135802,0.7891891891891892,0.7897990726429676,0.7904098994586234,0.7910216718266254,0.7916343919442292,0.7922480620155039,0.7928626842513576,0.7934782608695652,0.7940947940947941,0.7947122861586314,0.7953307392996108,0.7959501557632399,0.7957911145752143,0.7964118564742589,0.7970335675253708,0.796875,0.7974980453479281,0.7981220657276995,0.79796397807361,0.79858934169279,0.7992156862745098,0.7998430141287284,0.800471327572663,0.8011006289308176,0.8009441384736428,0.8015748031496063,0.8022064617809299,0.8028391167192429,0.8034727703235991,0.8041074249605056,0.8047430830039526,0.8045886075949367,0.8044338875692795,0.8050713153724247,0.8057097541633624,0.8063492063492064,0.806989674344718,0.8068362480127186,0.807478122513922,0.8081210191082803,0.8086124401913876,0.8092577813248204,0.8099041533546326,0.8105515587529976,0.8112,0.8118494795836669,0.811698717948718,0.8123496391339214,0.8130016051364366,0.8136546184738955,0.8143086816720257,0.8149637972646823,0.8156199677938808,0.8162771958098308,0.8161290322580645,0.8167877320419693,0.8166397415185783,0.8172999191592563,0.8179611650485437,0.8186234817813766,0.8184764991896273,0.819140308191403,0.8189935064935064,0.8188464662875711,0.8195121951219512,0.8201790073230268,0.8200325732899023,0.8207008964955175,0.8213703099510603,0.8212244897959183,0.8218954248366013,0.8225674570727719,0.823240589198036,0.823914823914824,0.8245901639344262,0.8252666119770303,0.8251231527093597,0.8258011503697618,0.8264802631578947,0.8271604938271605,0.8278418451400329,0.8285243198680956,0.8292079207920792,0.8290668868703551,0.8297520661157025,0.8296112489660876,0.8302980132450332,0.8301574150787076,0.8308457711442786,0.8307053941908714,0.8313953488372093,0.8312551953449709,0.8311148086522463,0.8318068276436303,0.8325,0.8323603002502085,0.8330550918196995,0.83375104427736,0.8336120401337793,0.8343096234309624,0.8350083752093802,0.8348700754400671,0.8355704697986577,0.836272040302267,0.8361344537815126,0.8368376787216149,0.8375420875420876,0.8382476832350463,0.8389544688026982,0.8396624472573839,0.8403716216216216,0.8402366863905325,0.8409475465313029,0.8416596104995766,0.8423728813559322,0.8430873621713316,0.8438030560271647,0.8445199660152931,0.8443877551020408,0.8442553191489361,0.8449744463373083,0.8456947996589941,0.8455631399317406,0.8454312553373186,0.8452991452991453,0.8451668092386655,0.8458904109589042,0.8457583547557841,0.8456260720411664,0.8463519313304722,0.8470790378006873,0.8469475494411006,0.8476764199655766,0.8484065460809647,0.8491379310344828,0.8498705780845557,0.8497409326424871,0.8504753673293,0.8512110726643599,0.8519480519480519,0.8518197573656846,0.852558542931483,0.8524305555555556,0.8531711555169418,0.8539130434782609,0.8546562228024369,0.8554006968641115,0.8561464690496948,0.856020942408377,0.856768558951965,0.8575174825174825,0.8573928258967629,0.8581436077057794,0.8580192813321648,0.8587719298245614,0.858647936786655,0.8585237258347979,0.8592788038698329,0.8600352112676056,0.8599118942731278,0.8606701940035273,0.8605472197705207,0.8613074204946997,0.8620689655172413,0.8619469026548673,0.8627103631532329,0.8625886524822695,0.8633540372670807,0.8632326820603907,0.864,0.8638790035587188,0.8646482635796973,0.8654188948306596,0.8661909009812667,0.8660714285714286,0.8668453976764968,0.8676207513416816,0.8683974932855864,0.8682795698924731,0.8681614349775785,0.8680430879712747,0.8688230008984726,0.8696043165467626,0.8703870387038704,0.8702702702702703,0.8701532912533815,0.8700361010830325,0.8699186991869918,0.8707052441229657,0.8705882352941177,0.8713768115942029,0.8712601994560291,0.8711433756805808,0.8710263396911898,0.8709090909090909,0.8707916287534122,0.8706739526411658,0.8705560619872379,0.8704379562043796,0.8703196347031964,0.8711151736745887,0.8719121683440073,0.8717948717948718,0.8725939505041247,0.8733944954128441,0.8741965105601469,0.875,0.8758049678012879,0.8766114180478821,0.8774193548387097,0.8773062730627307,0.8771929824561403,0.878003696857671,0.8788159111933395,0.8787037037037037,0.8795180722891566,0.8803339517625232,0.8802228412256268,0.8801115241635687,0.88,0.8798882681564246,0.880708294501398,0.8805970149253731,0.8814192343604108,0.8813084112149533,0.882132834424696,0.8829588014981273,0.8828491096532334,0.8836772983114447,0.8835680751173709,0.8843984962406015,0.8852304797742239,0.8860640301318268,0.885956644674835,0.8858490566037736,0.886685552407932,0.8875236294896031,0.8883632923368022,0.8882575757575758,0.8881516587677725,0.8889943074003795,0.8888888888888888,0.8896289248334919,0.8895238095238095,0.8903717826501429,0.8902671755725191,0.8901623686723973,0.8910133843212237,0.8918660287081339,0.8917624521072797,0.8916586768935763,0.8915547024952015,0.8924111431316042,0.8932692307692308,0.8931665062560153,0.8940269749518305,0.8939247830279653,0.8938223938223938,0.8946859903381642,0.8945841392649904,0.8944820909970959,0.8953488372093024,0.895247332686712,0.8961165048543689,0.8960155490767736,0.8959143968871596,0.8958130477117819,0.8957115009746589,0.895609756097561,0.8955078125,0.8963831867057673,0.8962818003913894,0.8961802154750245,0.8960784313725491,0.8969578017664377,0.8978388998035364,0.8977384464110127,0.8986220472440944,0.8985221674876848,0.8984220907297831,0.8993089832181639,0.8992094861660079,0.8991097922848664,0.899009900990099,0.8989098116947473,0.8988095238095238,0.8987090367428004,0.8986083499005965,0.8985074626865671,0.898406374501992,0.8983050847457628,0.8981018981018981,0.898,0.8978978978978979,0.8977955911823647,0.8976930792377131,0.8985943775100401,0.8994974874371859,0.8993963782696177,0.8992950654582075,0.8991935483870968,0.8990918264379415,0.9,0.8998988877654196,0.8997975708502024,0.900709219858156,0.9006085192697769,0.9015228426395939,0.9024390243902439,0.9033570701932858,0.9042769857433809,0.9041794087665648,0.9040816326530612,0.9039836567926456,0.9038854805725971,0.9037871033776868,0.9036885245901639,0.9046153846153846,0.9045174537987679,0.9044193216855088,0.904320987654321,0.9042224510813595,0.9041237113402062,0.9050567595459237,0.90599173553719,0.9069286452947259,0.906832298136646,0.9077720207253887,0.9087136929460581,0.9096573208722741,0.9095634095634095,0.9094693028095734,0.909375,0.9092805005213764,0.9102296450939458,0.910135841170324,0.9100418410041841,0.9099476439790576,0.909853249475891,0.9097586568730325,0.9096638655462185,0.9095688748685594,0.9093782929399368,0.9092827004219409,0.9102428722280888,0.9101479915433404,0.91005291005291,0.9110169491525424,0.9109225874867445,0.910828025477707,0.9107332624867163,0.9106382978723404,0.9105431309904153,0.9115138592750534,0.9114194236926361,0.9113247863247863,0.9112299465240642,0.911134903640257,0.9110396570203644,0.9109442060085837,0.9108485499462943,0.910752688172043,0.9117330462863293,0.9116379310344828,0.912621359223301,0.9125269978401728,0.9124324324324324,0.9134199134199135,0.914409534127844,0.9143167028199566,0.9153094462540716,0.9152173913043479,0.9151251360174102,0.9150326797385621,0.9149400218102508,0.9148471615720524,0.9158469945355191,0.9157549234135668,0.9156626506024096,0.9155701754385965,0.9154774972557629,0.9152915291529153,0.9151982378854625,0.9151047409040793,0.9150110375275938,0.9160220994475138,0.915929203539823,0.9158361018826136,0.9157427937915743,0.9156492785793563,0.9155555555555556,0.9154616240266963,0.9153674832962138,0.915273132664437,0.9151785714285714,0.9150837988826815,0.9149888143176734,0.9148936170212766,0.9147982062780269,0.9147025813692481,0.9157303370786517,0.9167604049493814,0.9166666666666666,0.9165727170236753,0.9164785553047404,0.9163841807909604,0.916289592760181,0.9160997732426304,0.9160045402951191,0.9159090909090909,0.9169510807736063,0.9168564920273349,0.9167616875712656,0.9178082191780822,0.9177142857142857,0.9176201372997712,0.9186712485681557,0.9185779816513762,0.9184845005740528,0.9195402298850575,0.9194476409666283,0.9193548387096774,0.9214780600461894,0.922543352601156,0.9224537037037037,0.9223638470451911,0.9222737819025522,0.9221835075493612,0.922093023255814,0.9220023282887078,0.921911421911422,0.9218203033838973,0.9217289719626168,0.9228070175438596,0.9227166276346604,0.9237983587338804,0.9237089201877934,0.9236192714453584,0.9235294117647059,0.9234393404004712,0.9245283018867925,0.9244391971664699,0.9243498817966903,0.9242603550295858,0.9241706161137441,0.9240806642941874,0.9239904988123515,0.9239001189060642,0.9238095238095239,0.9249106078665077,0.9248210023866349,0.9247311827956989,0.9246411483253588,0.925748502994012,0.9268585131894485,0.9267707082833133,0.9278846153846154,0.927797833935018,0.927710843373494,0.9276236429433052,0.927536231884058,0.9274486094316807,0.927360774818402,0.9284848484848485,0.9283980582524272,0.928311057108141,0.9282238442822385,0.928136419001218,0.9280487804878049,0.927960927960928,0.9278728606356969,0.9290085679314566,0.928921568627451,0.9288343558282208,0.9287469287469288,0.9286592865928659,0.9285714285714286,0.9284833538840938,0.9296296296296296,0.9295426452410384,0.9294554455445545,0.929368029739777,0.9305210918114144,0.9304347826086956,0.931592039800995,0.9315068493150684,0.9314214463840399,0.9325842696629213,0.9325,0.932415519399249,0.9323308270676691,0.9335006273525721,0.9334170854271356,0.9333333333333333,0.9332493702770781,0.9330808080808081,0.9329962073324906,0.9329113924050633,0.9340937896070975,0.934010152284264,0.9339263024142312,0.9338422391857506,0.9337579617834395,0.9336734693877551,0.933588761174968,0.9335038363171355,0.9334186939820742,0.9346153846153846,0.9345314505776636,0.9344473007712082,0.9343629343629344,0.9342783505154639,0.9341935483870968,0.9341085271317829,0.9353169469598965,0.9352331606217616,0.9351491569390402,0.935064935064935,0.9349804941482445,0.9348958333333334,0.9348109517601043,0.9347258485639687,0.934640522875817,0.9345549738219895,0.9344692005242464,0.9356955380577427,0.9356110381077529,0.9355263157894737,0.9354413702239789,0.9353562005277045,0.9352708058124174,0.9351851851851852,0.9350993377483444,0.9350132625994695,0.9349269588313412,0.9348404255319149,0.9347536617842876,0.9346666666666666,0.9345794392523364,0.9344919786096256,0.9344042838018741,0.9343163538873994,0.934228187919463,0.9341397849462365,0.9340511440107672,0.9353099730458221,0.9352226720647774,0.9351351351351351,0.9364005412719891,0.9363143631436315,0.9362279511533242,0.936141304347826,0.9360544217687075,0.9359673024523161,0.9358799454297408,0.9371584699453552,0.9370725034199726,0.9383561643835616,0.9396433470507545,0.9395604395604396,0.9394773039889959,0.9393939393939394,0.9393103448275862,0.9391424619640387,0.9390581717451524,0.9403606102635229,0.9402777777777778,0.9401947148817803,0.9401114206128134,0.9400278940027894,0.9413407821229051,0.9412587412587412,0.9425770308123249,0.9424964936886395,0.9424157303370787,0.9423347398030942,0.9422535211267605,0.9421720733427362,0.942090395480226,0.942008486562942,0.9419263456090652,0.9432624113475178,0.9431818181818182,0.9431009957325747,0.9444444444444444,0.9457917261055635,0.9457142857142857,0.9456366237482118,0.9455587392550143,0.945480631276901,0.9454022988505747,0.9453237410071943,0.9452449567723343,0.9451659451659452,0.9450867052023122,0.9464544138929089,0.946376811594203,0.9462989840348331,0.9462209302325582,0.9461426491994177,0.9460641399416909,0.945985401459854,0.945906432748538,0.9458272327964861,0.9457478005865103,0.9456681350954479,0.9455882352941176,0.9454277286135693,0.9453471196454948,0.9452662721893491,0.9466666666666667,0.9465875370919882,0.9465081723625557,0.9464285714285714,0.9463487332339792,0.9462686567164179,0.9461883408071748,0.9461077844311377,0.9460269865067467,0.9474474474474475,0.9473684210526315,0.947289156626506,0.947209653092006,0.947129909365559,0.9470499243570348,0.946969696969697,0.9468892261001517,0.9483282674772037,0.9482496194824962,0.948170731707317,0.9496183206106871,0.9495412844036697,0.9494640122511485,0.9493865030674846,0.9492307692307692,0.9491525423728814,0.9490740740740741,0.9489953632148377,0.9489164086687306,0.9488372093023256,0.9487577639751553,0.9486780715396579,0.9485981308411215,0.9485179407176287,0.9484375,0.9499217527386542,0.9498432601880877,0.9497645211930926,0.949685534591195,0.9496062992125984,0.9495268138801262,0.9510268562401264,0.9509493670886076,0.9524564183835182,0.9523809523809523,0.9523052464228935,0.9522292993630573,0.9521531100478469,0.9536,0.9535256410256411,0.9534510433386838,0.9533762057877814,0.9533011272141707,0.9532258064516129,0.9531502423263328,0.9546925566343042,0.9546191247974068,0.9545454545454546,0.9544715447154472,0.9560260586319218,0.9559543230016313,0.9558823529411765,0.955810147299509,0.9557377049180328,0.9556650246305419,0.9555921052631579,0.9555189456342669,0.9554455445544554,0.9553719008264463,0.9552980132450332,0.9552238805970149,0.9568106312292359,0.9584026622296173,0.9583333333333334,0.9582637729549248,0.9581939799331104,0.9597989949748744,0.959731543624161,0.9596638655462185,0.9595959595959596,0.9612141652613828,0.9628378378378378,0.9627749576988156,0.9627118644067797,0.9626485568760611,0.9642857142857143,0.9642248722316865,0.9641638225255973,0.9641025641025641,0.9639794168096055,0.9639175257731959,0.963855421686747,0.9637931034482758,0.9637305699481865,0.9636678200692042,0.9636048526863085,0.9635416666666666,0.9634782608695652,0.9634146341463414,0.9633507853403142,0.9632867132867133,0.9632224168126094,0.9631578947368421,0.9630931458699473,0.9630281690140845,0.9629629629629629,0.9628975265017667,0.9628318584070796,0.9627659574468085,0.9626998223801065,0.9626334519572953,0.9625668449197861,0.9625,0.962432915921288,0.9623655913978495,0.9622980251346499,0.9622302158273381,0.9621621621621622,0.9620938628158845,0.9620253164556962,0.9619565217391305,0.9618874773139746,0.9618181818181818,0.9617486338797814,0.9616788321167883,0.9616087751371115,0.9633699633699634,0.963302752293578,0.9632352941176471,0.9650092081031307,0.9649446494464945,0.9648798521256932,0.9648148148148148,0.9647495361781077,0.9646840148698885,0.9646182495344506,0.9645522388059702,0.9644859813084112,0.9644194756554307,0.9643527204502814,0.9642857142857143,0.9642184557438794,0.9641509433962264,0.9640831758034026,0.9640151515151515,0.9639468690702088,0.9638783269961977,0.9638095238095238,0.9637404580152672,0.9636711281070746,0.9636015325670498,0.963531669865643,0.9653846153846154,0.9653179190751445,0.9652509652509652,0.9671179883945842,0.9670542635658915,0.9669902912621359,0.9669260700389105,0.9688109161793372,0.96875,0.9686888454011742,0.9686274509803922,0.9685658153241651,0.968503937007874,0.9684418145956607,0.9683794466403162,0.9683168316831683,0.9682539682539683,0.9681908548707754,0.9681274900398407,0.9700598802395209,0.97,0.969939879759519,0.9698795180722891,0.9698189134808853,0.969758064516129,0.9696969696969697,0.9696356275303644,0.9695740365111561,0.9695121951219512,0.9694501018329938,0.9693251533742331,0.9692622950819673,0.9691991786447639,0.9691358024691358,0.9690721649484536,0.96900826446281,0.968944099378882,0.9688796680497925,0.9688149688149689,0.96875,0.9686847599164927,0.9686192468619247,0.9685534591194969,0.9684873949579832,0.968421052631579,0.9683544303797469,0.9682875264270613,0.9682203389830508,0.9681528662420382,0.9680851063829787,0.9680170575692963,0.967948717948718,0.9678800856531049,0.9678111587982833,0.967741935483871,0.9676724137931034,0.9676025917926566,0.9675324675324676,0.9674620390455532,0.967391304347826,0.9673202614379085,0.9672489082969432,0.9693654266958425,0.9692982456140351,0.9692307692307692,0.9713656387665198,0.9713024282560706,0.9734513274336283,0.9733924611973392,0.9733333333333334,0.9732739420935412,0.9732142857142857,0.9731543624161074,0.9752808988764045,0.9752252252252253,0.9751693002257337,0.9751131221719457,0.9750566893424036,0.975,0.9749430523917996,0.9748858447488584,0.977116704805492,0.9770642201834863,0.9770114942528736,0.9769585253456221,0.976905311778291,0.9768518518518519,0.9767981438515081,0.9767441860465116,0.9766899766899767,0.9766355140186916,0.9765807962529274,0.9765258215962441,0.9788235294117648,0.9787735849056604,0.9787234042553191,0.9786729857819905,0.9809976247030879,0.9809523809523809,0.9809069212410502,0.9808612440191388,0.9808153477218226,0.9807692307692307,0.980722891566265,0.9830917874396136,0.9830508474576272,0.9830097087378641,0.9829683698296837,0.9829268292682927,0.9828850855745721,0.9828431372549019,0.9828009828009828,0.9826732673267327,0.9826302729528535,0.9825870646766169,0.9825436408977556,0.9825,0.9824561403508771,0.9824120603015075,0.982367758186398,0.9823232323232324,0.9822784810126582,0.9822335025380711,0.9821882951653944,0.9821428571428571,0.9820971867007673,0.982051282051282,0.9820051413881749,0.9819587628865979,0.9819121447028424,0.9818652849740933,0.9818181818181818,0.9817708333333334,0.9817232375979112,0.981675392670157,0.9816272965879265,0.9815789473684211,0.9815303430079155,0.9814814814814815,0.9814323607427056,0.9813829787234043,0.9813333333333333,0.9812834224598931,0.9812332439678284,0.9811827956989247,0.9811320754716981,0.981081081081081,0.981029810298103,0.9809782608695652,0.9809264305177112,0.9808743169398907,0.9808219178082191,0.9807692307692307,0.9807162534435262,0.9806629834254144,0.9806094182825484,0.9805555555555555,0.9805013927576601,0.9804469273743017,0.9803921568627451,0.9803370786516854,0.980225988700565,0.9801699716713881,0.9801136363636364,0.98005698005698,0.98,0.9799426934097422,0.9798850574712644,0.9798270893371758,0.9797687861271677,0.9797101449275363,0.9796511627906976,0.9795918367346939,0.97953216374269,0.9794721407624634,0.9794117647058823,0.9793510324483776,0.9792284866468842,0.9791666666666666,0.9791044776119403,0.9790419161676647,0.978978978978979,0.9788519637462235,0.9787878787878788,0.9787234042553191,0.9786585365853658,0.9785932721712538,0.9785276073619632,0.9784615384615385,0.9783950617283951,0.978328173374613,0.9781931464174455,0.978125,0.9780564263322884,0.9779874213836478,0.9779179810725552,0.9778481012658228,0.9777777777777777,0.9808917197452229,0.9808306709265175,0.9807692307692307,0.9807073954983923,0.9806451612903225,0.9805825242718447,0.9805194805194806,0.9804560260586319,0.9803921568627451,0.980327868852459,0.9835526315789473,0.9834983498349835,0.9834437086092715,0.9833887043189369,0.9833333333333333,0.9832214765100671,0.9831649831649831,0.9831081081081081,0.9830508474576272,0.9829931972789115,0.9829351535836177,0.9828767123287672,0.9828178694158075,0.9827586206896551,0.9826989619377162,0.9825174825174825,0.9824561403508771,0.9823321554770318,0.9822695035460993,0.9822064056939501,0.9821428571428571,0.9820143884892086,0.9819494584837545,0.9818840579710145,0.9818181818181818,0.9817518248175182,0.9816849816849816,0.9816176470588235,0.981549815498155,0.9814814814814815,0.9814126394052045,0.9813432835820896,0.9812734082397003,0.9811320754716981,0.9810606060606061,0.9809885931558935,0.9809160305343512,0.9808429118773946,0.9807692307692307,0.9806949806949807,0.9806201550387597,0.980544747081712,0.98046875,0.9803921568627451,0.9803149606299213,0.9802371541501976,0.9801587301587301,0.9800796812749004,0.98,0.9799196787148594,0.9798387096774194,0.979757085020243,0.9796747967479674,0.9795918367346939,0.9795081967213115,0.9794238683127572,0.9793388429752066,0.979253112033195,0.9791666666666666,0.9790794979079498,0.9789915966386554,0.9789029535864979,0.9788135593220338,0.9785407725321889,0.978448275862069,0.9783549783549783,0.9782608695652174,0.9781659388646288,0.9780701754385965,0.9779735682819384,0.9778761061946902,0.9777777777777777,0.9776785714285714,0.9774774774774775,0.9773755656108597,0.9772727272727273,0.9770642201834863,0.9769585253456221,0.9767441860465116,0.9766355140186916,0.9765258215962441,0.9764150943396226,0.976303317535545,0.9761904761904762,0.9760765550239234,0.9759615384615384,0.9758454106280193,0.9804878048780488,0.9803921568627451,0.9802955665024631,0.9801980198019802,0.9800995024875622,0.985,0.9849246231155779,0.9848484848484849,0.9847715736040609,0.9846938775510204,0.9846153846153847,0.9845360824742269,0.9844559585492227,0.9842931937172775,0.9842105263157894,0.9841269841269841,0.983957219251337,0.9838709677419355,0.9837837837837838,0.9836956521739131,0.989010989010989,0.9888888888888889,0.9888268156424581,0.9887005649717514,0.9886363636363636,0.9885714285714285,0.9884393063583815,0.9883720930232558,0.9883040935672515,0.9882352941176471,0.9881656804733728,0.9880239520958084,0.9879518072289156,0.9878787878787879,0.9877300613496932,0.9876543209876543,0.9875776397515528,0.9875,0.9874213836477987,0.9873417721518988,0.9872611464968153,0.9871794871794872,0.9870967741935484,0.987012987012987,0.9869281045751634,0.9868421052631579,0.9867549668874173,0.9866666666666667,0.9865771812080537,0.9864864864864865,0.9863945578231292,0.993103448275862,0.9930555555555556,0.993006993006993,0.9929577464788732,0.9929078014184397,0.9928571428571429,0.9928057553956835,0.9927007299270073,0.9926470588235294,0.9925925925925926,0.9923664122137404,0.9922480620155039,0.9921259842519685,0.9920634920634921,0.9919354838709677,0.991869918699187,0.9918032786885246,0.9917355371900827,0.9916666666666667,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],"yaxis":"y"}],"layout":{"height":600,"legend":{"tracegroupgap":0},"shapes":[{"line":{"dash":"dash"},"type":"line","x0":0,"x1":1,"y0":1,"y1":0}],"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"title":{"text":"Precision-Recall Curve (AUC=0.8840)"},"width":800,"xaxis":{"anchor":"y","constrain":"domain","domain":[0,1],"title":{"text":"Recall"}},"yaxis":{"anchor":"x","domain":[0,1],"scaleanchor":"x","scaleratio":1,"title":{"text":"Precision"}}}},"text/html":["<div>                            <div id=\"b200abe3-45be-4995-a602-a16a6ac07bb0\" class=\"plotly-graph-div\" style=\"height:600px; width:800px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"b200abe3-45be-4995-a602-a16a6ac07bb0\")) {                    Plotly.newPlot(                        \"b200abe3-45be-4995-a602-a16a6ac07bb0\",                        [{\"fillpattern\":{\"shape\":\"\"},\"hovertemplate\":\"Recall=%{x}\\u003cbr\\u003ePrecision=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"stackgroup\":\"1\",\"x\":[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.995159728944821,0.995159728944821,0.995159728944821,0.9941916747337851,0.9941916747337851,0.9932236205227493,0.9932236205227493,0.9922555663117134,0.9922555663117134,0.9922555663117134,0.9922555663117134,0.9922555663117134,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9903194578896418,0.989351403678606,0.989351403678606,0.989351403678606,0.989351403678606,0.989351403678606,0.989351403678606,0.989351403678606,0.989351403678606,0.989351403678606,0.989351403678606,0.989351403678606,0.989351403678606,0.989351403678606,0.989351403678606,0.989351403678606,0.989351403678606,0.989351403678606,0.989351403678606,0.989351403678606,0.989351403678606,0.989351403678606,0.989351403678606,0.989351403678606,0.989351403678606,0.989351403678606,0.9883833494675702,0.9883833494675702,0.9883833494675702,0.9874152952565344,0.9874152952565344,0.9874152952565344,0.9864472410454985,0.9864472410454985,0.9864472410454985,0.9864472410454985,0.9864472410454985,0.9864472410454985,0.9854791868344628,0.9854791868344628,0.9854791868344628,0.9854791868344628,0.9854791868344628,0.9854791868344628,0.9854791868344628,0.9845111326234269,0.9835430784123911,0.9835430784123911,0.9835430784123911,0.9835430784123911,0.9835430784123911,0.9825750242013552,0.9825750242013552,0.9825750242013552,0.9816069699903195,0.9816069699903195,0.9816069699903195,0.9816069699903195,0.9816069699903195,0.9816069699903195,0.9806389157792836,0.9806389157792836,0.9806389157792836,0.9806389157792836,0.9806389157792836,0.9806389157792836,0.9806389157792836,0.9806389157792836,0.9796708615682478,0.9796708615682478,0.978702807357212,0.978702807357212,0.978702807357212,0.978702807357212,0.9777347531461762,0.9777347531461762,0.9767666989351403,0.9757986447241046,0.9757986447241046,0.9757986447241046,0.9748305905130688,0.9748305905130688,0.9748305905130688,0.9738625363020329,0.9738625363020329,0.9738625363020329,0.9738625363020329,0.9738625363020329,0.9738625363020329,0.9738625363020329,0.972894482090997,0.972894482090997,0.972894482090997,0.972894482090997,0.972894482090997,0.972894482090997,0.972894482090997,0.9719264278799613,0.9719264278799613,0.9709583736689255,0.9709583736689255,0.9699903194578896,0.9699903194578896,0.9690222652468539,0.9690222652468539,0.968054211035818,0.9670861568247822,0.9670861568247822,0.9670861568247822,0.9661181026137464,0.9661181026137464,0.9661181026137464,0.9651500484027106,0.9651500484027106,0.9651500484027106,0.9641819941916747,0.9641819941916747,0.9641819941916747,0.9632139399806389,0.9632139399806389,0.9632139399806389,0.9632139399806389,0.9632139399806389,0.9632139399806389,0.9632139399806389,0.9622458857696031,0.9622458857696031,0.9622458857696031,0.9622458857696031,0.9622458857696031,0.9622458857696031,0.9622458857696031,0.9612778315585673,0.9603097773475314,0.9603097773475314,0.9603097773475314,0.9593417231364957,0.9583736689254598,0.957405614714424,0.9564375605033882,0.9564375605033882,0.9554695062923524,0.9545014520813165,0.9545014520813165,0.9545014520813165,0.9535333978702807,0.9535333978702807,0.9535333978702807,0.9535333978702807,0.9535333978702807,0.952565343659245,0.952565343659245,0.952565343659245,0.952565343659245,0.9515972894482091,0.9515972894482091,0.9506292352371732,0.9506292352371732,0.9506292352371732,0.9506292352371732,0.9506292352371732,0.9506292352371732,0.9496611810261375,0.9496611810261375,0.9496611810261375,0.9486931268151017,0.9486931268151017,0.9477250726040658,0.9477250726040658,0.9467570183930301,0.9457889641819942,0.9457889641819942,0.9457889641819942,0.9448209099709584,0.9448209099709584,0.9438528557599225,0.9438528557599225,0.9438528557599225,0.9428848015488868,0.9428848015488868,0.9419167473378509,0.9419167473378509,0.9409486931268151,0.9409486931268151,0.9399806389157793,0.9399806389157793,0.9399806389157793,0.9399806389157793,0.9390125847047435,0.9390125847047435,0.9390125847047435,0.9390125847047435,0.9380445304937076,0.9370764762826719,0.936108422071636,0.936108422071636,0.936108422071636,0.936108422071636,0.9351403678606002,0.9341723136495643,0.9332042594385286,0.9322362052274927,0.9322362052274927,0.9312681510164569,0.9312681510164569,0.9303000968054211,0.9293320425943853,0.9283639883833494,0.9273959341723137,0.9264278799612778,0.925459825750242,0.9244917715392061,0.9235237173281704,0.9225556631171346,0.9225556631171346,0.9225556631171346,0.9215876089060987,0.9215876089060987,0.9215876089060987,0.9215876089060987,0.9215876089060987,0.9215876089060987,0.9215876089060987,0.9215876089060987,0.920619554695063,0.9196515004840271,0.9196515004840271,0.9196515004840271,0.9186834462729913,0.9186834462729913,0.9186834462729913,0.9177153920619555,0.9167473378509197,0.9157792836398838,0.914811229428848,0.914811229428848,0.9138431752178122,0.9138431752178122,0.9128751210067764,0.9128751210067764,0.9128751210067764,0.9119070667957405,0.9119070667957405,0.9109390125847048,0.9109390125847048,0.9109390125847048,0.9109390125847048,0.9099709583736689,0.9090029041626331,0.9090029041626331,0.9090029041626331,0.9090029041626331,0.9080348499515973,0.9070667957405615,0.9070667957405615,0.9060987415295256,0.9051306873184899,0.904162633107454,0.904162633107454,0.9031945788964182,0.9022265246853823,0.9022265246853823,0.9022265246853823,0.9012584704743466,0.9002904162633107,0.8993223620522749,0.8993223620522749,0.8993223620522749,0.8983543078412392,0.8983543078412392,0.8973862536302033,0.8964181994191674,0.8964181994191674,0.8954501452081317,0.8944820909970959,0.8944820909970959,0.89351403678606,0.89351403678606,0.8925459825750242,0.8915779283639884,0.8906098741529526,0.8896418199419167,0.888673765730881,0.8877057115198451,0.8877057115198451,0.8867376573088093,0.8857696030977735,0.8848015488867377,0.8848015488867377,0.8848015488867377,0.8838334946757018,0.8838334946757018,0.882865440464666,0.8818973862536302,0.8818973862536302,0.8809293320425944,0.8799612778315585,0.8789932236205228,0.8780251694094869,0.8770571151984511,0.8760890609874153,0.8751210067763795,0.8741529525653436,0.8731848983543078,0.872216844143272,0.8702807357212003,0.8693126815101646,0.8683446272991288,0.8673765730880929,0.8664085188770572,0.8664085188770572,0.8664085188770572,0.8654404646660213,0.8644724104549855,0.8635043562439496,0.8625363020329139,0.8625363020329139,0.861568247821878,0.8606001936108422,0.8606001936108422,0.8596321393998064,0.8596321393998064,0.8596321393998064,0.8596321393998064,0.8596321393998064,0.8586640851887706,0.8576960309777347,0.856727976766699,0.8557599225556631,0.8547918683446273,0.8538238141335914,0.8538238141335914,0.8528557599225557,0.8518877057115198,0.850919651500484,0.8499515972894482,0.8489835430784124,0.8489835430784124,0.8489835430784124,0.8489835430784124,0.8480154888673765,0.8480154888673765,0.8480154888673765,0.8480154888673765,0.8470474346563408,0.846079380445305,0.8451113262342691,0.8441432720232332,0.8441432720232332,0.8431752178121975,0.8422071636011617,0.8412391093901258,0.8402710551790901,0.8393030009680542,0.8383349467570184,0.8373668925459826,0.8354307841239109,0.8344627299128751,0.8344627299128751,0.8334946757018393,0.8325266214908035,0.8325266214908035,0.8315585672797676,0.8305905130687319,0.829622458857696,0.8286544046466602,0.8276863504356244,0.8276863504356244,0.8267182962245886,0.8257502420135527,0.8247821878025169,0.8238141335914811,0.8228460793804453,0.8218780251694094,0.8209099709583737,0.8199419167473379,0.8199419167473379,0.818973862536302,0.818973862536302,0.8180058083252663,0.8170377541142304,0.8170377541142304,0.8170377541142304,0.8160696999031946,0.8160696999031946,0.8151016456921588,0.814133591481123,0.8131655372700871,0.8121974830590513,0.8112294288480155,0.8112294288480155,0.8102613746369797,0.8092933204259438,0.8083252662149081,0.8073572120038722,0.8054211035818006,0.8044530493707648,0.8034849951597289,0.8025169409486931,0.8025169409486931,0.8015488867376573,0.8005808325266215,0.7996127783155856,0.7986447241045499,0.797676669893514,0.7967086156824782,0.7957405614714425,0.7947725072604066,0.7938044530493708,0.7928363988383349,0.7918683446272992,0.7909002904162633,0.7899322362052275,0.7889641819941917,0.7889641819941917,0.7889641819941917,0.7879961277831559,0.78702807357212,0.7860600193610843,0.7850919651500484,0.7841239109390126,0.782187802516941,0.7812197483059051,0.7802516940948693,0.7802516940948693,0.7792836398838335,0.7783155856727977,0.7783155856727977,0.7773475314617618,0.7763794772507261,0.7763794772507261,0.7754114230396902,0.7744433688286544,0.7744433688286544,0.7734753146176185,0.7725072604065828,0.7725072604065828,0.7725072604065828,0.771539206195547,0.7705711519845111,0.7696030977734754,0.7686350435624395,0.7676669893514037,0.7666989351403679,0.7657308809293321,0.7647628267182962,0.7637947725072604,0.7637947725072604,0.7628267182962246,0.7628267182962246,0.7618586640851888,0.7608906098741529,0.7599225556631172,0.7589545014520813,0.7589545014520813,0.7579864472410455,0.7570183930300097,0.7560503388189739,0.755082284607938,0.7541142303969022,0.7531461761858664,0.7521781219748306,0.7512100677637947,0.7512100677637947,0.750242013552759,0.7492739593417231,0.7483059051306873,0.7483059051306873,0.7483059051306873,0.7473378509196515,0.7473378509196515,0.7463697967086157,0.7454017424975798,0.744433688286544,0.7434656340755083,0.7424975798644724,0.7415295256534365,0.7415295256534365,0.7405614714424008,0.739593417231365,0.7386253630203291,0.7376573088092934,0.7366892545982575,0.7357212003872217,0.7347531461761858,0.7347531461761858,0.7337850919651501,0.7328170377541142,0.7318489835430784,0.7308809293320426,0.7299128751210068,0.7289448209099709,0.7289448209099709,0.7279767666989352,0.7270087124878993,0.7260406582768635,0.7260406582768635,0.7250726040658277,0.7250726040658277,0.7241045498547919,0.723136495643756,0.723136495643756,0.7221684414327202,0.7212003872216844,0.7202323330106486,0.7202323330106486,0.7192642787996127,0.718296224588577,0.7173281703775412,0.7153920619554696,0.7144240077444337,0.7134559535333979,0.7134559535333979,0.712487899322362,0.7115198451113263,0.7105517909002904,0.7095837366892546,0.7086156824782188,0.707647628267183,0.7066795740561471,0.7057115198451114,0.7057115198451114,0.7047434656340755,0.7037754114230397,0.7028073572120038,0.7018393030009681,0.7008712487899322,0.6999031945788964,0.6999031945788964,0.6989351403678606,0.6979670861568248,0.6969990319457889,0.6960309777347532,0.6950629235237173,0.6940948693126815,0.6931268151016456,0.6921587608906099,0.691190706679574,0.6902226524685382,0.6902226524685382,0.6892545982575025,0.6882865440464666,0.6873184898354308,0.686350435624395,0.6853823814133592,0.6844143272023233,0.6834462729912875,0.6824782187802517,0.6815101645692159,0.68054211035818,0.6795740561471443,0.6786060019361084,0.6776379477250726,0.6766698935140368,0.675701839303001,0.6747337850919651,0.6737657308809293,0.6727976766698935,0.6718296224588577,0.6718296224588577,0.6708615682478218,0.6698935140367861,0.6698935140367861,0.6689254598257502,0.6679574056147144,0.6669893514036787,0.6660212971926428,0.665053242981607,0.6640851887705711,0.6640851887705711,0.6631171345595354,0.6631171345595354,0.6631171345595354,0.6621490803484995,0.6611810261374637,0.6602129719264279,0.6592449177153921,0.6573088092933205,0.6563407550822846,0.6563407550822846,0.6553727008712488,0.6544046466602129,0.6534365924491772,0.6524685382381413,0.6524685382381413,0.6515004840271055,0.6515004840271055,0.6505324298160697,0.6495643756050339,0.648596321393998,0.6476282671829623,0.6466602129719264,0.6456921587608906,0.6447241045498547,0.643756050338819,0.643756050338819,0.6427879961277831,0.6418199419167473,0.6418199419167473,0.6418199419167473,0.6408518877057116,0.6398838334946757,0.6389157792836399,0.6379477250726041,0.6369796708615683,0.6360116166505324,0.6350435624394967,0.6340755082284608,0.633107454017425,0.633107454017425,0.6321393998063891,0.6311713455953534,0.6302032913843175,0.6292352371732817,0.6282671829622459,0.6272991287512101,0.6263310745401742,0.6253630203291385,0.6243949661181026,0.6234269119070668,0.6224588576960309,0.6205227492739593,0.6195546950629235,0.6185866408518877,0.6185866408518877,0.6176185866408519,0.616650532429816,0.6156824782187803,0.6147144240077445,0.6137463697967086,0.6127783155856728,0.611810261374637,0.6108422071636012,0.6108422071636012,0.6098741529525653,0.6089060987415296,0.6079380445304937,0.6069699903194579,0.6060019361084221,0.6050338818973863,0.6040658276863504,0.6040658276863504,0.6030977734753146,0.6021297192642788,0.6021297192642788,0.601161665053243,0.6001936108422071,0.5992255566311714,0.5972894482090997,0.5963213939980639,0.5953533397870281,0.5943852855759922,0.5934172313649564,0.5924491771539206,0.5914811229428848,0.590513068731849,0.5895450145208132,0.5885769603097774,0.5876089060987415,0.5876089060987415,0.5866408518877058,0.5856727976766699,0.5847047434656341,0.5837366892545982,0.5827686350435625,0.5827686350435625,0.5818005808325266,0.5818005808325266,0.5808325266214908,0.579864472410455,0.5788964181994192,0.5779283639883833,0.5769603097773476,0.5759922555663117,0.5750242013552759,0.57405614714424,0.5730880929332043,0.5721200387221684,0.5711519845111326,0.5711519845111326,0.5701839303000968,0.569215876089061,0.5682478218780251,0.5682478218780251,0.5672797676669894,0.5663117134559535,0.5653436592449177,0.5643756050338818,0.5634075508228461,0.5624394966118103,0.5614714424007744,0.5605033881897387,0.5595353339787028,0.558567279767667,0.5575992255566312,0.5575992255566312,0.5575992255566312,0.5566311713455954,0.5556631171345595,0.5546950629235237,0.5546950629235237,0.5537270087124879,0.5527589545014521,0.5517909002904162,0.5517909002904162,0.5517909002904162,0.5508228460793805,0.5498547918683446,0.5488867376573088,0.5488867376573088,0.547918683446273,0.5469506292352372,0.5459825750242013,0.5440464666021297,0.5430784123910939,0.542110358180058,0.5411423039690223,0.5401742497579864,0.5392061955469506,0.5382381413359149,0.537270087124879,0.5363020329138432,0.5353339787028074,0.5343659244917716,0.5333978702807357,0.5324298160696999,0.5314617618586641,0.5304937076476283,0.5295256534365924,0.5285575992255567,0.5275895450145208,0.526621490803485,0.5256534365924492,0.5246853823814134,0.5237173281703775,0.5227492739593417,0.5217812197483059,0.5208131655372701,0.5198451113262342,0.5188770571151985,0.5179090029041626,0.5169409486931268,0.515972894482091,0.5150048402710552,0.5140367860600193,0.5130687318489835,0.5121006776379478,0.5111326234269119,0.510164569215876,0.5091965150048403,0.5091965150048403,0.5082284607938045,0.5072604065827686,0.5072604065827686,0.5062923523717329,0.505324298160697,0.5043562439496612,0.5033881897386253,0.5024201355275896,0.5014520813165537,0.5004840271055179,0.4995159728944821,0.4985479186834463,0.4975798644724105,0.49661181026137463,0.49564375605033884,0.494675701839303,0.4937076476282672,0.4927395934172314,0.49177153920619554,0.49080348499515974,0.4898354307841239,0.4888673765730881,0.4878993223620523,0.48693126815101645,0.48596321393998065,0.48596321393998065,0.4849951597289448,0.484027105517909,0.484027105517909,0.4830590513068732,0.48209099709583736,0.48112294288480156,0.48112294288480156,0.4801548886737657,0.4791868344627299,0.4782187802516941,0.47725072604065827,0.4762826718296225,0.4753146176185866,0.4743465634075508,0.47337850919651503,0.4724104549854792,0.4714424007744434,0.47047434656340753,0.47047434656340753,0.46950629235237173,0.46853823814133594,0.4675701839303001,0.4666021297192643,0.46563407550822844,0.46466602129719264,0.46369796708615685,0.462729912875121,0.4617618586640852,0.46079380445304935,0.45885769603097776,0.4578896418199419,0.4569215876089061,0.45595353339787026,0.45498547918683446,0.45401742497579867,0.4530493707647628,0.452081316553727,0.45111326234269117,0.45014520813165537,0.4491771539206196,0.4482090997095837,0.44724104549854793,0.4462729912875121,0.4453049370764763,0.4443368828654405,0.44336882865440463,0.44240077444336884,0.441432720232333,0.4404646660212972,0.4394966118102614,0.43852855759922554,0.43756050338818975,0.4365924491771539,0.4356243949661181,0.4346563407550823,0.43368828654404645,0.43272023233301066,0.4317521781219748,0.430784123910939,0.4298160696999032,0.42884801548886736,0.42884801548886736,0.42787996127783157,0.4269119070667957,0.4269119070667957,0.4259438528557599,0.4259438528557599,0.4249757986447241,0.42400774443368827,0.4230396902226525,0.4220716360116166,0.42110358180058083,0.42013552758954503,0.4191674733785092,0.4181994191674734,0.41723136495643753,0.41626331074540174,0.41529525653436594,0.4143272023233301,0.4133591481122943,0.4133591481122943,0.41239109390125844,0.41142303969022265,0.41045498547918685,0.409486931268151,0.4085188770571152,0.4075508228460794,0.40658276863504356,0.40561471442400776,0.4046466602129719,0.4036786060019361,0.4027105517909003,0.4027105517909003,0.40174249757986447,0.40077444336882867,0.3998063891577928,0.3998063891577928,0.398838334946757,0.3978702807357212,0.3969022265246854,0.3959341723136496,0.39496611810261373,0.39399806389157793,0.39399806389157793,0.39303000968054214,0.3920619554695063,0.3910939012584705,0.39012584704743464,0.38915779283639884,0.38818973862536305,0.3872216844143272,0.38431752178121975,0.38334946757018395,0.3823814133591481,0.3814133591481123,0.38044530493707646,0.37947725072604066,0.37850919651500486,0.377541142303969,0.3765730880929332,0.37560503388189737,0.37463697967086157,0.3736689254598258,0.3727008712487899,0.3717328170377541,0.3707647628267183,0.3697967086156825,0.3688286544046467,0.36786060019361083,0.36689254598257504,0.3659244917715392,0.3649564375605034,0.3639883833494676,0.36302032913843174,0.36205227492739595,0.3610842207163601,0.3601161665053243,0.3591481122942885,0.35818005808325265,0.35721200387221685,0.356243949661181,0.3552758954501452,0.3543078412391094,0.35333978702807356,0.35237173281703776,0.3514036786060019,0.3504356243949661,0.3494675701839303,0.34849951597289447,0.3475314617618587,0.3465634075508228,0.345595353339787,0.34462729912875123,0.3436592449177154,0.3426911907066796,0.34172313649564373,0.34075508228460794,0.33978702807357214,0.3388189738625363,0.3378509196515005,0.33591481122942884,0.33494675701839305,0.3339787028073572,0.3330106485963214,0.33204259438528555,0.33107454017424975,0.33010648596321396,0.3291384317521781,0.3281703775411423,0.32720232333010646,0.32623426911907066,0.32526621490803487,0.324298160696999,0.3233301064859632,0.32236205227492737,0.3213939980638916,0.3194578896418199,0.31848983543078413,0.31752178121974833,0.3165537270087125,0.3155856727976767,0.31364956437560504,0.31268151016456924,0.3117134559535334,0.3107454017424976,0.30977734753146174,0.30880929332042595,0.30784123910939015,0.3068731848983543,0.3059051306873185,0.30396902226524686,0.30300096805421106,0.3020329138431752,0.3010648596321394,0.30009680542110356,0.29912875121006777,0.29816069699903197,0.29816069699903197,0.2971926427879961,0.2962245885769603,0.2952565343659245,0.2942884801548887,0.2933204259438529,0.29235237173281703,0.29138431752178123,0.2904162633107454,0.2894482090997096,0.2894482090997096,0.2884801548886738,0.28751210067763794,0.28654404646660214,0.2855759922555663,0.2836398838334947,0.28267182962245885,0.28170377541142305,0.2807357212003872,0.2797676669893514,0.2787996127783156,0.27783155856727976,0.27686350435624396,0.2758954501452081,0.2749273959341723,0.27202323330106487,0.271055179090029,0.2691190706679574,0.2681510164569216,0.2671829622458858,0.26621490803484993,0.26427879961277834,0.2633107454017425,0.2623426911907067,0.26137463697967084,0.26040658276863504,0.25943852855759925,0.2584704743465634,0.2575024201355276,0.25653436592449175,0.25556631171345595,0.25459825750242016,0.2536302032913843,0.25169409486931266,0.25072604065827686,0.24975798644724104,0.24878993223620524,0.24782187802516942,0.2468538238141336,0.24588576960309777,0.24491771539206195,0.24394966118102615,0.24298160696999033,0.2420135527589545,0.24104549854791868,0.24007744433688286,0.23910939012584706,0.23814133591481124,0.2371732817037754,0.2362052274927396,0.23523717328170377,0.23426911907066797,0.23330106485963215,0.23233301064859632,0.2313649564375605,0.23039690222652467,0.22942884801548888,0.22846079380445306,0.22749273959341723,0.2265246853823814,0.22555663117134558,0.2245885769603098,0.22362052274927396,0.2207163601161665,0.2197483059051307,0.21878025169409487,0.21781219748305905,0.21684414327202323,0.2158760890609874,0.2149080348499516,0.21393998063891578,0.21297192642787996,0.21200387221684414,0.21006776379477252,0.2090997095837367,0.20813165537270087,0.20619554695062922,0.20522749273959343,0.20329138431752178,0.20232333010648595,0.20135527589545016,0.20038722168441434,0.1994191674733785,0.1984511132623427,0.19748305905130686,0.19651500484027107,0.19554695062923524,0.19457889641819942,0.1936108422071636,0.19264278799612777,0.19167473378509198,0.19070667957405615,0.19070667957405615,0.18973862536302033,0.1887705711519845,0.18780251694094868,0.1868344627299129,0.18586640851887706,0.18489835430784124,0.18393030009680542,0.1819941916747338,0.18102613746369797,0.18005808325266215,0.1781219748305905,0.1771539206195547,0.17618586640851888,0.17521781219748306,0.17424975798644723,0.17231364956437561,0.1713455953533398,0.16940948693126814,0.16844143272023232,0.16747337850919652,0.16553727008712488,0.16456921587608905,0.16360116166505323,0.16263310745401743,0.1616650532429816,0.15972894482090996,0.15876089060987417,0.15779283639883834,0.1558567279767667,0.15488867376573087,0.15392061955469508,0.15295256534365925,0.15198451113262343,0.1510164569215876,0.15004840271055178,0.14908034849951599,0.14811229428848016,0.14714424007744434,0.14617618586640851,0.1452081316553727,0.1442400774443369,0.14327202323330107,0.14230396902226525,0.14133591481122942,0.1403678606001936,0.1393998063891578,0.13843175217812198,0.13746369796708616,0.13649564375605033,0.1355275895450145,0.1345595353339787,0.1335914811229429,0.13165537270087124,0.13068731848983542,0.12971926427879962,0.12584704743465633,0.12391093901258471,0.12197483059051308,0.12100677637947725,0.11907066795740562,0.1181026137463698,0.11713455953533398,0.11616650532429816,0.11519845111326234,0.11423039690222653,0.1132623426911907,0.1122942884801549,0.11132623426911907,0.10939012584704744,0.10842207163601161,0.1074540174249758,0.10551790900290416,0.10454985479186835,0.10358180058083252,0.10164569215876089,0.10067763794772508,0.09970958373668926,0.09874152952565343,0.09777347531461762,0.09583736689254599,0.09486931268151017,0.09390125847047434,0.09196515004840271,0.0909970958373669,0.09002904162633107,0.08906098741529525,0.08615682478218781,0.08422071636011616,0.07938044530493708,0.07163601161665054,0.06873184898354308,0.06679574056147145,0.06389157792836399,0.06098741529525654,0.05614714424007745,0.046466602129719266,0.0],\"xaxis\":\"x\",\"y\":[0.7341862117981521,0.7347083926031295,0.7352313167259786,0.7357549857549858,0.7362794012829651,0.7368045649072753,0.7373304782298359,0.7378571428571429,0.7383845604002859,0.7389127324749643,0.7394416607015032,0.7399713467048711,0.7405017921146954,0.7410329985652798,0.741564967695621,0.7420977011494253,0.7426312005751258,0.7431654676258993,0.7437005039596832,0.7442363112391931,0.7447728911319395,0.7453102453102453,0.7458483754512636,0.7463872832369942,0.7469269703543022,0.7474674384949349,0.7480086893555394,0.7485507246376811,0.7490935460478607,0.7496371552975326,0.7501815541031227,0.7507267441860465,0.7512727272727273,0.7518195050946143,0.752367079388201,0.7529154518950437,0.7534646243617797,0.754014598540146,0.7545653761869978,0.7551169590643275,0.7556693489392831,0.7562225475841874,0.756043956043956,0.7565982404692082,0.7571533382245048,0.7569750367107195,0.7575312270389419,0.7580882352941176,0.7586460632818248,0.7592047128129602,0.7597641857037583,0.7603244837758112,0.7608856088560886,0.7614475627769571,0.762010347376201,0.7625739644970414,0.7631384159881569,0.7637037037037037,0.7642698295033358,0.7648367952522255,0.7654046028210839,0.7659732540861813,0.7665427509293681,0.7671130952380952,0.7676842889054356,0.7682563338301043,0.7688292319164802,0.7694029850746269,0.7699775952203136,0.7705530642750373,0.7703814510097232,0.7709580838323353,0.7715355805243446,0.7721139430284858,0.7726931732933233,0.7732732732732732,0.7738542449286251,0.7744360902255639,0.7742663656884876,0.7748493975903614,0.7754333082140166,0.77526395173454,0.7758490566037736,0.7764350453172205,0.7762660619803476,0.7768532526475038,0.7766843300529902,0.7772727272727272,0.77710386656558,0.7776934749620638,0.7782839787395596,0.7788753799392097,0.779467680608365,0.7792998477929984,0.7798933739527799,0.7804878048780488,0.7810831426392068,0.7816793893129771,0.7815126050420168,0.7813455657492355,0.7819433817903596,0.7825421133231241,0.7831417624521073,0.7837423312883436,0.7843438219493477,0.7849462365591398,0.7855495772482706,0.7861538461538462,0.7867590454195535,0.7873651771956857,0.7879722436391673,0.7885802469135802,0.7891891891891892,0.7897990726429676,0.7904098994586234,0.7910216718266254,0.7916343919442292,0.7922480620155039,0.7928626842513576,0.7934782608695652,0.7940947940947941,0.7947122861586314,0.7953307392996108,0.7959501557632399,0.7957911145752143,0.7964118564742589,0.7970335675253708,0.796875,0.7974980453479281,0.7981220657276995,0.79796397807361,0.79858934169279,0.7992156862745098,0.7998430141287284,0.800471327572663,0.8011006289308176,0.8009441384736428,0.8015748031496063,0.8022064617809299,0.8028391167192429,0.8034727703235991,0.8041074249605056,0.8047430830039526,0.8045886075949367,0.8044338875692795,0.8050713153724247,0.8057097541633624,0.8063492063492064,0.806989674344718,0.8068362480127186,0.807478122513922,0.8081210191082803,0.8086124401913876,0.8092577813248204,0.8099041533546326,0.8105515587529976,0.8112,0.8118494795836669,0.811698717948718,0.8123496391339214,0.8130016051364366,0.8136546184738955,0.8143086816720257,0.8149637972646823,0.8156199677938808,0.8162771958098308,0.8161290322580645,0.8167877320419693,0.8166397415185783,0.8172999191592563,0.8179611650485437,0.8186234817813766,0.8184764991896273,0.819140308191403,0.8189935064935064,0.8188464662875711,0.8195121951219512,0.8201790073230268,0.8200325732899023,0.8207008964955175,0.8213703099510603,0.8212244897959183,0.8218954248366013,0.8225674570727719,0.823240589198036,0.823914823914824,0.8245901639344262,0.8252666119770303,0.8251231527093597,0.8258011503697618,0.8264802631578947,0.8271604938271605,0.8278418451400329,0.8285243198680956,0.8292079207920792,0.8290668868703551,0.8297520661157025,0.8296112489660876,0.8302980132450332,0.8301574150787076,0.8308457711442786,0.8307053941908714,0.8313953488372093,0.8312551953449709,0.8311148086522463,0.8318068276436303,0.8325,0.8323603002502085,0.8330550918196995,0.83375104427736,0.8336120401337793,0.8343096234309624,0.8350083752093802,0.8348700754400671,0.8355704697986577,0.836272040302267,0.8361344537815126,0.8368376787216149,0.8375420875420876,0.8382476832350463,0.8389544688026982,0.8396624472573839,0.8403716216216216,0.8402366863905325,0.8409475465313029,0.8416596104995766,0.8423728813559322,0.8430873621713316,0.8438030560271647,0.8445199660152931,0.8443877551020408,0.8442553191489361,0.8449744463373083,0.8456947996589941,0.8455631399317406,0.8454312553373186,0.8452991452991453,0.8451668092386655,0.8458904109589042,0.8457583547557841,0.8456260720411664,0.8463519313304722,0.8470790378006873,0.8469475494411006,0.8476764199655766,0.8484065460809647,0.8491379310344828,0.8498705780845557,0.8497409326424871,0.8504753673293,0.8512110726643599,0.8519480519480519,0.8518197573656846,0.852558542931483,0.8524305555555556,0.8531711555169418,0.8539130434782609,0.8546562228024369,0.8554006968641115,0.8561464690496948,0.856020942408377,0.856768558951965,0.8575174825174825,0.8573928258967629,0.8581436077057794,0.8580192813321648,0.8587719298245614,0.858647936786655,0.8585237258347979,0.8592788038698329,0.8600352112676056,0.8599118942731278,0.8606701940035273,0.8605472197705207,0.8613074204946997,0.8620689655172413,0.8619469026548673,0.8627103631532329,0.8625886524822695,0.8633540372670807,0.8632326820603907,0.864,0.8638790035587188,0.8646482635796973,0.8654188948306596,0.8661909009812667,0.8660714285714286,0.8668453976764968,0.8676207513416816,0.8683974932855864,0.8682795698924731,0.8681614349775785,0.8680430879712747,0.8688230008984726,0.8696043165467626,0.8703870387038704,0.8702702702702703,0.8701532912533815,0.8700361010830325,0.8699186991869918,0.8707052441229657,0.8705882352941177,0.8713768115942029,0.8712601994560291,0.8711433756805808,0.8710263396911898,0.8709090909090909,0.8707916287534122,0.8706739526411658,0.8705560619872379,0.8704379562043796,0.8703196347031964,0.8711151736745887,0.8719121683440073,0.8717948717948718,0.8725939505041247,0.8733944954128441,0.8741965105601469,0.875,0.8758049678012879,0.8766114180478821,0.8774193548387097,0.8773062730627307,0.8771929824561403,0.878003696857671,0.8788159111933395,0.8787037037037037,0.8795180722891566,0.8803339517625232,0.8802228412256268,0.8801115241635687,0.88,0.8798882681564246,0.880708294501398,0.8805970149253731,0.8814192343604108,0.8813084112149533,0.882132834424696,0.8829588014981273,0.8828491096532334,0.8836772983114447,0.8835680751173709,0.8843984962406015,0.8852304797742239,0.8860640301318268,0.885956644674835,0.8858490566037736,0.886685552407932,0.8875236294896031,0.8883632923368022,0.8882575757575758,0.8881516587677725,0.8889943074003795,0.8888888888888888,0.8896289248334919,0.8895238095238095,0.8903717826501429,0.8902671755725191,0.8901623686723973,0.8910133843212237,0.8918660287081339,0.8917624521072797,0.8916586768935763,0.8915547024952015,0.8924111431316042,0.8932692307692308,0.8931665062560153,0.8940269749518305,0.8939247830279653,0.8938223938223938,0.8946859903381642,0.8945841392649904,0.8944820909970959,0.8953488372093024,0.895247332686712,0.8961165048543689,0.8960155490767736,0.8959143968871596,0.8958130477117819,0.8957115009746589,0.895609756097561,0.8955078125,0.8963831867057673,0.8962818003913894,0.8961802154750245,0.8960784313725491,0.8969578017664377,0.8978388998035364,0.8977384464110127,0.8986220472440944,0.8985221674876848,0.8984220907297831,0.8993089832181639,0.8992094861660079,0.8991097922848664,0.899009900990099,0.8989098116947473,0.8988095238095238,0.8987090367428004,0.8986083499005965,0.8985074626865671,0.898406374501992,0.8983050847457628,0.8981018981018981,0.898,0.8978978978978979,0.8977955911823647,0.8976930792377131,0.8985943775100401,0.8994974874371859,0.8993963782696177,0.8992950654582075,0.8991935483870968,0.8990918264379415,0.9,0.8998988877654196,0.8997975708502024,0.900709219858156,0.9006085192697769,0.9015228426395939,0.9024390243902439,0.9033570701932858,0.9042769857433809,0.9041794087665648,0.9040816326530612,0.9039836567926456,0.9038854805725971,0.9037871033776868,0.9036885245901639,0.9046153846153846,0.9045174537987679,0.9044193216855088,0.904320987654321,0.9042224510813595,0.9041237113402062,0.9050567595459237,0.90599173553719,0.9069286452947259,0.906832298136646,0.9077720207253887,0.9087136929460581,0.9096573208722741,0.9095634095634095,0.9094693028095734,0.909375,0.9092805005213764,0.9102296450939458,0.910135841170324,0.9100418410041841,0.9099476439790576,0.909853249475891,0.9097586568730325,0.9096638655462185,0.9095688748685594,0.9093782929399368,0.9092827004219409,0.9102428722280888,0.9101479915433404,0.91005291005291,0.9110169491525424,0.9109225874867445,0.910828025477707,0.9107332624867163,0.9106382978723404,0.9105431309904153,0.9115138592750534,0.9114194236926361,0.9113247863247863,0.9112299465240642,0.911134903640257,0.9110396570203644,0.9109442060085837,0.9108485499462943,0.910752688172043,0.9117330462863293,0.9116379310344828,0.912621359223301,0.9125269978401728,0.9124324324324324,0.9134199134199135,0.914409534127844,0.9143167028199566,0.9153094462540716,0.9152173913043479,0.9151251360174102,0.9150326797385621,0.9149400218102508,0.9148471615720524,0.9158469945355191,0.9157549234135668,0.9156626506024096,0.9155701754385965,0.9154774972557629,0.9152915291529153,0.9151982378854625,0.9151047409040793,0.9150110375275938,0.9160220994475138,0.915929203539823,0.9158361018826136,0.9157427937915743,0.9156492785793563,0.9155555555555556,0.9154616240266963,0.9153674832962138,0.915273132664437,0.9151785714285714,0.9150837988826815,0.9149888143176734,0.9148936170212766,0.9147982062780269,0.9147025813692481,0.9157303370786517,0.9167604049493814,0.9166666666666666,0.9165727170236753,0.9164785553047404,0.9163841807909604,0.916289592760181,0.9160997732426304,0.9160045402951191,0.9159090909090909,0.9169510807736063,0.9168564920273349,0.9167616875712656,0.9178082191780822,0.9177142857142857,0.9176201372997712,0.9186712485681557,0.9185779816513762,0.9184845005740528,0.9195402298850575,0.9194476409666283,0.9193548387096774,0.9214780600461894,0.922543352601156,0.9224537037037037,0.9223638470451911,0.9222737819025522,0.9221835075493612,0.922093023255814,0.9220023282887078,0.921911421911422,0.9218203033838973,0.9217289719626168,0.9228070175438596,0.9227166276346604,0.9237983587338804,0.9237089201877934,0.9236192714453584,0.9235294117647059,0.9234393404004712,0.9245283018867925,0.9244391971664699,0.9243498817966903,0.9242603550295858,0.9241706161137441,0.9240806642941874,0.9239904988123515,0.9239001189060642,0.9238095238095239,0.9249106078665077,0.9248210023866349,0.9247311827956989,0.9246411483253588,0.925748502994012,0.9268585131894485,0.9267707082833133,0.9278846153846154,0.927797833935018,0.927710843373494,0.9276236429433052,0.927536231884058,0.9274486094316807,0.927360774818402,0.9284848484848485,0.9283980582524272,0.928311057108141,0.9282238442822385,0.928136419001218,0.9280487804878049,0.927960927960928,0.9278728606356969,0.9290085679314566,0.928921568627451,0.9288343558282208,0.9287469287469288,0.9286592865928659,0.9285714285714286,0.9284833538840938,0.9296296296296296,0.9295426452410384,0.9294554455445545,0.929368029739777,0.9305210918114144,0.9304347826086956,0.931592039800995,0.9315068493150684,0.9314214463840399,0.9325842696629213,0.9325,0.932415519399249,0.9323308270676691,0.9335006273525721,0.9334170854271356,0.9333333333333333,0.9332493702770781,0.9330808080808081,0.9329962073324906,0.9329113924050633,0.9340937896070975,0.934010152284264,0.9339263024142312,0.9338422391857506,0.9337579617834395,0.9336734693877551,0.933588761174968,0.9335038363171355,0.9334186939820742,0.9346153846153846,0.9345314505776636,0.9344473007712082,0.9343629343629344,0.9342783505154639,0.9341935483870968,0.9341085271317829,0.9353169469598965,0.9352331606217616,0.9351491569390402,0.935064935064935,0.9349804941482445,0.9348958333333334,0.9348109517601043,0.9347258485639687,0.934640522875817,0.9345549738219895,0.9344692005242464,0.9356955380577427,0.9356110381077529,0.9355263157894737,0.9354413702239789,0.9353562005277045,0.9352708058124174,0.9351851851851852,0.9350993377483444,0.9350132625994695,0.9349269588313412,0.9348404255319149,0.9347536617842876,0.9346666666666666,0.9345794392523364,0.9344919786096256,0.9344042838018741,0.9343163538873994,0.934228187919463,0.9341397849462365,0.9340511440107672,0.9353099730458221,0.9352226720647774,0.9351351351351351,0.9364005412719891,0.9363143631436315,0.9362279511533242,0.936141304347826,0.9360544217687075,0.9359673024523161,0.9358799454297408,0.9371584699453552,0.9370725034199726,0.9383561643835616,0.9396433470507545,0.9395604395604396,0.9394773039889959,0.9393939393939394,0.9393103448275862,0.9391424619640387,0.9390581717451524,0.9403606102635229,0.9402777777777778,0.9401947148817803,0.9401114206128134,0.9400278940027894,0.9413407821229051,0.9412587412587412,0.9425770308123249,0.9424964936886395,0.9424157303370787,0.9423347398030942,0.9422535211267605,0.9421720733427362,0.942090395480226,0.942008486562942,0.9419263456090652,0.9432624113475178,0.9431818181818182,0.9431009957325747,0.9444444444444444,0.9457917261055635,0.9457142857142857,0.9456366237482118,0.9455587392550143,0.945480631276901,0.9454022988505747,0.9453237410071943,0.9452449567723343,0.9451659451659452,0.9450867052023122,0.9464544138929089,0.946376811594203,0.9462989840348331,0.9462209302325582,0.9461426491994177,0.9460641399416909,0.945985401459854,0.945906432748538,0.9458272327964861,0.9457478005865103,0.9456681350954479,0.9455882352941176,0.9454277286135693,0.9453471196454948,0.9452662721893491,0.9466666666666667,0.9465875370919882,0.9465081723625557,0.9464285714285714,0.9463487332339792,0.9462686567164179,0.9461883408071748,0.9461077844311377,0.9460269865067467,0.9474474474474475,0.9473684210526315,0.947289156626506,0.947209653092006,0.947129909365559,0.9470499243570348,0.946969696969697,0.9468892261001517,0.9483282674772037,0.9482496194824962,0.948170731707317,0.9496183206106871,0.9495412844036697,0.9494640122511485,0.9493865030674846,0.9492307692307692,0.9491525423728814,0.9490740740740741,0.9489953632148377,0.9489164086687306,0.9488372093023256,0.9487577639751553,0.9486780715396579,0.9485981308411215,0.9485179407176287,0.9484375,0.9499217527386542,0.9498432601880877,0.9497645211930926,0.949685534591195,0.9496062992125984,0.9495268138801262,0.9510268562401264,0.9509493670886076,0.9524564183835182,0.9523809523809523,0.9523052464228935,0.9522292993630573,0.9521531100478469,0.9536,0.9535256410256411,0.9534510433386838,0.9533762057877814,0.9533011272141707,0.9532258064516129,0.9531502423263328,0.9546925566343042,0.9546191247974068,0.9545454545454546,0.9544715447154472,0.9560260586319218,0.9559543230016313,0.9558823529411765,0.955810147299509,0.9557377049180328,0.9556650246305419,0.9555921052631579,0.9555189456342669,0.9554455445544554,0.9553719008264463,0.9552980132450332,0.9552238805970149,0.9568106312292359,0.9584026622296173,0.9583333333333334,0.9582637729549248,0.9581939799331104,0.9597989949748744,0.959731543624161,0.9596638655462185,0.9595959595959596,0.9612141652613828,0.9628378378378378,0.9627749576988156,0.9627118644067797,0.9626485568760611,0.9642857142857143,0.9642248722316865,0.9641638225255973,0.9641025641025641,0.9639794168096055,0.9639175257731959,0.963855421686747,0.9637931034482758,0.9637305699481865,0.9636678200692042,0.9636048526863085,0.9635416666666666,0.9634782608695652,0.9634146341463414,0.9633507853403142,0.9632867132867133,0.9632224168126094,0.9631578947368421,0.9630931458699473,0.9630281690140845,0.9629629629629629,0.9628975265017667,0.9628318584070796,0.9627659574468085,0.9626998223801065,0.9626334519572953,0.9625668449197861,0.9625,0.962432915921288,0.9623655913978495,0.9622980251346499,0.9622302158273381,0.9621621621621622,0.9620938628158845,0.9620253164556962,0.9619565217391305,0.9618874773139746,0.9618181818181818,0.9617486338797814,0.9616788321167883,0.9616087751371115,0.9633699633699634,0.963302752293578,0.9632352941176471,0.9650092081031307,0.9649446494464945,0.9648798521256932,0.9648148148148148,0.9647495361781077,0.9646840148698885,0.9646182495344506,0.9645522388059702,0.9644859813084112,0.9644194756554307,0.9643527204502814,0.9642857142857143,0.9642184557438794,0.9641509433962264,0.9640831758034026,0.9640151515151515,0.9639468690702088,0.9638783269961977,0.9638095238095238,0.9637404580152672,0.9636711281070746,0.9636015325670498,0.963531669865643,0.9653846153846154,0.9653179190751445,0.9652509652509652,0.9671179883945842,0.9670542635658915,0.9669902912621359,0.9669260700389105,0.9688109161793372,0.96875,0.9686888454011742,0.9686274509803922,0.9685658153241651,0.968503937007874,0.9684418145956607,0.9683794466403162,0.9683168316831683,0.9682539682539683,0.9681908548707754,0.9681274900398407,0.9700598802395209,0.97,0.969939879759519,0.9698795180722891,0.9698189134808853,0.969758064516129,0.9696969696969697,0.9696356275303644,0.9695740365111561,0.9695121951219512,0.9694501018329938,0.9693251533742331,0.9692622950819673,0.9691991786447639,0.9691358024691358,0.9690721649484536,0.96900826446281,0.968944099378882,0.9688796680497925,0.9688149688149689,0.96875,0.9686847599164927,0.9686192468619247,0.9685534591194969,0.9684873949579832,0.968421052631579,0.9683544303797469,0.9682875264270613,0.9682203389830508,0.9681528662420382,0.9680851063829787,0.9680170575692963,0.967948717948718,0.9678800856531049,0.9678111587982833,0.967741935483871,0.9676724137931034,0.9676025917926566,0.9675324675324676,0.9674620390455532,0.967391304347826,0.9673202614379085,0.9672489082969432,0.9693654266958425,0.9692982456140351,0.9692307692307692,0.9713656387665198,0.9713024282560706,0.9734513274336283,0.9733924611973392,0.9733333333333334,0.9732739420935412,0.9732142857142857,0.9731543624161074,0.9752808988764045,0.9752252252252253,0.9751693002257337,0.9751131221719457,0.9750566893424036,0.975,0.9749430523917996,0.9748858447488584,0.977116704805492,0.9770642201834863,0.9770114942528736,0.9769585253456221,0.976905311778291,0.9768518518518519,0.9767981438515081,0.9767441860465116,0.9766899766899767,0.9766355140186916,0.9765807962529274,0.9765258215962441,0.9788235294117648,0.9787735849056604,0.9787234042553191,0.9786729857819905,0.9809976247030879,0.9809523809523809,0.9809069212410502,0.9808612440191388,0.9808153477218226,0.9807692307692307,0.980722891566265,0.9830917874396136,0.9830508474576272,0.9830097087378641,0.9829683698296837,0.9829268292682927,0.9828850855745721,0.9828431372549019,0.9828009828009828,0.9826732673267327,0.9826302729528535,0.9825870646766169,0.9825436408977556,0.9825,0.9824561403508771,0.9824120603015075,0.982367758186398,0.9823232323232324,0.9822784810126582,0.9822335025380711,0.9821882951653944,0.9821428571428571,0.9820971867007673,0.982051282051282,0.9820051413881749,0.9819587628865979,0.9819121447028424,0.9818652849740933,0.9818181818181818,0.9817708333333334,0.9817232375979112,0.981675392670157,0.9816272965879265,0.9815789473684211,0.9815303430079155,0.9814814814814815,0.9814323607427056,0.9813829787234043,0.9813333333333333,0.9812834224598931,0.9812332439678284,0.9811827956989247,0.9811320754716981,0.981081081081081,0.981029810298103,0.9809782608695652,0.9809264305177112,0.9808743169398907,0.9808219178082191,0.9807692307692307,0.9807162534435262,0.9806629834254144,0.9806094182825484,0.9805555555555555,0.9805013927576601,0.9804469273743017,0.9803921568627451,0.9803370786516854,0.980225988700565,0.9801699716713881,0.9801136363636364,0.98005698005698,0.98,0.9799426934097422,0.9798850574712644,0.9798270893371758,0.9797687861271677,0.9797101449275363,0.9796511627906976,0.9795918367346939,0.97953216374269,0.9794721407624634,0.9794117647058823,0.9793510324483776,0.9792284866468842,0.9791666666666666,0.9791044776119403,0.9790419161676647,0.978978978978979,0.9788519637462235,0.9787878787878788,0.9787234042553191,0.9786585365853658,0.9785932721712538,0.9785276073619632,0.9784615384615385,0.9783950617283951,0.978328173374613,0.9781931464174455,0.978125,0.9780564263322884,0.9779874213836478,0.9779179810725552,0.9778481012658228,0.9777777777777777,0.9808917197452229,0.9808306709265175,0.9807692307692307,0.9807073954983923,0.9806451612903225,0.9805825242718447,0.9805194805194806,0.9804560260586319,0.9803921568627451,0.980327868852459,0.9835526315789473,0.9834983498349835,0.9834437086092715,0.9833887043189369,0.9833333333333333,0.9832214765100671,0.9831649831649831,0.9831081081081081,0.9830508474576272,0.9829931972789115,0.9829351535836177,0.9828767123287672,0.9828178694158075,0.9827586206896551,0.9826989619377162,0.9825174825174825,0.9824561403508771,0.9823321554770318,0.9822695035460993,0.9822064056939501,0.9821428571428571,0.9820143884892086,0.9819494584837545,0.9818840579710145,0.9818181818181818,0.9817518248175182,0.9816849816849816,0.9816176470588235,0.981549815498155,0.9814814814814815,0.9814126394052045,0.9813432835820896,0.9812734082397003,0.9811320754716981,0.9810606060606061,0.9809885931558935,0.9809160305343512,0.9808429118773946,0.9807692307692307,0.9806949806949807,0.9806201550387597,0.980544747081712,0.98046875,0.9803921568627451,0.9803149606299213,0.9802371541501976,0.9801587301587301,0.9800796812749004,0.98,0.9799196787148594,0.9798387096774194,0.979757085020243,0.9796747967479674,0.9795918367346939,0.9795081967213115,0.9794238683127572,0.9793388429752066,0.979253112033195,0.9791666666666666,0.9790794979079498,0.9789915966386554,0.9789029535864979,0.9788135593220338,0.9785407725321889,0.978448275862069,0.9783549783549783,0.9782608695652174,0.9781659388646288,0.9780701754385965,0.9779735682819384,0.9778761061946902,0.9777777777777777,0.9776785714285714,0.9774774774774775,0.9773755656108597,0.9772727272727273,0.9770642201834863,0.9769585253456221,0.9767441860465116,0.9766355140186916,0.9765258215962441,0.9764150943396226,0.976303317535545,0.9761904761904762,0.9760765550239234,0.9759615384615384,0.9758454106280193,0.9804878048780488,0.9803921568627451,0.9802955665024631,0.9801980198019802,0.9800995024875622,0.985,0.9849246231155779,0.9848484848484849,0.9847715736040609,0.9846938775510204,0.9846153846153847,0.9845360824742269,0.9844559585492227,0.9842931937172775,0.9842105263157894,0.9841269841269841,0.983957219251337,0.9838709677419355,0.9837837837837838,0.9836956521739131,0.989010989010989,0.9888888888888889,0.9888268156424581,0.9887005649717514,0.9886363636363636,0.9885714285714285,0.9884393063583815,0.9883720930232558,0.9883040935672515,0.9882352941176471,0.9881656804733728,0.9880239520958084,0.9879518072289156,0.9878787878787879,0.9877300613496932,0.9876543209876543,0.9875776397515528,0.9875,0.9874213836477987,0.9873417721518988,0.9872611464968153,0.9871794871794872,0.9870967741935484,0.987012987012987,0.9869281045751634,0.9868421052631579,0.9867549668874173,0.9866666666666667,0.9865771812080537,0.9864864864864865,0.9863945578231292,0.993103448275862,0.9930555555555556,0.993006993006993,0.9929577464788732,0.9929078014184397,0.9928571428571429,0.9928057553956835,0.9927007299270073,0.9926470588235294,0.9925925925925926,0.9923664122137404,0.9922480620155039,0.9921259842519685,0.9920634920634921,0.9919354838709677,0.991869918699187,0.9918032786885246,0.9917355371900827,0.9916666666666667,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Recall\"},\"constrain\":\"domain\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Precision\"},\"scaleanchor\":\"x\",\"scaleratio\":1},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Precision-Recall Curve (AUC=0.8840)\"},\"height\":600,\"width\":800,\"shapes\":[{\"line\":{\"dash\":\"dash\"},\"type\":\"line\",\"x0\":0,\"x1\":1,\"y0\":1,\"y1\":0}],\"showlegend\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('b200abe3-45be-4995-a602-a16a6ac07bb0');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"}],"source":["target_score = extra_trees_clf.predict_proba(features_valid)[:, 1]\n","\n","fpr, tpr, thresholds = roc_curve(target_valid, target_score)\n","\n","fig = px.area(\n","    x=fpr, y=tpr,\n","    title=f'ROC Curve (AUC={auc(fpr, tpr):.4f})',\n","    labels=dict(x='False Positive Rate', y='True Positive Rate'),\n","    width=800, height=600\n",")\n","fig.add_shape(\n","    type='line', line=dict(dash='dash'),\n","    x0=0, x1=1, y0=0, y1=1\n",")\n","\n","fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n","fig.update_xaxes(constrain='domain')\n","fig.update_layout(showlegend=False)\n","fig.show()\n","\n","precision, recall, thresholds = precision_recall_curve(target_valid, target_score)\n","\n","fig = px.area(\n","    x=recall, y=precision,\n","    title=f'Precision-Recall Curve (AUC={auc(fpr, tpr):.4f})',\n","    labels=dict(x='Recall', y='Precision'),\n","    width=800, height=600\n",")\n","fig.add_shape(\n","    type='line', line=dict(dash='dash'),\n","    x0=0, x1=1, y0=1, y1=0\n",")\n","fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n","fig.update_xaxes(constrain='domain')\n","fig.update_layout(showlegend=False)\n","fig.show()"]},{"cell_type":"markdown","metadata":{},"source":["--------"]},{"cell_type":"markdown","metadata":{},"source":["# Logistic Regression"]},{"cell_type":"code","execution_count":640,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T16:53:23.562118Z","iopub.status.busy":"2023-11-30T16:53:23.561856Z","iopub.status.idle":"2023-11-30T16:53:41.358165Z","shell.execute_reply":"2023-11-30T16:53:41.356738Z","shell.execute_reply.started":"2023-11-30T16:53:23.562094Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Runtime:\n","CPU times: user 334 ms, sys: 123 ms, total: 457 ms\n","Wall time: 4.43 s\n"]}],"source":["%%time\n","log_model = LogisticRegression()\n","log_parameters = [{\"solver\": ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'],\n","                      \"fit_intercept\": [True, False],\n","                       \"penalty\": ['l1', 'l2', 'elasticnet'],\n","                      \"n_jobs\": list(range(1,200))}]\n","\n","log_clf = RandomizedSearchCV(log_model, log_parameters, scoring='roc_auc', n_jobs=-1, cv=cv)\n","log_clf.fit(features_train, target_train)\n","# create a variable for the best model\n","best_log = log_clf.best_estimator_\n","log_pred = best_log.predict(features_valid)\n","print('Runtime:')"]},{"cell_type":"code","execution_count":676,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 1000x500 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["sns.set(style=\"white\", color_codes=True)\n","plt.rcParams['axes.linewidth'] = 0.1\n","\n","fig, ax = plt.subplots(figsize = (10,5))\n","disp = CalibrationDisplay.from_estimator(log_clf, features_valid, target_valid, ax=ax)\n","plt.title('Calibration Chart - Logistic Regression', fontsize=10)\n","ax.set_xlabel('Mean predicted probability (Positive class: 1)', fontsize=10)\n","ax.set_ylabel('Fraction of positives (Positive class: 1)',fontsize=10)\n","\n","ax.tick_params(color='gray', labelcolor='gray')\n","for spine in ax.spines.values():\n","    spine.set_edgecolor('gray')\n","\n","\n","fig.tight_layout()\n","plt.legend(fontsize=8)\n","plt.show()"]},{"cell_type":"code","execution_count":642,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T16:53:41.367003Z","iopub.status.busy":"2023-11-30T16:53:41.363014Z","iopub.status.idle":"2023-11-30T16:53:45.451418Z","shell.execute_reply":"2023-11-30T16:53:45.450399Z","shell.execute_reply.started":"2023-11-30T16:53:41.366952Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Cross Validation Scores: [0.85124724 0.8327765  0.85178571 0.78652074 0.81972926 0.8421947\n"," 0.80411866 0.80244816 0.8662159  0.83342002 0.81100896 0.81016705\n"," 0.83533986 0.82379032 0.84467166 0.81984447 0.8406682  0.80745968\n"," 0.84688511 0.83786986 0.78523355 0.84017857 0.85815092 0.8328341\n"," 0.83398618 0.85092166 0.84161866 0.8296659  0.82209316 0.79449838\n"," 0.82300885 0.81800115 0.82263825 0.8344182  0.85351382 0.85711406\n"," 0.81486175 0.81431452 0.83685853 0.82714979 0.82764842 0.82730415\n"," 0.81641705 0.80270737 0.83554147 0.82926267 0.85374424 0.83767281\n"," 0.83240869 0.83619394]\n"]}],"source":["log_scores = cross_val_score(log_model, features_train, target_train, cv=cv, scoring='roc_auc')\n","print('Cross Validation Scores: {}'.format(log_scores))"]},{"cell_type":"code","execution_count":643,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T16:53:45.453259Z","iopub.status.busy":"2023-11-30T16:53:45.452705Z","iopub.status.idle":"2023-11-30T16:53:45.479560Z","shell.execute_reply":"2023-11-30T16:53:45.478438Z","shell.execute_reply.started":"2023-11-30T16:53:45.453224Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Best hyperparameters: {'solver': 'saga', 'penalty': 'l1', 'n_jobs': 111, 'fit_intercept': True}\n","\n","Best score: 0.8293990200295923\n","\n","Average Cross Validation Score: 0.829162458233739\n","\n","ROC AUC Score - Validation Dataset: 0.8560317024812213\n"]}],"source":["# summary\n","print('Best hyperparameters:',  log_clf.best_params_)\n","print()\n","print('Best score:',  log_clf.best_score_)\n","print()\n","print('Average Cross Validation Score: {}'.format(log_scores.mean()))\n","print()\n","print('ROC AUC Score - Validation Dataset:',  roc_auc_score(target_valid, log_clf.predict_proba(features_valid)[:, 1]))"]},{"cell_type":"markdown","metadata":{},"source":["# ROC AUC Curve - LogisticRegression"]},{"cell_type":"code","execution_count":644,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T16:53:45.489716Z","iopub.status.busy":"2023-11-30T16:53:45.485889Z","iopub.status.idle":"2023-11-30T16:53:45.726171Z","shell.execute_reply":"2023-11-30T16:53:45.725272Z","shell.execute_reply.started":"2023-11-30T16:53:45.489647Z"},"trusted":true},"outputs":[{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"fillpattern":{"shape":""},"hovertemplate":"False Positive Rate=%{x}<br>True Positive Rate=%{y}<extra></extra>","legendgroup":"","line":{"color":"#636efa"},"marker":{"symbol":"circle"},"mode":"lines","name":"","orientation":"v","showlegend":false,"stackgroup":"1","type":"scatter","x":[0,0,0,0.00267379679144385,0.00267379679144385,0.0053475935828877,0.0053475935828877,0.008021390374331552,0.008021390374331552,0.0106951871657754,0.0106951871657754,0.013368983957219251,0.013368983957219251,0.016042780748663103,0.016042780748663103,0.01871657754010695,0.01871657754010695,0.0213903743315508,0.0213903743315508,0.02406417112299465,0.02406417112299465,0.026737967914438502,0.026737967914438502,0.029411764705882353,0.029411764705882353,0.03208556149732621,0.03208556149732621,0.034759358288770054,0.034759358288770054,0.0374331550802139,0.0374331550802139,0.040106951871657755,0.040106951871657755,0.0427807486631016,0.0427807486631016,0.045454545454545456,0.045454545454545456,0.0481283422459893,0.0481283422459893,0.05080213903743316,0.05080213903743316,0.053475935828877004,0.053475935828877004,0.05614973262032086,0.05614973262032086,0.058823529411764705,0.058823529411764705,0.06149732620320856,0.06149732620320856,0.06417112299465241,0.06417112299465241,0.06684491978609626,0.06684491978609626,0.06951871657754011,0.06951871657754011,0.07219251336898395,0.07219251336898395,0.0748663101604278,0.0748663101604278,0.07754010695187166,0.07754010695187166,0.08021390374331551,0.08021390374331551,0.08288770053475936,0.08288770053475936,0.08288770053475936,0.08288770053475936,0.0855614973262032,0.0855614973262032,0.08823529411764706,0.08823529411764706,0.09090909090909091,0.09090909090909091,0.09358288770053476,0.09358288770053476,0.0962566844919786,0.0962566844919786,0.10160427807486631,0.10160427807486631,0.10427807486631016,0.10427807486631016,0.10695187165775401,0.10695187165775401,0.10962566844919786,0.10962566844919786,0.11229946524064172,0.11229946524064172,0.11497326203208556,0.11497326203208556,0.11764705882352941,0.11764705882352941,0.12299465240641712,0.12299465240641712,0.12566844919786097,0.12566844919786097,0.12834224598930483,0.12834224598930483,0.13101604278074866,0.13101604278074866,0.13368983957219252,0.13368983957219252,0.13636363636363635,0.13636363636363635,0.13903743315508021,0.13903743315508021,0.1443850267379679,0.1443850267379679,0.14705882352941177,0.14705882352941177,0.1497326203208556,0.1497326203208556,0.15240641711229946,0.15240641711229946,0.15508021390374332,0.15508021390374332,0.15775401069518716,0.15775401069518716,0.16042780748663102,0.16042780748663102,0.16310160427807488,0.16310160427807488,0.16844919786096257,0.16844919786096257,0.1711229946524064,0.1711229946524064,0.17379679144385027,0.17379679144385027,0.17647058823529413,0.17647058823529413,0.17914438502673796,0.17914438502673796,0.18449197860962566,0.18449197860962566,0.18716577540106952,0.18716577540106952,0.18983957219251338,0.18983957219251338,0.1925133689839572,0.1925133689839572,0.19518716577540107,0.19518716577540107,0.19786096256684493,0.19786096256684493,0.20053475935828877,0.20053475935828877,0.20588235294117646,0.20588235294117646,0.20855614973262032,0.20855614973262032,0.21122994652406418,0.21122994652406418,0.2192513368983957,0.2192513368983957,0.22192513368983957,0.22192513368983957,0.22994652406417113,0.22994652406417113,0.232620320855615,0.232620320855615,0.23529411764705882,0.23529411764705882,0.24064171122994651,0.24064171122994651,0.24331550802139038,0.24331550802139038,0.24866310160427807,0.24866310160427807,0.25133689839572193,0.25133689839572193,0.2540106951871658,0.2540106951871658,0.25668449197860965,0.25668449197860965,0.25935828877005346,0.25935828877005346,0.2647058823529412,0.2647058823529412,0.2700534759358289,0.2700534759358289,0.27807486631016043,0.27807486631016043,0.28342245989304815,0.28342245989304815,0.28609625668449196,0.28609625668449196,0.2914438502673797,0.2914438502673797,0.29411764705882354,0.29411764705882354,0.2967914438502674,0.2967914438502674,0.2994652406417112,0.2994652406417112,0.32085561497326204,0.32085561497326204,0.3235294117647059,0.3235294117647059,0.32887700534759357,0.32887700534759357,0.3315508021390374,0.3315508021390374,0.33689839572192515,0.33689839572192515,0.339572192513369,0.339572192513369,0.3449197860962567,0.3449197860962567,0.34759358288770054,0.34759358288770054,0.35561497326203206,0.35561497326203206,0.3582887700534759,0.3582887700534759,0.3609625668449198,0.3609625668449198,0.36363636363636365,0.36363636363636365,0.3663101604278075,0.3663101604278075,0.3689839572192513,0.3689839572192513,0.3716577540106952,0.3716577540106952,0.38235294117647056,0.38235294117647056,0.3850267379679144,0.3850267379679144,0.3983957219251337,0.3983957219251337,0.40106951871657753,0.40106951871657753,0.40641711229946526,0.40641711229946526,0.4090909090909091,0.4090909090909091,0.4197860962566845,0.4197860962566845,0.42245989304812837,0.42245989304812837,0.4411764705882353,0.4411764705882353,0.44385026737967914,0.44385026737967914,0.446524064171123,0.446524064171123,0.44919786096256686,0.44919786096256686,0.45187165775401067,0.45187165775401067,0.45454545454545453,0.45454545454545453,0.4572192513368984,0.4572192513368984,0.4625668449197861,0.4625668449197861,0.4679144385026738,0.4679144385026738,0.47058823529411764,0.47058823529411764,0.47593582887700536,0.47593582887700536,0.48128342245989303,0.48128342245989303,0.4893048128342246,0.4893048128342246,0.4919786096256685,0.4919786096256685,0.4946524064171123,0.4946524064171123,0.5026737967914439,0.5026737967914439,0.5106951871657754,0.5106951871657754,0.516042780748663,0.516042780748663,0.5187165775401069,0.5187165775401069,0.5267379679144385,0.5267379679144385,0.5294117647058824,0.5294117647058824,0.5374331550802139,0.5374331550802139,0.5454545454545454,0.5454545454545454,0.5508021390374331,0.5508021390374331,0.553475935828877,0.553475935828877,0.5588235294117647,0.5588235294117647,0.5614973262032086,0.5614973262032086,0.5668449197860963,0.5668449197860963,0.56951871657754,0.56951871657754,0.6042780748663101,0.6042780748663101,0.606951871657754,0.606951871657754,0.6176470588235294,0.6176470588235294,0.6203208556149733,0.6203208556149733,0.6229946524064172,0.6229946524064172,0.6310160427807486,0.6310160427807486,0.6417112299465241,0.6417112299465241,0.660427807486631,0.660427807486631,0.6764705882352942,0.6764705882352942,0.6844919786096256,0.6844919786096256,0.6951871657754011,0.6951871657754011,0.6978609625668449,0.6978609625668449,0.7032085561497327,0.7032085561497327,0.7085561497326203,0.7085561497326203,0.7192513368983957,0.7192513368983957,0.7406417112299465,0.7406417112299465,0.7459893048128342,0.7459893048128342,0.7540106951871658,0.7540106951871658,0.7887700534759359,0.7887700534759359,0.7941176470588235,0.7941176470588235,0.8021390374331551,0.8021390374331551,0.8101604278074866,0.8101604278074866,0.8128342245989305,0.8128342245989305,0.8315508021390374,0.8315508021390374,0.839572192513369,0.839572192513369,0.8475935828877005,0.8475935828877005,0.8716577540106952,0.8716577540106952,0.8770053475935828,0.8770053475935828,0.8877005347593583,0.8877005347593583,0.9037433155080213,0.9037433155080213,0.9385026737967914,0.9385026737967914,0.946524064171123,0.946524064171123,0.983957219251337,0.983957219251337,1],"xaxis":"x","y":[0,0.000968054211035818,0.031945788964181994,0.031945788964181994,0.061955469506292354,0.061955469506292354,0.09583736689254599,0.09583736689254599,0.10164569215876089,0.10164569215876089,0.10454985479186835,0.10454985479186835,0.16553727008712488,0.16553727008712488,0.22265246853823814,0.22265246853823814,0.23426911907066797,0.23426911907066797,0.2846079380445305,0.2846079380445305,0.31461761858664083,0.31461761858664083,0.32720232333010646,0.32720232333010646,0.3339787028073572,0.3339787028073572,0.3514036786060019,0.3514036786060019,0.3610842207163601,0.3610842207163601,0.3688286544046467,0.3688286544046467,0.3707647628267183,0.3707647628267183,0.37560503388189737,0.37560503388189737,0.4036786060019361,0.4036786060019361,0.4085188770571152,0.4085188770571152,0.4230396902226525,0.4230396902226525,0.46466602129719264,0.46466602129719264,0.4762826718296225,0.4762826718296225,0.4878993223620523,0.4878993223620523,0.5246853823814134,0.5246853823814134,0.5382381413359149,0.5382381413359149,0.5401742497579864,0.5401742497579864,0.5517909002904162,0.5517909002904162,0.5527589545014521,0.5527589545014521,0.5721200387221684,0.5721200387221684,0.57405614714424,0.57405614714424,0.5808325266214908,0.5808325266214908,0.5818005808325266,0.5837366892545982,0.5866408518877058,0.5866408518877058,0.5943852855759922,0.5943852855759922,0.5953533397870281,0.5953533397870281,0.5992255566311714,0.5992255566311714,0.6030977734753146,0.6030977734753146,0.6214908034849952,0.6214908034849952,0.6234269119070668,0.6234269119070668,0.6292352371732817,0.6292352371732817,0.6311713455953534,0.6311713455953534,0.6321393998063891,0.6321393998063891,0.6350435624394967,0.6350435624394967,0.648596321393998,0.648596321393998,0.6592449177153921,0.6592449177153921,0.6611810261374637,0.6611810261374637,0.675701839303001,0.675701839303001,0.6815101645692159,0.6815101645692159,0.6834462729912875,0.6834462729912875,0.6882865440464666,0.6882865440464666,0.6921587608906099,0.6921587608906099,0.6931268151016456,0.6931268151016456,0.6940948693126815,0.6940948693126815,0.6999031945788964,0.6999031945788964,0.7008712487899322,0.7008712487899322,0.7115198451113263,0.7115198451113263,0.7153920619554696,0.7153920619554696,0.7192642787996127,0.7192642787996127,0.7241045498547919,0.7241045498547919,0.7279767666989352,0.7279767666989352,0.7318489835430784,0.7318489835430784,0.7328170377541142,0.7328170377541142,0.7347531461761858,0.7347531461761858,0.7357212003872217,0.7357212003872217,0.7366892545982575,0.7366892545982575,0.7521781219748306,0.7521781219748306,0.7618586640851888,0.7618586640851888,0.7628267182962246,0.7628267182962246,0.7637947725072604,0.7637947725072604,0.7647628267182962,0.7647628267182962,0.7725072604065828,0.7725072604065828,0.7734753146176185,0.7734753146176185,0.782187802516941,0.782187802516941,0.7831558567279767,0.7831558567279767,0.7850919651500484,0.7850919651500484,0.7889641819941917,0.7889641819941917,0.797676669893514,0.797676669893514,0.7986447241045499,0.7986447241045499,0.7996127783155856,0.7996127783155856,0.8044530493707648,0.8044530493707648,0.8073572120038722,0.8073572120038722,0.8092933204259438,0.8092933204259438,0.8102613746369797,0.8102613746369797,0.8131655372700871,0.8131655372700871,0.8151016456921588,0.8151016456921588,0.8199419167473379,0.8199419167473379,0.8218780251694094,0.8218780251694094,0.8276863504356244,0.8276863504356244,0.8286544046466602,0.8286544046466602,0.8315585672797676,0.8315585672797676,0.8325266214908035,0.8325266214908035,0.8373668925459826,0.8373668925459826,0.8383349467570184,0.8383349467570184,0.8393030009680542,0.8393030009680542,0.8412391093901258,0.8412391093901258,0.8422071636011617,0.8422071636011617,0.8431752178121975,0.8431752178121975,0.8441432720232332,0.8441432720232332,0.846079380445305,0.846079380445305,0.8480154888673765,0.8480154888673765,0.8499515972894482,0.8499515972894482,0.8518877057115198,0.8518877057115198,0.8528557599225557,0.8528557599225557,0.8547918683446273,0.8547918683446273,0.8557599225556631,0.8557599225556631,0.8654404646660213,0.8654404646660213,0.8664085188770572,0.8664085188770572,0.8673765730880929,0.8673765730880929,0.8683446272991288,0.8683446272991288,0.872216844143272,0.872216844143272,0.8731848983543078,0.8731848983543078,0.8760890609874153,0.8760890609874153,0.8770571151984511,0.8770571151984511,0.8789932236205228,0.8789932236205228,0.8799612778315585,0.8799612778315585,0.888673765730881,0.888673765730881,0.8896418199419167,0.8896418199419167,0.8906098741529526,0.8906098741529526,0.89351403678606,0.89351403678606,0.8954501452081317,0.8954501452081317,0.9012584704743466,0.9012584704743466,0.9022265246853823,0.9022265246853823,0.9080348499515973,0.9080348499515973,0.9090029041626331,0.9090029041626331,0.9099709583736689,0.9099709583736689,0.9109390125847048,0.9109390125847048,0.914811229428848,0.914811229428848,0.9215876089060987,0.9215876089060987,0.9225556631171346,0.9225556631171346,0.9235237173281704,0.9235237173281704,0.925459825750242,0.925459825750242,0.9283639883833494,0.9283639883833494,0.9303000968054211,0.9303000968054211,0.9322362052274927,0.9322362052274927,0.9351403678606002,0.9351403678606002,0.936108422071636,0.936108422071636,0.9370764762826719,0.9370764762826719,0.9380445304937076,0.9380445304937076,0.9390125847047435,0.9390125847047435,0.9399806389157793,0.9399806389157793,0.9419167473378509,0.9419167473378509,0.9428848015488868,0.9428848015488868,0.9467570183930301,0.9467570183930301,0.9477250726040658,0.9477250726040658,0.9515972894482091,0.9515972894482091,0.9535333978702807,0.9535333978702807,0.9545014520813165,0.9545014520813165,0.9554695062923524,0.9554695062923524,0.9564375605033882,0.9564375605033882,0.957405614714424,0.957405614714424,0.9593417231364957,0.9593417231364957,0.9612778315585673,0.9612778315585673,0.9622458857696031,0.9622458857696031,0.9632139399806389,0.9632139399806389,0.9641819941916747,0.9641819941916747,0.9651500484027106,0.9651500484027106,0.9661181026137464,0.9661181026137464,0.9670861568247822,0.9670861568247822,0.9719264278799613,0.9719264278799613,0.9757986447241046,0.9757986447241046,0.9777347531461762,0.9777347531461762,0.978702807357212,0.978702807357212,0.9796708615682478,0.9796708615682478,0.9806389157792836,0.9806389157792836,0.9816069699903195,0.9816069699903195,0.9845111326234269,0.9845111326234269,0.9854791868344628,0.9854791868344628,0.9864472410454985,0.9864472410454985,0.9874152952565344,0.9874152952565344,0.9883833494675702,0.9883833494675702,0.989351403678606,0.989351403678606,0.9903194578896418,0.9903194578896418,0.9912875121006777,0.9912875121006777,0.9922555663117134,0.9922555663117134,0.9932236205227493,0.9932236205227493,0.995159728944821,0.995159728944821,0.9961277831558567,0.9961277831558567,0.9970958373668926,0.9970958373668926,0.9980638915779284,0.9980638915779284,0.9990319457889641,0.9990319457889641,1,1],"yaxis":"y"}],"layout":{"height":600,"legend":{"tracegroupgap":0},"shapes":[{"line":{"dash":"dash"},"type":"line","x0":0,"x1":1,"y0":0,"y1":1}],"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"title":{"text":"ROC Curve (AUC=0.8560)"},"width":800,"xaxis":{"anchor":"y","constrain":"domain","domain":[0,1],"title":{"text":"False Positive Rate"}},"yaxis":{"anchor":"x","domain":[0,1],"scaleanchor":"x","scaleratio":1,"title":{"text":"True Positive Rate"}}}},"text/html":["<div>                            <div id=\"5f30ac8a-240d-4e9c-aa61-84d37cfd72ed\" class=\"plotly-graph-div\" style=\"height:600px; width:800px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"5f30ac8a-240d-4e9c-aa61-84d37cfd72ed\")) {                    Plotly.newPlot(                        \"5f30ac8a-240d-4e9c-aa61-84d37cfd72ed\",                        [{\"fillpattern\":{\"shape\":\"\"},\"hovertemplate\":\"False Positive Rate=%{x}\\u003cbr\\u003eTrue Positive Rate=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"stackgroup\":\"1\",\"x\":[0.0,0.0,0.0,0.00267379679144385,0.00267379679144385,0.0053475935828877,0.0053475935828877,0.008021390374331552,0.008021390374331552,0.0106951871657754,0.0106951871657754,0.013368983957219251,0.013368983957219251,0.016042780748663103,0.016042780748663103,0.01871657754010695,0.01871657754010695,0.0213903743315508,0.0213903743315508,0.02406417112299465,0.02406417112299465,0.026737967914438502,0.026737967914438502,0.029411764705882353,0.029411764705882353,0.03208556149732621,0.03208556149732621,0.034759358288770054,0.034759358288770054,0.0374331550802139,0.0374331550802139,0.040106951871657755,0.040106951871657755,0.0427807486631016,0.0427807486631016,0.045454545454545456,0.045454545454545456,0.0481283422459893,0.0481283422459893,0.05080213903743316,0.05080213903743316,0.053475935828877004,0.053475935828877004,0.05614973262032086,0.05614973262032086,0.058823529411764705,0.058823529411764705,0.06149732620320856,0.06149732620320856,0.06417112299465241,0.06417112299465241,0.06684491978609626,0.06684491978609626,0.06951871657754011,0.06951871657754011,0.07219251336898395,0.07219251336898395,0.0748663101604278,0.0748663101604278,0.07754010695187166,0.07754010695187166,0.08021390374331551,0.08021390374331551,0.08288770053475936,0.08288770053475936,0.08288770053475936,0.08288770053475936,0.0855614973262032,0.0855614973262032,0.08823529411764706,0.08823529411764706,0.09090909090909091,0.09090909090909091,0.09358288770053476,0.09358288770053476,0.0962566844919786,0.0962566844919786,0.10160427807486631,0.10160427807486631,0.10427807486631016,0.10427807486631016,0.10695187165775401,0.10695187165775401,0.10962566844919786,0.10962566844919786,0.11229946524064172,0.11229946524064172,0.11497326203208556,0.11497326203208556,0.11764705882352941,0.11764705882352941,0.12299465240641712,0.12299465240641712,0.12566844919786097,0.12566844919786097,0.12834224598930483,0.12834224598930483,0.13101604278074866,0.13101604278074866,0.13368983957219252,0.13368983957219252,0.13636363636363635,0.13636363636363635,0.13903743315508021,0.13903743315508021,0.1443850267379679,0.1443850267379679,0.14705882352941177,0.14705882352941177,0.1497326203208556,0.1497326203208556,0.15240641711229946,0.15240641711229946,0.15508021390374332,0.15508021390374332,0.15775401069518716,0.15775401069518716,0.16042780748663102,0.16042780748663102,0.16310160427807488,0.16310160427807488,0.16844919786096257,0.16844919786096257,0.1711229946524064,0.1711229946524064,0.17379679144385027,0.17379679144385027,0.17647058823529413,0.17647058823529413,0.17914438502673796,0.17914438502673796,0.18449197860962566,0.18449197860962566,0.18716577540106952,0.18716577540106952,0.18983957219251338,0.18983957219251338,0.1925133689839572,0.1925133689839572,0.19518716577540107,0.19518716577540107,0.19786096256684493,0.19786096256684493,0.20053475935828877,0.20053475935828877,0.20588235294117646,0.20588235294117646,0.20855614973262032,0.20855614973262032,0.21122994652406418,0.21122994652406418,0.2192513368983957,0.2192513368983957,0.22192513368983957,0.22192513368983957,0.22994652406417113,0.22994652406417113,0.232620320855615,0.232620320855615,0.23529411764705882,0.23529411764705882,0.24064171122994651,0.24064171122994651,0.24331550802139038,0.24331550802139038,0.24866310160427807,0.24866310160427807,0.25133689839572193,0.25133689839572193,0.2540106951871658,0.2540106951871658,0.25668449197860965,0.25668449197860965,0.25935828877005346,0.25935828877005346,0.2647058823529412,0.2647058823529412,0.2700534759358289,0.2700534759358289,0.27807486631016043,0.27807486631016043,0.28342245989304815,0.28342245989304815,0.28609625668449196,0.28609625668449196,0.2914438502673797,0.2914438502673797,0.29411764705882354,0.29411764705882354,0.2967914438502674,0.2967914438502674,0.2994652406417112,0.2994652406417112,0.32085561497326204,0.32085561497326204,0.3235294117647059,0.3235294117647059,0.32887700534759357,0.32887700534759357,0.3315508021390374,0.3315508021390374,0.33689839572192515,0.33689839572192515,0.339572192513369,0.339572192513369,0.3449197860962567,0.3449197860962567,0.34759358288770054,0.34759358288770054,0.35561497326203206,0.35561497326203206,0.3582887700534759,0.3582887700534759,0.3609625668449198,0.3609625668449198,0.36363636363636365,0.36363636363636365,0.3663101604278075,0.3663101604278075,0.3689839572192513,0.3689839572192513,0.3716577540106952,0.3716577540106952,0.38235294117647056,0.38235294117647056,0.3850267379679144,0.3850267379679144,0.3983957219251337,0.3983957219251337,0.40106951871657753,0.40106951871657753,0.40641711229946526,0.40641711229946526,0.4090909090909091,0.4090909090909091,0.4197860962566845,0.4197860962566845,0.42245989304812837,0.42245989304812837,0.4411764705882353,0.4411764705882353,0.44385026737967914,0.44385026737967914,0.446524064171123,0.446524064171123,0.44919786096256686,0.44919786096256686,0.45187165775401067,0.45187165775401067,0.45454545454545453,0.45454545454545453,0.4572192513368984,0.4572192513368984,0.4625668449197861,0.4625668449197861,0.4679144385026738,0.4679144385026738,0.47058823529411764,0.47058823529411764,0.47593582887700536,0.47593582887700536,0.48128342245989303,0.48128342245989303,0.4893048128342246,0.4893048128342246,0.4919786096256685,0.4919786096256685,0.4946524064171123,0.4946524064171123,0.5026737967914439,0.5026737967914439,0.5106951871657754,0.5106951871657754,0.516042780748663,0.516042780748663,0.5187165775401069,0.5187165775401069,0.5267379679144385,0.5267379679144385,0.5294117647058824,0.5294117647058824,0.5374331550802139,0.5374331550802139,0.5454545454545454,0.5454545454545454,0.5508021390374331,0.5508021390374331,0.553475935828877,0.553475935828877,0.5588235294117647,0.5588235294117647,0.5614973262032086,0.5614973262032086,0.5668449197860963,0.5668449197860963,0.56951871657754,0.56951871657754,0.6042780748663101,0.6042780748663101,0.606951871657754,0.606951871657754,0.6176470588235294,0.6176470588235294,0.6203208556149733,0.6203208556149733,0.6229946524064172,0.6229946524064172,0.6310160427807486,0.6310160427807486,0.6417112299465241,0.6417112299465241,0.660427807486631,0.660427807486631,0.6764705882352942,0.6764705882352942,0.6844919786096256,0.6844919786096256,0.6951871657754011,0.6951871657754011,0.6978609625668449,0.6978609625668449,0.7032085561497327,0.7032085561497327,0.7085561497326203,0.7085561497326203,0.7192513368983957,0.7192513368983957,0.7406417112299465,0.7406417112299465,0.7459893048128342,0.7459893048128342,0.7540106951871658,0.7540106951871658,0.7887700534759359,0.7887700534759359,0.7941176470588235,0.7941176470588235,0.8021390374331551,0.8021390374331551,0.8101604278074866,0.8101604278074866,0.8128342245989305,0.8128342245989305,0.8315508021390374,0.8315508021390374,0.839572192513369,0.839572192513369,0.8475935828877005,0.8475935828877005,0.8716577540106952,0.8716577540106952,0.8770053475935828,0.8770053475935828,0.8877005347593583,0.8877005347593583,0.9037433155080213,0.9037433155080213,0.9385026737967914,0.9385026737967914,0.946524064171123,0.946524064171123,0.983957219251337,0.983957219251337,1.0],\"xaxis\":\"x\",\"y\":[0.0,0.000968054211035818,0.031945788964181994,0.031945788964181994,0.061955469506292354,0.061955469506292354,0.09583736689254599,0.09583736689254599,0.10164569215876089,0.10164569215876089,0.10454985479186835,0.10454985479186835,0.16553727008712488,0.16553727008712488,0.22265246853823814,0.22265246853823814,0.23426911907066797,0.23426911907066797,0.2846079380445305,0.2846079380445305,0.31461761858664083,0.31461761858664083,0.32720232333010646,0.32720232333010646,0.3339787028073572,0.3339787028073572,0.3514036786060019,0.3514036786060019,0.3610842207163601,0.3610842207163601,0.3688286544046467,0.3688286544046467,0.3707647628267183,0.3707647628267183,0.37560503388189737,0.37560503388189737,0.4036786060019361,0.4036786060019361,0.4085188770571152,0.4085188770571152,0.4230396902226525,0.4230396902226525,0.46466602129719264,0.46466602129719264,0.4762826718296225,0.4762826718296225,0.4878993223620523,0.4878993223620523,0.5246853823814134,0.5246853823814134,0.5382381413359149,0.5382381413359149,0.5401742497579864,0.5401742497579864,0.5517909002904162,0.5517909002904162,0.5527589545014521,0.5527589545014521,0.5721200387221684,0.5721200387221684,0.57405614714424,0.57405614714424,0.5808325266214908,0.5808325266214908,0.5818005808325266,0.5837366892545982,0.5866408518877058,0.5866408518877058,0.5943852855759922,0.5943852855759922,0.5953533397870281,0.5953533397870281,0.5992255566311714,0.5992255566311714,0.6030977734753146,0.6030977734753146,0.6214908034849952,0.6214908034849952,0.6234269119070668,0.6234269119070668,0.6292352371732817,0.6292352371732817,0.6311713455953534,0.6311713455953534,0.6321393998063891,0.6321393998063891,0.6350435624394967,0.6350435624394967,0.648596321393998,0.648596321393998,0.6592449177153921,0.6592449177153921,0.6611810261374637,0.6611810261374637,0.675701839303001,0.675701839303001,0.6815101645692159,0.6815101645692159,0.6834462729912875,0.6834462729912875,0.6882865440464666,0.6882865440464666,0.6921587608906099,0.6921587608906099,0.6931268151016456,0.6931268151016456,0.6940948693126815,0.6940948693126815,0.6999031945788964,0.6999031945788964,0.7008712487899322,0.7008712487899322,0.7115198451113263,0.7115198451113263,0.7153920619554696,0.7153920619554696,0.7192642787996127,0.7192642787996127,0.7241045498547919,0.7241045498547919,0.7279767666989352,0.7279767666989352,0.7318489835430784,0.7318489835430784,0.7328170377541142,0.7328170377541142,0.7347531461761858,0.7347531461761858,0.7357212003872217,0.7357212003872217,0.7366892545982575,0.7366892545982575,0.7521781219748306,0.7521781219748306,0.7618586640851888,0.7618586640851888,0.7628267182962246,0.7628267182962246,0.7637947725072604,0.7637947725072604,0.7647628267182962,0.7647628267182962,0.7725072604065828,0.7725072604065828,0.7734753146176185,0.7734753146176185,0.782187802516941,0.782187802516941,0.7831558567279767,0.7831558567279767,0.7850919651500484,0.7850919651500484,0.7889641819941917,0.7889641819941917,0.797676669893514,0.797676669893514,0.7986447241045499,0.7986447241045499,0.7996127783155856,0.7996127783155856,0.8044530493707648,0.8044530493707648,0.8073572120038722,0.8073572120038722,0.8092933204259438,0.8092933204259438,0.8102613746369797,0.8102613746369797,0.8131655372700871,0.8131655372700871,0.8151016456921588,0.8151016456921588,0.8199419167473379,0.8199419167473379,0.8218780251694094,0.8218780251694094,0.8276863504356244,0.8276863504356244,0.8286544046466602,0.8286544046466602,0.8315585672797676,0.8315585672797676,0.8325266214908035,0.8325266214908035,0.8373668925459826,0.8373668925459826,0.8383349467570184,0.8383349467570184,0.8393030009680542,0.8393030009680542,0.8412391093901258,0.8412391093901258,0.8422071636011617,0.8422071636011617,0.8431752178121975,0.8431752178121975,0.8441432720232332,0.8441432720232332,0.846079380445305,0.846079380445305,0.8480154888673765,0.8480154888673765,0.8499515972894482,0.8499515972894482,0.8518877057115198,0.8518877057115198,0.8528557599225557,0.8528557599225557,0.8547918683446273,0.8547918683446273,0.8557599225556631,0.8557599225556631,0.8654404646660213,0.8654404646660213,0.8664085188770572,0.8664085188770572,0.8673765730880929,0.8673765730880929,0.8683446272991288,0.8683446272991288,0.872216844143272,0.872216844143272,0.8731848983543078,0.8731848983543078,0.8760890609874153,0.8760890609874153,0.8770571151984511,0.8770571151984511,0.8789932236205228,0.8789932236205228,0.8799612778315585,0.8799612778315585,0.888673765730881,0.888673765730881,0.8896418199419167,0.8896418199419167,0.8906098741529526,0.8906098741529526,0.89351403678606,0.89351403678606,0.8954501452081317,0.8954501452081317,0.9012584704743466,0.9012584704743466,0.9022265246853823,0.9022265246853823,0.9080348499515973,0.9080348499515973,0.9090029041626331,0.9090029041626331,0.9099709583736689,0.9099709583736689,0.9109390125847048,0.9109390125847048,0.914811229428848,0.914811229428848,0.9215876089060987,0.9215876089060987,0.9225556631171346,0.9225556631171346,0.9235237173281704,0.9235237173281704,0.925459825750242,0.925459825750242,0.9283639883833494,0.9283639883833494,0.9303000968054211,0.9303000968054211,0.9322362052274927,0.9322362052274927,0.9351403678606002,0.9351403678606002,0.936108422071636,0.936108422071636,0.9370764762826719,0.9370764762826719,0.9380445304937076,0.9380445304937076,0.9390125847047435,0.9390125847047435,0.9399806389157793,0.9399806389157793,0.9419167473378509,0.9419167473378509,0.9428848015488868,0.9428848015488868,0.9467570183930301,0.9467570183930301,0.9477250726040658,0.9477250726040658,0.9515972894482091,0.9515972894482091,0.9535333978702807,0.9535333978702807,0.9545014520813165,0.9545014520813165,0.9554695062923524,0.9554695062923524,0.9564375605033882,0.9564375605033882,0.957405614714424,0.957405614714424,0.9593417231364957,0.9593417231364957,0.9612778315585673,0.9612778315585673,0.9622458857696031,0.9622458857696031,0.9632139399806389,0.9632139399806389,0.9641819941916747,0.9641819941916747,0.9651500484027106,0.9651500484027106,0.9661181026137464,0.9661181026137464,0.9670861568247822,0.9670861568247822,0.9719264278799613,0.9719264278799613,0.9757986447241046,0.9757986447241046,0.9777347531461762,0.9777347531461762,0.978702807357212,0.978702807357212,0.9796708615682478,0.9796708615682478,0.9806389157792836,0.9806389157792836,0.9816069699903195,0.9816069699903195,0.9845111326234269,0.9845111326234269,0.9854791868344628,0.9854791868344628,0.9864472410454985,0.9864472410454985,0.9874152952565344,0.9874152952565344,0.9883833494675702,0.9883833494675702,0.989351403678606,0.989351403678606,0.9903194578896418,0.9903194578896418,0.9912875121006777,0.9912875121006777,0.9922555663117134,0.9922555663117134,0.9932236205227493,0.9932236205227493,0.995159728944821,0.995159728944821,0.9961277831558567,0.9961277831558567,0.9970958373668926,0.9970958373668926,0.9980638915779284,0.9980638915779284,0.9990319457889641,0.9990319457889641,1.0,1.0],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"False Positive Rate\"},\"constrain\":\"domain\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"True Positive Rate\"},\"scaleanchor\":\"x\",\"scaleratio\":1},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"ROC Curve (AUC=0.8560)\"},\"height\":600,\"width\":800,\"shapes\":[{\"line\":{\"dash\":\"dash\"},\"type\":\"line\",\"x0\":0,\"x1\":1,\"y0\":0,\"y1\":1}],\"showlegend\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('5f30ac8a-240d-4e9c-aa61-84d37cfd72ed');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"fillpattern":{"shape":""},"hovertemplate":"Recall=%{x}<br>Precision=%{y}<extra></extra>","legendgroup":"","line":{"color":"#636efa"},"marker":{"symbol":"circle"},"mode":"lines","name":"","orientation":"v","showlegend":false,"stackgroup":"1","type":"scatter","x":[1,1,1,1,1,1,1,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.9941916747337851,0.9932236205227493,0.9932236205227493,0.9932236205227493,0.9922555663117134,0.9922555663117134,0.9922555663117134,0.9922555663117134,0.9922555663117134,0.9922555663117134,0.9922555663117134,0.9922555663117134,0.9922555663117134,0.9922555663117134,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.989351403678606,0.989351403678606,0.989351403678606,0.989351403678606,0.989351403678606,0.989351403678606,0.989351403678606,0.989351403678606,0.9883833494675702,0.9883833494675702,0.9874152952565344,0.9874152952565344,0.9874152952565344,0.9874152952565344,0.9864472410454985,0.9864472410454985,0.9864472410454985,0.9864472410454985,0.9854791868344628,0.9854791868344628,0.9854791868344628,0.9845111326234269,0.9845111326234269,0.9845111326234269,0.9845111326234269,0.9845111326234269,0.9845111326234269,0.9845111326234269,0.9845111326234269,0.9845111326234269,0.9845111326234269,0.9845111326234269,0.9845111326234269,0.9845111326234269,0.9845111326234269,0.9835430784123911,0.9825750242013552,0.9816069699903195,0.9816069699903195,0.9816069699903195,0.9816069699903195,0.9806389157792836,0.9806389157792836,0.9806389157792836,0.9796708615682478,0.9796708615682478,0.9796708615682478,0.9796708615682478,0.9796708615682478,0.9796708615682478,0.9796708615682478,0.9796708615682478,0.9796708615682478,0.978702807357212,0.978702807357212,0.978702807357212,0.978702807357212,0.978702807357212,0.9777347531461762,0.9777347531461762,0.9777347531461762,0.9767666989351403,0.9757986447241046,0.9757986447241046,0.9757986447241046,0.9748305905130688,0.9738625363020329,0.972894482090997,0.9719264278799613,0.9719264278799613,0.9709583736689255,0.9699903194578896,0.9690222652468539,0.968054211035818,0.9670861568247822,0.9670861568247822,0.9670861568247822,0.9670861568247822,0.9670861568247822,0.9661181026137464,0.9661181026137464,0.9661181026137464,0.9661181026137464,0.9651500484027106,0.9651500484027106,0.9651500484027106,0.9651500484027106,0.9651500484027106,0.9651500484027106,0.9651500484027106,0.9641819941916747,0.9641819941916747,0.9641819941916747,0.9641819941916747,0.9641819941916747,0.9641819941916747,0.9641819941916747,0.9641819941916747,0.9632139399806389,0.9632139399806389,0.9632139399806389,0.9632139399806389,0.9632139399806389,0.9622458857696031,0.9622458857696031,0.9622458857696031,0.9622458857696031,0.9612778315585673,0.9612778315585673,0.9603097773475314,0.9593417231364957,0.9593417231364957,0.9583736689254598,0.957405614714424,0.957405614714424,0.957405614714424,0.957405614714424,0.957405614714424,0.9564375605033882,0.9564375605033882,0.9554695062923524,0.9554695062923524,0.9554695062923524,0.9554695062923524,0.9554695062923524,0.9554695062923524,0.9554695062923524,0.9554695062923524,0.9554695062923524,0.9554695062923524,0.9554695062923524,0.9554695062923524,0.9554695062923524,0.9554695062923524,0.9545014520813165,0.9545014520813165,0.9535333978702807,0.9535333978702807,0.9535333978702807,0.952565343659245,0.9515972894482091,0.9515972894482091,0.9506292352371732,0.9496611810261375,0.9486931268151017,0.9477250726040658,0.9477250726040658,0.9477250726040658,0.9467570183930301,0.9467570183930301,0.9457889641819942,0.9448209099709584,0.9438528557599225,0.9428848015488868,0.9428848015488868,0.9428848015488868,0.9419167473378509,0.9419167473378509,0.9419167473378509,0.9419167473378509,0.9409486931268151,0.9399806389157793,0.9399806389157793,0.9399806389157793,0.9399806389157793,0.9390125847047435,0.9390125847047435,0.9380445304937076,0.9380445304937076,0.9380445304937076,0.9380445304937076,0.9370764762826719,0.9370764762826719,0.936108422071636,0.936108422071636,0.936108422071636,0.9351403678606002,0.9351403678606002,0.9351403678606002,0.9351403678606002,0.9341723136495643,0.9332042594385286,0.9322362052274927,0.9322362052274927,0.9322362052274927,0.9322362052274927,0.9312681510164569,0.9303000968054211,0.9303000968054211,0.9293320425943853,0.9283639883833494,0.9283639883833494,0.9273959341723137,0.9264278799612778,0.925459825750242,0.925459825750242,0.925459825750242,0.925459825750242,0.9244917715392061,0.9235237173281704,0.9235237173281704,0.9235237173281704,0.9225556631171346,0.9225556631171346,0.9225556631171346,0.9215876089060987,0.9215876089060987,0.920619554695063,0.9196515004840271,0.9186834462729913,0.9177153920619555,0.9167473378509197,0.9157792836398838,0.914811229428848,0.914811229428848,0.914811229428848,0.9138431752178122,0.9128751210067764,0.9119070667957405,0.9109390125847048,0.9109390125847048,0.9109390125847048,0.9099709583736689,0.9099709583736689,0.9090029041626331,0.9090029041626331,0.9080348499515973,0.9080348499515973,0.9070667957405615,0.9060987415295256,0.9051306873184899,0.904162633107454,0.9031945788964182,0.9022265246853823,0.9022265246853823,0.9012584704743466,0.9012584704743466,0.9002904162633107,0.8993223620522749,0.8983543078412392,0.8973862536302033,0.8964181994191674,0.8954501452081317,0.8954501452081317,0.8944820909970959,0.89351403678606,0.89351403678606,0.89351403678606,0.89351403678606,0.89351403678606,0.89351403678606,0.89351403678606,0.89351403678606,0.8925459825750242,0.8915779283639884,0.8906098741529526,0.8906098741529526,0.8896418199419167,0.8896418199419167,0.8896418199419167,0.8896418199419167,0.8896418199419167,0.888673765730881,0.888673765730881,0.8877057115198451,0.8867376573088093,0.8857696030977735,0.8848015488867377,0.8838334946757018,0.882865440464666,0.8818973862536302,0.8809293320425944,0.8799612778315585,0.8799612778315585,0.8799612778315585,0.8789932236205228,0.8789932236205228,0.8780251694094869,0.8770571151984511,0.8770571151984511,0.8770571151984511,0.8770571151984511,0.8770571151984511,0.8770571151984511,0.8760890609874153,0.8760890609874153,0.8751210067763795,0.8741529525653436,0.8731848983543078,0.8731848983543078,0.8731848983543078,0.8731848983543078,0.8731848983543078,0.872216844143272,0.872216844143272,0.8712487899322362,0.8702807357212003,0.8693126815101646,0.8683446272991288,0.8683446272991288,0.8673765730880929,0.8673765730880929,0.8664085188770572,0.8664085188770572,0.8654404646660213,0.8654404646660213,0.8644724104549855,0.8635043562439496,0.8625363020329139,0.861568247821878,0.8606001936108422,0.8596321393998064,0.8586640851887706,0.8576960309777347,0.856727976766699,0.8557599225556631,0.8557599225556631,0.8547918683446273,0.8547918683446273,0.8547918683446273,0.8547918683446273,0.8538238141335914,0.8528557599225557,0.8528557599225557,0.8518877057115198,0.8518877057115198,0.8518877057115198,0.850919651500484,0.8499515972894482,0.8499515972894482,0.8489835430784124,0.8480154888673765,0.8480154888673765,0.8480154888673765,0.8470474346563408,0.846079380445305,0.846079380445305,0.8451113262342691,0.8441432720232332,0.8441432720232332,0.8441432720232332,0.8431752178121975,0.8431752178121975,0.8422071636011617,0.8422071636011617,0.8422071636011617,0.8422071636011617,0.8422071636011617,0.8422071636011617,0.8422071636011617,0.8422071636011617,0.8422071636011617,0.8412391093901258,0.8412391093901258,0.8402710551790901,0.8393030009680542,0.8393030009680542,0.8383349467570184,0.8383349467570184,0.8373668925459826,0.8373668925459826,0.8373668925459826,0.8363988383349468,0.8354307841239109,0.8344627299128751,0.8334946757018393,0.8325266214908035,0.8325266214908035,0.8315585672797676,0.8315585672797676,0.8315585672797676,0.8305905130687319,0.829622458857696,0.8286544046466602,0.8286544046466602,0.8286544046466602,0.8286544046466602,0.8276863504356244,0.8276863504356244,0.8276863504356244,0.8267182962245886,0.8257502420135527,0.8247821878025169,0.8238141335914811,0.8228460793804453,0.8218780251694094,0.8218780251694094,0.8218780251694094,0.8209099709583737,0.8199419167473379,0.8199419167473379,0.818973862536302,0.8180058083252663,0.8170377541142304,0.8160696999031946,0.8151016456921588,0.8151016456921588,0.814133591481123,0.8131655372700871,0.8131655372700871,0.8121974830590513,0.8112294288480155,0.8102613746369797,0.8102613746369797,0.8092933204259438,0.8092933204259438,0.8092933204259438,0.8083252662149081,0.8073572120038722,0.8073572120038722,0.8063891577928364,0.8054211035818006,0.8044530493707648,0.8044530493707648,0.8044530493707648,0.8034849951597289,0.8025169409486931,0.8015488867376573,0.8005808325266215,0.7996127783155856,0.7996127783155856,0.7986447241045499,0.7986447241045499,0.797676669893514,0.797676669893514,0.797676669893514,0.797676669893514,0.7967086156824782,0.7957405614714425,0.7947725072604066,0.7938044530493708,0.7928363988383349,0.7918683446272992,0.7909002904162633,0.7899322362052275,0.7889641819941917,0.7889641819941917,0.7879961277831559,0.78702807357212,0.7860600193610843,0.7850919651500484,0.7850919651500484,0.7850919651500484,0.7850919651500484,0.7841239109390126,0.7831558567279767,0.7831558567279767,0.782187802516941,0.782187802516941,0.7812197483059051,0.7802516940948693,0.7792836398838335,0.7783155856727977,0.7773475314617618,0.7763794772507261,0.7754114230396902,0.7744433688286544,0.7734753146176185,0.7734753146176185,0.7734753146176185,0.7725072604065828,0.7725072604065828,0.771539206195547,0.7705711519845111,0.7696030977734754,0.7686350435624395,0.7676669893514037,0.7666989351403679,0.7657308809293321,0.7647628267182962,0.7647628267182962,0.7637947725072604,0.7637947725072604,0.7628267182962246,0.7628267182962246,0.7618586640851888,0.7618586640851888,0.7608906098741529,0.7599225556631172,0.7589545014520813,0.7579864472410455,0.7570183930300097,0.7560503388189739,0.755082284607938,0.7541142303969022,0.7531461761858664,0.7521781219748306,0.7521781219748306,0.7512100677637947,0.750242013552759,0.7492739593417231,0.7483059051306873,0.7473378509196515,0.7463697967086157,0.7454017424975798,0.744433688286544,0.7434656340755083,0.7424975798644724,0.7415295256534365,0.7405614714424008,0.739593417231365,0.7386253630203291,0.7376573088092934,0.7366892545982575,0.7366892545982575,0.7366892545982575,0.7357212003872217,0.7357212003872217,0.7347531461761858,0.7347531461761858,0.7337850919651501,0.7328170377541142,0.7328170377541142,0.7318489835430784,0.7318489835430784,0.7308809293320426,0.7299128751210068,0.7289448209099709,0.7279767666989352,0.7279767666989352,0.7279767666989352,0.7270087124878993,0.7260406582768635,0.7250726040658277,0.7241045498547919,0.7241045498547919,0.723136495643756,0.7221684414327202,0.7212003872216844,0.7202323330106486,0.7192642787996127,0.7192642787996127,0.718296224588577,0.7173281703775412,0.7163601161665053,0.7153920619554696,0.7153920619554696,0.7144240077444337,0.7134559535333979,0.712487899322362,0.7115198451113263,0.7115198451113263,0.7105517909002904,0.7095837366892546,0.7086156824782188,0.707647628267183,0.7066795740561471,0.7057115198451114,0.7047434656340755,0.7037754114230397,0.7028073572120038,0.7018393030009681,0.7008712487899322,0.7008712487899322,0.6999031945788964,0.6999031945788964,0.6989351403678606,0.6979670861568248,0.6969990319457889,0.6960309777347532,0.6950629235237173,0.6940948693126815,0.6940948693126815,0.6931268151016456,0.6931268151016456,0.6931268151016456,0.6921587608906099,0.6921587608906099,0.691190706679574,0.6902226524685382,0.6892545982575025,0.6882865440464666,0.6882865440464666,0.6873184898354308,0.686350435624395,0.6853823814133592,0.6844143272023233,0.6834462729912875,0.6834462729912875,0.6824782187802517,0.6815101645692159,0.6815101645692159,0.68054211035818,0.6795740561471443,0.6786060019361084,0.6776379477250726,0.6766698935140368,0.675701839303001,0.675701839303001,0.6747337850919651,0.6737657308809293,0.6727976766698935,0.6718296224588577,0.6708615682478218,0.6698935140367861,0.6689254598257502,0.6679574056147144,0.6669893514036787,0.6660212971926428,0.665053242981607,0.6640851887705711,0.6631171345595354,0.6621490803484995,0.6611810261374637,0.6611810261374637,0.6602129719264279,0.6592449177153921,0.6592449177153921,0.6592449177153921,0.6582768635043562,0.6573088092933205,0.6563407550822846,0.6553727008712488,0.6544046466602129,0.6534365924491772,0.6524685382381413,0.6515004840271055,0.6505324298160697,0.6495643756050339,0.648596321393998,0.648596321393998,0.6476282671829623,0.6466602129719264,0.6456921587608906,0.6447241045498547,0.643756050338819,0.6427879961277831,0.6418199419167473,0.6408518877057116,0.6398838334946757,0.6389157792836399,0.6379477250726041,0.6369796708615683,0.6360116166505324,0.6350435624394967,0.6350435624394967,0.6340755082284608,0.633107454017425,0.6321393998063891,0.6321393998063891,0.6311713455953534,0.6311713455953534,0.6302032913843175,0.6292352371732817,0.6292352371732817,0.6282671829622459,0.6272991287512101,0.6263310745401742,0.6253630203291385,0.6243949661181026,0.6234269119070668,0.6234269119070668,0.6224588576960309,0.6214908034849952,0.6214908034849952,0.6214908034849952,0.6205227492739593,0.6195546950629235,0.6185866408518877,0.6176185866408519,0.616650532429816,0.6156824782187803,0.6147144240077445,0.6137463697967086,0.6127783155856728,0.611810261374637,0.6108422071636012,0.6098741529525653,0.6089060987415296,0.6079380445304937,0.6069699903194579,0.6060019361084221,0.6050338818973863,0.6040658276863504,0.6030977734753146,0.6030977734753146,0.6021297192642788,0.601161665053243,0.6001936108422071,0.5992255566311714,0.5992255566311714,0.5982575024201355,0.5972894482090997,0.5963213939980639,0.5953533397870281,0.5953533397870281,0.5943852855759922,0.5943852855759922,0.5934172313649564,0.5924491771539206,0.5914811229428848,0.590513068731849,0.5895450145208132,0.5885769603097774,0.5876089060987415,0.5866408518877058,0.5866408518877058,0.5856727976766699,0.5847047434656341,0.5837366892545982,0.5818005808325266,0.5808325266214908,0.5808325266214908,0.579864472410455,0.5788964181994192,0.5779283639883833,0.5769603097773476,0.5759922555663117,0.5750242013552759,0.57405614714424,0.57405614714424,0.5730880929332043,0.5721200387221684,0.5721200387221684,0.5711519845111326,0.5701839303000968,0.569215876089061,0.5682478218780251,0.5672797676669894,0.5663117134559535,0.5653436592449177,0.5643756050338818,0.5634075508228461,0.5624394966118103,0.5614714424007744,0.5605033881897387,0.5595353339787028,0.558567279767667,0.5575992255566312,0.5566311713455954,0.5556631171345595,0.5546950629235237,0.5537270087124879,0.5527589545014521,0.5527589545014521,0.5517909002904162,0.5517909002904162,0.5508228460793805,0.5498547918683446,0.5488867376573088,0.547918683446273,0.5469506292352372,0.5459825750242013,0.5450145208131656,0.5440464666021297,0.5430784123910939,0.542110358180058,0.5411423039690223,0.5401742497579864,0.5401742497579864,0.5392061955469506,0.5382381413359149,0.5382381413359149,0.537270087124879,0.5363020329138432,0.5353339787028074,0.5343659244917716,0.5333978702807357,0.5324298160696999,0.5314617618586641,0.5304937076476283,0.5295256534365924,0.5285575992255567,0.5275895450145208,0.526621490803485,0.5256534365924492,0.5246853823814134,0.5246853823814134,0.5237173281703775,0.5227492739593417,0.5217812197483059,0.5208131655372701,0.5198451113262342,0.5188770571151985,0.5179090029041626,0.5169409486931268,0.515972894482091,0.5150048402710552,0.5140367860600193,0.5130687318489835,0.5121006776379478,0.5111326234269119,0.510164569215876,0.5091965150048403,0.5082284607938045,0.5072604065827686,0.5062923523717329,0.505324298160697,0.5043562439496612,0.5033881897386253,0.5024201355275896,0.5014520813165537,0.5004840271055179,0.4995159728944821,0.4985479186834463,0.4975798644724105,0.49661181026137463,0.49564375605033884,0.494675701839303,0.4937076476282672,0.4927395934172314,0.49177153920619554,0.49080348499515974,0.4898354307841239,0.4888673765730881,0.4878993223620523,0.4878993223620523,0.48693126815101645,0.48596321393998065,0.4849951597289448,0.484027105517909,0.4830590513068732,0.48209099709583736,0.48112294288480156,0.4801548886737657,0.4791868344627299,0.4782187802516941,0.47725072604065827,0.4762826718296225,0.4762826718296225,0.4753146176185866,0.4743465634075508,0.47337850919651503,0.4724104549854792,0.4714424007744434,0.47047434656340753,0.46950629235237173,0.46853823814133594,0.4675701839303001,0.4666021297192643,0.46563407550822844,0.46466602129719264,0.46466602129719264,0.46369796708615685,0.462729912875121,0.4617618586640852,0.46079380445304935,0.45982575024201355,0.45885769603097776,0.4578896418199419,0.4569215876089061,0.45595353339787026,0.45498547918683446,0.45401742497579867,0.4530493707647628,0.452081316553727,0.45111326234269117,0.45014520813165537,0.4491771539206196,0.4482090997095837,0.44724104549854793,0.4462729912875121,0.4453049370764763,0.4443368828654405,0.44336882865440463,0.44240077444336884,0.441432720232333,0.4404646660212972,0.4394966118102614,0.43852855759922554,0.43756050338818975,0.4365924491771539,0.4356243949661181,0.4346563407550823,0.43368828654404645,0.43272023233301066,0.4317521781219748,0.430784123910939,0.4298160696999032,0.42884801548886736,0.42787996127783157,0.4269119070667957,0.4259438528557599,0.4249757986447241,0.42400774443368827,0.4230396902226525,0.4230396902226525,0.4220716360116166,0.42110358180058083,0.42013552758954503,0.4191674733785092,0.4181994191674734,0.41723136495643753,0.41626331074540174,0.41529525653436594,0.4143272023233301,0.4133591481122943,0.41239109390125844,0.41142303969022265,0.41045498547918685,0.409486931268151,0.4085188770571152,0.4085188770571152,0.4075508228460794,0.40658276863504356,0.40561471442400776,0.4046466602129719,0.4036786060019361,0.4036786060019361,0.4027105517909003,0.40174249757986447,0.40077444336882867,0.3998063891577928,0.398838334946757,0.3978702807357212,0.3969022265246854,0.3959341723136496,0.39496611810261373,0.39399806389157793,0.39303000968054214,0.3920619554695063,0.3910939012584705,0.39012584704743464,0.38915779283639884,0.38818973862536305,0.3872216844143272,0.3862536302032914,0.38528557599225555,0.38431752178121975,0.38334946757018395,0.3823814133591481,0.3814133591481123,0.38044530493707646,0.37947725072604066,0.37850919651500486,0.377541142303969,0.3765730880929332,0.37560503388189737,0.37560503388189737,0.37463697967086157,0.3736689254598258,0.3727008712487899,0.3717328170377541,0.3707647628267183,0.3707647628267183,0.3697967086156825,0.3688286544046467,0.3688286544046467,0.36786060019361083,0.36689254598257504,0.3659244917715392,0.3649564375605034,0.3639883833494676,0.36302032913843174,0.36205227492739595,0.3610842207163601,0.3610842207163601,0.3601161665053243,0.3591481122942885,0.35818005808325265,0.35721200387221685,0.356243949661181,0.3552758954501452,0.3543078412391094,0.35333978702807356,0.35237173281703776,0.3514036786060019,0.3514036786060019,0.3504356243949661,0.3494675701839303,0.34849951597289447,0.3475314617618587,0.3465634075508228,0.345595353339787,0.34462729912875123,0.3436592449177154,0.3426911907066796,0.34172313649564373,0.34075508228460794,0.33978702807357214,0.3388189738625363,0.3378509196515005,0.33688286544046464,0.33591481122942884,0.33494675701839305,0.3339787028073572,0.3339787028073572,0.3330106485963214,0.33204259438528555,0.33107454017424975,0.33010648596321396,0.3291384317521781,0.3281703775411423,0.32720232333010646,0.32720232333010646,0.32623426911907066,0.32526621490803487,0.324298160696999,0.3233301064859632,0.32236205227492737,0.3213939980638916,0.3204259438528558,0.3194578896418199,0.31848983543078413,0.31752178121974833,0.3165537270087125,0.3155856727976767,0.31461761858664083,0.31461761858664083,0.31364956437560504,0.31268151016456924,0.3117134559535334,0.3107454017424976,0.30977734753146174,0.30880929332042595,0.30784123910939015,0.3068731848983543,0.3059051306873185,0.30493707647628265,0.30396902226524686,0.30300096805421106,0.3020329138431752,0.3010648596321394,0.30009680542110356,0.29912875121006777,0.29816069699903197,0.2971926427879961,0.2962245885769603,0.2952565343659245,0.2942884801548887,0.2933204259438529,0.29235237173281703,0.29138431752178123,0.2904162633107454,0.2894482090997096,0.2884801548886738,0.28751210067763794,0.28654404646660214,0.2855759922555663,0.2846079380445305,0.2846079380445305,0.2836398838334947,0.28267182962245885,0.28170377541142305,0.2807357212003872,0.2797676669893514,0.2787996127783156,0.27783155856727976,0.27686350435624396,0.2758954501452081,0.2749273959341723,0.2739593417231365,0.27299128751210067,0.27202323330106487,0.271055179090029,0.2700871248789932,0.2691190706679574,0.2681510164569216,0.2671829622458858,0.26621490803484993,0.26524685382381413,0.26427879961277834,0.2633107454017425,0.2623426911907067,0.26137463697967084,0.26040658276863504,0.25943852855759925,0.2584704743465634,0.2575024201355276,0.25653436592449175,0.25556631171345595,0.25459825750242016,0.2536302032913843,0.2526621490803485,0.25169409486931266,0.25072604065827686,0.24975798644724104,0.24878993223620524,0.24782187802516942,0.2468538238141336,0.24588576960309777,0.24491771539206195,0.24394966118102615,0.24298160696999033,0.2420135527589545,0.24104549854791868,0.24007744433688286,0.23910939012584706,0.23814133591481124,0.2371732817037754,0.2362052274927396,0.23523717328170377,0.23426911907066797,0.23426911907066797,0.23330106485963215,0.23233301064859632,0.2313649564375605,0.23039690222652467,0.22942884801548888,0.22846079380445306,0.22749273959341723,0.2265246853823814,0.22555663117134558,0.2245885769603098,0.22362052274927396,0.22265246853823814,0.22265246853823814,0.22168441432720232,0.2207163601161665,0.2197483059051307,0.21878025169409487,0.21781219748305905,0.21684414327202323,0.2158760890609874,0.2149080348499516,0.21393998063891578,0.21297192642787996,0.21200387221684414,0.2110358180058083,0.21006776379477252,0.2090997095837367,0.20813165537270087,0.20716360116166505,0.20619554695062922,0.20522749273959343,0.2042594385285576,0.20329138431752178,0.20232333010648595,0.20135527589545016,0.20038722168441434,0.1994191674733785,0.1984511132623427,0.19748305905130686,0.19651500484027107,0.19554695062923524,0.19457889641819942,0.1936108422071636,0.19264278799612777,0.19167473378509198,0.19070667957405615,0.18973862536302033,0.1887705711519845,0.18780251694094868,0.1868344627299129,0.18586640851887706,0.18489835430784124,0.18393030009680542,0.1829622458857696,0.1819941916747338,0.18102613746369797,0.18005808325266215,0.17909002904162633,0.1781219748305905,0.1771539206195547,0.17618586640851888,0.17521781219748306,0.17424975798644723,0.1732817037754114,0.17231364956437561,0.1713455953533398,0.17037754114230397,0.16940948693126814,0.16844143272023232,0.16747337850919652,0.1665053242981607,0.16553727008712488,0.16553727008712488,0.16456921587608905,0.16360116166505323,0.16263310745401743,0.1616650532429816,0.1606969990319458,0.15972894482090996,0.15876089060987417,0.15779283639883834,0.15682478218780252,0.1558567279767667,0.15488867376573087,0.15392061955469508,0.15295256534365925,0.15198451113262343,0.1510164569215876,0.15004840271055178,0.14908034849951599,0.14811229428848016,0.14714424007744434,0.14617618586640851,0.1452081316553727,0.1442400774443369,0.14327202323330107,0.14230396902226525,0.14133591481122942,0.1403678606001936,0.1393998063891578,0.13843175217812198,0.13746369796708616,0.13649564375605033,0.1355275895450145,0.1345595353339787,0.1335914811229429,0.13262342691190707,0.13165537270087124,0.13068731848983542,0.12971926427879962,0.1287512100677638,0.12778315585672798,0.12681510164569215,0.12584704743465633,0.12487899322362052,0.12391093901258471,0.12294288480154889,0.12197483059051308,0.12100677637947725,0.12003872216844143,0.11907066795740562,0.1181026137463698,0.11713455953533398,0.11616650532429816,0.11519845111326234,0.11423039690222653,0.1132623426911907,0.1122942884801549,0.11132623426911907,0.11035818005808325,0.10939012584704744,0.10842207163601161,0.1074540174249758,0.10648596321393998,0.10551790900290416,0.10454985479186835,0.10454985479186835,0.10358180058083252,0.10261374636979671,0.10164569215876089,0.10164569215876089,0.10067763794772508,0.09970958373668926,0.09874152952565343,0.09777347531461762,0.0968054211035818,0.09583736689254599,0.09583736689254599,0.09486931268151017,0.09390125847047434,0.09293320425943853,0.09196515004840271,0.0909970958373669,0.09002904162633107,0.08906098741529525,0.08809293320425944,0.08712487899322362,0.08615682478218781,0.08518877057115198,0.08422071636011616,0.08325266214908035,0.08228460793804453,0.08131655372700872,0.0803484995159729,0.07938044530493708,0.07841239109390126,0.07744433688286544,0.07647628267182963,0.0755082284607938,0.07454017424975799,0.07357212003872217,0.07260406582768635,0.07163601161665054,0.07066795740561471,0.0696999031945789,0.06873184898354308,0.06776379477250725,0.06679574056147145,0.06582768635043562,0.06485963213939981,0.06389157792836399,0.06292352371732816,0.061955469506292354,0.061955469506292354,0.06098741529525654,0.060019361084220714,0.0590513068731849,0.05808325266214908,0.057115198451113264,0.05614714424007745,0.05517909002904162,0.05421103581800581,0.05324298160696999,0.05227492739593417,0.051306873184898356,0.05033881897386254,0.049370764762826716,0.0484027105517909,0.04743465634075508,0.046466602129719266,0.04549854791868345,0.044530493707647625,0.04356243949661181,0.04259438528557599,0.041626331074540175,0.04065827686350436,0.03969022265246854,0.03872216844143272,0.0377541142303969,0.036786060019361085,0.03581800580832527,0.03484995159728945,0.03388189738625363,0.03291384317521781,0.031945788964181994,0.031945788964181994,0.030977734753146177,0.030009680542110357,0.02904162633107454,0.028073572120038724,0.027105517909002903,0.026137463697967087,0.02516940948693127,0.02420135527589545,0.023233301064859633,0.022265246853823813,0.021297192642787996,0.02032913843175218,0.01936108422071636,0.018393030009680542,0.017424975798644726,0.016456921587608905,0.015488867376573089,0.01452081316553727,0.013552758954501452,0.012584704743465635,0.011616650532429816,0.010648596321393998,0.00968054211035818,0.008712487899322363,0.007744433688286544,0.006776379477250726,0.005808325266214908,0.00484027105517909,0.003872216844143272,0.002904162633107454,0.001936108422071636,0.000968054211035818,0],"xaxis":"x","y":[0.7341862117981521,0.7347083926031295,0.7352313167259786,0.7357549857549858,0.7362794012829651,0.7368045649072753,0.7373304782298359,0.7371428571428571,0.7376697641172266,0.7381974248927039,0.7387258410880458,0.7392550143266475,0.7397849462365591,0.7403156384505022,0.7408470926058865,0.7413793103448276,0.7419122933141624,0.7424460431654676,0.7429805615550756,0.7435158501440923,0.7440519105984138,0.7445887445887446,0.7444043321299639,0.744942196531792,0.7454808387563269,0.7460202604920405,0.7458363504706734,0.7463768115942029,0.7469180565627266,0.7474600870827286,0.7480029048656499,0.748546511627907,0.7490909090909091,0.7496360989810772,0.7501820830298617,0.750728862973761,0.75127644055434,0.7518248175182481,0.7523739956172388,0.7529239766081871,0.7527432333577176,0.753294289897511,0.7538461538461538,0.7543988269794721,0.7549523110785032,0.7555066079295154,0.7560617193240264,0.7558823529411764,0.7564385577630611,0.7569955817378498,0.7575534266764923,0.7581120943952803,0.7579335793357933,0.757754800590842,0.7583148558758315,0.7588757396449705,0.7586972612879349,0.7592592592592593,0.759822090437361,0.7603857566765578,0.7609502598366741,0.7615156017830609,0.7620817843866171,0.7626488095238095,0.763216679076694,0.763785394932936,0.7636092468307233,0.764179104477612,0.7647498132935027,0.7653213751868461,0.7651458489154824,0.7657185628742516,0.7662921348314606,0.7668665667166417,0.7666916729182296,0.7672672672672672,0.7678437265214124,0.7684210526315789,0.7689992475545523,0.7695783132530121,0.7701582516955539,0.770739064856712,0.7705660377358491,0.7711480362537765,0.7709750566893424,0.7715582450832073,0.7721423164269493,0.7727272727272727,0.7725549658832449,0.7731411229135053,0.7737281700835231,0.7743161094224924,0.7741444866920152,0.7747336377473364,0.7753236862147753,0.7751524390243902,0.7757437070938215,0.7763358778625954,0.7769289533995416,0.7775229357798165,0.7781178270849273,0.7787136294027565,0.7793103448275862,0.7799079754601227,0.7805065234075211,0.7811059907834101,0.781706379707917,0.7823076923076923,0.7829099307159353,0.7827426810477658,0.7825751734772552,0.7824074074074074,0.783011583011583,0.7836166924265843,0.7842227378190255,0.7840557275541795,0.7846630518977536,0.7852713178294574,0.7851047323506595,0.7857142857142857,0.7863247863247863,0.7869362363919129,0.7875486381322957,0.7881619937694704,0.7887763055339049,0.7893915756630265,0.790007806401249,0.78984375,0.7904612978889758,0.7910798122065728,0.7916992952231793,0.792319749216301,0.792156862745098,0.792778649921507,0.793401413982718,0.7932389937106918,0.7930763178599528,0.7937007874015748,0.7943262411347518,0.7941640378548895,0.7940015785319653,0.7938388625592417,0.7936758893280632,0.7943037974683544,0.7941409342834521,0.7939778129952456,0.7938144329896907,0.7936507936507936,0.7934868943606036,0.7941176470588235,0.7947494033412887,0.7953821656050956,0.7960159362549801,0.79585326953748,0.7964884277733439,0.7971246006389776,0.7977617905675459,0.7976,0.7982385908726981,0.7988782051282052,0.7995188452285485,0.8001605136436597,0.8008032128514057,0.8014469453376206,0.8012872083668544,0.8019323671497585,0.8025785656728445,0.8032258064516129,0.8038740920096852,0.8045234248788369,0.8051738075990299,0.8058252427184466,0.805668016194332,0.8063209076175041,0.8069748580697486,0.8076298701298701,0.8082859463850528,0.808130081300813,0.8087876322213181,0.8094462540716613,0.8101059494702526,0.8099510603588908,0.8106122448979591,0.8104575163398693,0.8103025347506132,0.8109656301145662,0.8108108108108109,0.8106557377049181,0.8113207547169812,0.8119868637110016,0.8126540673788003,0.8133223684210527,0.8131687242798354,0.8138385502471169,0.8136850783182193,0.8143564356435643,0.815028901734104,0.815702479338843,0.8163771712158809,0.8170529801324503,0.8177299088649544,0.818407960199005,0.8190871369294606,0.8197674418604651,0.8204488778054863,0.8211314475873545,0.8218151540383014,0.8225,0.8223519599666389,0.8230383973288815,0.822890559732665,0.8235785953177257,0.8242677824267782,0.8241206030150754,0.8239731768650461,0.8246644295302014,0.8245172124265323,0.8243697478991596,0.8242220353238016,0.8240740740740741,0.8247683235046336,0.8254637436762225,0.8253164556962025,0.8260135135135135,0.8258664412510567,0.8257191201353637,0.825571549534293,0.8254237288135593,0.8261238337574215,0.8268251273344652,0.826677994902294,0.8273809523809523,0.8280851063829787,0.8287904599659285,0.8286445012787724,0.8284982935153583,0.829205807002562,0.82991452991453,0.8306244653550042,0.8304794520547946,0.831191088260497,0.8310463121783876,0.8317596566523605,0.8324742268041238,0.8331900257953568,0.8330464716006885,0.8337639965546942,0.8336206896551724,0.8343399482312338,0.8350604490500864,0.8349178910976663,0.8356401384083045,0.8363636363636363,0.8370883882149047,0.836947094535993,0.8368055555555556,0.8366637706342311,0.837391304347826,0.8381201044386423,0.8388501742160279,0.8387096774193549,0.8385689354275742,0.8393013100436681,0.8391608391608392,0.8390201224846894,0.839754816112084,0.8396143733567046,0.8394736842105263,0.839332748024583,0.8400702987697716,0.8408091468777484,0.8415492957746479,0.8414096916299559,0.8412698412698413,0.8420123565754634,0.842756183745583,0.8426171529619806,0.8433628318584071,0.8441098317094774,0.8439716312056738,0.84472049689441,0.844582593250444,0.8444444444444444,0.844306049822064,0.8441674087266251,0.8440285204991087,0.8438893844781445,0.84375,0.8445040214477212,0.8452593917710197,0.8451208594449419,0.8449820788530465,0.8448430493273542,0.8447037701974865,0.8454627133872417,0.8462230215827338,0.8460846084608461,0.8468468468468469,0.8467087466185753,0.8474729241877257,0.8473351400180669,0.8481012658227848,0.8479638009049774,0.8478260869565217,0.8476881233000907,0.8475499092558983,0.8474114441416893,0.8472727272727273,0.8480436760691538,0.8479052823315119,0.8486782133090246,0.8485401459854015,0.8484018264840183,0.8482632541133455,0.848124428179323,0.847985347985348,0.847846012832264,0.8486238532110092,0.8484848484848485,0.8483455882352942,0.8491260349586016,0.8499079189686924,0.8506912442396314,0.8514760147601476,0.8522622345337026,0.8530499075785583,0.8538390379278445,0.8537037037037037,0.8535681186283596,0.8534322820037106,0.8542246982358404,0.854089219330855,0.8548837209302326,0.8556797020484171,0.8564771668219944,0.8572761194029851,0.8571428571428571,0.8579439252336448,0.8578110383536015,0.8576779026217228,0.8575445173383318,0.8574108818011257,0.8572769953051643,0.8571428571428571,0.8570084666039511,0.8568738229755178,0.8567389255419415,0.8575471698113207,0.8583569405099151,0.8582230623818525,0.859035004730369,0.8589015151515151,0.8587677725118483,0.8595825426944972,0.8603988603988604,0.8612167300380228,0.8620361560418649,0.8628571428571429,0.8627264061010487,0.8635496183206107,0.8634192932187201,0.8632887189292543,0.8631578947368421,0.8639846743295019,0.8648130393096836,0.8656429942418427,0.866474543707973,0.8663461538461539,0.8671799807507219,0.8670520231213873,0.866923818707811,0.8667953667953668,0.8666666666666667,0.867504835589942,0.8673765730880929,0.8682170542635659,0.8680892337536372,0.8689320388349514,0.8688046647230321,0.8696498054474708,0.8695228821811101,0.8693957115009746,0.8692682926829268,0.869140625,0.8690127077223851,0.8688845401174168,0.8687561214495593,0.8686274509803922,0.8684985279685966,0.8683693516699411,0.8692232055063913,0.8690944881889764,0.8699507389162562,0.8708086785009862,0.8716683119447186,0.8715415019762845,0.8714144411473789,0.8722772277227723,0.8721506442021804,0.873015873015873,0.8738828202581926,0.8737574552683897,0.8736318407960199,0.8745019920318725,0.8743768693918246,0.874251497005988,0.8751248751248751,0.876,0.8758758758758759,0.875751503006012,0.876629889669007,0.8765060240963856,0.8763819095477386,0.8772635814889336,0.878147029204431,0.8780241935483871,0.8789101917255298,0.8787878787878788,0.8796764408493428,0.8805668016194332,0.8814589665653495,0.8823529411764706,0.883248730964467,0.8841463414634146,0.8850457782299085,0.8859470468431772,0.8858307849133538,0.886734693877551,0.8866189989785496,0.8865030674846626,0.887410440122825,0.8872950819672131,0.8882051282051282,0.8880903490759754,0.8890030832476875,0.8899176954732511,0.8898043254376931,0.8896907216494845,0.8895768833849329,0.8894628099173554,0.889348500517063,0.8902691511387164,0.8901554404145078,0.8910788381742739,0.8920041536863966,0.8918918918918919,0.8917793964620188,0.8916666666666667,0.8925964546402503,0.8935281837160751,0.8944618599791013,0.8943514644351465,0.8952879581151832,0.8962264150943396,0.8961175236096537,0.8960084033613446,0.8958990536277602,0.8957894736842106,0.8956796628029505,0.8955696202531646,0.8965153115100317,0.8974630021141649,0.8973544973544973,0.8972457627118644,0.8981972428419936,0.8980891719745223,0.89798087141339,0.8978723404255319,0.8977635782747604,0.8976545842217484,0.8986125933831377,0.8985042735042735,0.8983957219251337,0.8993576017130621,0.8992497320471597,0.8991416309012875,0.8990332975295381,0.9,0.8998923573735199,0.9008620689655172,0.9018338727076591,0.9017278617710583,0.9016216216216216,0.9025974025974026,0.9024918743228603,0.9023861171366594,0.9022801302931596,0.9032608695652173,0.9042437431991295,0.9041394335511983,0.9040348964013086,0.9039301310043668,0.9038251366120219,0.9037199124726477,0.904709748083242,0.9046052631578947,0.9055982436882547,0.9054945054945055,0.9064906490649065,0.9074889867841409,0.9084895259095921,0.9083885209713024,0.9082872928176795,0.9081858407079646,0.9080841638981174,0.9079822616407982,0.9078801331853497,0.9077777777777778,0.9076751946607341,0.9075723830734966,0.9085841694537347,0.9084821428571429,0.9083798882681564,0.9082774049217002,0.9081746920492721,0.9091928251121076,0.9102132435465768,0.9112359550561798,0.9111361079865017,0.911036036036036,0.9120631341600902,0.9119638826185101,0.9129943502824859,0.9128959276018099,0.912797281993205,0.9126984126984127,0.9125993189557321,0.9125,0.9124004550625711,0.9123006833712984,0.9122006841505131,0.9121004566210046,0.9131428571428571,0.914187643020595,0.9140893470790378,0.9151376146788991,0.9150401836969001,0.9149425287356322,0.9148446490218642,0.9147465437788018,0.9146482122260668,0.9145496535796767,0.9144508670520232,0.9143518518518519,0.9154113557358053,0.9153132250580046,0.9163763066202091,0.9162790697674419,0.9173457508731082,0.9172494172494172,0.9183197199533255,0.9182242990654206,0.9181286549707602,0.9180327868852459,0.917936694021102,0.9178403755868545,0.917743830787309,0.9176470588235294,0.917550058892815,0.9174528301886793,0.9173553719008265,0.9184397163120568,0.9183431952662722,0.9182464454976303,0.9181494661921709,0.9180522565320665,0.9179548156956004,0.9178571428571428,0.9177592371871275,0.9176610978520287,0.9175627240143369,0.9174641148325359,0.9173652694610779,0.9172661870503597,0.9171668667466987,0.9170673076923077,0.9169675090252708,0.9168674698795181,0.9179734620024126,0.9190821256038647,0.9189842805320435,0.9200968523002422,0.92,0.9211165048543689,0.9210206561360875,0.9209245742092458,0.9220462850182704,0.9219512195121952,0.9230769230769231,0.9229828850855746,0.9228886168910648,0.9227941176470589,0.9226993865030675,0.9238329238329238,0.9249692496924969,0.9248768472906403,0.9247842170160296,0.9246913580246914,0.9245982694684796,0.9257425742574258,0.9256505576208178,0.9255583126550868,0.9254658385093167,0.9253731343283582,0.925280199252802,0.92643391521197,0.9263420724094882,0.92625,0.9261576971214017,0.9260651629072681,0.9272271016311167,0.9271356783919598,0.9270440251572327,0.9269521410579346,0.926860025220681,0.928030303030303,0.9279393173198482,0.9278481012658227,0.9277566539923955,0.9276649746192893,0.9275730622617535,0.9274809160305344,0.9273885350318471,0.9272959183673469,0.9272030651340997,0.9271099744245525,0.9270166453265045,0.9282051282051282,0.9281129653401797,0.929305912596401,0.9292149292149292,0.9291237113402062,0.9290322580645162,0.9289405684754521,0.9288486416558862,0.9287564766839378,0.9299610894941635,0.9298701298701298,0.9310793237971391,0.9322916666666666,0.9322033898305084,0.933420365535248,0.9333333333333333,0.9332460732984293,0.9331585845347313,0.9330708661417323,0.9342969776609724,0.9342105263157895,0.9341238471673254,0.9340369393139841,0.9339498018494056,0.9338624338624338,0.9350993377483444,0.9350132625994695,0.9349269588313412,0.9361702127659575,0.9360852197070573,0.936,0.9359145527369827,0.9358288770053476,0.9357429718875502,0.935656836461126,0.9369127516778524,0.9368279569892473,0.9367429340511441,0.9366576819407008,0.9365721997300944,0.9364864864864865,0.9364005412719891,0.9363143631436315,0.9362279511533242,0.936141304347826,0.9360544217687075,0.9359673024523161,0.9358799454297408,0.9357923497267759,0.9357045143638851,0.9356164383561644,0.9368998628257887,0.9368131868131868,0.936726272352132,0.9380165289256198,0.9393103448275862,0.9392265193370166,0.9391424619640387,0.9390581717451524,0.9389736477115118,0.9388888888888889,0.9388038942976356,0.9387186629526463,0.9386331938633193,0.9385474860335196,0.9384615384615385,0.938375350140056,0.9396914446002805,0.9396067415730337,0.939521800281294,0.9394366197183098,0.9393511988716502,0.9392655367231638,0.9391796322489392,0.9390934844192634,0.9390070921985816,0.9389204545454546,0.9388335704125178,0.9387464387464387,0.9386590584878745,0.9385714285714286,0.9384835479256081,0.9398280802292264,0.93974175035868,0.9396551724137931,0.939568345323741,0.9409221902017291,0.9408369408369408,0.9421965317919075,0.9421128798842258,0.9420289855072463,0.9433962264150944,0.9433139534883721,0.9432314410480349,0.9431486880466472,0.9430656934306569,0.9429824561403509,0.9428989751098097,0.9442815249266863,0.9441997063142438,0.9441176470588235,0.9455081001472754,0.9469026548672567,0.946824224519941,0.9467455621301775,0.9466666666666667,0.9465875370919882,0.9465081723625557,0.9464285714285714,0.9463487332339792,0.9462686567164179,0.9461883408071748,0.9461077844311377,0.9460269865067467,0.9459459459459459,0.9458646616541353,0.9457831325301205,0.9457013574660633,0.945619335347432,0.9455370650529501,0.9454545454545454,0.9453717754172989,0.9468085106382979,0.9467275494672754,0.9466463414634146,0.9465648854961832,0.9464831804281345,0.9479326186830015,0.9478527607361963,0.9477726574500768,0.9476923076923077,0.9476117103235747,0.9490740740740741,0.9489953632148377,0.9504643962848297,0.9503875968992248,0.9503105590062112,0.9502332814930016,0.9501557632398754,0.9500780031201248,0.95,0.9499217527386542,0.9498432601880877,0.9513343799058085,0.9512578616352201,0.9511811023622048,0.9511041009463722,0.9509493670886076,0.9508716323296355,0.9523809523809523,0.9523052464228935,0.9522292993630573,0.9521531100478469,0.952076677316294,0.952,0.9519230769230769,0.9518459069020867,0.9533762057877814,0.9533011272141707,0.9532258064516129,0.9547657512116317,0.9546925566343042,0.9546191247974068,0.9545454545454546,0.9544715447154472,0.9543973941368078,0.9543230016313213,0.954248366013072,0.9541734860883797,0.9540983606557377,0.9540229885057471,0.9539473684210527,0.9538714991762768,0.9537953795379538,0.9537190082644628,0.9536423841059603,0.9535655058043118,0.9534883720930233,0.9534109816971714,0.9533333333333334,0.9532554257095158,0.9548494983277592,0.9547738693467337,0.9563758389261745,0.9563025210084034,0.9562289562289562,0.9561551433389545,0.956081081081081,0.9560067681895094,0.9559322033898305,0.9558573853989814,0.95578231292517,0.9557069846678024,0.9556313993174061,0.9555555555555556,0.9554794520547946,0.9571183533447685,0.9570446735395189,0.9569707401032702,0.9586206896551724,0.9585492227979274,0.9584775086505191,0.9584055459272097,0.9583333333333334,0.9582608695652174,0.9581881533101045,0.9581151832460733,0.958041958041958,0.957968476357268,0.9578947368421052,0.9578207381370826,0.9577464788732394,0.9576719576719577,0.9575971731448764,0.95929203539823,0.9592198581560284,0.9591474245115453,0.9590747330960854,0.9590017825311943,0.9589285714285715,0.9588550983899821,0.9587813620071685,0.9587073608617595,0.9586330935251799,0.9585585585585585,0.9584837545126353,0.9584086799276673,0.9583333333333334,0.9582577132486388,0.9581818181818181,0.9581056466302368,0.958029197080292,0.9579524680073126,0.9578754578754579,0.9577981651376147,0.9577205882352942,0.9576427255985267,0.9575645756457565,0.9574861367837338,0.9574074074074074,0.9573283858998145,0.9572490706319703,0.957169459962756,0.957089552238806,0.9570093457943926,0.9569288389513109,0.9568480300187617,0.956766917293233,0.9566854990583804,0.9566037735849057,0.9565217391304348,0.9564393939393939,0.9563567362428842,0.9581749049429658,0.9580952380952381,0.9580152671755725,0.9579349904397706,0.9578544061302682,0.9577735124760077,0.9576923076923077,0.9576107899807321,0.9575289575289575,0.9574468085106383,0.9573643410852714,0.9572815533980582,0.9571984435797666,0.9590643274853801,0.958984375,0.958904109589041,0.9588235294117647,0.9587426326129665,0.9586614173228346,0.9585798816568047,0.958498023715415,0.9584158415841584,0.9583333333333334,0.9582504970178927,0.9581673306772909,0.9580838323353293,0.96,0.9599198396793587,0.9598393574297188,0.959758551307847,0.9596774193548387,0.9595959595959596,0.9595141700404858,0.9594320486815415,0.959349593495935,0.9592668024439919,0.9591836734693877,0.9591002044989775,0.9590163934426229,0.9589322381930184,0.9588477366255144,0.9587628865979382,0.9586776859504132,0.9585921325051759,0.9585062240663901,0.9584199584199584,0.9583333333333334,0.9582463465553236,0.9581589958158996,0.9580712788259959,0.957983193277311,0.9578947368421052,0.9578059071729957,0.9577167019027484,0.9576271186440678,0.9575371549893843,0.9574468085106383,0.9573560767590619,0.9572649572649573,0.9571734475374732,0.9570815450643777,0.956989247311828,0.9568965517241379,0.9568034557235421,0.9567099567099567,0.9566160520607375,0.9565217391304348,0.9564270152505446,0.9563318777292577,0.9562363238512035,0.9583333333333334,0.9582417582417583,0.9581497797356828,0.9580573951434879,0.9579646017699115,0.9578713968957872,0.9577777777777777,0.9576837416481069,0.9575892857142857,0.9574944071588367,0.9573991031390134,0.9573033707865168,0.9572072072072072,0.9571106094808126,0.9570135746606335,0.9569160997732427,0.9590909090909091,0.958997722095672,0.958904109589041,0.9588100686498856,0.9587155963302753,0.9586206896551724,0.9608294930875576,0.9607390300230947,0.9606481481481481,0.9605568445475638,0.9604651162790697,0.9603729603729604,0.9602803738317757,0.9601873536299765,0.960093896713615,0.96,0.9599056603773585,0.9598108747044918,0.9597156398104265,0.9596199524940617,0.9595238095238096,0.9594272076372315,0.9593301435406698,0.9592326139088729,0.9591346153846154,0.9590361445783132,0.9589371980676329,0.9588377723970944,0.9587378640776699,0.9586374695863747,0.9585365853658536,0.9584352078239609,0.9583333333333334,0.9582309582309583,0.958128078817734,0.9580246913580247,0.9603960396039604,0.9602977667493796,0.9601990049751243,0.9600997506234414,0.96,0.9598997493734336,0.9623115577889447,0.9622166246851386,0.9621212121212122,0.9645569620253165,0.9644670050761421,0.9643765903307888,0.9642857142857143,0.9641943734015346,0.9641025641025641,0.9640102827763496,0.9639175257731959,0.9638242894056848,0.966321243523316,0.9662337662337662,0.9661458333333334,0.9660574412532638,0.9659685863874345,0.9658792650918635,0.9657894736842105,0.9656992084432717,0.9656084656084656,0.9655172413793104,0.9654255319148937,0.968,0.9679144385026738,0.967828418230563,0.967741935483871,0.967654986522911,0.9675675675675676,0.967479674796748,0.967391304347826,0.9673024523160763,0.9672131147540983,0.9671232876712329,0.967032967032967,0.9669421487603306,0.9668508287292817,0.9667590027700831,0.9666666666666667,0.9665738161559888,0.9664804469273743,0.9663865546218487,0.9691011235955056,0.9690140845070423,0.9689265536723164,0.9688385269121813,0.96875,0.9686609686609686,0.9685714285714285,0.9684813753581661,0.9712643678160919,0.9711815561959655,0.9710982658959537,0.9710144927536232,0.9709302325581395,0.9708454810495627,0.9707602339181286,0.9706744868035191,0.9705882352941176,0.9705014749262537,0.9704142011834319,0.9703264094955489,0.9702380952380952,0.9701492537313433,0.9730538922155688,0.972972972972973,0.9728915662650602,0.972809667673716,0.9727272727272728,0.9726443768996961,0.9725609756097561,0.9724770642201835,0.9723926380368099,0.9723076923076923,0.9722222222222222,0.9721362229102167,0.9720496894409938,0.9719626168224299,0.971875,0.9717868338557993,0.9716981132075472,0.9716088328075709,0.9715189873417721,0.9714285714285714,0.9713375796178344,0.9712460063897763,0.9711538461538461,0.9710610932475884,0.9709677419354839,0.970873786407767,0.9707792207792207,0.9706840390879479,0.9705882352941176,0.9704918032786886,0.9703947368421053,0.9702970297029703,0.9735099337748344,0.973421926910299,0.9733333333333334,0.9732441471571907,0.9731543624161074,0.9730639730639731,0.972972972972973,0.9728813559322034,0.9727891156462585,0.9726962457337884,0.9726027397260274,0.9725085910652921,0.9724137931034482,0.972318339100346,0.9722222222222222,0.9721254355400697,0.972027972027972,0.9719298245614035,0.971830985915493,0.9717314487632509,0.9716312056737588,0.9715302491103203,0.9714285714285714,0.9713261648745519,0.9712230215827338,0.9711191335740073,0.9710144927536232,0.9709090909090909,0.9708029197080292,0.9706959706959707,0.9705882352941176,0.9704797047970479,0.9703703703703703,0.9702602230483272,0.9701492537313433,0.9700374531835206,0.9699248120300752,0.969811320754717,0.9696969696969697,0.9695817490494296,0.9694656488549618,0.9693486590038314,0.9692307692307692,0.9691119691119691,0.9689922480620154,0.9688715953307393,0.96875,0.9686274509803922,0.968503937007874,0.9683794466403162,0.9682539682539683,0.9681274900398407,0.968,0.9718875502008032,0.9717741935483871,0.97165991902834,0.9715447154471545,0.9714285714285714,0.9713114754098361,0.9711934156378601,0.9710743801652892,0.970954356846473,0.9708333333333333,0.9707112970711297,0.9705882352941176,0.9704641350210971,0.9745762711864406,0.9744680851063829,0.9743589743589743,0.9742489270386266,0.9741379310344828,0.974025974025974,0.9739130434782609,0.9737991266375546,0.9736842105263158,0.973568281938326,0.9734513274336283,0.9733333333333334,0.9732142857142857,0.9730941704035875,0.972972972972973,0.9728506787330317,0.9727272727272728,0.9726027397260274,0.9724770642201835,0.9723502304147466,0.9722222222222222,0.9720930232558139,0.9719626168224299,0.971830985915493,0.9716981132075472,0.9715639810426541,0.9714285714285714,0.9712918660287081,0.9711538461538461,0.9710144927536232,0.970873786407767,0.9707317073170731,0.9705882352941176,0.9704433497536946,0.9702970297029703,0.9701492537313433,0.97,0.9698492462311558,0.9696969696969697,0.9695431472081218,0.9693877551020408,0.9692307692307692,0.9690721649484536,0.9689119170984456,0.96875,0.9685863874345549,0.968421052631579,0.9682539682539683,0.9680851063829787,0.9679144385026738,0.967741935483871,0.9675675675675676,0.967391304347826,0.9672131147540983,0.967032967032967,0.9668508287292817,0.9666666666666667,0.9664804469273743,0.9662921348314607,0.9661016949152542,0.9715909090909091,0.9714285714285714,0.9712643678160919,0.9710982658959537,0.9709302325581395,0.9707602339181286,0.9705882352941176,0.9704142011834319,0.9702380952380952,0.9700598802395209,0.9698795180722891,0.9696969696969697,0.9695121951219512,0.9693251533742331,0.9691358024691358,0.968944099378882,0.96875,0.9685534591194969,0.9683544303797469,0.9681528662420382,0.967948717948718,0.967741935483871,0.9675324675324676,0.9673202614379085,0.9671052631578947,0.9668874172185431,0.9666666666666667,0.9664429530201343,0.9662162162162162,0.9659863945578231,0.9657534246575342,0.9655172413793104,0.9652777777777778,0.965034965034965,0.9647887323943662,0.9645390070921985,0.9642857142857143,0.9640287769784173,0.9637681159420289,0.9635036496350365,0.9632352941176471,0.9629629629629629,0.9626865671641791,0.9624060150375939,0.9621212121212122,0.9618320610687023,0.9615384615384616,0.9612403100775194,0.9609375,0.9606299212598425,0.9603174603174603,0.96,0.9596774193548387,0.959349593495935,0.9590163934426229,0.9586776859504132,0.9583333333333334,0.957983193277311,0.9576271186440678,0.9572649572649573,0.9568965517241379,0.9565217391304348,0.956140350877193,0.9557522123893806,0.9642857142857143,0.963963963963964,0.9636363636363636,0.963302752293578,0.9722222222222222,0.9719626168224299,0.9716981132075472,0.9714285714285714,0.9711538461538461,0.970873786407767,0.9705882352941176,0.9801980198019802,0.98,0.9797979797979798,0.9795918367346939,0.979381443298969,0.9791666666666666,0.9789473684210527,0.9787234042553191,0.978494623655914,0.9782608695652174,0.978021978021978,0.9777777777777777,0.9775280898876404,0.9772727272727273,0.9770114942528736,0.9767441860465116,0.9764705882352941,0.9761904761904762,0.9759036144578314,0.975609756097561,0.9753086419753086,0.975,0.9746835443037974,0.9743589743589743,0.974025974025974,0.9736842105263158,0.9733333333333334,0.972972972972973,0.9726027397260274,0.9722222222222222,0.971830985915493,0.9714285714285714,0.9710144927536232,0.9705882352941176,0.9701492537313433,0.9696969696969697,0.9846153846153847,0.984375,0.9841269841269841,0.9838709677419355,0.9836065573770492,0.9833333333333333,0.9830508474576272,0.9827586206896551,0.9824561403508771,0.9821428571428571,0.9818181818181818,0.9814814814814815,0.9811320754716981,0.9807692307692307,0.9803921568627451,0.98,0.9795918367346939,0.9791666666666666,0.9787234042553191,0.9782608695652174,0.9777777777777777,0.9772727272727273,0.9767441860465116,0.9761904761904762,0.975609756097561,0.975,0.9743589743589743,0.9736842105263158,0.972972972972973,0.9722222222222222,0.9714285714285714,0.9705882352941176,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],"yaxis":"y"}],"layout":{"height":600,"legend":{"tracegroupgap":0},"shapes":[{"line":{"dash":"dash"},"type":"line","x0":0,"x1":1,"y0":1,"y1":0}],"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"title":{"text":"Precision-Recall Curve (AUC=0.8560)"},"width":800,"xaxis":{"anchor":"y","constrain":"domain","domain":[0,1],"title":{"text":"Recall"}},"yaxis":{"anchor":"x","domain":[0,1],"scaleanchor":"x","scaleratio":1,"title":{"text":"Precision"}}}},"text/html":["<div>                            <div id=\"a2365146-b54f-4618-813d-78d0a7afc006\" class=\"plotly-graph-div\" style=\"height:600px; width:800px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"a2365146-b54f-4618-813d-78d0a7afc006\")) {                    Plotly.newPlot(                        \"a2365146-b54f-4618-813d-78d0a7afc006\",                        [{\"fillpattern\":{\"shape\":\"\"},\"hovertemplate\":\"Recall=%{x}\\u003cbr\\u003ePrecision=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"stackgroup\":\"1\",\"x\":[1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.9941916747337851,0.9932236205227493,0.9932236205227493,0.9932236205227493,0.9922555663117134,0.9922555663117134,0.9922555663117134,0.9922555663117134,0.9922555663117134,0.9922555663117134,0.9922555663117134,0.9922555663117134,0.9922555663117134,0.9922555663117134,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.989351403678606,0.989351403678606,0.989351403678606,0.989351403678606,0.989351403678606,0.989351403678606,0.989351403678606,0.989351403678606,0.9883833494675702,0.9883833494675702,0.9874152952565344,0.9874152952565344,0.9874152952565344,0.9874152952565344,0.9864472410454985,0.9864472410454985,0.9864472410454985,0.9864472410454985,0.9854791868344628,0.9854791868344628,0.9854791868344628,0.9845111326234269,0.9845111326234269,0.9845111326234269,0.9845111326234269,0.9845111326234269,0.9845111326234269,0.9845111326234269,0.9845111326234269,0.9845111326234269,0.9845111326234269,0.9845111326234269,0.9845111326234269,0.9845111326234269,0.9845111326234269,0.9835430784123911,0.9825750242013552,0.9816069699903195,0.9816069699903195,0.9816069699903195,0.9816069699903195,0.9806389157792836,0.9806389157792836,0.9806389157792836,0.9796708615682478,0.9796708615682478,0.9796708615682478,0.9796708615682478,0.9796708615682478,0.9796708615682478,0.9796708615682478,0.9796708615682478,0.9796708615682478,0.978702807357212,0.978702807357212,0.978702807357212,0.978702807357212,0.978702807357212,0.9777347531461762,0.9777347531461762,0.9777347531461762,0.9767666989351403,0.9757986447241046,0.9757986447241046,0.9757986447241046,0.9748305905130688,0.9738625363020329,0.972894482090997,0.9719264278799613,0.9719264278799613,0.9709583736689255,0.9699903194578896,0.9690222652468539,0.968054211035818,0.9670861568247822,0.9670861568247822,0.9670861568247822,0.9670861568247822,0.9670861568247822,0.9661181026137464,0.9661181026137464,0.9661181026137464,0.9661181026137464,0.9651500484027106,0.9651500484027106,0.9651500484027106,0.9651500484027106,0.9651500484027106,0.9651500484027106,0.9651500484027106,0.9641819941916747,0.9641819941916747,0.9641819941916747,0.9641819941916747,0.9641819941916747,0.9641819941916747,0.9641819941916747,0.9641819941916747,0.9632139399806389,0.9632139399806389,0.9632139399806389,0.9632139399806389,0.9632139399806389,0.9622458857696031,0.9622458857696031,0.9622458857696031,0.9622458857696031,0.9612778315585673,0.9612778315585673,0.9603097773475314,0.9593417231364957,0.9593417231364957,0.9583736689254598,0.957405614714424,0.957405614714424,0.957405614714424,0.957405614714424,0.957405614714424,0.9564375605033882,0.9564375605033882,0.9554695062923524,0.9554695062923524,0.9554695062923524,0.9554695062923524,0.9554695062923524,0.9554695062923524,0.9554695062923524,0.9554695062923524,0.9554695062923524,0.9554695062923524,0.9554695062923524,0.9554695062923524,0.9554695062923524,0.9554695062923524,0.9545014520813165,0.9545014520813165,0.9535333978702807,0.9535333978702807,0.9535333978702807,0.952565343659245,0.9515972894482091,0.9515972894482091,0.9506292352371732,0.9496611810261375,0.9486931268151017,0.9477250726040658,0.9477250726040658,0.9477250726040658,0.9467570183930301,0.9467570183930301,0.9457889641819942,0.9448209099709584,0.9438528557599225,0.9428848015488868,0.9428848015488868,0.9428848015488868,0.9419167473378509,0.9419167473378509,0.9419167473378509,0.9419167473378509,0.9409486931268151,0.9399806389157793,0.9399806389157793,0.9399806389157793,0.9399806389157793,0.9390125847047435,0.9390125847047435,0.9380445304937076,0.9380445304937076,0.9380445304937076,0.9380445304937076,0.9370764762826719,0.9370764762826719,0.936108422071636,0.936108422071636,0.936108422071636,0.9351403678606002,0.9351403678606002,0.9351403678606002,0.9351403678606002,0.9341723136495643,0.9332042594385286,0.9322362052274927,0.9322362052274927,0.9322362052274927,0.9322362052274927,0.9312681510164569,0.9303000968054211,0.9303000968054211,0.9293320425943853,0.9283639883833494,0.9283639883833494,0.9273959341723137,0.9264278799612778,0.925459825750242,0.925459825750242,0.925459825750242,0.925459825750242,0.9244917715392061,0.9235237173281704,0.9235237173281704,0.9235237173281704,0.9225556631171346,0.9225556631171346,0.9225556631171346,0.9215876089060987,0.9215876089060987,0.920619554695063,0.9196515004840271,0.9186834462729913,0.9177153920619555,0.9167473378509197,0.9157792836398838,0.914811229428848,0.914811229428848,0.914811229428848,0.9138431752178122,0.9128751210067764,0.9119070667957405,0.9109390125847048,0.9109390125847048,0.9109390125847048,0.9099709583736689,0.9099709583736689,0.9090029041626331,0.9090029041626331,0.9080348499515973,0.9080348499515973,0.9070667957405615,0.9060987415295256,0.9051306873184899,0.904162633107454,0.9031945788964182,0.9022265246853823,0.9022265246853823,0.9012584704743466,0.9012584704743466,0.9002904162633107,0.8993223620522749,0.8983543078412392,0.8973862536302033,0.8964181994191674,0.8954501452081317,0.8954501452081317,0.8944820909970959,0.89351403678606,0.89351403678606,0.89351403678606,0.89351403678606,0.89351403678606,0.89351403678606,0.89351403678606,0.89351403678606,0.8925459825750242,0.8915779283639884,0.8906098741529526,0.8906098741529526,0.8896418199419167,0.8896418199419167,0.8896418199419167,0.8896418199419167,0.8896418199419167,0.888673765730881,0.888673765730881,0.8877057115198451,0.8867376573088093,0.8857696030977735,0.8848015488867377,0.8838334946757018,0.882865440464666,0.8818973862536302,0.8809293320425944,0.8799612778315585,0.8799612778315585,0.8799612778315585,0.8789932236205228,0.8789932236205228,0.8780251694094869,0.8770571151984511,0.8770571151984511,0.8770571151984511,0.8770571151984511,0.8770571151984511,0.8770571151984511,0.8760890609874153,0.8760890609874153,0.8751210067763795,0.8741529525653436,0.8731848983543078,0.8731848983543078,0.8731848983543078,0.8731848983543078,0.8731848983543078,0.872216844143272,0.872216844143272,0.8712487899322362,0.8702807357212003,0.8693126815101646,0.8683446272991288,0.8683446272991288,0.8673765730880929,0.8673765730880929,0.8664085188770572,0.8664085188770572,0.8654404646660213,0.8654404646660213,0.8644724104549855,0.8635043562439496,0.8625363020329139,0.861568247821878,0.8606001936108422,0.8596321393998064,0.8586640851887706,0.8576960309777347,0.856727976766699,0.8557599225556631,0.8557599225556631,0.8547918683446273,0.8547918683446273,0.8547918683446273,0.8547918683446273,0.8538238141335914,0.8528557599225557,0.8528557599225557,0.8518877057115198,0.8518877057115198,0.8518877057115198,0.850919651500484,0.8499515972894482,0.8499515972894482,0.8489835430784124,0.8480154888673765,0.8480154888673765,0.8480154888673765,0.8470474346563408,0.846079380445305,0.846079380445305,0.8451113262342691,0.8441432720232332,0.8441432720232332,0.8441432720232332,0.8431752178121975,0.8431752178121975,0.8422071636011617,0.8422071636011617,0.8422071636011617,0.8422071636011617,0.8422071636011617,0.8422071636011617,0.8422071636011617,0.8422071636011617,0.8422071636011617,0.8412391093901258,0.8412391093901258,0.8402710551790901,0.8393030009680542,0.8393030009680542,0.8383349467570184,0.8383349467570184,0.8373668925459826,0.8373668925459826,0.8373668925459826,0.8363988383349468,0.8354307841239109,0.8344627299128751,0.8334946757018393,0.8325266214908035,0.8325266214908035,0.8315585672797676,0.8315585672797676,0.8315585672797676,0.8305905130687319,0.829622458857696,0.8286544046466602,0.8286544046466602,0.8286544046466602,0.8286544046466602,0.8276863504356244,0.8276863504356244,0.8276863504356244,0.8267182962245886,0.8257502420135527,0.8247821878025169,0.8238141335914811,0.8228460793804453,0.8218780251694094,0.8218780251694094,0.8218780251694094,0.8209099709583737,0.8199419167473379,0.8199419167473379,0.818973862536302,0.8180058083252663,0.8170377541142304,0.8160696999031946,0.8151016456921588,0.8151016456921588,0.814133591481123,0.8131655372700871,0.8131655372700871,0.8121974830590513,0.8112294288480155,0.8102613746369797,0.8102613746369797,0.8092933204259438,0.8092933204259438,0.8092933204259438,0.8083252662149081,0.8073572120038722,0.8073572120038722,0.8063891577928364,0.8054211035818006,0.8044530493707648,0.8044530493707648,0.8044530493707648,0.8034849951597289,0.8025169409486931,0.8015488867376573,0.8005808325266215,0.7996127783155856,0.7996127783155856,0.7986447241045499,0.7986447241045499,0.797676669893514,0.797676669893514,0.797676669893514,0.797676669893514,0.7967086156824782,0.7957405614714425,0.7947725072604066,0.7938044530493708,0.7928363988383349,0.7918683446272992,0.7909002904162633,0.7899322362052275,0.7889641819941917,0.7889641819941917,0.7879961277831559,0.78702807357212,0.7860600193610843,0.7850919651500484,0.7850919651500484,0.7850919651500484,0.7850919651500484,0.7841239109390126,0.7831558567279767,0.7831558567279767,0.782187802516941,0.782187802516941,0.7812197483059051,0.7802516940948693,0.7792836398838335,0.7783155856727977,0.7773475314617618,0.7763794772507261,0.7754114230396902,0.7744433688286544,0.7734753146176185,0.7734753146176185,0.7734753146176185,0.7725072604065828,0.7725072604065828,0.771539206195547,0.7705711519845111,0.7696030977734754,0.7686350435624395,0.7676669893514037,0.7666989351403679,0.7657308809293321,0.7647628267182962,0.7647628267182962,0.7637947725072604,0.7637947725072604,0.7628267182962246,0.7628267182962246,0.7618586640851888,0.7618586640851888,0.7608906098741529,0.7599225556631172,0.7589545014520813,0.7579864472410455,0.7570183930300097,0.7560503388189739,0.755082284607938,0.7541142303969022,0.7531461761858664,0.7521781219748306,0.7521781219748306,0.7512100677637947,0.750242013552759,0.7492739593417231,0.7483059051306873,0.7473378509196515,0.7463697967086157,0.7454017424975798,0.744433688286544,0.7434656340755083,0.7424975798644724,0.7415295256534365,0.7405614714424008,0.739593417231365,0.7386253630203291,0.7376573088092934,0.7366892545982575,0.7366892545982575,0.7366892545982575,0.7357212003872217,0.7357212003872217,0.7347531461761858,0.7347531461761858,0.7337850919651501,0.7328170377541142,0.7328170377541142,0.7318489835430784,0.7318489835430784,0.7308809293320426,0.7299128751210068,0.7289448209099709,0.7279767666989352,0.7279767666989352,0.7279767666989352,0.7270087124878993,0.7260406582768635,0.7250726040658277,0.7241045498547919,0.7241045498547919,0.723136495643756,0.7221684414327202,0.7212003872216844,0.7202323330106486,0.7192642787996127,0.7192642787996127,0.718296224588577,0.7173281703775412,0.7163601161665053,0.7153920619554696,0.7153920619554696,0.7144240077444337,0.7134559535333979,0.712487899322362,0.7115198451113263,0.7115198451113263,0.7105517909002904,0.7095837366892546,0.7086156824782188,0.707647628267183,0.7066795740561471,0.7057115198451114,0.7047434656340755,0.7037754114230397,0.7028073572120038,0.7018393030009681,0.7008712487899322,0.7008712487899322,0.6999031945788964,0.6999031945788964,0.6989351403678606,0.6979670861568248,0.6969990319457889,0.6960309777347532,0.6950629235237173,0.6940948693126815,0.6940948693126815,0.6931268151016456,0.6931268151016456,0.6931268151016456,0.6921587608906099,0.6921587608906099,0.691190706679574,0.6902226524685382,0.6892545982575025,0.6882865440464666,0.6882865440464666,0.6873184898354308,0.686350435624395,0.6853823814133592,0.6844143272023233,0.6834462729912875,0.6834462729912875,0.6824782187802517,0.6815101645692159,0.6815101645692159,0.68054211035818,0.6795740561471443,0.6786060019361084,0.6776379477250726,0.6766698935140368,0.675701839303001,0.675701839303001,0.6747337850919651,0.6737657308809293,0.6727976766698935,0.6718296224588577,0.6708615682478218,0.6698935140367861,0.6689254598257502,0.6679574056147144,0.6669893514036787,0.6660212971926428,0.665053242981607,0.6640851887705711,0.6631171345595354,0.6621490803484995,0.6611810261374637,0.6611810261374637,0.6602129719264279,0.6592449177153921,0.6592449177153921,0.6592449177153921,0.6582768635043562,0.6573088092933205,0.6563407550822846,0.6553727008712488,0.6544046466602129,0.6534365924491772,0.6524685382381413,0.6515004840271055,0.6505324298160697,0.6495643756050339,0.648596321393998,0.648596321393998,0.6476282671829623,0.6466602129719264,0.6456921587608906,0.6447241045498547,0.643756050338819,0.6427879961277831,0.6418199419167473,0.6408518877057116,0.6398838334946757,0.6389157792836399,0.6379477250726041,0.6369796708615683,0.6360116166505324,0.6350435624394967,0.6350435624394967,0.6340755082284608,0.633107454017425,0.6321393998063891,0.6321393998063891,0.6311713455953534,0.6311713455953534,0.6302032913843175,0.6292352371732817,0.6292352371732817,0.6282671829622459,0.6272991287512101,0.6263310745401742,0.6253630203291385,0.6243949661181026,0.6234269119070668,0.6234269119070668,0.6224588576960309,0.6214908034849952,0.6214908034849952,0.6214908034849952,0.6205227492739593,0.6195546950629235,0.6185866408518877,0.6176185866408519,0.616650532429816,0.6156824782187803,0.6147144240077445,0.6137463697967086,0.6127783155856728,0.611810261374637,0.6108422071636012,0.6098741529525653,0.6089060987415296,0.6079380445304937,0.6069699903194579,0.6060019361084221,0.6050338818973863,0.6040658276863504,0.6030977734753146,0.6030977734753146,0.6021297192642788,0.601161665053243,0.6001936108422071,0.5992255566311714,0.5992255566311714,0.5982575024201355,0.5972894482090997,0.5963213939980639,0.5953533397870281,0.5953533397870281,0.5943852855759922,0.5943852855759922,0.5934172313649564,0.5924491771539206,0.5914811229428848,0.590513068731849,0.5895450145208132,0.5885769603097774,0.5876089060987415,0.5866408518877058,0.5866408518877058,0.5856727976766699,0.5847047434656341,0.5837366892545982,0.5818005808325266,0.5808325266214908,0.5808325266214908,0.579864472410455,0.5788964181994192,0.5779283639883833,0.5769603097773476,0.5759922555663117,0.5750242013552759,0.57405614714424,0.57405614714424,0.5730880929332043,0.5721200387221684,0.5721200387221684,0.5711519845111326,0.5701839303000968,0.569215876089061,0.5682478218780251,0.5672797676669894,0.5663117134559535,0.5653436592449177,0.5643756050338818,0.5634075508228461,0.5624394966118103,0.5614714424007744,0.5605033881897387,0.5595353339787028,0.558567279767667,0.5575992255566312,0.5566311713455954,0.5556631171345595,0.5546950629235237,0.5537270087124879,0.5527589545014521,0.5527589545014521,0.5517909002904162,0.5517909002904162,0.5508228460793805,0.5498547918683446,0.5488867376573088,0.547918683446273,0.5469506292352372,0.5459825750242013,0.5450145208131656,0.5440464666021297,0.5430784123910939,0.542110358180058,0.5411423039690223,0.5401742497579864,0.5401742497579864,0.5392061955469506,0.5382381413359149,0.5382381413359149,0.537270087124879,0.5363020329138432,0.5353339787028074,0.5343659244917716,0.5333978702807357,0.5324298160696999,0.5314617618586641,0.5304937076476283,0.5295256534365924,0.5285575992255567,0.5275895450145208,0.526621490803485,0.5256534365924492,0.5246853823814134,0.5246853823814134,0.5237173281703775,0.5227492739593417,0.5217812197483059,0.5208131655372701,0.5198451113262342,0.5188770571151985,0.5179090029041626,0.5169409486931268,0.515972894482091,0.5150048402710552,0.5140367860600193,0.5130687318489835,0.5121006776379478,0.5111326234269119,0.510164569215876,0.5091965150048403,0.5082284607938045,0.5072604065827686,0.5062923523717329,0.505324298160697,0.5043562439496612,0.5033881897386253,0.5024201355275896,0.5014520813165537,0.5004840271055179,0.4995159728944821,0.4985479186834463,0.4975798644724105,0.49661181026137463,0.49564375605033884,0.494675701839303,0.4937076476282672,0.4927395934172314,0.49177153920619554,0.49080348499515974,0.4898354307841239,0.4888673765730881,0.4878993223620523,0.4878993223620523,0.48693126815101645,0.48596321393998065,0.4849951597289448,0.484027105517909,0.4830590513068732,0.48209099709583736,0.48112294288480156,0.4801548886737657,0.4791868344627299,0.4782187802516941,0.47725072604065827,0.4762826718296225,0.4762826718296225,0.4753146176185866,0.4743465634075508,0.47337850919651503,0.4724104549854792,0.4714424007744434,0.47047434656340753,0.46950629235237173,0.46853823814133594,0.4675701839303001,0.4666021297192643,0.46563407550822844,0.46466602129719264,0.46466602129719264,0.46369796708615685,0.462729912875121,0.4617618586640852,0.46079380445304935,0.45982575024201355,0.45885769603097776,0.4578896418199419,0.4569215876089061,0.45595353339787026,0.45498547918683446,0.45401742497579867,0.4530493707647628,0.452081316553727,0.45111326234269117,0.45014520813165537,0.4491771539206196,0.4482090997095837,0.44724104549854793,0.4462729912875121,0.4453049370764763,0.4443368828654405,0.44336882865440463,0.44240077444336884,0.441432720232333,0.4404646660212972,0.4394966118102614,0.43852855759922554,0.43756050338818975,0.4365924491771539,0.4356243949661181,0.4346563407550823,0.43368828654404645,0.43272023233301066,0.4317521781219748,0.430784123910939,0.4298160696999032,0.42884801548886736,0.42787996127783157,0.4269119070667957,0.4259438528557599,0.4249757986447241,0.42400774443368827,0.4230396902226525,0.4230396902226525,0.4220716360116166,0.42110358180058083,0.42013552758954503,0.4191674733785092,0.4181994191674734,0.41723136495643753,0.41626331074540174,0.41529525653436594,0.4143272023233301,0.4133591481122943,0.41239109390125844,0.41142303969022265,0.41045498547918685,0.409486931268151,0.4085188770571152,0.4085188770571152,0.4075508228460794,0.40658276863504356,0.40561471442400776,0.4046466602129719,0.4036786060019361,0.4036786060019361,0.4027105517909003,0.40174249757986447,0.40077444336882867,0.3998063891577928,0.398838334946757,0.3978702807357212,0.3969022265246854,0.3959341723136496,0.39496611810261373,0.39399806389157793,0.39303000968054214,0.3920619554695063,0.3910939012584705,0.39012584704743464,0.38915779283639884,0.38818973862536305,0.3872216844143272,0.3862536302032914,0.38528557599225555,0.38431752178121975,0.38334946757018395,0.3823814133591481,0.3814133591481123,0.38044530493707646,0.37947725072604066,0.37850919651500486,0.377541142303969,0.3765730880929332,0.37560503388189737,0.37560503388189737,0.37463697967086157,0.3736689254598258,0.3727008712487899,0.3717328170377541,0.3707647628267183,0.3707647628267183,0.3697967086156825,0.3688286544046467,0.3688286544046467,0.36786060019361083,0.36689254598257504,0.3659244917715392,0.3649564375605034,0.3639883833494676,0.36302032913843174,0.36205227492739595,0.3610842207163601,0.3610842207163601,0.3601161665053243,0.3591481122942885,0.35818005808325265,0.35721200387221685,0.356243949661181,0.3552758954501452,0.3543078412391094,0.35333978702807356,0.35237173281703776,0.3514036786060019,0.3514036786060019,0.3504356243949661,0.3494675701839303,0.34849951597289447,0.3475314617618587,0.3465634075508228,0.345595353339787,0.34462729912875123,0.3436592449177154,0.3426911907066796,0.34172313649564373,0.34075508228460794,0.33978702807357214,0.3388189738625363,0.3378509196515005,0.33688286544046464,0.33591481122942884,0.33494675701839305,0.3339787028073572,0.3339787028073572,0.3330106485963214,0.33204259438528555,0.33107454017424975,0.33010648596321396,0.3291384317521781,0.3281703775411423,0.32720232333010646,0.32720232333010646,0.32623426911907066,0.32526621490803487,0.324298160696999,0.3233301064859632,0.32236205227492737,0.3213939980638916,0.3204259438528558,0.3194578896418199,0.31848983543078413,0.31752178121974833,0.3165537270087125,0.3155856727976767,0.31461761858664083,0.31461761858664083,0.31364956437560504,0.31268151016456924,0.3117134559535334,0.3107454017424976,0.30977734753146174,0.30880929332042595,0.30784123910939015,0.3068731848983543,0.3059051306873185,0.30493707647628265,0.30396902226524686,0.30300096805421106,0.3020329138431752,0.3010648596321394,0.30009680542110356,0.29912875121006777,0.29816069699903197,0.2971926427879961,0.2962245885769603,0.2952565343659245,0.2942884801548887,0.2933204259438529,0.29235237173281703,0.29138431752178123,0.2904162633107454,0.2894482090997096,0.2884801548886738,0.28751210067763794,0.28654404646660214,0.2855759922555663,0.2846079380445305,0.2846079380445305,0.2836398838334947,0.28267182962245885,0.28170377541142305,0.2807357212003872,0.2797676669893514,0.2787996127783156,0.27783155856727976,0.27686350435624396,0.2758954501452081,0.2749273959341723,0.2739593417231365,0.27299128751210067,0.27202323330106487,0.271055179090029,0.2700871248789932,0.2691190706679574,0.2681510164569216,0.2671829622458858,0.26621490803484993,0.26524685382381413,0.26427879961277834,0.2633107454017425,0.2623426911907067,0.26137463697967084,0.26040658276863504,0.25943852855759925,0.2584704743465634,0.2575024201355276,0.25653436592449175,0.25556631171345595,0.25459825750242016,0.2536302032913843,0.2526621490803485,0.25169409486931266,0.25072604065827686,0.24975798644724104,0.24878993223620524,0.24782187802516942,0.2468538238141336,0.24588576960309777,0.24491771539206195,0.24394966118102615,0.24298160696999033,0.2420135527589545,0.24104549854791868,0.24007744433688286,0.23910939012584706,0.23814133591481124,0.2371732817037754,0.2362052274927396,0.23523717328170377,0.23426911907066797,0.23426911907066797,0.23330106485963215,0.23233301064859632,0.2313649564375605,0.23039690222652467,0.22942884801548888,0.22846079380445306,0.22749273959341723,0.2265246853823814,0.22555663117134558,0.2245885769603098,0.22362052274927396,0.22265246853823814,0.22265246853823814,0.22168441432720232,0.2207163601161665,0.2197483059051307,0.21878025169409487,0.21781219748305905,0.21684414327202323,0.2158760890609874,0.2149080348499516,0.21393998063891578,0.21297192642787996,0.21200387221684414,0.2110358180058083,0.21006776379477252,0.2090997095837367,0.20813165537270087,0.20716360116166505,0.20619554695062922,0.20522749273959343,0.2042594385285576,0.20329138431752178,0.20232333010648595,0.20135527589545016,0.20038722168441434,0.1994191674733785,0.1984511132623427,0.19748305905130686,0.19651500484027107,0.19554695062923524,0.19457889641819942,0.1936108422071636,0.19264278799612777,0.19167473378509198,0.19070667957405615,0.18973862536302033,0.1887705711519845,0.18780251694094868,0.1868344627299129,0.18586640851887706,0.18489835430784124,0.18393030009680542,0.1829622458857696,0.1819941916747338,0.18102613746369797,0.18005808325266215,0.17909002904162633,0.1781219748305905,0.1771539206195547,0.17618586640851888,0.17521781219748306,0.17424975798644723,0.1732817037754114,0.17231364956437561,0.1713455953533398,0.17037754114230397,0.16940948693126814,0.16844143272023232,0.16747337850919652,0.1665053242981607,0.16553727008712488,0.16553727008712488,0.16456921587608905,0.16360116166505323,0.16263310745401743,0.1616650532429816,0.1606969990319458,0.15972894482090996,0.15876089060987417,0.15779283639883834,0.15682478218780252,0.1558567279767667,0.15488867376573087,0.15392061955469508,0.15295256534365925,0.15198451113262343,0.1510164569215876,0.15004840271055178,0.14908034849951599,0.14811229428848016,0.14714424007744434,0.14617618586640851,0.1452081316553727,0.1442400774443369,0.14327202323330107,0.14230396902226525,0.14133591481122942,0.1403678606001936,0.1393998063891578,0.13843175217812198,0.13746369796708616,0.13649564375605033,0.1355275895450145,0.1345595353339787,0.1335914811229429,0.13262342691190707,0.13165537270087124,0.13068731848983542,0.12971926427879962,0.1287512100677638,0.12778315585672798,0.12681510164569215,0.12584704743465633,0.12487899322362052,0.12391093901258471,0.12294288480154889,0.12197483059051308,0.12100677637947725,0.12003872216844143,0.11907066795740562,0.1181026137463698,0.11713455953533398,0.11616650532429816,0.11519845111326234,0.11423039690222653,0.1132623426911907,0.1122942884801549,0.11132623426911907,0.11035818005808325,0.10939012584704744,0.10842207163601161,0.1074540174249758,0.10648596321393998,0.10551790900290416,0.10454985479186835,0.10454985479186835,0.10358180058083252,0.10261374636979671,0.10164569215876089,0.10164569215876089,0.10067763794772508,0.09970958373668926,0.09874152952565343,0.09777347531461762,0.0968054211035818,0.09583736689254599,0.09583736689254599,0.09486931268151017,0.09390125847047434,0.09293320425943853,0.09196515004840271,0.0909970958373669,0.09002904162633107,0.08906098741529525,0.08809293320425944,0.08712487899322362,0.08615682478218781,0.08518877057115198,0.08422071636011616,0.08325266214908035,0.08228460793804453,0.08131655372700872,0.0803484995159729,0.07938044530493708,0.07841239109390126,0.07744433688286544,0.07647628267182963,0.0755082284607938,0.07454017424975799,0.07357212003872217,0.07260406582768635,0.07163601161665054,0.07066795740561471,0.0696999031945789,0.06873184898354308,0.06776379477250725,0.06679574056147145,0.06582768635043562,0.06485963213939981,0.06389157792836399,0.06292352371732816,0.061955469506292354,0.061955469506292354,0.06098741529525654,0.060019361084220714,0.0590513068731849,0.05808325266214908,0.057115198451113264,0.05614714424007745,0.05517909002904162,0.05421103581800581,0.05324298160696999,0.05227492739593417,0.051306873184898356,0.05033881897386254,0.049370764762826716,0.0484027105517909,0.04743465634075508,0.046466602129719266,0.04549854791868345,0.044530493707647625,0.04356243949661181,0.04259438528557599,0.041626331074540175,0.04065827686350436,0.03969022265246854,0.03872216844143272,0.0377541142303969,0.036786060019361085,0.03581800580832527,0.03484995159728945,0.03388189738625363,0.03291384317521781,0.031945788964181994,0.031945788964181994,0.030977734753146177,0.030009680542110357,0.02904162633107454,0.028073572120038724,0.027105517909002903,0.026137463697967087,0.02516940948693127,0.02420135527589545,0.023233301064859633,0.022265246853823813,0.021297192642787996,0.02032913843175218,0.01936108422071636,0.018393030009680542,0.017424975798644726,0.016456921587608905,0.015488867376573089,0.01452081316553727,0.013552758954501452,0.012584704743465635,0.011616650532429816,0.010648596321393998,0.00968054211035818,0.008712487899322363,0.007744433688286544,0.006776379477250726,0.005808325266214908,0.00484027105517909,0.003872216844143272,0.002904162633107454,0.001936108422071636,0.000968054211035818,0.0],\"xaxis\":\"x\",\"y\":[0.7341862117981521,0.7347083926031295,0.7352313167259786,0.7357549857549858,0.7362794012829651,0.7368045649072753,0.7373304782298359,0.7371428571428571,0.7376697641172266,0.7381974248927039,0.7387258410880458,0.7392550143266475,0.7397849462365591,0.7403156384505022,0.7408470926058865,0.7413793103448276,0.7419122933141624,0.7424460431654676,0.7429805615550756,0.7435158501440923,0.7440519105984138,0.7445887445887446,0.7444043321299639,0.744942196531792,0.7454808387563269,0.7460202604920405,0.7458363504706734,0.7463768115942029,0.7469180565627266,0.7474600870827286,0.7480029048656499,0.748546511627907,0.7490909090909091,0.7496360989810772,0.7501820830298617,0.750728862973761,0.75127644055434,0.7518248175182481,0.7523739956172388,0.7529239766081871,0.7527432333577176,0.753294289897511,0.7538461538461538,0.7543988269794721,0.7549523110785032,0.7555066079295154,0.7560617193240264,0.7558823529411764,0.7564385577630611,0.7569955817378498,0.7575534266764923,0.7581120943952803,0.7579335793357933,0.757754800590842,0.7583148558758315,0.7588757396449705,0.7586972612879349,0.7592592592592593,0.759822090437361,0.7603857566765578,0.7609502598366741,0.7615156017830609,0.7620817843866171,0.7626488095238095,0.763216679076694,0.763785394932936,0.7636092468307233,0.764179104477612,0.7647498132935027,0.7653213751868461,0.7651458489154824,0.7657185628742516,0.7662921348314606,0.7668665667166417,0.7666916729182296,0.7672672672672672,0.7678437265214124,0.7684210526315789,0.7689992475545523,0.7695783132530121,0.7701582516955539,0.770739064856712,0.7705660377358491,0.7711480362537765,0.7709750566893424,0.7715582450832073,0.7721423164269493,0.7727272727272727,0.7725549658832449,0.7731411229135053,0.7737281700835231,0.7743161094224924,0.7741444866920152,0.7747336377473364,0.7753236862147753,0.7751524390243902,0.7757437070938215,0.7763358778625954,0.7769289533995416,0.7775229357798165,0.7781178270849273,0.7787136294027565,0.7793103448275862,0.7799079754601227,0.7805065234075211,0.7811059907834101,0.781706379707917,0.7823076923076923,0.7829099307159353,0.7827426810477658,0.7825751734772552,0.7824074074074074,0.783011583011583,0.7836166924265843,0.7842227378190255,0.7840557275541795,0.7846630518977536,0.7852713178294574,0.7851047323506595,0.7857142857142857,0.7863247863247863,0.7869362363919129,0.7875486381322957,0.7881619937694704,0.7887763055339049,0.7893915756630265,0.790007806401249,0.78984375,0.7904612978889758,0.7910798122065728,0.7916992952231793,0.792319749216301,0.792156862745098,0.792778649921507,0.793401413982718,0.7932389937106918,0.7930763178599528,0.7937007874015748,0.7943262411347518,0.7941640378548895,0.7940015785319653,0.7938388625592417,0.7936758893280632,0.7943037974683544,0.7941409342834521,0.7939778129952456,0.7938144329896907,0.7936507936507936,0.7934868943606036,0.7941176470588235,0.7947494033412887,0.7953821656050956,0.7960159362549801,0.79585326953748,0.7964884277733439,0.7971246006389776,0.7977617905675459,0.7976,0.7982385908726981,0.7988782051282052,0.7995188452285485,0.8001605136436597,0.8008032128514057,0.8014469453376206,0.8012872083668544,0.8019323671497585,0.8025785656728445,0.8032258064516129,0.8038740920096852,0.8045234248788369,0.8051738075990299,0.8058252427184466,0.805668016194332,0.8063209076175041,0.8069748580697486,0.8076298701298701,0.8082859463850528,0.808130081300813,0.8087876322213181,0.8094462540716613,0.8101059494702526,0.8099510603588908,0.8106122448979591,0.8104575163398693,0.8103025347506132,0.8109656301145662,0.8108108108108109,0.8106557377049181,0.8113207547169812,0.8119868637110016,0.8126540673788003,0.8133223684210527,0.8131687242798354,0.8138385502471169,0.8136850783182193,0.8143564356435643,0.815028901734104,0.815702479338843,0.8163771712158809,0.8170529801324503,0.8177299088649544,0.818407960199005,0.8190871369294606,0.8197674418604651,0.8204488778054863,0.8211314475873545,0.8218151540383014,0.8225,0.8223519599666389,0.8230383973288815,0.822890559732665,0.8235785953177257,0.8242677824267782,0.8241206030150754,0.8239731768650461,0.8246644295302014,0.8245172124265323,0.8243697478991596,0.8242220353238016,0.8240740740740741,0.8247683235046336,0.8254637436762225,0.8253164556962025,0.8260135135135135,0.8258664412510567,0.8257191201353637,0.825571549534293,0.8254237288135593,0.8261238337574215,0.8268251273344652,0.826677994902294,0.8273809523809523,0.8280851063829787,0.8287904599659285,0.8286445012787724,0.8284982935153583,0.829205807002562,0.82991452991453,0.8306244653550042,0.8304794520547946,0.831191088260497,0.8310463121783876,0.8317596566523605,0.8324742268041238,0.8331900257953568,0.8330464716006885,0.8337639965546942,0.8336206896551724,0.8343399482312338,0.8350604490500864,0.8349178910976663,0.8356401384083045,0.8363636363636363,0.8370883882149047,0.836947094535993,0.8368055555555556,0.8366637706342311,0.837391304347826,0.8381201044386423,0.8388501742160279,0.8387096774193549,0.8385689354275742,0.8393013100436681,0.8391608391608392,0.8390201224846894,0.839754816112084,0.8396143733567046,0.8394736842105263,0.839332748024583,0.8400702987697716,0.8408091468777484,0.8415492957746479,0.8414096916299559,0.8412698412698413,0.8420123565754634,0.842756183745583,0.8426171529619806,0.8433628318584071,0.8441098317094774,0.8439716312056738,0.84472049689441,0.844582593250444,0.8444444444444444,0.844306049822064,0.8441674087266251,0.8440285204991087,0.8438893844781445,0.84375,0.8445040214477212,0.8452593917710197,0.8451208594449419,0.8449820788530465,0.8448430493273542,0.8447037701974865,0.8454627133872417,0.8462230215827338,0.8460846084608461,0.8468468468468469,0.8467087466185753,0.8474729241877257,0.8473351400180669,0.8481012658227848,0.8479638009049774,0.8478260869565217,0.8476881233000907,0.8475499092558983,0.8474114441416893,0.8472727272727273,0.8480436760691538,0.8479052823315119,0.8486782133090246,0.8485401459854015,0.8484018264840183,0.8482632541133455,0.848124428179323,0.847985347985348,0.847846012832264,0.8486238532110092,0.8484848484848485,0.8483455882352942,0.8491260349586016,0.8499079189686924,0.8506912442396314,0.8514760147601476,0.8522622345337026,0.8530499075785583,0.8538390379278445,0.8537037037037037,0.8535681186283596,0.8534322820037106,0.8542246982358404,0.854089219330855,0.8548837209302326,0.8556797020484171,0.8564771668219944,0.8572761194029851,0.8571428571428571,0.8579439252336448,0.8578110383536015,0.8576779026217228,0.8575445173383318,0.8574108818011257,0.8572769953051643,0.8571428571428571,0.8570084666039511,0.8568738229755178,0.8567389255419415,0.8575471698113207,0.8583569405099151,0.8582230623818525,0.859035004730369,0.8589015151515151,0.8587677725118483,0.8595825426944972,0.8603988603988604,0.8612167300380228,0.8620361560418649,0.8628571428571429,0.8627264061010487,0.8635496183206107,0.8634192932187201,0.8632887189292543,0.8631578947368421,0.8639846743295019,0.8648130393096836,0.8656429942418427,0.866474543707973,0.8663461538461539,0.8671799807507219,0.8670520231213873,0.866923818707811,0.8667953667953668,0.8666666666666667,0.867504835589942,0.8673765730880929,0.8682170542635659,0.8680892337536372,0.8689320388349514,0.8688046647230321,0.8696498054474708,0.8695228821811101,0.8693957115009746,0.8692682926829268,0.869140625,0.8690127077223851,0.8688845401174168,0.8687561214495593,0.8686274509803922,0.8684985279685966,0.8683693516699411,0.8692232055063913,0.8690944881889764,0.8699507389162562,0.8708086785009862,0.8716683119447186,0.8715415019762845,0.8714144411473789,0.8722772277227723,0.8721506442021804,0.873015873015873,0.8738828202581926,0.8737574552683897,0.8736318407960199,0.8745019920318725,0.8743768693918246,0.874251497005988,0.8751248751248751,0.876,0.8758758758758759,0.875751503006012,0.876629889669007,0.8765060240963856,0.8763819095477386,0.8772635814889336,0.878147029204431,0.8780241935483871,0.8789101917255298,0.8787878787878788,0.8796764408493428,0.8805668016194332,0.8814589665653495,0.8823529411764706,0.883248730964467,0.8841463414634146,0.8850457782299085,0.8859470468431772,0.8858307849133538,0.886734693877551,0.8866189989785496,0.8865030674846626,0.887410440122825,0.8872950819672131,0.8882051282051282,0.8880903490759754,0.8890030832476875,0.8899176954732511,0.8898043254376931,0.8896907216494845,0.8895768833849329,0.8894628099173554,0.889348500517063,0.8902691511387164,0.8901554404145078,0.8910788381742739,0.8920041536863966,0.8918918918918919,0.8917793964620188,0.8916666666666667,0.8925964546402503,0.8935281837160751,0.8944618599791013,0.8943514644351465,0.8952879581151832,0.8962264150943396,0.8961175236096537,0.8960084033613446,0.8958990536277602,0.8957894736842106,0.8956796628029505,0.8955696202531646,0.8965153115100317,0.8974630021141649,0.8973544973544973,0.8972457627118644,0.8981972428419936,0.8980891719745223,0.89798087141339,0.8978723404255319,0.8977635782747604,0.8976545842217484,0.8986125933831377,0.8985042735042735,0.8983957219251337,0.8993576017130621,0.8992497320471597,0.8991416309012875,0.8990332975295381,0.9,0.8998923573735199,0.9008620689655172,0.9018338727076591,0.9017278617710583,0.9016216216216216,0.9025974025974026,0.9024918743228603,0.9023861171366594,0.9022801302931596,0.9032608695652173,0.9042437431991295,0.9041394335511983,0.9040348964013086,0.9039301310043668,0.9038251366120219,0.9037199124726477,0.904709748083242,0.9046052631578947,0.9055982436882547,0.9054945054945055,0.9064906490649065,0.9074889867841409,0.9084895259095921,0.9083885209713024,0.9082872928176795,0.9081858407079646,0.9080841638981174,0.9079822616407982,0.9078801331853497,0.9077777777777778,0.9076751946607341,0.9075723830734966,0.9085841694537347,0.9084821428571429,0.9083798882681564,0.9082774049217002,0.9081746920492721,0.9091928251121076,0.9102132435465768,0.9112359550561798,0.9111361079865017,0.911036036036036,0.9120631341600902,0.9119638826185101,0.9129943502824859,0.9128959276018099,0.912797281993205,0.9126984126984127,0.9125993189557321,0.9125,0.9124004550625711,0.9123006833712984,0.9122006841505131,0.9121004566210046,0.9131428571428571,0.914187643020595,0.9140893470790378,0.9151376146788991,0.9150401836969001,0.9149425287356322,0.9148446490218642,0.9147465437788018,0.9146482122260668,0.9145496535796767,0.9144508670520232,0.9143518518518519,0.9154113557358053,0.9153132250580046,0.9163763066202091,0.9162790697674419,0.9173457508731082,0.9172494172494172,0.9183197199533255,0.9182242990654206,0.9181286549707602,0.9180327868852459,0.917936694021102,0.9178403755868545,0.917743830787309,0.9176470588235294,0.917550058892815,0.9174528301886793,0.9173553719008265,0.9184397163120568,0.9183431952662722,0.9182464454976303,0.9181494661921709,0.9180522565320665,0.9179548156956004,0.9178571428571428,0.9177592371871275,0.9176610978520287,0.9175627240143369,0.9174641148325359,0.9173652694610779,0.9172661870503597,0.9171668667466987,0.9170673076923077,0.9169675090252708,0.9168674698795181,0.9179734620024126,0.9190821256038647,0.9189842805320435,0.9200968523002422,0.92,0.9211165048543689,0.9210206561360875,0.9209245742092458,0.9220462850182704,0.9219512195121952,0.9230769230769231,0.9229828850855746,0.9228886168910648,0.9227941176470589,0.9226993865030675,0.9238329238329238,0.9249692496924969,0.9248768472906403,0.9247842170160296,0.9246913580246914,0.9245982694684796,0.9257425742574258,0.9256505576208178,0.9255583126550868,0.9254658385093167,0.9253731343283582,0.925280199252802,0.92643391521197,0.9263420724094882,0.92625,0.9261576971214017,0.9260651629072681,0.9272271016311167,0.9271356783919598,0.9270440251572327,0.9269521410579346,0.926860025220681,0.928030303030303,0.9279393173198482,0.9278481012658227,0.9277566539923955,0.9276649746192893,0.9275730622617535,0.9274809160305344,0.9273885350318471,0.9272959183673469,0.9272030651340997,0.9271099744245525,0.9270166453265045,0.9282051282051282,0.9281129653401797,0.929305912596401,0.9292149292149292,0.9291237113402062,0.9290322580645162,0.9289405684754521,0.9288486416558862,0.9287564766839378,0.9299610894941635,0.9298701298701298,0.9310793237971391,0.9322916666666666,0.9322033898305084,0.933420365535248,0.9333333333333333,0.9332460732984293,0.9331585845347313,0.9330708661417323,0.9342969776609724,0.9342105263157895,0.9341238471673254,0.9340369393139841,0.9339498018494056,0.9338624338624338,0.9350993377483444,0.9350132625994695,0.9349269588313412,0.9361702127659575,0.9360852197070573,0.936,0.9359145527369827,0.9358288770053476,0.9357429718875502,0.935656836461126,0.9369127516778524,0.9368279569892473,0.9367429340511441,0.9366576819407008,0.9365721997300944,0.9364864864864865,0.9364005412719891,0.9363143631436315,0.9362279511533242,0.936141304347826,0.9360544217687075,0.9359673024523161,0.9358799454297408,0.9357923497267759,0.9357045143638851,0.9356164383561644,0.9368998628257887,0.9368131868131868,0.936726272352132,0.9380165289256198,0.9393103448275862,0.9392265193370166,0.9391424619640387,0.9390581717451524,0.9389736477115118,0.9388888888888889,0.9388038942976356,0.9387186629526463,0.9386331938633193,0.9385474860335196,0.9384615384615385,0.938375350140056,0.9396914446002805,0.9396067415730337,0.939521800281294,0.9394366197183098,0.9393511988716502,0.9392655367231638,0.9391796322489392,0.9390934844192634,0.9390070921985816,0.9389204545454546,0.9388335704125178,0.9387464387464387,0.9386590584878745,0.9385714285714286,0.9384835479256081,0.9398280802292264,0.93974175035868,0.9396551724137931,0.939568345323741,0.9409221902017291,0.9408369408369408,0.9421965317919075,0.9421128798842258,0.9420289855072463,0.9433962264150944,0.9433139534883721,0.9432314410480349,0.9431486880466472,0.9430656934306569,0.9429824561403509,0.9428989751098097,0.9442815249266863,0.9441997063142438,0.9441176470588235,0.9455081001472754,0.9469026548672567,0.946824224519941,0.9467455621301775,0.9466666666666667,0.9465875370919882,0.9465081723625557,0.9464285714285714,0.9463487332339792,0.9462686567164179,0.9461883408071748,0.9461077844311377,0.9460269865067467,0.9459459459459459,0.9458646616541353,0.9457831325301205,0.9457013574660633,0.945619335347432,0.9455370650529501,0.9454545454545454,0.9453717754172989,0.9468085106382979,0.9467275494672754,0.9466463414634146,0.9465648854961832,0.9464831804281345,0.9479326186830015,0.9478527607361963,0.9477726574500768,0.9476923076923077,0.9476117103235747,0.9490740740740741,0.9489953632148377,0.9504643962848297,0.9503875968992248,0.9503105590062112,0.9502332814930016,0.9501557632398754,0.9500780031201248,0.95,0.9499217527386542,0.9498432601880877,0.9513343799058085,0.9512578616352201,0.9511811023622048,0.9511041009463722,0.9509493670886076,0.9508716323296355,0.9523809523809523,0.9523052464228935,0.9522292993630573,0.9521531100478469,0.952076677316294,0.952,0.9519230769230769,0.9518459069020867,0.9533762057877814,0.9533011272141707,0.9532258064516129,0.9547657512116317,0.9546925566343042,0.9546191247974068,0.9545454545454546,0.9544715447154472,0.9543973941368078,0.9543230016313213,0.954248366013072,0.9541734860883797,0.9540983606557377,0.9540229885057471,0.9539473684210527,0.9538714991762768,0.9537953795379538,0.9537190082644628,0.9536423841059603,0.9535655058043118,0.9534883720930233,0.9534109816971714,0.9533333333333334,0.9532554257095158,0.9548494983277592,0.9547738693467337,0.9563758389261745,0.9563025210084034,0.9562289562289562,0.9561551433389545,0.956081081081081,0.9560067681895094,0.9559322033898305,0.9558573853989814,0.95578231292517,0.9557069846678024,0.9556313993174061,0.9555555555555556,0.9554794520547946,0.9571183533447685,0.9570446735395189,0.9569707401032702,0.9586206896551724,0.9585492227979274,0.9584775086505191,0.9584055459272097,0.9583333333333334,0.9582608695652174,0.9581881533101045,0.9581151832460733,0.958041958041958,0.957968476357268,0.9578947368421052,0.9578207381370826,0.9577464788732394,0.9576719576719577,0.9575971731448764,0.95929203539823,0.9592198581560284,0.9591474245115453,0.9590747330960854,0.9590017825311943,0.9589285714285715,0.9588550983899821,0.9587813620071685,0.9587073608617595,0.9586330935251799,0.9585585585585585,0.9584837545126353,0.9584086799276673,0.9583333333333334,0.9582577132486388,0.9581818181818181,0.9581056466302368,0.958029197080292,0.9579524680073126,0.9578754578754579,0.9577981651376147,0.9577205882352942,0.9576427255985267,0.9575645756457565,0.9574861367837338,0.9574074074074074,0.9573283858998145,0.9572490706319703,0.957169459962756,0.957089552238806,0.9570093457943926,0.9569288389513109,0.9568480300187617,0.956766917293233,0.9566854990583804,0.9566037735849057,0.9565217391304348,0.9564393939393939,0.9563567362428842,0.9581749049429658,0.9580952380952381,0.9580152671755725,0.9579349904397706,0.9578544061302682,0.9577735124760077,0.9576923076923077,0.9576107899807321,0.9575289575289575,0.9574468085106383,0.9573643410852714,0.9572815533980582,0.9571984435797666,0.9590643274853801,0.958984375,0.958904109589041,0.9588235294117647,0.9587426326129665,0.9586614173228346,0.9585798816568047,0.958498023715415,0.9584158415841584,0.9583333333333334,0.9582504970178927,0.9581673306772909,0.9580838323353293,0.96,0.9599198396793587,0.9598393574297188,0.959758551307847,0.9596774193548387,0.9595959595959596,0.9595141700404858,0.9594320486815415,0.959349593495935,0.9592668024439919,0.9591836734693877,0.9591002044989775,0.9590163934426229,0.9589322381930184,0.9588477366255144,0.9587628865979382,0.9586776859504132,0.9585921325051759,0.9585062240663901,0.9584199584199584,0.9583333333333334,0.9582463465553236,0.9581589958158996,0.9580712788259959,0.957983193277311,0.9578947368421052,0.9578059071729957,0.9577167019027484,0.9576271186440678,0.9575371549893843,0.9574468085106383,0.9573560767590619,0.9572649572649573,0.9571734475374732,0.9570815450643777,0.956989247311828,0.9568965517241379,0.9568034557235421,0.9567099567099567,0.9566160520607375,0.9565217391304348,0.9564270152505446,0.9563318777292577,0.9562363238512035,0.9583333333333334,0.9582417582417583,0.9581497797356828,0.9580573951434879,0.9579646017699115,0.9578713968957872,0.9577777777777777,0.9576837416481069,0.9575892857142857,0.9574944071588367,0.9573991031390134,0.9573033707865168,0.9572072072072072,0.9571106094808126,0.9570135746606335,0.9569160997732427,0.9590909090909091,0.958997722095672,0.958904109589041,0.9588100686498856,0.9587155963302753,0.9586206896551724,0.9608294930875576,0.9607390300230947,0.9606481481481481,0.9605568445475638,0.9604651162790697,0.9603729603729604,0.9602803738317757,0.9601873536299765,0.960093896713615,0.96,0.9599056603773585,0.9598108747044918,0.9597156398104265,0.9596199524940617,0.9595238095238096,0.9594272076372315,0.9593301435406698,0.9592326139088729,0.9591346153846154,0.9590361445783132,0.9589371980676329,0.9588377723970944,0.9587378640776699,0.9586374695863747,0.9585365853658536,0.9584352078239609,0.9583333333333334,0.9582309582309583,0.958128078817734,0.9580246913580247,0.9603960396039604,0.9602977667493796,0.9601990049751243,0.9600997506234414,0.96,0.9598997493734336,0.9623115577889447,0.9622166246851386,0.9621212121212122,0.9645569620253165,0.9644670050761421,0.9643765903307888,0.9642857142857143,0.9641943734015346,0.9641025641025641,0.9640102827763496,0.9639175257731959,0.9638242894056848,0.966321243523316,0.9662337662337662,0.9661458333333334,0.9660574412532638,0.9659685863874345,0.9658792650918635,0.9657894736842105,0.9656992084432717,0.9656084656084656,0.9655172413793104,0.9654255319148937,0.968,0.9679144385026738,0.967828418230563,0.967741935483871,0.967654986522911,0.9675675675675676,0.967479674796748,0.967391304347826,0.9673024523160763,0.9672131147540983,0.9671232876712329,0.967032967032967,0.9669421487603306,0.9668508287292817,0.9667590027700831,0.9666666666666667,0.9665738161559888,0.9664804469273743,0.9663865546218487,0.9691011235955056,0.9690140845070423,0.9689265536723164,0.9688385269121813,0.96875,0.9686609686609686,0.9685714285714285,0.9684813753581661,0.9712643678160919,0.9711815561959655,0.9710982658959537,0.9710144927536232,0.9709302325581395,0.9708454810495627,0.9707602339181286,0.9706744868035191,0.9705882352941176,0.9705014749262537,0.9704142011834319,0.9703264094955489,0.9702380952380952,0.9701492537313433,0.9730538922155688,0.972972972972973,0.9728915662650602,0.972809667673716,0.9727272727272728,0.9726443768996961,0.9725609756097561,0.9724770642201835,0.9723926380368099,0.9723076923076923,0.9722222222222222,0.9721362229102167,0.9720496894409938,0.9719626168224299,0.971875,0.9717868338557993,0.9716981132075472,0.9716088328075709,0.9715189873417721,0.9714285714285714,0.9713375796178344,0.9712460063897763,0.9711538461538461,0.9710610932475884,0.9709677419354839,0.970873786407767,0.9707792207792207,0.9706840390879479,0.9705882352941176,0.9704918032786886,0.9703947368421053,0.9702970297029703,0.9735099337748344,0.973421926910299,0.9733333333333334,0.9732441471571907,0.9731543624161074,0.9730639730639731,0.972972972972973,0.9728813559322034,0.9727891156462585,0.9726962457337884,0.9726027397260274,0.9725085910652921,0.9724137931034482,0.972318339100346,0.9722222222222222,0.9721254355400697,0.972027972027972,0.9719298245614035,0.971830985915493,0.9717314487632509,0.9716312056737588,0.9715302491103203,0.9714285714285714,0.9713261648745519,0.9712230215827338,0.9711191335740073,0.9710144927536232,0.9709090909090909,0.9708029197080292,0.9706959706959707,0.9705882352941176,0.9704797047970479,0.9703703703703703,0.9702602230483272,0.9701492537313433,0.9700374531835206,0.9699248120300752,0.969811320754717,0.9696969696969697,0.9695817490494296,0.9694656488549618,0.9693486590038314,0.9692307692307692,0.9691119691119691,0.9689922480620154,0.9688715953307393,0.96875,0.9686274509803922,0.968503937007874,0.9683794466403162,0.9682539682539683,0.9681274900398407,0.968,0.9718875502008032,0.9717741935483871,0.97165991902834,0.9715447154471545,0.9714285714285714,0.9713114754098361,0.9711934156378601,0.9710743801652892,0.970954356846473,0.9708333333333333,0.9707112970711297,0.9705882352941176,0.9704641350210971,0.9745762711864406,0.9744680851063829,0.9743589743589743,0.9742489270386266,0.9741379310344828,0.974025974025974,0.9739130434782609,0.9737991266375546,0.9736842105263158,0.973568281938326,0.9734513274336283,0.9733333333333334,0.9732142857142857,0.9730941704035875,0.972972972972973,0.9728506787330317,0.9727272727272728,0.9726027397260274,0.9724770642201835,0.9723502304147466,0.9722222222222222,0.9720930232558139,0.9719626168224299,0.971830985915493,0.9716981132075472,0.9715639810426541,0.9714285714285714,0.9712918660287081,0.9711538461538461,0.9710144927536232,0.970873786407767,0.9707317073170731,0.9705882352941176,0.9704433497536946,0.9702970297029703,0.9701492537313433,0.97,0.9698492462311558,0.9696969696969697,0.9695431472081218,0.9693877551020408,0.9692307692307692,0.9690721649484536,0.9689119170984456,0.96875,0.9685863874345549,0.968421052631579,0.9682539682539683,0.9680851063829787,0.9679144385026738,0.967741935483871,0.9675675675675676,0.967391304347826,0.9672131147540983,0.967032967032967,0.9668508287292817,0.9666666666666667,0.9664804469273743,0.9662921348314607,0.9661016949152542,0.9715909090909091,0.9714285714285714,0.9712643678160919,0.9710982658959537,0.9709302325581395,0.9707602339181286,0.9705882352941176,0.9704142011834319,0.9702380952380952,0.9700598802395209,0.9698795180722891,0.9696969696969697,0.9695121951219512,0.9693251533742331,0.9691358024691358,0.968944099378882,0.96875,0.9685534591194969,0.9683544303797469,0.9681528662420382,0.967948717948718,0.967741935483871,0.9675324675324676,0.9673202614379085,0.9671052631578947,0.9668874172185431,0.9666666666666667,0.9664429530201343,0.9662162162162162,0.9659863945578231,0.9657534246575342,0.9655172413793104,0.9652777777777778,0.965034965034965,0.9647887323943662,0.9645390070921985,0.9642857142857143,0.9640287769784173,0.9637681159420289,0.9635036496350365,0.9632352941176471,0.9629629629629629,0.9626865671641791,0.9624060150375939,0.9621212121212122,0.9618320610687023,0.9615384615384616,0.9612403100775194,0.9609375,0.9606299212598425,0.9603174603174603,0.96,0.9596774193548387,0.959349593495935,0.9590163934426229,0.9586776859504132,0.9583333333333334,0.957983193277311,0.9576271186440678,0.9572649572649573,0.9568965517241379,0.9565217391304348,0.956140350877193,0.9557522123893806,0.9642857142857143,0.963963963963964,0.9636363636363636,0.963302752293578,0.9722222222222222,0.9719626168224299,0.9716981132075472,0.9714285714285714,0.9711538461538461,0.970873786407767,0.9705882352941176,0.9801980198019802,0.98,0.9797979797979798,0.9795918367346939,0.979381443298969,0.9791666666666666,0.9789473684210527,0.9787234042553191,0.978494623655914,0.9782608695652174,0.978021978021978,0.9777777777777777,0.9775280898876404,0.9772727272727273,0.9770114942528736,0.9767441860465116,0.9764705882352941,0.9761904761904762,0.9759036144578314,0.975609756097561,0.9753086419753086,0.975,0.9746835443037974,0.9743589743589743,0.974025974025974,0.9736842105263158,0.9733333333333334,0.972972972972973,0.9726027397260274,0.9722222222222222,0.971830985915493,0.9714285714285714,0.9710144927536232,0.9705882352941176,0.9701492537313433,0.9696969696969697,0.9846153846153847,0.984375,0.9841269841269841,0.9838709677419355,0.9836065573770492,0.9833333333333333,0.9830508474576272,0.9827586206896551,0.9824561403508771,0.9821428571428571,0.9818181818181818,0.9814814814814815,0.9811320754716981,0.9807692307692307,0.9803921568627451,0.98,0.9795918367346939,0.9791666666666666,0.9787234042553191,0.9782608695652174,0.9777777777777777,0.9772727272727273,0.9767441860465116,0.9761904761904762,0.975609756097561,0.975,0.9743589743589743,0.9736842105263158,0.972972972972973,0.9722222222222222,0.9714285714285714,0.9705882352941176,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Recall\"},\"constrain\":\"domain\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Precision\"},\"scaleanchor\":\"x\",\"scaleratio\":1},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Precision-Recall Curve (AUC=0.8560)\"},\"height\":600,\"width\":800,\"shapes\":[{\"line\":{\"dash\":\"dash\"},\"type\":\"line\",\"x0\":0,\"x1\":1,\"y0\":1,\"y1\":0}],\"showlegend\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('a2365146-b54f-4618-813d-78d0a7afc006');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"}],"source":["target_score = log_clf.predict_proba(features_valid)[:, 1]\n","\n","fpr, tpr, thresholds = roc_curve(target_valid, target_score)\n","\n","fig = px.area(\n","    x=fpr, y=tpr,\n","    title=f'ROC Curve (AUC={auc(fpr, tpr):.4f})',\n","    labels=dict(x='False Positive Rate', y='True Positive Rate'),\n","    width=800, height=600\n",")\n","fig.add_shape(\n","    type='line', line=dict(dash='dash'),\n","    x0=0, x1=1, y0=0, y1=1\n",")\n","\n","fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n","fig.update_xaxes(constrain='domain')\n","fig.update_layout(showlegend=False)\n","fig.show()\n","\n","precision, recall, thresholds = precision_recall_curve(target_valid, target_score)\n","\n","fig = px.area(\n","    x=recall, y=precision,\n","    title=f'Precision-Recall Curve (AUC={auc(fpr, tpr):.4f})',\n","    labels=dict(x='Recall', y='Precision'),\n","    width=800, height=600\n",")\n","fig.add_shape(\n","    type='line', line=dict(dash='dash'),\n","    x0=0, x1=1, y0=1, y1=0\n",")\n","fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n","fig.update_xaxes(constrain='domain')\n","fig.update_layout(showlegend=False)\n","fig.show()"]},{"cell_type":"markdown","metadata":{},"source":["-------"]},{"cell_type":"markdown","metadata":{},"source":["# Ridge Classification"]},{"cell_type":"code","execution_count":645,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T16:53:45.727614Z","iopub.status.busy":"2023-11-30T16:53:45.727326Z","iopub.status.idle":"2023-11-30T16:53:53.993580Z","shell.execute_reply":"2023-11-30T16:53:53.992668Z","shell.execute_reply.started":"2023-11-30T16:53:45.727589Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Runtime:\n"]}],"source":["ridge_model = RidgeClassifier(random_state=random_state)\n","ridge_parameters = [{\"alpha\": list(range(0,1000)), \n","                     \"fit_intercept\": [True, False], \n","                     \"solver\": ['svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']}]\n","\n","ridge_clf = RandomizedSearchCV(ridge_model, ridge_parameters, scoring='roc_auc', n_jobs=-1, cv=cv)\n","ridge_clf.fit(features_train, target_train)\n","# create a variable for the best model\n","best_ridge = ridge_clf.best_estimator_\n","ridge_pred = best_ridge.predict(features_valid)\n","print('Runtime:')"]},{"cell_type":"code","execution_count":646,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T16:53:53.995997Z","iopub.status.busy":"2023-11-30T16:53:53.995322Z","iopub.status.idle":"2023-11-30T16:53:55.327974Z","shell.execute_reply":"2023-11-30T16:53:55.326745Z","shell.execute_reply.started":"2023-11-30T16:53:53.995962Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Cross Validation Scores: [0.84617808 0.83467742 0.85218894 0.77952189 0.81604263 0.84153226\n"," 0.8        0.80063364 0.85821197 0.83434466 0.8157631  0.80884217\n"," 0.82825461 0.81782834 0.85132488 0.81730991 0.83090438 0.80095046\n"," 0.841684   0.83287101 0.78468941 0.83548387 0.85538594 0.83084677\n"," 0.82272465 0.84720622 0.83977535 0.82825461 0.82033056 0.78730351\n"," 0.82587278 0.8155818  0.81201037 0.83666475 0.84881912 0.85192972\n"," 0.80815092 0.80918779 0.83434466 0.82350902 0.81942893 0.82675691\n"," 0.81466014 0.79795507 0.83372696 0.8249712  0.85567396 0.83231567\n"," 0.83394013 0.831773  ]\n"]}],"source":["ridge_scores = cross_val_score(ridge_model, features_train, target_train, cv=cv, scoring='roc_auc')\n","print('Cross Validation Scores: {}'.format(ridge_scores))"]},{"cell_type":"code","execution_count":647,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T16:53:55.330829Z","iopub.status.busy":"2023-11-30T16:53:55.329727Z","iopub.status.idle":"2023-11-30T16:53:55.339315Z","shell.execute_reply":"2023-11-30T16:53:55.338321Z","shell.execute_reply.started":"2023-11-30T16:53:55.330795Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Best hyperparameters: {'solver': 'svd', 'fit_intercept': True, 'alpha': 157}\n","\n","Best score: 0.8254656537214189\n","\n","Average Cross Validation Score: 0.8259667628691291\n"]}],"source":["# summary\n","print('Best hyperparameters:',  ridge_clf.best_params_)\n","print()\n","print('Best score:',  ridge_clf.best_score_)\n","print()\n","print('Average Cross Validation Score: {}'.format(ridge_scores.mean()))"]},{"cell_type":"markdown","metadata":{},"source":["-------"]},{"cell_type":"markdown","metadata":{},"source":["# LightGBM"]},{"cell_type":"code","execution_count":648,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T16:53:55.342580Z","iopub.status.busy":"2023-11-30T16:53:55.341944Z","iopub.status.idle":"2023-11-30T16:54:28.984603Z","shell.execute_reply":"2023-11-30T16:54:28.983717Z","shell.execute_reply.started":"2023-11-30T16:53:55.342548Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008197 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008258 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008116 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008061 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008162 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008635 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007423 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.197030 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000857 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005083 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002641 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001559 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002950 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004796 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005912 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002715 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001198 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003727 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029053 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004223 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000651 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002339 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001750 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003203 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000909 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013973 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001447 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010908 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000928 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001999 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012033 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002596 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002075 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001718 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002424 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002302 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001403 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001412 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000881 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007418 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007875 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001428 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002493 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016203 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001677 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002936 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002237 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000684 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004271 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000658 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 570\n","\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002189 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.215224 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007121 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009912 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003616 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002851 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001392 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.168884 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002397 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008946 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n","[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001994 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024141 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008116 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003614 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009575 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000608 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003323 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002732 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003741 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000795 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004962 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000824 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015413 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000612 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004182 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025732 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008344 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001125 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007307 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000571 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002617 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001623 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.084232 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001840 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001797 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003003 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000615 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026047 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003617 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.121699 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003283 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009299 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000602 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005320 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000687 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001719 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014554 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001921 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.057958 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007020 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000662 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000751 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003840 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003041 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001752 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001269 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033268 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005362 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007327 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007089 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.133608 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004289 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000513 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002429 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001009 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001694 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001331 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004055 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002858 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004398 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017491 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.112482 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004674 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001938 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001695 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003138 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005959 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001857 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002243 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001233 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006147 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002721 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004509 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.132966 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001214 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001362 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003337 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001811 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019475 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006408 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005677 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001354 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001396 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010627 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.253523 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003910 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009648 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001259 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011508 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032078 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005241 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001412 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.138285 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004701 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000945 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004531 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001756 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006138 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003510 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002058 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001595 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040702 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002645 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001804 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001983 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001829 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001574 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001714 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002140 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001735 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001770 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001458 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001770 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004258 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001728 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010442 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001809 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003249 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000734 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001618 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003614 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002697 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004114 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004353 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009846 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001111 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002833 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001847 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001269 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001142 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002131 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003739 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001320 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001883 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023970 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001500 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001669 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004072 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000907 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001819 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003119 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.126914 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038027 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.063622 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002551 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001583 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001636 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001634 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003580 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002851 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001261 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001901 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001646 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003171 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041765 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046745 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003130 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010847 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003864 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004078 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.049376 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004736 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004962 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.[LightGBM] [Info] Total Bins 570\n","\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.160399 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025538 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003288 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018882 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003365 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001797 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002365 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005328 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003298 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003312 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004824 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004674 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004144 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002633 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003913 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003867 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001989 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003104 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002833 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003525 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003286 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002342 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002996 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005335 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002718 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002509 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.081901 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.062133 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002861 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002779 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002923 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004565 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003205 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002870 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003828 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005208 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034484 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006907 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003536 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003006 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.081417 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.129048 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005607 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002470 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002510 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002302 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002188 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003810 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018894 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002862 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018817 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003367 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059553 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001947 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009856 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005079 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002458 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003097 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001933 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001108 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002269 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003690 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002090 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.133911 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002635 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002545 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.129999 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002317 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003917 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005657 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007655 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005974 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001541 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015126 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003672 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002013 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002168 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002018 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005469 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001862 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002085 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012813 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002777 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002997 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002377 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002012 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.3, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001303 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002270 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001914 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002502 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007802 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002851 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002673 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002178 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003530 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002019 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006771 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009971 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Total Bins 570\n","\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018057 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002543 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009546 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010957 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001025 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001785 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002048 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002773 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002633 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008014 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002718 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002782 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004493 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002446 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007347 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003402 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003555 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011876 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.085472 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001911 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002366 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002222 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026076 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002348 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002261 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002613 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002422 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005718 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004755 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n"]},{"name":"stderr","output_type":"stream","text":["[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /private/var/folders/wc/6x35sr293njgq8g1xgc9fzlm0000gn/T/pip-install-6ex9ihsl/lightgbm_69c33b30bfb64530b2236e55e790ae94/src/boosting/rf.hpp, line 37 .\n","\n","[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /private/var/folders/wc/6x35sr293njgq8g1xgc9fzlm0000gn/T/pip-install-6ex9ihsl/lightgbm_69c33b30bfb64530b2236e55e790ae94/src/boosting/rf.hpp, line 37 .\n","\n","[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /private/var/folders/wc/6x35sr293njgq8g1xgc9fzlm0000gn/T/pip-install-6ex9ihsl/lightgbm_69c33b30bfb64530b2236e55e790ae94/src/boosting/rf.hpp, line 37 .\n","\n","[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /private/var/folders/wc/6x35sr293njgq8g1xgc9fzlm0000gn/T/pip-install-6ex9ihsl/lightgbm_69c33b30bfb64530b2236e55e790ae94/src/boosting/rf.hpp, line 37 .\n","\n","[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /private/var/folders/wc/6x35sr293njgq8g1xgc9fzlm0000gn/T/pip-install-6ex9ihsl/lightgbm_69c33b30bfb64530b2236e55e790ae94/src/boosting/rf.hpp, line 37 .\n","\n","[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /private/var/folders/wc/6x35sr293njgq8g1xgc9fzlm0000gn/T/pip-install-6ex9ihsl/lightgbm_69c33b30bfb64530b2236e55e790ae94/src/boosting/rf.hpp, line 37 .\n","\n","[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /private/var/folders/wc/6x35sr293njgq8g1xgc9fzlm0000gn/T/pip-install-6ex9ihsl/lightgbm_69c33b30bfb64530b2236e55e790ae94/src/boosting/rf.hpp, line 37 .\n","\n","[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /private/var/folders/wc/6x35sr293njgq8g1xgc9fzlm0000gn/T/pip-install-6ex9ihsl/lightgbm_69c33b30bfb64530b2236e55e790ae94/src/boosting/rf.hpp, line 37 .\n","\n","[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /private/var/folders/wc/6x35sr293njgq8g1xgc9fzlm0000gn/T/pip-install-6ex9ihsl/lightgbm_69c33b30bfb64530b2236e55e790ae94/src/boosting/rf.hpp, line 37 .\n","\n","[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /private/var/folders/wc/6x35sr293njgq8g1xgc9fzlm0000gn/T/pip-install-6ex9ihsl/lightgbm_69c33b30bfb64530b2236e55e790ae94/src/boosting/rf.hpp, line 37 .\n","\n","[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /private/var/folders/wc/6x35sr293njgq8g1xgc9fzlm0000gn/T/pip-install-6ex9ihsl/lightgbm_69c33b30bfb64530b2236e55e790ae94/src/boosting/rf.hpp, line 37 .\n","\n","[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /private/var/folders/wc/6x35sr293njgq8g1xgc9fzlm0000gn/T/pip-install-6ex9ihsl/lightgbm_69c33b30bfb64530b2236e55e790ae94/src/boosting/rf.hpp, line 37 .\n","\n","[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /private/var/folders/wc/6x35sr293njgq8g1xgc9fzlm0000gn/T/pip-install-6ex9ihsl/lightgbm_69c33b30bfb64530b2236e55e790ae94/src/boosting/rf.hpp, line 37 .\n","\n","[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /private/var/folders/wc/6x35sr293njgq8g1xgc9fzlm0000gn/T/pip-install-6ex9ihsl/lightgbm_69c33b30bfb64530b2236e55e790ae94/src/boosting/rf.hpp, line 37 .\n","\n","[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /private/var/folders/wc/6x35sr293njgq8g1xgc9fzlm0000gn/T/pip-install-6ex9ihsl/lightgbm_69c33b30bfb64530b2236e55e790ae94/src/boosting/rf.hpp, line 37 .\n","\n","[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /private/var/folders/wc/6x35sr293njgq8g1xgc9fzlm0000gn/T/pip-install-6ex9ihsl/lightgbm_69c33b30bfb64530b2236e55e790ae94/src/boosting/rf.hpp, line 37 .\n","\n","[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /private/var/folders/wc/6x35sr293njgq8g1xgc9fzlm0000gn/T/pip-install-6ex9ihsl/lightgbm_69c33b30bfb64530b2236e55e790ae94/src/boosting/rf.hpp, line 37 .\n","\n","[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /private/var/folders/wc/6x35sr293njgq8g1xgc9fzlm0000gn/T/pip-install-6ex9ihsl/lightgbm_69c33b30bfb64530b2236e55e790ae94/src/boosting/rf.hpp, line 37 .\n","\n","[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /private/var/folders/wc/6x35sr293njgq8g1xgc9fzlm0000gn/T/pip-install-6ex9ihsl/lightgbm_69c33b30bfb64530b2236e55e790ae94/src/boosting/rf.hpp, line 37 .\n","\n"]},{"name":"stdout","output_type":"stream","text":["[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009"]},{"name":"stderr","output_type":"stream","text":["[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /private/var/folders/wc/6x35sr293njgq8g1xgc9fzlm0000gn/T/pip-install-6ex9ihsl/lightgbm_69c33b30bfb64530b2236e55e790ae94/src/boosting/rf.hpp, line 37 .\n","\n","[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /private/var/folders/wc/6x35sr293njgq8g1xgc9fzlm0000gn/T/pip-install-6ex9ihsl/lightgbm_69c33b30bfb64530b2236e55e790ae94/src/boosting/rf.hpp, line 37 .\n","\n","[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /private/var/folders/wc/6x35sr293njgq8g1xgc9fzlm0000gn/T/pip-install-6ex9ihsl/lightgbm_69c33b30bfb64530b2236e55e790ae94/src/boosting/rf.hpp, line 37 .\n","\n","[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /private/var/folders/wc/6x35sr293njgq8g1xgc9fzlm0000gn/T/pip-install-6ex9ihsl/lightgbm_69c33b30bfb64530b2236e55e790ae94/src/boosting/rf.hpp, line 37 .\n","\n","[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /private/var/folders/wc/6x35sr293njgq8g1xgc9fzlm0000gn/T/pip-install-6ex9ihsl/lightgbm_69c33b30bfb64530b2236e55e790ae94/src/boosting/rf.hpp, line 37 .\n","\n","[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /private/var/folders/wc/6x35sr293njgq8g1xgc9fzlm0000gn/T/pip-install-6ex9ihsl/lightgbm_69c33b30bfb64530b2236e55e790ae94/src/boosting/rf.hpp, line 37 .\n","\n","[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /private/var/folders/wc/6x35sr293njgq8g1xgc9fzlm0000gn/T/pip-install-6ex9ihsl/lightgbm_69c33b30bfb64530b2236e55e790ae94/src/boosting/rf.hpp, line 37 .\n","\n","[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /private/var/folders/wc/6x35sr293njgq8g1xgc9fzlm0000gn/T/pip-install-6ex9ihsl/lightgbm_69c33b30bfb64530b2236e55e790ae94/src/boosting/rf.hpp, line 37 .\n","\n","[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /private/var/folders/wc/6x35sr293njgq8g1xgc9fzlm0000gn/T/pip-install-6ex9ihsl/lightgbm_69c33b30bfb64530b2236e55e790ae94/src/boosting/rf.hpp, line 37 .\n","\n","[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /private/var/folders/wc/6x35sr293njgq8g1xgc9fzlm0000gn/T/pip-install-6ex9ihsl/lightgbm_69c33b30bfb64530b2236e55e790ae94/src/boosting/rf.hpp, line 37 .\n","\n","[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /private/var/folders/wc/6x35sr293njgq8g1xgc9fzlm0000gn/T/pip-install-6ex9ihsl/lightgbm_69c33b30bfb64530b2236e55e790ae94/src/boosting/rf.hpp, line 37 .\n","\n","[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /private/var/folders/wc/6x35sr293njgq8g1xgc9fzlm0000gn/T/pip-install-6ex9ihsl/lightgbm_69c33b30bfb64530b2236e55e790ae94/src/boosting/rf.hpp, line 37 .\n","\n","[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /private/var/folders/wc/6x35sr293njgq8g1xgc9fzlm0000gn/T/pip-install-6ex9ihsl/lightgbm_69c33b30bfb64530b2236e55e790ae94/src/boosting/rf.hpp, line 37 .\n","\n","[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /private/var/folders/wc/6x35sr293njgq8g1xgc9fzlm0000gn/T/pip-install-6ex9ihsl/lightgbm_69c33b30bfb64530b2236e55e790ae94/src/boosting/rf.hpp, line 37 .\n","\n","[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /private/var/folders/wc/6x35sr293njgq8g1xgc9fzlm0000gn/T/pip-install-6ex9ihsl/lightgbm_69c33b30bfb64530b2236e55e790ae94/src/boosting/rf.hpp, line 37 .\n","\n","[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /private/var/folders/wc/6x35sr293njgq8g1xgc9fzlm0000gn/T/pip-install-6ex9ihsl/lightgbm_69c33b30bfb64530b2236e55e790ae94/src/boosting/rf.hpp, line 37 .\n","\n","[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /private/var/folders/wc/6x35sr293njgq8g1xgc9fzlm0000gn/T/pip-install-6ex9ihsl/lightgbm_69c33b30bfb64530b2236e55e790ae94/src/boosting/rf.hpp, line 37 .\n","\n","[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /private/var/folders/wc/6x35sr293njgq8g1xgc9fzlm0000gn/T/pip-install-6ex9ihsl/lightgbm_69c33b30bfb64530b2236e55e790ae94/src/boosting/rf.hpp, line 37 .\n","\n","[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /private/var/folders/wc/6x35sr293njgq8g1xgc9fzlm0000gn/T/pip-install-6ex9ihsl/lightgbm_69c33b30bfb64530b2236e55e790ae94/src/boosting/rf.hpp, line 37 .\n","\n","[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /private/var/folders/wc/6x35sr293njgq8g1xgc9fzlm0000gn/T/pip-install-6ex9ihsl/lightgbm_69c33b30bfb64530b2236e55e790ae94/src/boosting/rf.hpp, line 37 .\n","\n","[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /private/var/folders/wc/6x35sr293njgq8g1xgc9fzlm0000gn/T/pip-install-6ex9ihsl/lightgbm_69c33b30bfb64530b2236e55e790ae94/src/boosting/rf.hpp, line 37 .\n","\n","[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /private/var/folders/wc/6x35sr293njgq8g1xgc9fzlm0000gn/T/pip-install-6ex9ihsl/lightgbm_69c33b30bfb64530b2236e55e790ae94/src/boosting/rf.hpp, line 37 .\n","\n","[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /private/var/folders/wc/6x35sr293njgq8g1xgc9fzlm0000gn/T/pip-install-6ex9ihsl/lightgbm_69c33b30bfb64530b2236e55e790ae94/src/boosting/rf.hpp, line 37 .\n","\n","[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /private/var/folders/wc/6x35sr293njgq8g1xgc9fzlm0000gn/T/pip-install-6ex9ihsl/lightgbm_69c33b30bfb64530b2236e55e790ae94/src/boosting/rf.hpp, line 37 .\n","\n","[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /private/var/folders/wc/6x35sr293njgq8g1xgc9fzlm0000gn/T/pip-install-6ex9ihsl/lightgbm_69c33b30bfb64530b2236e55e790ae94/src/boosting/rf.hpp, line 37 .\n","\n","[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /private/var/folders/wc/6x35sr293njgq8g1xgc9fzlm0000gn/T/pip-install-6ex9ihsl/lightgbm_69c33b30bfb64530b2236e55e790ae94/src/boosting/rf.hpp, line 37 .\n","\n","[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /private/var/folders/wc/6x35sr293njgq8g1xgc9fzlm0000gn/T/pip-install-6ex9ihsl/lightgbm_69c33b30bfb64530b2236e55e790ae94/src/boosting/rf.hpp, line 37 .\n","\n","[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /private/var/folders/wc/6x35sr293njgq8g1xgc9fzlm0000gn/T/pip-install-6ex9ihsl/lightgbm_69c33b30bfb64530b2236e55e790ae94/src/boosting/rf.hpp, line 37 .\n","\n","[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /private/var/folders/wc/6x35sr293njgq8g1xgc9fzlm0000gn/T/pip-install-6ex9ihsl/lightgbm_69c33b30bfb64530b2236e55e790ae94/src/boosting/rf.hpp, line 37 .\n","\n"]},{"name":"stdout","output_type":"stream","text":["\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002910 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006668 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013009 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005713 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011023 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010973 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009114 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013940 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n"]},{"name":"stderr","output_type":"stream","text":["[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /private/var/folders/wc/6x35sr293njgq8g1xgc9fzlm0000gn/T/pip-install-6ex9ihsl/lightgbm_69c33b30bfb64530b2236e55e790ae94/src/boosting/rf.hpp, line 37 .\n","\n","[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /private/var/folders/wc/6x35sr293njgq8g1xgc9fzlm0000gn/T/pip-install-6ex9ihsl/lightgbm_69c33b30bfb64530b2236e55e790ae94/src/boosting/rf.hpp, line 37 .\n","\n"]},{"name":"stdout","output_type":"stream","text":["[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016888 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002560 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002370 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002355 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007610 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001937 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002084 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019935 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006615 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006919 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004779 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006969 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002137 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001916 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002956 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001743 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003736 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002195 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003781 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002061 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001976 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003630 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003622 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005235 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001694 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002028 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002026 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.064610 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002186 seconds.\n","You can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001996 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001444 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003146 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002049 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001851 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001567 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007010 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019939 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002523 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20[LightGBM] [Info] Start training from score 1.017356\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003601 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006011 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002242 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002347 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011072 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013638 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002358 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002991 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.129657 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004948 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002950 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001818 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002300 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.1\n","[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n","[LightGBM] [Warning] min_data_in_leaf is set=30, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=30\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002129 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003378 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003643 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011463 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.093390 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003479 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002265 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001833 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.055265 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002825 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002813 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003432 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005715 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.056917 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000701 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035685 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002974 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004062 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002692 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005569 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002495 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003208 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002550 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003722 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030847 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002598 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002399 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002802 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006007 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026489 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002358 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003891 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002856 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003350 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013923 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002926 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013969 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002284 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002374 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002142 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020388 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n","[LightGBM] [Warning] bagging_fraction is set=0.1, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","[LightGBM] [Info] Number of positive: 3097, number of negative: 1121\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004067 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 4218, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734234 -> initscore=1.016213\n","[LightGBM] [Info] Start training from score 1.016213\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","Runtime:\n","CPU times: user 1.36 s, sys: 1.74 s, total: 3.1 s\n","Wall time: 1min 52s\n"]}],"source":["%%time\n","\n","lgb_model = lgb.LGBMClassifier(random_state=random_state)\n","\n","lgb_params = {\n","#'objective': ['binary'],\n","'boosting_type': ['gbdt', 'dart', 'rf'],\n","'num_leaves': [1,6,8,12,22,26,28,31,35,40],\n","'learning_rate': [0.001,0.01, 0.05, 0.08, 0.09, 0.1, 0.11, 0.15, 0.2, 0.3, 0.5, 0.7, 0.8, 0.9, 1],\n","'feature_fraction': [0.1, 0.2, 0.5, 0.6, 0.8, 0.9, 1],\n","'max_depth': [1,6,8,12,15,18,22,25,30],\n","'min_data_in_leaf': [20,25,30],\n","'bagging_fraction': [0.1,0.3,0.5,0.7,1],\n","#'num_iterations': [1,6,8,12,20,22,30,35]\n","}\n","\n","lgb_clf = RandomizedSearchCV(lgb_model, lgb_params, scoring='roc_auc', n_jobs=10, cv=cv)\n","lgb_clf.fit(features_train, target_train)\n","# create a variable for the best model\n","best_lgb = lgb_clf.best_estimator_\n","lgb_pred = best_lgb.predict(features_valid)\n","print('Runtime:')"]},{"cell_type":"code","execution_count":677,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 1000x500 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["sns.set(style=\"white\", color_codes=True)\n","plt.rcParams['axes.linewidth'] = 0.1\n","\n","fig, ax = plt.subplots(figsize = (10,5))\n","disp = CalibrationDisplay.from_estimator(lgb_clf, features_valid, target_valid, ax=ax)\n","plt.title('Calibration Chart - LGBM Classifier', fontsize=10)\n","ax.set_xlabel('Mean predicted probability (Positive class: 1)', fontsize=10)\n","ax.set_ylabel('Fraction of positives (Positive class: 1)',fontsize=10)\n","\n","ax.tick_params(color='gray', labelcolor='gray')\n","for spine in ax.spines.values():\n","    spine.set_edgecolor('gray')\n","\n","\n","fig.tight_layout()\n","plt.legend(fontsize=8)\n","plt.show()"]},{"cell_type":"code","execution_count":650,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T16:54:28.989434Z","iopub.status.busy":"2023-11-30T16:54:28.988544Z","iopub.status.idle":"2023-11-30T16:54:34.691369Z","shell.execute_reply":"2023-11-30T16:54:34.690609Z","shell.execute_reply.started":"2023-11-30T16:54:28.989397Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002086 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000708 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000752 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000719 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000733 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000661 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000788 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000793 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000721 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000632 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000646 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000797 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000717 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000737 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000670 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000766 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000779 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000674 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000544 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000758 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000749 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000739 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000568 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000657 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000675 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000790 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000785 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000612 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000703 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000670 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000704 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000812 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000689 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000867 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000870 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000758 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000843 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000787 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000827 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000873 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1008\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000820 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734457 -> initscore=1.017356\n","[LightGBM] [Info] Start training from score 1.017356\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000763 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000505 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000659 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000728 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000609 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000979 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2787, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000734 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3796, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734194 -> initscore=1.016006\n","[LightGBM] [Info] Start training from score 1.016006\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000710 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","[LightGBM] [Info] Number of positive: 2788, number of negative: 1009\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000688 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 3797, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734264 -> initscore=1.016365\n","[LightGBM] [Info] Start training from score 1.016365\n","Cross Validation Scores: [0.92287424 0.89749424 0.92220622 0.87747696 0.92615207 0.90812212\n"," 0.89979839 0.89285714 0.92400601 0.90895169 0.87453103 0.88315092\n"," 0.90913018 0.89386521 0.9280818  0.91129032 0.93047235 0.88773041\n"," 0.92782016 0.91452843 0.88936621 0.90967742 0.91998848 0.90691244\n"," 0.896803   0.92540323 0.9203629  0.91627304 0.90531091 0.87956542\n"," 0.90652118 0.88513825 0.91071429 0.92404954 0.92315668 0.93585829\n"," 0.90374424 0.89331797 0.89820273 0.89901179 0.93034911 0.91826037\n"," 0.89017857 0.88680876 0.91751152 0.89363479 0.91687788 0.92707373\n"," 0.90406842 0.91874711]\n"]}],"source":["lgb_scores = cross_val_score(lgb_model, features_train, target_train, cv=cv, scoring='roc_auc')\n","print('Cross Validation Scores: {}'.format(lgb_scores))"]},{"cell_type":"code","execution_count":651,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T16:54:34.697463Z","iopub.status.busy":"2023-11-30T16:54:34.695161Z","iopub.status.idle":"2023-11-30T16:54:34.712956Z","shell.execute_reply":"2023-11-30T16:54:34.712295Z","shell.execute_reply.started":"2023-11-30T16:54:34.697431Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Best hyperparameters: {'num_leaves': 28, 'min_data_in_leaf': 20, 'max_depth': 22, 'learning_rate': 0.8, 'feature_fraction': 0.9, 'boosting_type': 'dart', 'bagging_fraction': 1}\n","\n","Best score: 0.9032872523472055\n","\n","Average Cross Validation Score: 0.9078685635877259\n","\n","[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n","ROC AUC Score - Validation Dataset: 0.9163021364490529\n"]}],"source":["# summary\n","print('Best hyperparameters:',  lgb_clf.best_params_)\n","print()\n","print('Best score:',  lgb_clf.best_score_)\n","print()\n","print('Average Cross Validation Score: {}'.format(lgb_scores.mean()))\n","print()\n","print('ROC AUC Score - Validation Dataset:',  roc_auc_score(target_valid, lgb_clf.predict_proba(features_valid)[:, 1]))"]},{"cell_type":"markdown","metadata":{},"source":["# ROC AUC Curve - LightGBM"]},{"cell_type":"code","execution_count":652,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T16:54:34.716893Z","iopub.status.busy":"2023-11-30T16:54:34.716406Z","iopub.status.idle":"2023-11-30T16:54:34.854502Z","shell.execute_reply":"2023-11-30T16:54:34.853716Z","shell.execute_reply.started":"2023-11-30T16:54:34.716859Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n","[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n","[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n"]},{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"fillpattern":{"shape":""},"hovertemplate":"False Positive Rate=%{x}<br>True Positive Rate=%{y}<extra></extra>","legendgroup":"","line":{"color":"#636efa"},"marker":{"symbol":"circle"},"mode":"lines","name":"","orientation":"v","showlegend":false,"stackgroup":"1","type":"scatter","x":[0,0,0,0.00267379679144385,0.00267379679144385,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.008021390374331552,0.008021390374331552,0.008021390374331552,0.008021390374331552,0.0106951871657754,0.0106951871657754,0.013368983957219251,0.013368983957219251,0.016042780748663103,0.016042780748663103,0.016042780748663103,0.016042780748663103,0.0213903743315508,0.0213903743315508,0.02406417112299465,0.02406417112299465,0.026737967914438502,0.026737967914438502,0.029411764705882353,0.029411764705882353,0.03208556149732621,0.03208556149732621,0.034759358288770054,0.034759358288770054,0.034759358288770054,0.0374331550802139,0.0374331550802139,0.040106951871657755,0.040106951871657755,0.0427807486631016,0.0427807486631016,0.045454545454545456,0.045454545454545456,0.0481283422459893,0.0481283422459893,0.05080213903743316,0.05080213903743316,0.053475935828877004,0.053475935828877004,0.05614973262032086,0.05614973262032086,0.058823529411764705,0.058823529411764705,0.06149732620320856,0.06149732620320856,0.06417112299465241,0.06417112299465241,0.06684491978609626,0.06684491978609626,0.06951871657754011,0.06951871657754011,0.07219251336898395,0.07219251336898395,0.0748663101604278,0.0748663101604278,0.07754010695187166,0.07754010695187166,0.08021390374331551,0.08021390374331551,0.08288770053475936,0.08288770053475936,0.08823529411764706,0.08823529411764706,0.09090909090909091,0.09090909090909091,0.09358288770053476,0.09358288770053476,0.0962566844919786,0.0962566844919786,0.09893048128342247,0.09893048128342247,0.10160427807486631,0.10160427807486631,0.10427807486631016,0.10427807486631016,0.10695187165775401,0.10695187165775401,0.10962566844919786,0.10962566844919786,0.10962566844919786,0.10962566844919786,0.11229946524064172,0.11229946524064172,0.11497326203208556,0.11497326203208556,0.11764705882352941,0.11764705882352941,0.12032085561497326,0.12032085561497326,0.12299465240641712,0.12299465240641712,0.12566844919786097,0.12566844919786097,0.12834224598930483,0.12834224598930483,0.12834224598930483,0.12834224598930483,0.13101604278074866,0.13101604278074866,0.13368983957219252,0.13368983957219252,0.13636363636363635,0.13636363636363635,0.13903743315508021,0.13903743315508021,0.14171122994652408,0.14171122994652408,0.1443850267379679,0.1443850267379679,0.14705882352941177,0.14705882352941177,0.1497326203208556,0.1497326203208556,0.15240641711229946,0.15240641711229946,0.15508021390374332,0.15508021390374332,0.15775401069518716,0.15775401069518716,0.16310160427807488,0.16310160427807488,0.16844919786096257,0.16844919786096257,0.1711229946524064,0.1711229946524064,0.17647058823529413,0.17647058823529413,0.17914438502673796,0.17914438502673796,0.18181818181818182,0.18181818181818182,0.18449197860962566,0.18449197860962566,0.18716577540106952,0.18716577540106952,0.18983957219251338,0.18983957219251338,0.19518716577540107,0.19518716577540107,0.19786096256684493,0.19786096256684493,0.20053475935828877,0.20053475935828877,0.20320855614973263,0.20320855614973263,0.20588235294117646,0.20588235294117646,0.20855614973262032,0.20855614973262032,0.21122994652406418,0.21122994652406418,0.2192513368983957,0.2192513368983957,0.22192513368983957,0.22192513368983957,0.22459893048128343,0.22459893048128343,0.22994652406417113,0.22994652406417113,0.23529411764705882,0.23529411764705882,0.24064171122994651,0.24064171122994651,0.24331550802139038,0.24331550802139038,0.24866310160427807,0.24866310160427807,0.25935828877005346,0.25935828877005346,0.2620320855614973,0.2620320855614973,0.2647058823529412,0.2647058823529412,0.2700534759358289,0.2700534759358289,0.2727272727272727,0.2727272727272727,0.27540106951871657,0.27540106951871657,0.27807486631016043,0.27807486631016043,0.2807486631016043,0.2807486631016043,0.28609625668449196,0.28609625668449196,0.2887700534759358,0.2887700534759358,0.2914438502673797,0.2914438502673797,0.29411764705882354,0.29411764705882354,0.30213903743315507,0.30213903743315507,0.3048128342245989,0.3048128342245989,0.31016042780748665,0.31016042780748665,0.31283422459893045,0.31283422459893045,0.3235294117647059,0.3235294117647059,0.32620320855614976,0.32620320855614976,0.33689839572192515,0.33689839572192515,0.34759358288770054,0.34759358288770054,0.3582887700534759,0.3582887700534759,0.3609625668449198,0.3609625668449198,0.3663101604278075,0.3663101604278075,0.3689839572192513,0.3689839572192513,0.38235294117647056,0.38235294117647056,0.39037433155080214,0.39037433155080214,0.4037433155080214,0.4037433155080214,0.4090909090909091,0.4090909090909091,0.4144385026737968,0.4144385026737968,0.41711229946524064,0.41711229946524064,0.4197860962566845,0.4197860962566845,0.42780748663101603,0.42780748663101603,0.43315508021390375,0.43315508021390375,0.4385026737967914,0.4385026737967914,0.4411764705882353,0.4411764705882353,0.44385026737967914,0.44385026737967914,0.4572192513368984,0.4572192513368984,0.46524064171123,0.46524064171123,0.4732620320855615,0.4732620320855615,0.47593582887700536,0.47593582887700536,0.4786096256684492,0.4786096256684492,0.48128342245989303,0.48128342245989303,0.4839572192513369,0.4839572192513369,0.5080213903743316,0.5080213903743316,0.5240641711229946,0.5240641711229946,0.5320855614973262,0.5374331550802139,0.5561497326203209,0.5561497326203209,0.56951871657754,0.56951871657754,0.5962566844919787,0.5962566844919787,0.6898395721925134,0.6951871657754011,0.8074866310160428,0.8128342245989305,0.9946524064171123,1],"xaxis":"x","y":[0,0.000968054211035818,0.05324298160696999,0.05324298160696999,0.08228460793804453,0.08228460793804453,0.10261374636979671,0.10454985479186835,0.1132623426911907,0.11713455953533398,0.12003872216844143,0.15779283639883834,0.15779283639883834,0.15972894482090996,0.16263310745401743,0.16456921587608905,0.16456921587608905,0.18780251694094868,0.18780251694094868,0.1994191674733785,0.1994191674733785,0.22942884801548888,0.2313649564375605,0.26040658276863504,0.26040658276863504,0.3020329138431752,0.3020329138431752,0.3727008712487899,0.3727008712487899,0.3765730880929332,0.3765730880929332,0.38818973862536305,0.38818973862536305,0.3910939012584705,0.3910939012584705,0.39303000968054214,0.409486931268151,0.409486931268151,0.4259438528557599,0.4259438528557599,0.4365924491771539,0.4365924491771539,0.45982575024201355,0.45982575024201355,0.4898354307841239,0.4898354307841239,0.5450145208131656,0.5450145208131656,0.5459825750242013,0.5459825750242013,0.5527589545014521,0.5527589545014521,0.5924491771539206,0.5924491771539206,0.6060019361084221,0.6060019361084221,0.6205227492739593,0.6205227492739593,0.6282671829622459,0.6282671829622459,0.6302032913843175,0.6302032913843175,0.6447241045498547,0.6447241045498547,0.648596321393998,0.648596321393998,0.6563407550822846,0.6563407550822846,0.675701839303001,0.675701839303001,0.6989351403678606,0.6989351403678606,0.6999031945788964,0.6999031945788964,0.7028073572120038,0.7028073572120038,0.7047434656340755,0.7047434656340755,0.712487899322362,0.712487899322362,0.718296224588577,0.718296224588577,0.7192642787996127,0.7192642787996127,0.7250726040658277,0.7250726040658277,0.7279767666989352,0.7279767666989352,0.7308809293320426,0.7308809293320426,0.7318489835430784,0.7337850919651501,0.739593417231365,0.739593417231365,0.7434656340755083,0.7434656340755083,0.7492739593417231,0.7492739593417231,0.7541142303969022,0.7541142303969022,0.755082284607938,0.755082284607938,0.7647628267182962,0.7647628267182962,0.7696030977734754,0.7696030977734754,0.7744433688286544,0.7763794772507261,0.7938044530493708,0.7938044530493708,0.8063891577928364,0.8063891577928364,0.8102613746369797,0.8102613746369797,0.8131655372700871,0.8131655372700871,0.8247821878025169,0.8247821878025169,0.8257502420135527,0.8257502420135527,0.8325266214908035,0.8325266214908035,0.8412391093901258,0.8412391093901258,0.850919651500484,0.850919651500484,0.8547918683446273,0.8547918683446273,0.856727976766699,0.856727976766699,0.8596321393998064,0.8596321393998064,0.861568247821878,0.861568247821878,0.8635043562439496,0.8635043562439496,0.8693126815101646,0.8693126815101646,0.8741529525653436,0.8741529525653436,0.8760890609874153,0.8760890609874153,0.8809293320425944,0.8809293320425944,0.8818973862536302,0.8818973862536302,0.882865440464666,0.882865440464666,0.8867376573088093,0.8867376573088093,0.8877057115198451,0.8877057115198451,0.8906098741529526,0.8906098741529526,0.8915779283639884,0.8915779283639884,0.8954501452081317,0.8954501452081317,0.8964181994191674,0.8964181994191674,0.8983543078412392,0.8983543078412392,0.9002904162633107,0.9002904162633107,0.9080348499515973,0.9080348499515973,0.9090029041626331,0.9090029041626331,0.9099709583736689,0.9099709583736689,0.9119070667957405,0.9119070667957405,0.9128751210067764,0.9128751210067764,0.9138431752178122,0.9138431752178122,0.9157792836398838,0.9157792836398838,0.9177153920619555,0.9177153920619555,0.9196515004840271,0.9196515004840271,0.9215876089060987,0.9215876089060987,0.9235237173281704,0.9235237173281704,0.925459825750242,0.925459825750242,0.9273959341723137,0.9273959341723137,0.9283639883833494,0.9283639883833494,0.9293320425943853,0.9293320425943853,0.9303000968054211,0.9303000968054211,0.9322362052274927,0.9322362052274927,0.9332042594385286,0.9332042594385286,0.9341723136495643,0.9341723136495643,0.9351403678606002,0.9351403678606002,0.936108422071636,0.936108422071636,0.9380445304937076,0.9380445304937076,0.9419167473378509,0.9419167473378509,0.9457889641819942,0.9457889641819942,0.9486931268151017,0.9486931268151017,0.9564375605033882,0.9564375605033882,0.9603097773475314,0.9603097773475314,0.9622458857696031,0.9622458857696031,0.9651500484027106,0.9651500484027106,0.968054211035818,0.968054211035818,0.9690222652468539,0.9690222652468539,0.9709583736689255,0.9709583736689255,0.9719264278799613,0.9719264278799613,0.972894482090997,0.972894482090997,0.9738625363020329,0.9738625363020329,0.9748305905130688,0.9748305905130688,0.9757986447241046,0.9757986447241046,0.9767666989351403,0.9767666989351403,0.978702807357212,0.978702807357212,0.9796708615682478,0.9796708615682478,0.9816069699903195,0.9816069699903195,0.9835430784123911,0.9835430784123911,0.9854791868344628,0.9854791868344628,0.9864472410454985,0.9864472410454985,0.9874152952565344,0.9874152952565344,0.9883833494675702,0.9883833494675702,0.989351403678606,0.989351403678606,0.9912875121006777,0.9912875121006777,0.9922555663117134,0.9922555663117134,0.9932236205227493,0.9932236205227493,0.9941916747337851,0.9941916747337851,0.995159728944821,0.995159728944821,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9980638915779284,0.9980638915779284,0.9990319457889641,0.9990319457889641,1,1,1,1,1,1,1],"yaxis":"y"}],"layout":{"height":600,"legend":{"tracegroupgap":0},"shapes":[{"line":{"dash":"dash"},"type":"line","x0":0,"x1":1,"y0":0,"y1":1}],"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"title":{"text":"ROC Curve (AUC=0.9163)"},"width":800,"xaxis":{"anchor":"y","constrain":"domain","domain":[0,1],"title":{"text":"False Positive Rate"}},"yaxis":{"anchor":"x","domain":[0,1],"scaleanchor":"x","scaleratio":1,"title":{"text":"True Positive Rate"}}}},"text/html":["<div>                            <div id=\"cad172ec-67e8-45e7-bc1e-b36466277da8\" class=\"plotly-graph-div\" style=\"height:600px; width:800px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"cad172ec-67e8-45e7-bc1e-b36466277da8\")) {                    Plotly.newPlot(                        \"cad172ec-67e8-45e7-bc1e-b36466277da8\",                        [{\"fillpattern\":{\"shape\":\"\"},\"hovertemplate\":\"False Positive Rate=%{x}\\u003cbr\\u003eTrue Positive Rate=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"stackgroup\":\"1\",\"x\":[0.0,0.0,0.0,0.00267379679144385,0.00267379679144385,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.0053475935828877,0.008021390374331552,0.008021390374331552,0.008021390374331552,0.008021390374331552,0.0106951871657754,0.0106951871657754,0.013368983957219251,0.013368983957219251,0.016042780748663103,0.016042780748663103,0.016042780748663103,0.016042780748663103,0.0213903743315508,0.0213903743315508,0.02406417112299465,0.02406417112299465,0.026737967914438502,0.026737967914438502,0.029411764705882353,0.029411764705882353,0.03208556149732621,0.03208556149732621,0.034759358288770054,0.034759358288770054,0.034759358288770054,0.0374331550802139,0.0374331550802139,0.040106951871657755,0.040106951871657755,0.0427807486631016,0.0427807486631016,0.045454545454545456,0.045454545454545456,0.0481283422459893,0.0481283422459893,0.05080213903743316,0.05080213903743316,0.053475935828877004,0.053475935828877004,0.05614973262032086,0.05614973262032086,0.058823529411764705,0.058823529411764705,0.06149732620320856,0.06149732620320856,0.06417112299465241,0.06417112299465241,0.06684491978609626,0.06684491978609626,0.06951871657754011,0.06951871657754011,0.07219251336898395,0.07219251336898395,0.0748663101604278,0.0748663101604278,0.07754010695187166,0.07754010695187166,0.08021390374331551,0.08021390374331551,0.08288770053475936,0.08288770053475936,0.08823529411764706,0.08823529411764706,0.09090909090909091,0.09090909090909091,0.09358288770053476,0.09358288770053476,0.0962566844919786,0.0962566844919786,0.09893048128342247,0.09893048128342247,0.10160427807486631,0.10160427807486631,0.10427807486631016,0.10427807486631016,0.10695187165775401,0.10695187165775401,0.10962566844919786,0.10962566844919786,0.10962566844919786,0.10962566844919786,0.11229946524064172,0.11229946524064172,0.11497326203208556,0.11497326203208556,0.11764705882352941,0.11764705882352941,0.12032085561497326,0.12032085561497326,0.12299465240641712,0.12299465240641712,0.12566844919786097,0.12566844919786097,0.12834224598930483,0.12834224598930483,0.12834224598930483,0.12834224598930483,0.13101604278074866,0.13101604278074866,0.13368983957219252,0.13368983957219252,0.13636363636363635,0.13636363636363635,0.13903743315508021,0.13903743315508021,0.14171122994652408,0.14171122994652408,0.1443850267379679,0.1443850267379679,0.14705882352941177,0.14705882352941177,0.1497326203208556,0.1497326203208556,0.15240641711229946,0.15240641711229946,0.15508021390374332,0.15508021390374332,0.15775401069518716,0.15775401069518716,0.16310160427807488,0.16310160427807488,0.16844919786096257,0.16844919786096257,0.1711229946524064,0.1711229946524064,0.17647058823529413,0.17647058823529413,0.17914438502673796,0.17914438502673796,0.18181818181818182,0.18181818181818182,0.18449197860962566,0.18449197860962566,0.18716577540106952,0.18716577540106952,0.18983957219251338,0.18983957219251338,0.19518716577540107,0.19518716577540107,0.19786096256684493,0.19786096256684493,0.20053475935828877,0.20053475935828877,0.20320855614973263,0.20320855614973263,0.20588235294117646,0.20588235294117646,0.20855614973262032,0.20855614973262032,0.21122994652406418,0.21122994652406418,0.2192513368983957,0.2192513368983957,0.22192513368983957,0.22192513368983957,0.22459893048128343,0.22459893048128343,0.22994652406417113,0.22994652406417113,0.23529411764705882,0.23529411764705882,0.24064171122994651,0.24064171122994651,0.24331550802139038,0.24331550802139038,0.24866310160427807,0.24866310160427807,0.25935828877005346,0.25935828877005346,0.2620320855614973,0.2620320855614973,0.2647058823529412,0.2647058823529412,0.2700534759358289,0.2700534759358289,0.2727272727272727,0.2727272727272727,0.27540106951871657,0.27540106951871657,0.27807486631016043,0.27807486631016043,0.2807486631016043,0.2807486631016043,0.28609625668449196,0.28609625668449196,0.2887700534759358,0.2887700534759358,0.2914438502673797,0.2914438502673797,0.29411764705882354,0.29411764705882354,0.30213903743315507,0.30213903743315507,0.3048128342245989,0.3048128342245989,0.31016042780748665,0.31016042780748665,0.31283422459893045,0.31283422459893045,0.3235294117647059,0.3235294117647059,0.32620320855614976,0.32620320855614976,0.33689839572192515,0.33689839572192515,0.34759358288770054,0.34759358288770054,0.3582887700534759,0.3582887700534759,0.3609625668449198,0.3609625668449198,0.3663101604278075,0.3663101604278075,0.3689839572192513,0.3689839572192513,0.38235294117647056,0.38235294117647056,0.39037433155080214,0.39037433155080214,0.4037433155080214,0.4037433155080214,0.4090909090909091,0.4090909090909091,0.4144385026737968,0.4144385026737968,0.41711229946524064,0.41711229946524064,0.4197860962566845,0.4197860962566845,0.42780748663101603,0.42780748663101603,0.43315508021390375,0.43315508021390375,0.4385026737967914,0.4385026737967914,0.4411764705882353,0.4411764705882353,0.44385026737967914,0.44385026737967914,0.4572192513368984,0.4572192513368984,0.46524064171123,0.46524064171123,0.4732620320855615,0.4732620320855615,0.47593582887700536,0.47593582887700536,0.4786096256684492,0.4786096256684492,0.48128342245989303,0.48128342245989303,0.4839572192513369,0.4839572192513369,0.5080213903743316,0.5080213903743316,0.5240641711229946,0.5240641711229946,0.5320855614973262,0.5374331550802139,0.5561497326203209,0.5561497326203209,0.56951871657754,0.56951871657754,0.5962566844919787,0.5962566844919787,0.6898395721925134,0.6951871657754011,0.8074866310160428,0.8128342245989305,0.9946524064171123,1.0],\"xaxis\":\"x\",\"y\":[0.0,0.000968054211035818,0.05324298160696999,0.05324298160696999,0.08228460793804453,0.08228460793804453,0.10261374636979671,0.10454985479186835,0.1132623426911907,0.11713455953533398,0.12003872216844143,0.15779283639883834,0.15779283639883834,0.15972894482090996,0.16263310745401743,0.16456921587608905,0.16456921587608905,0.18780251694094868,0.18780251694094868,0.1994191674733785,0.1994191674733785,0.22942884801548888,0.2313649564375605,0.26040658276863504,0.26040658276863504,0.3020329138431752,0.3020329138431752,0.3727008712487899,0.3727008712487899,0.3765730880929332,0.3765730880929332,0.38818973862536305,0.38818973862536305,0.3910939012584705,0.3910939012584705,0.39303000968054214,0.409486931268151,0.409486931268151,0.4259438528557599,0.4259438528557599,0.4365924491771539,0.4365924491771539,0.45982575024201355,0.45982575024201355,0.4898354307841239,0.4898354307841239,0.5450145208131656,0.5450145208131656,0.5459825750242013,0.5459825750242013,0.5527589545014521,0.5527589545014521,0.5924491771539206,0.5924491771539206,0.6060019361084221,0.6060019361084221,0.6205227492739593,0.6205227492739593,0.6282671829622459,0.6282671829622459,0.6302032913843175,0.6302032913843175,0.6447241045498547,0.6447241045498547,0.648596321393998,0.648596321393998,0.6563407550822846,0.6563407550822846,0.675701839303001,0.675701839303001,0.6989351403678606,0.6989351403678606,0.6999031945788964,0.6999031945788964,0.7028073572120038,0.7028073572120038,0.7047434656340755,0.7047434656340755,0.712487899322362,0.712487899322362,0.718296224588577,0.718296224588577,0.7192642787996127,0.7192642787996127,0.7250726040658277,0.7250726040658277,0.7279767666989352,0.7279767666989352,0.7308809293320426,0.7308809293320426,0.7318489835430784,0.7337850919651501,0.739593417231365,0.739593417231365,0.7434656340755083,0.7434656340755083,0.7492739593417231,0.7492739593417231,0.7541142303969022,0.7541142303969022,0.755082284607938,0.755082284607938,0.7647628267182962,0.7647628267182962,0.7696030977734754,0.7696030977734754,0.7744433688286544,0.7763794772507261,0.7938044530493708,0.7938044530493708,0.8063891577928364,0.8063891577928364,0.8102613746369797,0.8102613746369797,0.8131655372700871,0.8131655372700871,0.8247821878025169,0.8247821878025169,0.8257502420135527,0.8257502420135527,0.8325266214908035,0.8325266214908035,0.8412391093901258,0.8412391093901258,0.850919651500484,0.850919651500484,0.8547918683446273,0.8547918683446273,0.856727976766699,0.856727976766699,0.8596321393998064,0.8596321393998064,0.861568247821878,0.861568247821878,0.8635043562439496,0.8635043562439496,0.8693126815101646,0.8693126815101646,0.8741529525653436,0.8741529525653436,0.8760890609874153,0.8760890609874153,0.8809293320425944,0.8809293320425944,0.8818973862536302,0.8818973862536302,0.882865440464666,0.882865440464666,0.8867376573088093,0.8867376573088093,0.8877057115198451,0.8877057115198451,0.8906098741529526,0.8906098741529526,0.8915779283639884,0.8915779283639884,0.8954501452081317,0.8954501452081317,0.8964181994191674,0.8964181994191674,0.8983543078412392,0.8983543078412392,0.9002904162633107,0.9002904162633107,0.9080348499515973,0.9080348499515973,0.9090029041626331,0.9090029041626331,0.9099709583736689,0.9099709583736689,0.9119070667957405,0.9119070667957405,0.9128751210067764,0.9128751210067764,0.9138431752178122,0.9138431752178122,0.9157792836398838,0.9157792836398838,0.9177153920619555,0.9177153920619555,0.9196515004840271,0.9196515004840271,0.9215876089060987,0.9215876089060987,0.9235237173281704,0.9235237173281704,0.925459825750242,0.925459825750242,0.9273959341723137,0.9273959341723137,0.9283639883833494,0.9283639883833494,0.9293320425943853,0.9293320425943853,0.9303000968054211,0.9303000968054211,0.9322362052274927,0.9322362052274927,0.9332042594385286,0.9332042594385286,0.9341723136495643,0.9341723136495643,0.9351403678606002,0.9351403678606002,0.936108422071636,0.936108422071636,0.9380445304937076,0.9380445304937076,0.9419167473378509,0.9419167473378509,0.9457889641819942,0.9457889641819942,0.9486931268151017,0.9486931268151017,0.9564375605033882,0.9564375605033882,0.9603097773475314,0.9603097773475314,0.9622458857696031,0.9622458857696031,0.9651500484027106,0.9651500484027106,0.968054211035818,0.968054211035818,0.9690222652468539,0.9690222652468539,0.9709583736689255,0.9709583736689255,0.9719264278799613,0.9719264278799613,0.972894482090997,0.972894482090997,0.9738625363020329,0.9738625363020329,0.9748305905130688,0.9748305905130688,0.9757986447241046,0.9757986447241046,0.9767666989351403,0.9767666989351403,0.978702807357212,0.978702807357212,0.9796708615682478,0.9796708615682478,0.9816069699903195,0.9816069699903195,0.9835430784123911,0.9835430784123911,0.9854791868344628,0.9854791868344628,0.9864472410454985,0.9864472410454985,0.9874152952565344,0.9874152952565344,0.9883833494675702,0.9883833494675702,0.989351403678606,0.989351403678606,0.9912875121006777,0.9912875121006777,0.9922555663117134,0.9922555663117134,0.9932236205227493,0.9932236205227493,0.9941916747337851,0.9941916747337851,0.995159728944821,0.995159728944821,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9980638915779284,0.9980638915779284,0.9990319457889641,0.9990319457889641,1.0,1.0,1.0,1.0,1.0,1.0,1.0],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"False Positive Rate\"},\"constrain\":\"domain\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"True Positive Rate\"},\"scaleanchor\":\"x\",\"scaleratio\":1},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"ROC Curve (AUC=0.9163)\"},\"height\":600,\"width\":800,\"shapes\":[{\"line\":{\"dash\":\"dash\"},\"type\":\"line\",\"x0\":0,\"x1\":1,\"y0\":0,\"y1\":1}],\"showlegend\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('cad172ec-67e8-45e7-bc1e-b36466277da8');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"fillpattern":{"shape":""},"hovertemplate":"Recall=%{x}<br>Precision=%{y}<extra></extra>","legendgroup":"","line":{"color":"#636efa"},"marker":{"symbol":"circle"},"mode":"lines","name":"","orientation":"v","showlegend":false,"stackgroup":"1","type":"scatter","x":[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9970958373668926,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9932236205227493,0.9932236205227493,0.9922555663117134,0.9922555663117134,0.9912875121006777,0.9912875121006777,0.9903194578896418,0.989351403678606,0.989351403678606,0.9883833494675702,0.9883833494675702,0.9883833494675702,0.9883833494675702,0.9874152952565344,0.9874152952565344,0.9874152952565344,0.9874152952565344,0.9864472410454985,0.9864472410454985,0.9864472410454985,0.9864472410454985,0.9864472410454985,0.9864472410454985,0.9854791868344628,0.9854791868344628,0.9845111326234269,0.9835430784123911,0.9835430784123911,0.9825750242013552,0.9816069699903195,0.9816069699903195,0.9816069699903195,0.9806389157792836,0.9796708615682478,0.9796708615682478,0.9796708615682478,0.978702807357212,0.978702807357212,0.978702807357212,0.978702807357212,0.9777347531461762,0.9767666989351403,0.9767666989351403,0.9757986447241046,0.9757986447241046,0.9748305905130688,0.9748305905130688,0.9748305905130688,0.9738625363020329,0.9738625363020329,0.9738625363020329,0.972894482090997,0.972894482090997,0.972894482090997,0.972894482090997,0.972894482090997,0.972894482090997,0.9719264278799613,0.9719264278799613,0.9719264278799613,0.9719264278799613,0.9709583736689255,0.9709583736689255,0.9709583736689255,0.9709583736689255,0.9709583736689255,0.9709583736689255,0.9699903194578896,0.9690222652468539,0.9690222652468539,0.968054211035818,0.968054211035818,0.968054211035818,0.9670861568247822,0.9661181026137464,0.9651500484027106,0.9651500484027106,0.9641819941916747,0.9632139399806389,0.9622458857696031,0.9622458857696031,0.9622458857696031,0.9622458857696031,0.9622458857696031,0.9612778315585673,0.9603097773475314,0.9603097773475314,0.9603097773475314,0.9603097773475314,0.9603097773475314,0.9593417231364957,0.9583736689254598,0.957405614714424,0.9564375605033882,0.9564375605033882,0.9564375605033882,0.9564375605033882,0.9564375605033882,0.9554695062923524,0.9545014520813165,0.9535333978702807,0.952565343659245,0.9515972894482091,0.9506292352371732,0.9496611810261375,0.9486931268151017,0.9486931268151017,0.9477250726040658,0.9467570183930301,0.9457889641819942,0.9457889641819942,0.9457889641819942,0.9457889641819942,0.9457889641819942,0.9448209099709584,0.9438528557599225,0.9428848015488868,0.9419167473378509,0.9419167473378509,0.9409486931268151,0.9399806389157793,0.9390125847047435,0.9380445304937076,0.9380445304937076,0.9380445304937076,0.9370764762826719,0.936108422071636,0.936108422071636,0.9351403678606002,0.9351403678606002,0.9351403678606002,0.9351403678606002,0.9341723136495643,0.9341723136495643,0.9332042594385286,0.9332042594385286,0.9322362052274927,0.9322362052274927,0.9312681510164569,0.9303000968054211,0.9303000968054211,0.9303000968054211,0.9293320425943853,0.9293320425943853,0.9283639883833494,0.9283639883833494,0.9273959341723137,0.9273959341723137,0.9264278799612778,0.925459825750242,0.925459825750242,0.9244917715392061,0.9235237173281704,0.9235237173281704,0.9235237173281704,0.9225556631171346,0.9215876089060987,0.9215876089060987,0.920619554695063,0.9196515004840271,0.9196515004840271,0.9186834462729913,0.9177153920619555,0.9177153920619555,0.9177153920619555,0.9177153920619555,0.9177153920619555,0.9167473378509197,0.9157792836398838,0.9157792836398838,0.9157792836398838,0.914811229428848,0.9138431752178122,0.9138431752178122,0.9128751210067764,0.9128751210067764,0.9128751210067764,0.9119070667957405,0.9119070667957405,0.9119070667957405,0.9109390125847048,0.9099709583736689,0.9099709583736689,0.9099709583736689,0.9090029041626331,0.9090029041626331,0.9080348499515973,0.9080348499515973,0.9070667957405615,0.9060987415295256,0.9051306873184899,0.904162633107454,0.9031945788964182,0.9022265246853823,0.9012584704743466,0.9002904162633107,0.9002904162633107,0.9002904162633107,0.9002904162633107,0.8993223620522749,0.8983543078412392,0.8983543078412392,0.8973862536302033,0.8964181994191674,0.8964181994191674,0.8954501452081317,0.8954501452081317,0.8944820909970959,0.89351403678606,0.8925459825750242,0.8915779283639884,0.8915779283639884,0.8906098741529526,0.8906098741529526,0.8896418199419167,0.888673765730881,0.8877057115198451,0.8877057115198451,0.8867376573088093,0.8867376573088093,0.8867376573088093,0.8857696030977735,0.8848015488867377,0.8838334946757018,0.882865440464666,0.882865440464666,0.8818973862536302,0.8818973862536302,0.8809293320425944,0.8809293320425944,0.8799612778315585,0.8789932236205228,0.8780251694094869,0.8770571151984511,0.8760890609874153,0.8760890609874153,0.8751210067763795,0.8741529525653436,0.8741529525653436,0.8731848983543078,0.872216844143272,0.8712487899322362,0.8702807357212003,0.8693126815101646,0.8693126815101646,0.8693126815101646,0.8683446272991288,0.8673765730880929,0.8664085188770572,0.8654404646660213,0.8644724104549855,0.8635043562439496,0.8635043562439496,0.8625363020329139,0.861568247821878,0.861568247821878,0.861568247821878,0.8606001936108422,0.8596321393998064,0.8596321393998064,0.8596321393998064,0.8586640851887706,0.8576960309777347,0.856727976766699,0.856727976766699,0.8557599225556631,0.8547918683446273,0.8547918683446273,0.8538238141335914,0.8528557599225557,0.8518877057115198,0.850919651500484,0.850919651500484,0.8499515972894482,0.8489835430784124,0.8480154888673765,0.8470474346563408,0.846079380445305,0.8451113262342691,0.8441432720232332,0.8431752178121975,0.8422071636011617,0.8412391093901258,0.8412391093901258,0.8402710551790901,0.8393030009680542,0.8383349467570184,0.8373668925459826,0.8363988383349468,0.8354307841239109,0.8344627299128751,0.8334946757018393,0.8325266214908035,0.8325266214908035,0.8315585672797676,0.8305905130687319,0.829622458857696,0.8286544046466602,0.8276863504356244,0.8267182962245886,0.8257502420135527,0.8257502420135527,0.8247821878025169,0.8247821878025169,0.8238141335914811,0.8228460793804453,0.8218780251694094,0.8209099709583737,0.8199419167473379,0.818973862536302,0.8180058083252663,0.8170377541142304,0.8160696999031946,0.8151016456921588,0.814133591481123,0.8131655372700871,0.8131655372700871,0.8121974830590513,0.8112294288480155,0.8102613746369797,0.8102613746369797,0.8092933204259438,0.8083252662149081,0.8073572120038722,0.8063891577928364,0.8063891577928364,0.8054211035818006,0.8044530493707648,0.8034849951597289,0.8025169409486931,0.8015488867376573,0.8005808325266215,0.7996127783155856,0.7986447241045499,0.797676669893514,0.7967086156824782,0.7957405614714425,0.7947725072604066,0.7938044530493708,0.7938044530493708,0.7928363988383349,0.7918683446272992,0.7909002904162633,0.7899322362052275,0.7889641819941917,0.7879961277831559,0.78702807357212,0.7860600193610843,0.7850919651500484,0.7841239109390126,0.7831558567279767,0.782187802516941,0.7812197483059051,0.7802516940948693,0.7792836398838335,0.7783155856727977,0.7773475314617618,0.7763794772507261,0.7744433688286544,0.7734753146176185,0.7725072604065828,0.771539206195547,0.7705711519845111,0.7696030977734754,0.7696030977734754,0.7686350435624395,0.7676669893514037,0.7666989351403679,0.7657308809293321,0.7647628267182962,0.7647628267182962,0.7637947725072604,0.7628267182962246,0.7618586640851888,0.7608906098741529,0.7599225556631172,0.7589545014520813,0.7579864472410455,0.7570183930300097,0.7560503388189739,0.755082284607938,0.755082284607938,0.7541142303969022,0.7541142303969022,0.7531461761858664,0.7521781219748306,0.7512100677637947,0.750242013552759,0.7492739593417231,0.7492739593417231,0.7483059051306873,0.7473378509196515,0.7463697967086157,0.7454017424975798,0.744433688286544,0.7434656340755083,0.7434656340755083,0.7424975798644724,0.7415295256534365,0.7405614714424008,0.739593417231365,0.739593417231365,0.7386253630203291,0.7376573088092934,0.7366892545982575,0.7357212003872217,0.7347531461761858,0.7337850919651501,0.7318489835430784,0.7308809293320426,0.7308809293320426,0.7299128751210068,0.7289448209099709,0.7279767666989352,0.7279767666989352,0.7270087124878993,0.7260406582768635,0.7250726040658277,0.7250726040658277,0.7241045498547919,0.723136495643756,0.7221684414327202,0.7212003872216844,0.7202323330106486,0.7192642787996127,0.7192642787996127,0.718296224588577,0.718296224588577,0.7173281703775412,0.7163601161665053,0.7153920619554696,0.7144240077444337,0.7134559535333979,0.712487899322362,0.712487899322362,0.7115198451113263,0.7105517909002904,0.7095837366892546,0.7086156824782188,0.707647628267183,0.7066795740561471,0.7057115198451114,0.7047434656340755,0.7047434656340755,0.7037754114230397,0.7028073572120038,0.7028073572120038,0.7018393030009681,0.7008712487899322,0.6999031945788964,0.6999031945788964,0.6999031945788964,0.6989351403678606,0.6989351403678606,0.6979670861568248,0.6969990319457889,0.6960309777347532,0.6950629235237173,0.6940948693126815,0.6931268151016456,0.6921587608906099,0.691190706679574,0.6902226524685382,0.6892545982575025,0.6882865440464666,0.6873184898354308,0.686350435624395,0.6853823814133592,0.6844143272023233,0.6834462729912875,0.6824782187802517,0.6815101645692159,0.68054211035818,0.6795740561471443,0.6786060019361084,0.6776379477250726,0.6766698935140368,0.675701839303001,0.675701839303001,0.6747337850919651,0.6737657308809293,0.6727976766698935,0.6718296224588577,0.6708615682478218,0.6698935140367861,0.6689254598257502,0.6679574056147144,0.6669893514036787,0.6660212971926428,0.665053242981607,0.6640851887705711,0.6631171345595354,0.6621490803484995,0.6611810261374637,0.6602129719264279,0.6592449177153921,0.6582768635043562,0.6573088092933205,0.6563407550822846,0.6563407550822846,0.6553727008712488,0.6544046466602129,0.6534365924491772,0.6524685382381413,0.6515004840271055,0.6505324298160697,0.6495643756050339,0.648596321393998,0.648596321393998,0.6476282671829623,0.6466602129719264,0.6456921587608906,0.6447241045498547,0.6447241045498547,0.643756050338819,0.6427879961277831,0.6418199419167473,0.6408518877057116,0.6398838334946757,0.6389157792836399,0.6379477250726041,0.6369796708615683,0.6360116166505324,0.6350435624394967,0.6340755082284608,0.633107454017425,0.6321393998063891,0.6311713455953534,0.6302032913843175,0.6302032913843175,0.6292352371732817,0.6282671829622459,0.6282671829622459,0.6272991287512101,0.6263310745401742,0.6253630203291385,0.6243949661181026,0.6234269119070668,0.6224588576960309,0.6214908034849952,0.6205227492739593,0.6205227492739593,0.6195546950629235,0.6185866408518877,0.6176185866408519,0.616650532429816,0.6156824782187803,0.6147144240077445,0.6137463697967086,0.6127783155856728,0.611810261374637,0.6108422071636012,0.6098741529525653,0.6089060987415296,0.6079380445304937,0.6069699903194579,0.6060019361084221,0.6060019361084221,0.6050338818973863,0.6040658276863504,0.6030977734753146,0.6021297192642788,0.601161665053243,0.6001936108422071,0.5992255566311714,0.5982575024201355,0.5972894482090997,0.5963213939980639,0.5953533397870281,0.5943852855759922,0.5934172313649564,0.5924491771539206,0.5924491771539206,0.5914811229428848,0.590513068731849,0.5895450145208132,0.5885769603097774,0.5876089060987415,0.5866408518877058,0.5856727976766699,0.5847047434656341,0.5837366892545982,0.5827686350435625,0.5818005808325266,0.5808325266214908,0.579864472410455,0.5788964181994192,0.5779283639883833,0.5769603097773476,0.5759922555663117,0.5750242013552759,0.57405614714424,0.5730880929332043,0.5721200387221684,0.5711519845111326,0.5701839303000968,0.569215876089061,0.5682478218780251,0.5672797676669894,0.5663117134559535,0.5653436592449177,0.5643756050338818,0.5634075508228461,0.5624394966118103,0.5614714424007744,0.5605033881897387,0.5595353339787028,0.558567279767667,0.5575992255566312,0.5566311713455954,0.5556631171345595,0.5546950629235237,0.5537270087124879,0.5527589545014521,0.5527589545014521,0.5517909002904162,0.5508228460793805,0.5498547918683446,0.5488867376573088,0.547918683446273,0.5469506292352372,0.5459825750242013,0.5459825750242013,0.5450145208131656,0.5450145208131656,0.5440464666021297,0.5430784123910939,0.542110358180058,0.5411423039690223,0.5401742497579864,0.5392061955469506,0.5382381413359149,0.537270087124879,0.5363020329138432,0.5353339787028074,0.5343659244917716,0.5333978702807357,0.5324298160696999,0.5314617618586641,0.5304937076476283,0.5295256534365924,0.5285575992255567,0.5275895450145208,0.526621490803485,0.5256534365924492,0.5246853823814134,0.5237173281703775,0.5227492739593417,0.5217812197483059,0.5208131655372701,0.5198451113262342,0.5188770571151985,0.5179090029041626,0.5169409486931268,0.515972894482091,0.5150048402710552,0.5140367860600193,0.5130687318489835,0.5121006776379478,0.5111326234269119,0.510164569215876,0.5091965150048403,0.5082284607938045,0.5072604065827686,0.5062923523717329,0.505324298160697,0.5043562439496612,0.5033881897386253,0.5024201355275896,0.5014520813165537,0.5004840271055179,0.4995159728944821,0.4985479186834463,0.4975798644724105,0.49661181026137463,0.49564375605033884,0.494675701839303,0.4937076476282672,0.4927395934172314,0.49177153920619554,0.49080348499515974,0.4898354307841239,0.4898354307841239,0.4888673765730881,0.4878993223620523,0.48693126815101645,0.48596321393998065,0.4849951597289448,0.484027105517909,0.4830590513068732,0.48209099709583736,0.48112294288480156,0.4801548886737657,0.4791868344627299,0.4782187802516941,0.47725072604065827,0.4762826718296225,0.4753146176185866,0.4743465634075508,0.47337850919651503,0.4724104549854792,0.4714424007744434,0.47047434656340753,0.46950629235237173,0.46853823814133594,0.4675701839303001,0.4666021297192643,0.46563407550822844,0.46466602129719264,0.46369796708615685,0.462729912875121,0.4617618586640852,0.46079380445304935,0.45982575024201355,0.45982575024201355,0.45885769603097776,0.4578896418199419,0.4569215876089061,0.45595353339787026,0.45498547918683446,0.45401742497579867,0.4530493707647628,0.452081316553727,0.45111326234269117,0.45014520813165537,0.4491771539206196,0.4482090997095837,0.44724104549854793,0.4462729912875121,0.4453049370764763,0.4443368828654405,0.44336882865440463,0.44240077444336884,0.441432720232333,0.4404646660212972,0.4394966118102614,0.43852855759922554,0.43756050338818975,0.4365924491771539,0.4365924491771539,0.4356243949661181,0.4346563407550823,0.43368828654404645,0.43272023233301066,0.4317521781219748,0.430784123910939,0.4298160696999032,0.42884801548886736,0.42787996127783157,0.4269119070667957,0.4259438528557599,0.4259438528557599,0.4249757986447241,0.42400774443368827,0.4230396902226525,0.4220716360116166,0.42110358180058083,0.42013552758954503,0.4191674733785092,0.4181994191674734,0.41723136495643753,0.41626331074540174,0.41529525653436594,0.4143272023233301,0.4133591481122943,0.41239109390125844,0.41142303969022265,0.41045498547918685,0.409486931268151,0.409486931268151,0.4085188770571152,0.4075508228460794,0.40658276863504356,0.40561471442400776,0.4046466602129719,0.4036786060019361,0.4027105517909003,0.40174249757986447,0.40077444336882867,0.3998063891577928,0.398838334946757,0.3978702807357212,0.3969022265246854,0.3959341723136496,0.39496611810261373,0.39399806389157793,0.39303000968054214,0.3910939012584705,0.3910939012584705,0.39012584704743464,0.38915779283639884,0.38818973862536305,0.38818973862536305,0.3872216844143272,0.3862536302032914,0.38528557599225555,0.38431752178121975,0.38334946757018395,0.3823814133591481,0.3814133591481123,0.38044530493707646,0.37947725072604066,0.37850919651500486,0.377541142303969,0.3765730880929332,0.3765730880929332,0.37560503388189737,0.37463697967086157,0.3736689254598258,0.3727008712487899,0.3727008712487899,0.3717328170377541,0.3707647628267183,0.3697967086156825,0.3688286544046467,0.36786060019361083,0.36689254598257504,0.3659244917715392,0.3649564375605034,0.3639883833494676,0.36302032913843174,0.36205227492739595,0.3610842207163601,0.3601161665053243,0.3591481122942885,0.35818005808325265,0.35721200387221685,0.356243949661181,0.3552758954501452,0.3543078412391094,0.35333978702807356,0.35237173281703776,0.3514036786060019,0.3504356243949661,0.3494675701839303,0.34849951597289447,0.3475314617618587,0.3465634075508228,0.345595353339787,0.34462729912875123,0.3436592449177154,0.3426911907066796,0.34172313649564373,0.34075508228460794,0.33978702807357214,0.3388189738625363,0.3378509196515005,0.33688286544046464,0.33591481122942884,0.33494675701839305,0.3339787028073572,0.3330106485963214,0.33204259438528555,0.33107454017424975,0.33010648596321396,0.3291384317521781,0.3281703775411423,0.32720232333010646,0.32623426911907066,0.32526621490803487,0.324298160696999,0.3233301064859632,0.32236205227492737,0.3213939980638916,0.3204259438528558,0.3194578896418199,0.31848983543078413,0.31752178121974833,0.3165537270087125,0.3155856727976767,0.31461761858664083,0.31364956437560504,0.31268151016456924,0.3117134559535334,0.3107454017424976,0.30977734753146174,0.30880929332042595,0.30784123910939015,0.3068731848983543,0.3059051306873185,0.30493707647628265,0.30396902226524686,0.30300096805421106,0.3020329138431752,0.3020329138431752,0.3010648596321394,0.30009680542110356,0.29912875121006777,0.29816069699903197,0.2971926427879961,0.2962245885769603,0.2952565343659245,0.2942884801548887,0.2933204259438529,0.29235237173281703,0.29138431752178123,0.2904162633107454,0.2894482090997096,0.2884801548886738,0.28751210067763794,0.28654404646660214,0.2855759922555663,0.2846079380445305,0.2836398838334947,0.28267182962245885,0.28170377541142305,0.2807357212003872,0.2797676669893514,0.2787996127783156,0.27783155856727976,0.27686350435624396,0.2758954501452081,0.2749273959341723,0.2739593417231365,0.27299128751210067,0.27202323330106487,0.271055179090029,0.2700871248789932,0.2691190706679574,0.2681510164569216,0.2671829622458858,0.26621490803484993,0.26524685382381413,0.26427879961277834,0.2633107454017425,0.2623426911907067,0.26137463697967084,0.26040658276863504,0.26040658276863504,0.26040658276863504,0.25943852855759925,0.2584704743465634,0.2575024201355276,0.25653436592449175,0.25556631171345595,0.25459825750242016,0.2536302032913843,0.2526621490803485,0.25169409486931266,0.25072604065827686,0.24975798644724104,0.24878993223620524,0.24782187802516942,0.2468538238141336,0.24588576960309777,0.24491771539206195,0.24394966118102615,0.24298160696999033,0.2420135527589545,0.24104549854791868,0.24007744433688286,0.23910939012584706,0.23814133591481124,0.2371732817037754,0.2362052274927396,0.23523717328170377,0.23426911907066797,0.23330106485963215,0.23233301064859632,0.2313649564375605,0.22942884801548888,0.22846079380445306,0.22749273959341723,0.2265246853823814,0.22555663117134558,0.2245885769603098,0.22362052274927396,0.22265246853823814,0.22168441432720232,0.2207163601161665,0.2197483059051307,0.21878025169409487,0.21781219748305905,0.21684414327202323,0.2158760890609874,0.2149080348499516,0.21393998063891578,0.21297192642787996,0.21200387221684414,0.2110358180058083,0.21006776379477252,0.2090997095837367,0.20813165537270087,0.20716360116166505,0.20619554695062922,0.20522749273959343,0.2042594385285576,0.20329138431752178,0.20232333010648595,0.20135527589545016,0.20038722168441434,0.1994191674733785,0.1994191674733785,0.1984511132623427,0.19748305905130686,0.19651500484027107,0.19554695062923524,0.19457889641819942,0.1936108422071636,0.19264278799612777,0.19167473378509198,0.19070667957405615,0.18973862536302033,0.1887705711519845,0.18780251694094868,0.18780251694094868,0.1868344627299129,0.18586640851887706,0.18489835430784124,0.18393030009680542,0.1829622458857696,0.1819941916747338,0.18102613746369797,0.18005808325266215,0.17909002904162633,0.1781219748305905,0.1771539206195547,0.17618586640851888,0.17521781219748306,0.17424975798644723,0.1732817037754114,0.17231364956437561,0.1713455953533398,0.17037754114230397,0.16940948693126814,0.16844143272023232,0.16747337850919652,0.1665053242981607,0.16553727008712488,0.16456921587608905,0.16456921587608905,0.16360116166505323,0.16263310745401743,0.15972894482090996,0.15876089060987417,0.15779283639883834,0.15779283639883834,0.15682478218780252,0.1558567279767667,0.15488867376573087,0.15392061955469508,0.15295256534365925,0.15198451113262343,0.1510164569215876,0.15004840271055178,0.14908034849951599,0.14811229428848016,0.14714424007744434,0.14617618586640851,0.1452081316553727,0.1442400774443369,0.14327202323330107,0.14230396902226525,0.14133591481122942,0.1403678606001936,0.1393998063891578,0.13843175217812198,0.13746369796708616,0.13649564375605033,0.1355275895450145,0.1345595353339787,0.1335914811229429,0.13262342691190707,0.13165537270087124,0.13068731848983542,0.12971926427879962,0.1287512100677638,0.12778315585672798,0.12681510164569215,0.12584704743465633,0.12487899322362052,0.12391093901258471,0.12294288480154889,0.12197483059051308,0.12100677637947725,0.12003872216844143,0.11713455953533398,0.1132623426911907,0.1122942884801549,0.11132623426911907,0.11035818005808325,0.10939012584704744,0.10842207163601161,0.1074540174249758,0.10648596321393998,0.10551790900290416,0.10454985479186835,0.10261374636979671,0.10164569215876089,0.10067763794772508,0.09970958373668926,0.09874152952565343,0.09777347531461762,0.0968054211035818,0.09583736689254599,0.09486931268151017,0.09390125847047434,0.09293320425943853,0.09196515004840271,0.0909970958373669,0.09002904162633107,0.08906098741529525,0.08809293320425944,0.08712487899322362,0.08615682478218781,0.08518877057115198,0.08422071636011616,0.08325266214908035,0.08228460793804453,0.08228460793804453,0.08131655372700872,0.0803484995159729,0.07938044530493708,0.07841239109390126,0.07744433688286544,0.07647628267182963,0.0755082284607938,0.07454017424975799,0.07357212003872217,0.07260406582768635,0.07163601161665054,0.07066795740561471,0.0696999031945789,0.06873184898354308,0.06776379477250725,0.06679574056147145,0.06582768635043562,0.06485963213939981,0.06389157792836399,0.06292352371732816,0.061955469506292354,0.06098741529525654,0.060019361084220714,0.0590513068731849,0.05808325266214908,0.057115198451113264,0.05614714424007745,0.05517909002904162,0.05421103581800581,0.05324298160696999,0.05324298160696999,0.05227492739593417,0.051306873184898356,0.05033881897386254,0.049370764762826716,0.0484027105517909,0.04743465634075508,0.046466602129719266,0.04549854791868345,0.044530493707647625,0.04356243949661181,0.04259438528557599,0.041626331074540175,0.04065827686350436,0.03969022265246854,0.03872216844143272,0.0377541142303969,0.036786060019361085,0.03581800580832527,0.03484995159728945,0.03388189738625363,0.03291384317521781,0.031945788964181994,0.030977734753146177,0.030009680542110357,0.02904162633107454,0.028073572120038724,0.027105517909002903,0.026137463697967087,0.02516940948693127,0.02420135527589545,0.023233301064859633,0.022265246853823813,0.021297192642787996,0.02032913843175218,0.01936108422071636,0.018393030009680542,0.017424975798644726,0.016456921587608905,0.015488867376573089,0.01452081316553727,0.013552758954501452,0.012584704743465635,0.011616650532429816,0.010648596321393998,0.00968054211035818,0.008712487899322363,0.007744433688286544,0.006776379477250726,0.005808325266214908,0.00484027105517909,0.003872216844143272,0.002904162633107454,0.001936108422071636,0.000968054211035818,0],"xaxis":"x","y":[0.7341862117981521,0.7352313167259786,0.7357549857549858,0.7362794012829651,0.7368045649072753,0.7373304782298359,0.7378571428571429,0.7383845604002859,0.7389127324749643,0.7394416607015032,0.7399713467048711,0.7405017921146954,0.7410329985652798,0.741564967695621,0.7420977011494253,0.7426312005751258,0.7431654676258993,0.7437005039596832,0.7442363112391931,0.7447728911319395,0.7453102453102453,0.7458483754512636,0.7463872832369942,0.7469269703543022,0.7474674384949349,0.7480086893555394,0.7485507246376811,0.7490935460478607,0.7496371552975326,0.7501815541031227,0.7507267441860465,0.7512727272727273,0.7518195050946143,0.752367079388201,0.7529154518950437,0.7534646243617797,0.754014598540146,0.7545653761869978,0.7551169590643275,0.7556693489392831,0.7562225475841874,0.7567765567765568,0.7573313782991202,0.7578870139398386,0.7584434654919237,0.7590007347538574,0.7595588235294117,0.7601177336276674,0.7606774668630338,0.7612380250552689,0.7617994100294986,0.7623616236162362,0.7629246676514032,0.7634885439763488,0.7640532544378699,0.764618800888231,0.7651851851851852,0.765752409191994,0.766320474777448,0.7668893838158871,0.7674591381872214,0.7680297397769517,0.7686011904761905,0.7691734921816828,0.7697466467958272,0.7703206562266965,0.7708955223880597,0.7714712471994025,0.7720478325859492,0.7726252804786836,0.7737827715355805,0.7743628185907047,0.7749437359339835,0.7755255255255256,0.7761081893313299,0.7766917293233083,0.7772761474793077,0.7778614457831325,0.7784476262245666,0.7790346907993967,0.779622641509434,0.7802114803625377,0.780801209372638,0.7813918305597579,0.7819833459500378,0.7825757575757576,0.7831690674753601,0.783763277693475,0.7843583902809416,0.7849544072948328,0.785551330798479,0.7861491628614916,0.7867479055597868,0.7873475609756098,0.7879481311975591,0.7885496183206107,0.7891520244461421,0.7897553516819572,0.7903596021423106,0.7909647779479326,0.7915708812260537,0.7921779141104295,0.7927858787413661,0.793394777265745,0.7940046118370484,0.7946153846153846,0.7952270977675134,0.7958397534668721,0.7964533538936006,0.7970679012345679,0.7976833976833977,0.7982998454404946,0.7989172467130704,0.8001549186676995,0.8007751937984496,0.8013964313421257,0.8020186335403726,0.8026418026418026,0.8032659409020217,0.8038910505836576,0.8045171339563862,0.8051441932969603,0.8057722308892356,0.8064012490241999,0.80703125,0.8076622361219703,0.8082942097026604,0.8089271730618638,0.8095611285266457,0.8101960784313725,0.8108320251177394,0.8114689709347996,0.8121069182389937,0.8127458693941778,0.8133858267716535,0.814026792750197,0.8146687697160884,0.8153117600631413,0.815955766192733,0.8166007905138339,0.817246835443038,0.8178939034045922,0.8185419968304279,0.8191911181601903,0.8198412698412698,0.8204924543288324,0.8211446740858506,0.8217979315831344,0.822452229299363,0.8223107569721115,0.8229665071770335,0.8236233040702314,0.8242811501597445,0.8249400479616307,0.8256,0.8262610088070457,0.8269230769230769,0.8275862068965517,0.8282504012841091,0.8289156626506025,0.8287781350482315,0.829444891391794,0.8301127214170693,0.830781627719581,0.8314516129032258,0.8321226795803067,0.8319870759289176,0.8318512530315278,0.8325242718446602,0.8331983805668016,0.8338735818476499,0.8345498783454988,0.8352272727272727,0.8359057676685622,0.8365853658536585,0.8379478827361564,0.8386308068459658,0.8393148450244698,0.84,0.8398692810457516,0.8405560098119379,0.8412438625204582,0.8419328419328419,0.8426229508196721,0.8433141919606235,0.8440065681444991,0.8438783894823336,0.8445723684210527,0.8452674897119341,0.8459637561779242,0.8466611706512778,0.8473597359735974,0.8480594549958712,0.8487603305785124,0.8494623655913979,0.8501655629139073,0.8500414250207126,0.8507462686567164,0.8506224066390041,0.8513289036544851,0.8512053200332502,0.8519134775374376,0.8517901748542881,0.8516666666666667,0.8523769808173478,0.8522537562604341,0.8529657477025898,0.8536789297658863,0.8543933054393306,0.8542713567839196,0.8549874266554903,0.8557046979865772,0.8564231738035264,0.8563025210084033,0.8570227081581161,0.8577441077441077,0.8584667228306655,0.8591905564924115,0.859915611814346,0.8597972972972973,0.8605240912933221,0.8604060913705583,0.8602878916172735,0.8610169491525423,0.8608990670059372,0.8607809847198642,0.8615123194562447,0.8622448979591837,0.8621276595744681,0.8620102214650767,0.8627450980392157,0.863481228668942,0.8633646456020495,0.8641025641025641,0.864841745081266,0.865582191780822,0.8654670094258783,0.8653516295025729,0.8660944206008584,0.865979381443299,0.8667239896818573,0.8666092943201377,0.8673557278208441,0.868103448275862,0.8679896462467644,0.8687392055267703,0.8694900605012964,0.8693771626297578,0.8701298701298701,0.8708838821490468,0.8716392020815265,0.8723958333333334,0.8731537793223284,0.8730434782608696,0.8738033072236727,0.8745644599303136,0.8753269398430689,0.87521815008726,0.8759825327510917,0.8767482517482518,0.8775153105861767,0.8782837127845884,0.8790534618755478,0.8789473684210526,0.8788410886742757,0.8796133567662566,0.8795074758135444,0.8802816901408451,0.8810572687224669,0.8809523809523809,0.880847308031774,0.8807420494699647,0.8815207780725022,0.8814159292035398,0.8813108945969885,0.8812056737588653,0.8819875776397516,0.8827708703374778,0.8835555555555555,0.8843416370106761,0.8842386464826358,0.8841354723707665,0.8849241748438894,0.8857142857142857,0.8865058087578195,0.8872987477638641,0.8871978513876455,0.8870967741935484,0.8869955156950673,0.8868940754039497,0.8876909254267745,0.8884892086330936,0.8892889288928892,0.8900900900900901,0.8899909828674482,0.8898916967509025,0.8897922312556459,0.8896925858951176,0.8895927601809954,0.8894927536231884,0.8893925657298277,0.8892921960072595,0.8900999091734787,0.89,0.8898999090081893,0.8897996357012751,0.8906107566089334,0.8914233576642335,0.8922374429223744,0.8930530164533821,0.8929551692589204,0.8928571428571429,0.8927589367552704,0.8926605504587156,0.8934802571166207,0.8933823529411765,0.8932842686292548,0.8931860036832413,0.8930875576036866,0.8939114391143912,0.8947368421052632,0.8946395563770795,0.8945420906567992,0.8953703703703704,0.8952734012974977,0.8961038961038961,0.8969359331476323,0.8977695167286245,0.8976744186046511,0.8985102420856611,0.8984156570363467,0.8992537313432836,0.8991596638655462,0.9,0.8999064546304958,0.899812734082397,0.9006560449859419,0.9015009380863039,0.9014084507042254,0.9022556390977443,0.9021636876763875,0.9030131826741996,0.9029217719132894,0.9037735849056604,0.9036827195467422,0.9035916824196597,0.9044465468306528,0.9043560606060606,0.9042654028436019,0.905123339658444,0.905982905982906,0.905893536121673,0.9058039961941009,0.9066666666666666,0.9065776930409915,0.9064885496183206,0.9073543457497613,0.9072657743785851,0.907177033492823,0.9080459770114943,0.9089165867689357,0.9097888675623801,0.9106628242074928,0.9105769230769231,0.9104908565928778,0.9113680154142582,0.9122468659594986,0.9121621621621622,0.9120772946859903,0.9129593810444874,0.9128751210067764,0.9137596899224806,0.9146459747817652,0.9145631067961165,0.9154518950437318,0.9163424124513618,0.9162609542356378,0.9161793372319688,0.9170731707317074,0.91796875,0.9178885630498533,0.9187866927592955,0.9187071498530852,0.9196078431372549,0.9195289499509323,0.9194499017681729,0.9193706981317601,0.9192913385826772,0.9192118226600985,0.9191321499013807,0.9190523198420533,0.9189723320158103,0.9198813056379822,0.9207920792079208,0.9217046580773043,0.9216269841269841,0.9215491559086395,0.9224652087475149,0.9223880597014925,0.9223107569721115,0.9232303090727817,0.9231536926147704,0.9240759240759241,0.924,0.923923923923924,0.9238476953907816,0.9237713139418254,0.9246987951807228,0.9246231155778895,0.9255533199195171,0.9254783484390735,0.9254032258064516,0.9253279515640767,0.9262626262626262,0.9261880687563195,0.9271255060728745,0.92806484295846,0.9279918864097363,0.9279187817258884,0.9278455284552846,0.9277721261444557,0.9287169042769857,0.928644240570846,0.9295918367346939,0.9295199182839632,0.9304703476482618,0.9303991811668373,0.930327868852459,0.9302564102564103,0.9301848049281314,0.9301130524152107,0.9310699588477366,0.9309989701338826,0.9309278350515464,0.9318885448916409,0.9318181818181818,0.9317476732161324,0.9316770186335404,0.9316062176165804,0.9315352697095436,0.9325025960539979,0.9334719334719335,0.9334027055150884,0.9333333333333333,0.9332638164754953,0.9331941544885177,0.9331243469174504,0.9330543933054394,0.9340314136125655,0.9339622641509434,0.9338929695697796,0.9348739495798319,0.935856992639327,0.9357894736842105,0.9357218124341412,0.9367088607594937,0.9376979936642027,0.9376321353065539,0.9375661375661376,0.9375,0.9384941675503712,0.9384288747346072,0.9383634431455898,0.9393617021276596,0.939297124600639,0.9392324093816631,0.9391675560298826,0.9391025641025641,0.9401069518716577,0.9400428265524625,0.939978563772776,0.9399141630901288,0.9398496240601504,0.9397849462365592,0.9397201291711518,0.9396551724137931,0.9395900755124056,0.9395248380129589,0.9394594594594594,0.9404761904761905,0.9404117009750813,0.940347071583514,0.9402823018458197,0.9402173913043478,0.940152339499456,0.9400871459694989,0.9400218102508179,0.9399563318777293,0.9398907103825137,0.9409190371991247,0.940854326396495,0.9407894736842105,0.9407244785949506,0.9406593406593406,0.9405940594059405,0.9405286343612335,0.9404630650496141,0.9415011037527594,0.9414364640883978,0.9424778761061947,0.9424141749723145,0.9423503325942351,0.9422863485016648,0.9422222222222222,0.9421579532814238,0.9420935412026726,0.9420289855072463,0.9419642857142857,0.9418994413407821,0.941834451901566,0.9417693169092946,0.9417040358744395,0.9427609427609428,0.9426966292134832,0.9426321709786277,0.9425675675675675,0.943630214205186,0.9435665914221218,0.943502824858757,0.9434389140271493,0.9433748584371461,0.9444444444444444,0.9443813847900113,0.9443181818181818,0.944254835039818,0.9441913439635535,0.9441277080957811,0.9440639269406392,0.944,0.9439359267734554,0.9438717067583047,0.9438073394495413,0.9437428243398392,0.9436781609195403,0.9436133486766398,0.9447004608294931,0.9446366782006921,0.9445727482678984,0.9445086705202312,0.9444444444444444,0.944380069524913,0.9443155452436195,0.9442508710801394,0.9441860465116279,0.9441210710128056,0.9440559440559441,0.9439906651108518,0.9439252336448598,0.9438596491228071,0.9437939110070258,0.943728018757327,0.9436619718309859,0.9435957696827262,0.9435294117647058,0.9433962264150944,0.9433293978748524,0.9432624113475178,0.9431952662721893,0.943127962085308,0.9430604982206405,0.9441805225653207,0.9441141498216409,0.944047619047619,0.9439809296781884,0.9439140811455847,0.9438470728793309,0.9449760765550239,0.9449101796407186,0.9448441247002398,0.9447779111644657,0.9447115384615384,0.9446450060168472,0.944578313253012,0.9445114595898673,0.9444444444444444,0.9443772672309553,0.9443099273607748,0.9454545454545454,0.9453883495145631,0.9465370595382746,0.9464720194647201,0.9464068209500609,0.9463414634146341,0.9462759462759462,0.9462102689486552,0.9473684210526315,0.9473039215686274,0.947239263803681,0.9471744471744472,0.947109471094711,0.9470443349753694,0.9469790382244143,0.9481481481481482,0.9480840543881335,0.948019801980198,0.9479553903345725,0.9478908188585607,0.9490683229813665,0.9490049751243781,0.9489414694894147,0.9488778054862843,0.9488139825218477,0.94875,0.9486858573216521,0.9485570890840652,0.9484924623115578,0.949685534591195,0.9496221662468514,0.9495586380832283,0.9494949494949495,0.9506953223767383,0.950632911392405,0.9505703422053232,0.950507614213198,0.951715374841169,0.9516539440203562,0.9515923566878981,0.951530612244898,0.9514687100893997,0.9514066496163683,0.9513444302176697,0.9525641025641025,0.9525032092426188,0.9537275064267352,0.9536679536679536,0.9536082474226805,0.9535483870967741,0.9534883720930233,0.9534282018111255,0.9533678756476683,0.9546044098573282,0.9545454545454546,0.9544863459037711,0.9544270833333334,0.954367666232073,0.9543080939947781,0.954248366013072,0.9541884816753927,0.9541284403669725,0.9553805774278216,0.9553219448094612,0.9552631578947368,0.9565217391304348,0.9564643799472295,0.9564068692206077,0.9563492063492064,0.9576158940397351,0.9588859416445623,0.9588313413014609,0.9601063829787234,0.9600532623169108,0.96,0.9599465954606141,0.9598930481283422,0.9598393574297188,0.9597855227882037,0.959731543624161,0.9596774193548387,0.9596231493943472,0.9595687331536388,0.9595141700404858,0.9594594594594594,0.959404600811908,0.959349593495935,0.9592944369063772,0.9592391304347826,0.9591836734693877,0.9591280653950953,0.9590723055934516,0.9590163934426229,0.9589603283173734,0.958904109589041,0.9588477366255144,0.9587912087912088,0.9601100412654745,0.9600550964187328,0.96,0.9599447513812155,0.9598893499308437,0.9598337950138505,0.9597780859916782,0.9597222222222223,0.9596662030598053,0.9596100278551533,0.9595536959553695,0.9594972067039106,0.9594405594405594,0.9593837535014006,0.9593267882187938,0.9592696629213483,0.9592123769338959,0.9591549295774648,0.9590973201692524,0.9590395480225988,0.958981612446959,0.9603399433427762,0.9602836879432625,0.9602272727272727,0.9601706970128022,0.9601139601139601,0.9600570613409415,0.96,0.9599427753934192,0.9598853868194842,0.9612625538020086,0.9612068965517241,0.9611510791366906,0.9610951008645533,0.961038961038961,0.9624277456647399,0.9623733719247467,0.9623188405797102,0.9622641509433962,0.9622093023255814,0.9621542940320232,0.9620991253644315,0.962043795620438,0.9619883040935673,0.9619326500732065,0.9618768328445748,0.9618208516886931,0.961764705882353,0.9617083946980854,0.9616519174041298,0.9615952732644018,0.9630177514792899,0.9629629629629629,0.9629080118694362,0.9643387815750372,0.9642857142857143,0.9642324888226528,0.9641791044776119,0.9641255605381166,0.9640718562874252,0.9640179910044977,0.963963963963964,0.9639097744360903,0.9653614457831325,0.9653092006033183,0.9652567975830816,0.9652042360060514,0.9651515151515152,0.9650986342943855,0.9650455927051672,0.9649923896499238,0.9649390243902439,0.9648854961832061,0.9648318042813455,0.9647779479326187,0.9647239263803681,0.9646697388632872,0.9646153846153847,0.9645608628659477,0.9660493827160493,0.9659969088098919,0.9659442724458205,0.9658914728682171,0.9658385093167702,0.9657853810264385,0.9657320872274143,0.9656786271450858,0.965625,0.9655712050078247,0.9655172413793104,0.9654631083202512,0.9654088050314465,0.9653543307086614,0.9652996845425867,0.966824644549763,0.9667721518987342,0.9667194928684627,0.9666666666666667,0.9666136724960255,0.9665605095541401,0.9665071770334929,0.9664536741214057,0.9664,0.9663461538461539,0.9662921348314607,0.9662379421221865,0.966183574879227,0.9661290322580646,0.9660743134087237,0.9660194174757282,0.965964343598055,0.9659090909090909,0.9658536585365853,0.9657980456026058,0.965742251223491,0.9656862745098039,0.9656301145662848,0.9655737704918033,0.9655172413793104,0.9654605263157895,0.9654036243822076,0.9653465346534653,0.9652892561983472,0.9652317880794702,0.9651741293532339,0.9651162790697675,0.9650582362728786,0.965,0.9649415692821369,0.9648829431438127,0.964824120603015,0.964765100671141,0.9647058823529412,0.9646464646464646,0.9645868465430016,0.964527027027027,0.9661590524534687,0.9661016949152542,0.966044142614601,0.9659863945578231,0.9659284497444633,0.9658703071672355,0.9658119658119658,0.9657534246575342,0.967409948542024,0.9673539518900344,0.9690189328743546,0.9689655172413794,0.9689119170984456,0.9688581314878892,0.9688041594454073,0.96875,0.9686956521739131,0.9686411149825784,0.9685863874345549,0.9685314685314685,0.968476357267951,0.968421052631579,0.968365553602812,0.9683098591549296,0.9682539682539683,0.9681978798586572,0.968141592920354,0.9680851063829787,0.9680284191829485,0.9679715302491103,0.9679144385026738,0.9678571428571429,0.9677996422182469,0.967741935483871,0.9676840215439856,0.9676258992805755,0.9675675675675676,0.9675090252707581,0.9674502712477396,0.967391304347826,0.9673321234119783,0.9672727272727273,0.9672131147540983,0.9671532846715328,0.9670932358318098,0.967032967032967,0.9669724770642202,0.9669117647058824,0.9668508287292817,0.966789667896679,0.966728280961183,0.9666666666666667,0.9666048237476809,0.966542750929368,0.9664804469273743,0.9664179104477612,0.9663551401869159,0.9662921348314607,0.9662288930581614,0.9661654135338346,0.9661016949152542,0.9660377358490566,0.9659735349716446,0.9659090909090909,0.9658444022770398,0.9657794676806084,0.9657142857142857,0.9656488549618321,0.9674952198852772,0.9674329501915708,0.9673704414587332,0.9673076923076923,0.9672447013487476,0.9671814671814671,0.9671179883945842,0.9670542635658915,0.9669902912621359,0.9669260700389105,0.9668615984405458,0.966796875,0.9667318982387475,0.9666666666666667,0.9666011787819253,0.9665354330708661,0.9664694280078896,0.9664031620553359,0.9663366336633663,0.9662698412698413,0.9662027833001988,0.9661354581673307,0.9660678642714571,0.966,0.9659318637274549,0.9658634538152611,0.96579476861167,0.9657258064516129,0.9656565656565657,0.9655870445344129,0.9655172413793104,0.9654471544715447,0.9674134419551935,0.9673469387755103,0.967280163599182,0.9672131147540983,0.9671457905544147,0.9670781893004116,0.9670103092783505,0.9669421487603306,0.9668737060041408,0.966804979253112,0.9667359667359667,0.9666666666666667,0.9665970772442589,0.9665271966527197,0.9664570230607966,0.9663865546218487,0.9663157894736842,0.9662447257383966,0.9661733615221987,0.9661016949152542,0.9660297239915074,0.9659574468085106,0.9658848614072495,0.9658119658119658,0.9657387580299786,0.9678111587982833,0.967741935483871,0.9676724137931034,0.9676025917926566,0.9675324675324676,0.9674620390455532,0.967391304347826,0.9673202614379085,0.9672489082969432,0.9671772428884027,0.9671052631578947,0.967032967032967,0.9691629955947136,0.9690949227373068,0.9690265486725663,0.9689578713968958,0.9688888888888889,0.9688195991091314,0.96875,0.9686800894854586,0.968609865470852,0.9685393258426966,0.9684684684684685,0.9683972911963883,0.9683257918552036,0.9682539682539683,0.9681818181818181,0.9681093394077449,0.9680365296803652,0.9679633867276888,0.9701834862385321,0.9701149425287356,0.9700460829493087,0.9699769053117783,0.9699074074074074,0.9698375870069605,0.9697674418604652,0.9696969696969697,0.969626168224299,0.9695550351288056,0.9694835680751174,0.9694117647058823,0.9693396226415094,0.9692671394799054,0.9691943127962085,0.9691211401425178,0.969047619047619,0.9689737470167065,0.9688249400479616,0.9711538461538461,0.9710843373493976,0.9710144927536232,0.9709443099273608,0.9733009708737864,0.9732360097323601,0.973170731707317,0.9731051344743277,0.9730392156862745,0.972972972972973,0.9729064039408867,0.9728395061728395,0.9727722772277227,0.9727047146401985,0.972636815920398,0.972568578553616,0.9725,0.974937343358396,0.9748743718592965,0.9748110831234257,0.9747474747474747,0.9746835443037974,0.9771573604060914,0.9770992366412213,0.9770408163265306,0.9769820971867008,0.9769230769230769,0.9768637532133676,0.9768041237113402,0.9767441860465116,0.9766839378238342,0.9766233766233766,0.9765625,0.9765013054830287,0.9764397905759162,0.9763779527559056,0.9763157894736842,0.9762532981530343,0.9761904761904762,0.9761273209549072,0.976063829787234,0.976,0.9759358288770054,0.9758713136729222,0.9758064516129032,0.9757412398921833,0.9756756756756757,0.975609756097561,0.9755434782608695,0.9754768392370572,0.9754098360655737,0.9753424657534246,0.9752747252747253,0.9752066115702479,0.9751381215469613,0.9750692520775623,0.975,0.9749303621169917,0.9748603351955307,0.9747899159663865,0.9747191011235955,0.9746478873239437,0.9745762711864406,0.9745042492917847,0.9744318181818182,0.9743589743589743,0.9742857142857143,0.9742120343839542,0.9741379310344828,0.9740634005763689,0.9739884393063584,0.9739130434782609,0.9738372093023255,0.9737609329446064,0.9736842105263158,0.9736070381231672,0.9735294117647059,0.9734513274336283,0.9733727810650887,0.973293768545994,0.9732142857142857,0.9731343283582089,0.9730538922155688,0.972972972972973,0.9728915662650602,0.972809667673716,0.9727272727272728,0.9726443768996961,0.9725609756097561,0.9724770642201835,0.9723926380368099,0.9723076923076923,0.9722222222222222,0.9721362229102167,0.9720496894409938,0.9719626168224299,0.975,0.9749216300940439,0.9748427672955975,0.9747634069400631,0.9746835443037974,0.9746031746031746,0.9745222929936306,0.9744408945686901,0.9743589743589743,0.9742765273311897,0.9741935483870968,0.9741100323624595,0.974025974025974,0.9739413680781759,0.9738562091503268,0.9737704918032787,0.9736842105263158,0.9735973597359736,0.9735099337748344,0.973421926910299,0.9733333333333334,0.9732441471571907,0.9731543624161074,0.9730639730639731,0.972972972972973,0.9728813559322034,0.9727891156462585,0.9726962457337884,0.9726027397260274,0.9725085910652921,0.9724137931034482,0.972318339100346,0.9722222222222222,0.9721254355400697,0.972027972027972,0.9719298245614035,0.971830985915493,0.9717314487632509,0.9716312056737588,0.9715302491103203,0.9714285714285714,0.9713261648745519,0.9712230215827338,0.9711191335740073,0.9746376811594203,0.9781818181818182,0.9781021897810219,0.978021978021978,0.9779411764705882,0.977859778597786,0.9777777777777777,0.9776951672862454,0.9776119402985075,0.9775280898876404,0.9774436090225563,0.9773584905660377,0.9772727272727273,0.9771863117870723,0.9770992366412213,0.9770114942528736,0.9769230769230769,0.9768339768339769,0.9767441860465116,0.9766536964980544,0.9765625,0.9764705882352941,0.9763779527559056,0.9762845849802372,0.9761904761904762,0.9760956175298805,0.976,0.9759036144578314,0.9758064516129032,0.9757085020242915,0.975609756097561,0.9755102040816327,0.9753086419753086,0.9752066115702479,0.975103734439834,0.975,0.9748953974895398,0.9747899159663865,0.9746835443037974,0.9745762711864406,0.9744680851063829,0.9743589743589743,0.9742489270386266,0.9741379310344828,0.974025974025974,0.9739130434782609,0.9737991266375546,0.9736842105263158,0.973568281938326,0.9734513274336283,0.9733333333333334,0.9732142857142857,0.9730941704035875,0.972972972972973,0.9728506787330317,0.9727272727272728,0.9726027397260274,0.9724770642201835,0.9723502304147466,0.9722222222222222,0.9720930232558139,0.9719626168224299,0.971830985915493,0.9716981132075472,0.976303317535545,0.9761904761904762,0.9760765550239234,0.9759615384615384,0.9758454106280193,0.9757281553398058,0.975609756097561,0.9754901960784313,0.9753694581280788,0.9752475247524752,0.9751243781094527,0.975,0.9748743718592965,0.9797979797979798,0.9796954314720813,0.9795918367346939,0.9794871794871794,0.979381443298969,0.9792746113989638,0.9791666666666666,0.9790575916230366,0.9789473684210527,0.9788359788359788,0.9787234042553191,0.9786096256684492,0.978494623655914,0.9783783783783784,0.9782608695652174,0.9781420765027322,0.978021978021978,0.9779005524861878,0.9777777777777777,0.9776536312849162,0.9775280898876404,0.9774011299435028,0.9772727272727273,0.9771428571428571,0.9770114942528736,0.9826589595375722,0.9825581395348837,0.9824561403508771,0.9821428571428571,0.9820359281437125,0.9819277108433735,0.9878787878787879,0.9878048780487805,0.9877300613496932,0.9876543209876543,0.9875776397515528,0.9875,0.9874213836477987,0.9873417721518988,0.9872611464968153,0.9871794871794872,0.9870967741935484,0.987012987012987,0.9869281045751634,0.9868421052631579,0.9867549668874173,0.9866666666666667,0.9865771812080537,0.9864864864864865,0.9863945578231292,0.9863013698630136,0.9862068965517241,0.9861111111111112,0.986013986013986,0.9859154929577465,0.9858156028368794,0.9857142857142858,0.9856115107913669,0.9855072463768116,0.9854014598540146,0.9852941176470589,0.9851851851851852,0.9850746268656716,0.9849624060150376,0.9848484848484849,0.9847328244274809,0.9846153846153847,0.9844961240310077,0.984375,0.984251968503937,0.9841269841269841,0.983739837398374,0.9831932773109243,0.9830508474576272,0.9829059829059829,0.9827586206896551,0.9826086956521739,0.9824561403508771,0.9823008849557522,0.9821428571428571,0.9819819819819819,0.9818181818181818,0.9814814814814815,0.9813084112149533,0.9811320754716981,0.9809523809523809,0.9807692307692307,0.9805825242718447,0.9803921568627451,0.9801980198019802,0.98,0.9797979797979798,0.9795918367346939,0.979381443298969,0.9791666666666666,0.9789473684210527,0.9787234042553191,0.978494623655914,0.9782608695652174,0.978021978021978,0.9777777777777777,0.9775280898876404,0.9772727272727273,0.9770114942528736,0.9883720930232558,0.9882352941176471,0.9880952380952381,0.9879518072289156,0.9878048780487805,0.9876543209876543,0.9875,0.9873417721518988,0.9871794871794872,0.987012987012987,0.9868421052631579,0.9866666666666667,0.9864864864864865,0.9863013698630136,0.9861111111111112,0.9859154929577465,0.9857142857142858,0.9855072463768116,0.9852941176470589,0.9850746268656716,0.9848484848484849,0.9846153846153847,0.984375,0.9841269841269841,0.9838709677419355,0.9836065573770492,0.9833333333333333,0.9830508474576272,0.9827586206896551,0.9824561403508771,0.9821428571428571,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],"yaxis":"y"}],"layout":{"height":600,"legend":{"tracegroupgap":0},"shapes":[{"line":{"dash":"dash"},"type":"line","x0":0,"x1":1,"y0":1,"y1":0}],"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"title":{"text":"Precision-Recall Curve (AUC=0.9163)"},"width":800,"xaxis":{"anchor":"y","constrain":"domain","domain":[0,1],"title":{"text":"Recall"}},"yaxis":{"anchor":"x","domain":[0,1],"scaleanchor":"x","scaleratio":1,"title":{"text":"Precision"}}}},"text/html":["<div>                            <div id=\"dcbe661a-1ea2-4a0b-9e6b-9277d872d085\" class=\"plotly-graph-div\" style=\"height:600px; width:800px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"dcbe661a-1ea2-4a0b-9e6b-9277d872d085\")) {                    Plotly.newPlot(                        \"dcbe661a-1ea2-4a0b-9e6b-9277d872d085\",                        [{\"fillpattern\":{\"shape\":\"\"},\"hovertemplate\":\"Recall=%{x}\\u003cbr\\u003ePrecision=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"stackgroup\":\"1\",\"x\":[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9970958373668926,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9932236205227493,0.9932236205227493,0.9922555663117134,0.9922555663117134,0.9912875121006777,0.9912875121006777,0.9903194578896418,0.989351403678606,0.989351403678606,0.9883833494675702,0.9883833494675702,0.9883833494675702,0.9883833494675702,0.9874152952565344,0.9874152952565344,0.9874152952565344,0.9874152952565344,0.9864472410454985,0.9864472410454985,0.9864472410454985,0.9864472410454985,0.9864472410454985,0.9864472410454985,0.9854791868344628,0.9854791868344628,0.9845111326234269,0.9835430784123911,0.9835430784123911,0.9825750242013552,0.9816069699903195,0.9816069699903195,0.9816069699903195,0.9806389157792836,0.9796708615682478,0.9796708615682478,0.9796708615682478,0.978702807357212,0.978702807357212,0.978702807357212,0.978702807357212,0.9777347531461762,0.9767666989351403,0.9767666989351403,0.9757986447241046,0.9757986447241046,0.9748305905130688,0.9748305905130688,0.9748305905130688,0.9738625363020329,0.9738625363020329,0.9738625363020329,0.972894482090997,0.972894482090997,0.972894482090997,0.972894482090997,0.972894482090997,0.972894482090997,0.9719264278799613,0.9719264278799613,0.9719264278799613,0.9719264278799613,0.9709583736689255,0.9709583736689255,0.9709583736689255,0.9709583736689255,0.9709583736689255,0.9709583736689255,0.9699903194578896,0.9690222652468539,0.9690222652468539,0.968054211035818,0.968054211035818,0.968054211035818,0.9670861568247822,0.9661181026137464,0.9651500484027106,0.9651500484027106,0.9641819941916747,0.9632139399806389,0.9622458857696031,0.9622458857696031,0.9622458857696031,0.9622458857696031,0.9622458857696031,0.9612778315585673,0.9603097773475314,0.9603097773475314,0.9603097773475314,0.9603097773475314,0.9603097773475314,0.9593417231364957,0.9583736689254598,0.957405614714424,0.9564375605033882,0.9564375605033882,0.9564375605033882,0.9564375605033882,0.9564375605033882,0.9554695062923524,0.9545014520813165,0.9535333978702807,0.952565343659245,0.9515972894482091,0.9506292352371732,0.9496611810261375,0.9486931268151017,0.9486931268151017,0.9477250726040658,0.9467570183930301,0.9457889641819942,0.9457889641819942,0.9457889641819942,0.9457889641819942,0.9457889641819942,0.9448209099709584,0.9438528557599225,0.9428848015488868,0.9419167473378509,0.9419167473378509,0.9409486931268151,0.9399806389157793,0.9390125847047435,0.9380445304937076,0.9380445304937076,0.9380445304937076,0.9370764762826719,0.936108422071636,0.936108422071636,0.9351403678606002,0.9351403678606002,0.9351403678606002,0.9351403678606002,0.9341723136495643,0.9341723136495643,0.9332042594385286,0.9332042594385286,0.9322362052274927,0.9322362052274927,0.9312681510164569,0.9303000968054211,0.9303000968054211,0.9303000968054211,0.9293320425943853,0.9293320425943853,0.9283639883833494,0.9283639883833494,0.9273959341723137,0.9273959341723137,0.9264278799612778,0.925459825750242,0.925459825750242,0.9244917715392061,0.9235237173281704,0.9235237173281704,0.9235237173281704,0.9225556631171346,0.9215876089060987,0.9215876089060987,0.920619554695063,0.9196515004840271,0.9196515004840271,0.9186834462729913,0.9177153920619555,0.9177153920619555,0.9177153920619555,0.9177153920619555,0.9177153920619555,0.9167473378509197,0.9157792836398838,0.9157792836398838,0.9157792836398838,0.914811229428848,0.9138431752178122,0.9138431752178122,0.9128751210067764,0.9128751210067764,0.9128751210067764,0.9119070667957405,0.9119070667957405,0.9119070667957405,0.9109390125847048,0.9099709583736689,0.9099709583736689,0.9099709583736689,0.9090029041626331,0.9090029041626331,0.9080348499515973,0.9080348499515973,0.9070667957405615,0.9060987415295256,0.9051306873184899,0.904162633107454,0.9031945788964182,0.9022265246853823,0.9012584704743466,0.9002904162633107,0.9002904162633107,0.9002904162633107,0.9002904162633107,0.8993223620522749,0.8983543078412392,0.8983543078412392,0.8973862536302033,0.8964181994191674,0.8964181994191674,0.8954501452081317,0.8954501452081317,0.8944820909970959,0.89351403678606,0.8925459825750242,0.8915779283639884,0.8915779283639884,0.8906098741529526,0.8906098741529526,0.8896418199419167,0.888673765730881,0.8877057115198451,0.8877057115198451,0.8867376573088093,0.8867376573088093,0.8867376573088093,0.8857696030977735,0.8848015488867377,0.8838334946757018,0.882865440464666,0.882865440464666,0.8818973862536302,0.8818973862536302,0.8809293320425944,0.8809293320425944,0.8799612778315585,0.8789932236205228,0.8780251694094869,0.8770571151984511,0.8760890609874153,0.8760890609874153,0.8751210067763795,0.8741529525653436,0.8741529525653436,0.8731848983543078,0.872216844143272,0.8712487899322362,0.8702807357212003,0.8693126815101646,0.8693126815101646,0.8693126815101646,0.8683446272991288,0.8673765730880929,0.8664085188770572,0.8654404646660213,0.8644724104549855,0.8635043562439496,0.8635043562439496,0.8625363020329139,0.861568247821878,0.861568247821878,0.861568247821878,0.8606001936108422,0.8596321393998064,0.8596321393998064,0.8596321393998064,0.8586640851887706,0.8576960309777347,0.856727976766699,0.856727976766699,0.8557599225556631,0.8547918683446273,0.8547918683446273,0.8538238141335914,0.8528557599225557,0.8518877057115198,0.850919651500484,0.850919651500484,0.8499515972894482,0.8489835430784124,0.8480154888673765,0.8470474346563408,0.846079380445305,0.8451113262342691,0.8441432720232332,0.8431752178121975,0.8422071636011617,0.8412391093901258,0.8412391093901258,0.8402710551790901,0.8393030009680542,0.8383349467570184,0.8373668925459826,0.8363988383349468,0.8354307841239109,0.8344627299128751,0.8334946757018393,0.8325266214908035,0.8325266214908035,0.8315585672797676,0.8305905130687319,0.829622458857696,0.8286544046466602,0.8276863504356244,0.8267182962245886,0.8257502420135527,0.8257502420135527,0.8247821878025169,0.8247821878025169,0.8238141335914811,0.8228460793804453,0.8218780251694094,0.8209099709583737,0.8199419167473379,0.818973862536302,0.8180058083252663,0.8170377541142304,0.8160696999031946,0.8151016456921588,0.814133591481123,0.8131655372700871,0.8131655372700871,0.8121974830590513,0.8112294288480155,0.8102613746369797,0.8102613746369797,0.8092933204259438,0.8083252662149081,0.8073572120038722,0.8063891577928364,0.8063891577928364,0.8054211035818006,0.8044530493707648,0.8034849951597289,0.8025169409486931,0.8015488867376573,0.8005808325266215,0.7996127783155856,0.7986447241045499,0.797676669893514,0.7967086156824782,0.7957405614714425,0.7947725072604066,0.7938044530493708,0.7938044530493708,0.7928363988383349,0.7918683446272992,0.7909002904162633,0.7899322362052275,0.7889641819941917,0.7879961277831559,0.78702807357212,0.7860600193610843,0.7850919651500484,0.7841239109390126,0.7831558567279767,0.782187802516941,0.7812197483059051,0.7802516940948693,0.7792836398838335,0.7783155856727977,0.7773475314617618,0.7763794772507261,0.7744433688286544,0.7734753146176185,0.7725072604065828,0.771539206195547,0.7705711519845111,0.7696030977734754,0.7696030977734754,0.7686350435624395,0.7676669893514037,0.7666989351403679,0.7657308809293321,0.7647628267182962,0.7647628267182962,0.7637947725072604,0.7628267182962246,0.7618586640851888,0.7608906098741529,0.7599225556631172,0.7589545014520813,0.7579864472410455,0.7570183930300097,0.7560503388189739,0.755082284607938,0.755082284607938,0.7541142303969022,0.7541142303969022,0.7531461761858664,0.7521781219748306,0.7512100677637947,0.750242013552759,0.7492739593417231,0.7492739593417231,0.7483059051306873,0.7473378509196515,0.7463697967086157,0.7454017424975798,0.744433688286544,0.7434656340755083,0.7434656340755083,0.7424975798644724,0.7415295256534365,0.7405614714424008,0.739593417231365,0.739593417231365,0.7386253630203291,0.7376573088092934,0.7366892545982575,0.7357212003872217,0.7347531461761858,0.7337850919651501,0.7318489835430784,0.7308809293320426,0.7308809293320426,0.7299128751210068,0.7289448209099709,0.7279767666989352,0.7279767666989352,0.7270087124878993,0.7260406582768635,0.7250726040658277,0.7250726040658277,0.7241045498547919,0.723136495643756,0.7221684414327202,0.7212003872216844,0.7202323330106486,0.7192642787996127,0.7192642787996127,0.718296224588577,0.718296224588577,0.7173281703775412,0.7163601161665053,0.7153920619554696,0.7144240077444337,0.7134559535333979,0.712487899322362,0.712487899322362,0.7115198451113263,0.7105517909002904,0.7095837366892546,0.7086156824782188,0.707647628267183,0.7066795740561471,0.7057115198451114,0.7047434656340755,0.7047434656340755,0.7037754114230397,0.7028073572120038,0.7028073572120038,0.7018393030009681,0.7008712487899322,0.6999031945788964,0.6999031945788964,0.6999031945788964,0.6989351403678606,0.6989351403678606,0.6979670861568248,0.6969990319457889,0.6960309777347532,0.6950629235237173,0.6940948693126815,0.6931268151016456,0.6921587608906099,0.691190706679574,0.6902226524685382,0.6892545982575025,0.6882865440464666,0.6873184898354308,0.686350435624395,0.6853823814133592,0.6844143272023233,0.6834462729912875,0.6824782187802517,0.6815101645692159,0.68054211035818,0.6795740561471443,0.6786060019361084,0.6776379477250726,0.6766698935140368,0.675701839303001,0.675701839303001,0.6747337850919651,0.6737657308809293,0.6727976766698935,0.6718296224588577,0.6708615682478218,0.6698935140367861,0.6689254598257502,0.6679574056147144,0.6669893514036787,0.6660212971926428,0.665053242981607,0.6640851887705711,0.6631171345595354,0.6621490803484995,0.6611810261374637,0.6602129719264279,0.6592449177153921,0.6582768635043562,0.6573088092933205,0.6563407550822846,0.6563407550822846,0.6553727008712488,0.6544046466602129,0.6534365924491772,0.6524685382381413,0.6515004840271055,0.6505324298160697,0.6495643756050339,0.648596321393998,0.648596321393998,0.6476282671829623,0.6466602129719264,0.6456921587608906,0.6447241045498547,0.6447241045498547,0.643756050338819,0.6427879961277831,0.6418199419167473,0.6408518877057116,0.6398838334946757,0.6389157792836399,0.6379477250726041,0.6369796708615683,0.6360116166505324,0.6350435624394967,0.6340755082284608,0.633107454017425,0.6321393998063891,0.6311713455953534,0.6302032913843175,0.6302032913843175,0.6292352371732817,0.6282671829622459,0.6282671829622459,0.6272991287512101,0.6263310745401742,0.6253630203291385,0.6243949661181026,0.6234269119070668,0.6224588576960309,0.6214908034849952,0.6205227492739593,0.6205227492739593,0.6195546950629235,0.6185866408518877,0.6176185866408519,0.616650532429816,0.6156824782187803,0.6147144240077445,0.6137463697967086,0.6127783155856728,0.611810261374637,0.6108422071636012,0.6098741529525653,0.6089060987415296,0.6079380445304937,0.6069699903194579,0.6060019361084221,0.6060019361084221,0.6050338818973863,0.6040658276863504,0.6030977734753146,0.6021297192642788,0.601161665053243,0.6001936108422071,0.5992255566311714,0.5982575024201355,0.5972894482090997,0.5963213939980639,0.5953533397870281,0.5943852855759922,0.5934172313649564,0.5924491771539206,0.5924491771539206,0.5914811229428848,0.590513068731849,0.5895450145208132,0.5885769603097774,0.5876089060987415,0.5866408518877058,0.5856727976766699,0.5847047434656341,0.5837366892545982,0.5827686350435625,0.5818005808325266,0.5808325266214908,0.579864472410455,0.5788964181994192,0.5779283639883833,0.5769603097773476,0.5759922555663117,0.5750242013552759,0.57405614714424,0.5730880929332043,0.5721200387221684,0.5711519845111326,0.5701839303000968,0.569215876089061,0.5682478218780251,0.5672797676669894,0.5663117134559535,0.5653436592449177,0.5643756050338818,0.5634075508228461,0.5624394966118103,0.5614714424007744,0.5605033881897387,0.5595353339787028,0.558567279767667,0.5575992255566312,0.5566311713455954,0.5556631171345595,0.5546950629235237,0.5537270087124879,0.5527589545014521,0.5527589545014521,0.5517909002904162,0.5508228460793805,0.5498547918683446,0.5488867376573088,0.547918683446273,0.5469506292352372,0.5459825750242013,0.5459825750242013,0.5450145208131656,0.5450145208131656,0.5440464666021297,0.5430784123910939,0.542110358180058,0.5411423039690223,0.5401742497579864,0.5392061955469506,0.5382381413359149,0.537270087124879,0.5363020329138432,0.5353339787028074,0.5343659244917716,0.5333978702807357,0.5324298160696999,0.5314617618586641,0.5304937076476283,0.5295256534365924,0.5285575992255567,0.5275895450145208,0.526621490803485,0.5256534365924492,0.5246853823814134,0.5237173281703775,0.5227492739593417,0.5217812197483059,0.5208131655372701,0.5198451113262342,0.5188770571151985,0.5179090029041626,0.5169409486931268,0.515972894482091,0.5150048402710552,0.5140367860600193,0.5130687318489835,0.5121006776379478,0.5111326234269119,0.510164569215876,0.5091965150048403,0.5082284607938045,0.5072604065827686,0.5062923523717329,0.505324298160697,0.5043562439496612,0.5033881897386253,0.5024201355275896,0.5014520813165537,0.5004840271055179,0.4995159728944821,0.4985479186834463,0.4975798644724105,0.49661181026137463,0.49564375605033884,0.494675701839303,0.4937076476282672,0.4927395934172314,0.49177153920619554,0.49080348499515974,0.4898354307841239,0.4898354307841239,0.4888673765730881,0.4878993223620523,0.48693126815101645,0.48596321393998065,0.4849951597289448,0.484027105517909,0.4830590513068732,0.48209099709583736,0.48112294288480156,0.4801548886737657,0.4791868344627299,0.4782187802516941,0.47725072604065827,0.4762826718296225,0.4753146176185866,0.4743465634075508,0.47337850919651503,0.4724104549854792,0.4714424007744434,0.47047434656340753,0.46950629235237173,0.46853823814133594,0.4675701839303001,0.4666021297192643,0.46563407550822844,0.46466602129719264,0.46369796708615685,0.462729912875121,0.4617618586640852,0.46079380445304935,0.45982575024201355,0.45982575024201355,0.45885769603097776,0.4578896418199419,0.4569215876089061,0.45595353339787026,0.45498547918683446,0.45401742497579867,0.4530493707647628,0.452081316553727,0.45111326234269117,0.45014520813165537,0.4491771539206196,0.4482090997095837,0.44724104549854793,0.4462729912875121,0.4453049370764763,0.4443368828654405,0.44336882865440463,0.44240077444336884,0.441432720232333,0.4404646660212972,0.4394966118102614,0.43852855759922554,0.43756050338818975,0.4365924491771539,0.4365924491771539,0.4356243949661181,0.4346563407550823,0.43368828654404645,0.43272023233301066,0.4317521781219748,0.430784123910939,0.4298160696999032,0.42884801548886736,0.42787996127783157,0.4269119070667957,0.4259438528557599,0.4259438528557599,0.4249757986447241,0.42400774443368827,0.4230396902226525,0.4220716360116166,0.42110358180058083,0.42013552758954503,0.4191674733785092,0.4181994191674734,0.41723136495643753,0.41626331074540174,0.41529525653436594,0.4143272023233301,0.4133591481122943,0.41239109390125844,0.41142303969022265,0.41045498547918685,0.409486931268151,0.409486931268151,0.4085188770571152,0.4075508228460794,0.40658276863504356,0.40561471442400776,0.4046466602129719,0.4036786060019361,0.4027105517909003,0.40174249757986447,0.40077444336882867,0.3998063891577928,0.398838334946757,0.3978702807357212,0.3969022265246854,0.3959341723136496,0.39496611810261373,0.39399806389157793,0.39303000968054214,0.3910939012584705,0.3910939012584705,0.39012584704743464,0.38915779283639884,0.38818973862536305,0.38818973862536305,0.3872216844143272,0.3862536302032914,0.38528557599225555,0.38431752178121975,0.38334946757018395,0.3823814133591481,0.3814133591481123,0.38044530493707646,0.37947725072604066,0.37850919651500486,0.377541142303969,0.3765730880929332,0.3765730880929332,0.37560503388189737,0.37463697967086157,0.3736689254598258,0.3727008712487899,0.3727008712487899,0.3717328170377541,0.3707647628267183,0.3697967086156825,0.3688286544046467,0.36786060019361083,0.36689254598257504,0.3659244917715392,0.3649564375605034,0.3639883833494676,0.36302032913843174,0.36205227492739595,0.3610842207163601,0.3601161665053243,0.3591481122942885,0.35818005808325265,0.35721200387221685,0.356243949661181,0.3552758954501452,0.3543078412391094,0.35333978702807356,0.35237173281703776,0.3514036786060019,0.3504356243949661,0.3494675701839303,0.34849951597289447,0.3475314617618587,0.3465634075508228,0.345595353339787,0.34462729912875123,0.3436592449177154,0.3426911907066796,0.34172313649564373,0.34075508228460794,0.33978702807357214,0.3388189738625363,0.3378509196515005,0.33688286544046464,0.33591481122942884,0.33494675701839305,0.3339787028073572,0.3330106485963214,0.33204259438528555,0.33107454017424975,0.33010648596321396,0.3291384317521781,0.3281703775411423,0.32720232333010646,0.32623426911907066,0.32526621490803487,0.324298160696999,0.3233301064859632,0.32236205227492737,0.3213939980638916,0.3204259438528558,0.3194578896418199,0.31848983543078413,0.31752178121974833,0.3165537270087125,0.3155856727976767,0.31461761858664083,0.31364956437560504,0.31268151016456924,0.3117134559535334,0.3107454017424976,0.30977734753146174,0.30880929332042595,0.30784123910939015,0.3068731848983543,0.3059051306873185,0.30493707647628265,0.30396902226524686,0.30300096805421106,0.3020329138431752,0.3020329138431752,0.3010648596321394,0.30009680542110356,0.29912875121006777,0.29816069699903197,0.2971926427879961,0.2962245885769603,0.2952565343659245,0.2942884801548887,0.2933204259438529,0.29235237173281703,0.29138431752178123,0.2904162633107454,0.2894482090997096,0.2884801548886738,0.28751210067763794,0.28654404646660214,0.2855759922555663,0.2846079380445305,0.2836398838334947,0.28267182962245885,0.28170377541142305,0.2807357212003872,0.2797676669893514,0.2787996127783156,0.27783155856727976,0.27686350435624396,0.2758954501452081,0.2749273959341723,0.2739593417231365,0.27299128751210067,0.27202323330106487,0.271055179090029,0.2700871248789932,0.2691190706679574,0.2681510164569216,0.2671829622458858,0.26621490803484993,0.26524685382381413,0.26427879961277834,0.2633107454017425,0.2623426911907067,0.26137463697967084,0.26040658276863504,0.26040658276863504,0.26040658276863504,0.25943852855759925,0.2584704743465634,0.2575024201355276,0.25653436592449175,0.25556631171345595,0.25459825750242016,0.2536302032913843,0.2526621490803485,0.25169409486931266,0.25072604065827686,0.24975798644724104,0.24878993223620524,0.24782187802516942,0.2468538238141336,0.24588576960309777,0.24491771539206195,0.24394966118102615,0.24298160696999033,0.2420135527589545,0.24104549854791868,0.24007744433688286,0.23910939012584706,0.23814133591481124,0.2371732817037754,0.2362052274927396,0.23523717328170377,0.23426911907066797,0.23330106485963215,0.23233301064859632,0.2313649564375605,0.22942884801548888,0.22846079380445306,0.22749273959341723,0.2265246853823814,0.22555663117134558,0.2245885769603098,0.22362052274927396,0.22265246853823814,0.22168441432720232,0.2207163601161665,0.2197483059051307,0.21878025169409487,0.21781219748305905,0.21684414327202323,0.2158760890609874,0.2149080348499516,0.21393998063891578,0.21297192642787996,0.21200387221684414,0.2110358180058083,0.21006776379477252,0.2090997095837367,0.20813165537270087,0.20716360116166505,0.20619554695062922,0.20522749273959343,0.2042594385285576,0.20329138431752178,0.20232333010648595,0.20135527589545016,0.20038722168441434,0.1994191674733785,0.1994191674733785,0.1984511132623427,0.19748305905130686,0.19651500484027107,0.19554695062923524,0.19457889641819942,0.1936108422071636,0.19264278799612777,0.19167473378509198,0.19070667957405615,0.18973862536302033,0.1887705711519845,0.18780251694094868,0.18780251694094868,0.1868344627299129,0.18586640851887706,0.18489835430784124,0.18393030009680542,0.1829622458857696,0.1819941916747338,0.18102613746369797,0.18005808325266215,0.17909002904162633,0.1781219748305905,0.1771539206195547,0.17618586640851888,0.17521781219748306,0.17424975798644723,0.1732817037754114,0.17231364956437561,0.1713455953533398,0.17037754114230397,0.16940948693126814,0.16844143272023232,0.16747337850919652,0.1665053242981607,0.16553727008712488,0.16456921587608905,0.16456921587608905,0.16360116166505323,0.16263310745401743,0.15972894482090996,0.15876089060987417,0.15779283639883834,0.15779283639883834,0.15682478218780252,0.1558567279767667,0.15488867376573087,0.15392061955469508,0.15295256534365925,0.15198451113262343,0.1510164569215876,0.15004840271055178,0.14908034849951599,0.14811229428848016,0.14714424007744434,0.14617618586640851,0.1452081316553727,0.1442400774443369,0.14327202323330107,0.14230396902226525,0.14133591481122942,0.1403678606001936,0.1393998063891578,0.13843175217812198,0.13746369796708616,0.13649564375605033,0.1355275895450145,0.1345595353339787,0.1335914811229429,0.13262342691190707,0.13165537270087124,0.13068731848983542,0.12971926427879962,0.1287512100677638,0.12778315585672798,0.12681510164569215,0.12584704743465633,0.12487899322362052,0.12391093901258471,0.12294288480154889,0.12197483059051308,0.12100677637947725,0.12003872216844143,0.11713455953533398,0.1132623426911907,0.1122942884801549,0.11132623426911907,0.11035818005808325,0.10939012584704744,0.10842207163601161,0.1074540174249758,0.10648596321393998,0.10551790900290416,0.10454985479186835,0.10261374636979671,0.10164569215876089,0.10067763794772508,0.09970958373668926,0.09874152952565343,0.09777347531461762,0.0968054211035818,0.09583736689254599,0.09486931268151017,0.09390125847047434,0.09293320425943853,0.09196515004840271,0.0909970958373669,0.09002904162633107,0.08906098741529525,0.08809293320425944,0.08712487899322362,0.08615682478218781,0.08518877057115198,0.08422071636011616,0.08325266214908035,0.08228460793804453,0.08228460793804453,0.08131655372700872,0.0803484995159729,0.07938044530493708,0.07841239109390126,0.07744433688286544,0.07647628267182963,0.0755082284607938,0.07454017424975799,0.07357212003872217,0.07260406582768635,0.07163601161665054,0.07066795740561471,0.0696999031945789,0.06873184898354308,0.06776379477250725,0.06679574056147145,0.06582768635043562,0.06485963213939981,0.06389157792836399,0.06292352371732816,0.061955469506292354,0.06098741529525654,0.060019361084220714,0.0590513068731849,0.05808325266214908,0.057115198451113264,0.05614714424007745,0.05517909002904162,0.05421103581800581,0.05324298160696999,0.05324298160696999,0.05227492739593417,0.051306873184898356,0.05033881897386254,0.049370764762826716,0.0484027105517909,0.04743465634075508,0.046466602129719266,0.04549854791868345,0.044530493707647625,0.04356243949661181,0.04259438528557599,0.041626331074540175,0.04065827686350436,0.03969022265246854,0.03872216844143272,0.0377541142303969,0.036786060019361085,0.03581800580832527,0.03484995159728945,0.03388189738625363,0.03291384317521781,0.031945788964181994,0.030977734753146177,0.030009680542110357,0.02904162633107454,0.028073572120038724,0.027105517909002903,0.026137463697967087,0.02516940948693127,0.02420135527589545,0.023233301064859633,0.022265246853823813,0.021297192642787996,0.02032913843175218,0.01936108422071636,0.018393030009680542,0.017424975798644726,0.016456921587608905,0.015488867376573089,0.01452081316553727,0.013552758954501452,0.012584704743465635,0.011616650532429816,0.010648596321393998,0.00968054211035818,0.008712487899322363,0.007744433688286544,0.006776379477250726,0.005808325266214908,0.00484027105517909,0.003872216844143272,0.002904162633107454,0.001936108422071636,0.000968054211035818,0.0],\"xaxis\":\"x\",\"y\":[0.7341862117981521,0.7352313167259786,0.7357549857549858,0.7362794012829651,0.7368045649072753,0.7373304782298359,0.7378571428571429,0.7383845604002859,0.7389127324749643,0.7394416607015032,0.7399713467048711,0.7405017921146954,0.7410329985652798,0.741564967695621,0.7420977011494253,0.7426312005751258,0.7431654676258993,0.7437005039596832,0.7442363112391931,0.7447728911319395,0.7453102453102453,0.7458483754512636,0.7463872832369942,0.7469269703543022,0.7474674384949349,0.7480086893555394,0.7485507246376811,0.7490935460478607,0.7496371552975326,0.7501815541031227,0.7507267441860465,0.7512727272727273,0.7518195050946143,0.752367079388201,0.7529154518950437,0.7534646243617797,0.754014598540146,0.7545653761869978,0.7551169590643275,0.7556693489392831,0.7562225475841874,0.7567765567765568,0.7573313782991202,0.7578870139398386,0.7584434654919237,0.7590007347538574,0.7595588235294117,0.7601177336276674,0.7606774668630338,0.7612380250552689,0.7617994100294986,0.7623616236162362,0.7629246676514032,0.7634885439763488,0.7640532544378699,0.764618800888231,0.7651851851851852,0.765752409191994,0.766320474777448,0.7668893838158871,0.7674591381872214,0.7680297397769517,0.7686011904761905,0.7691734921816828,0.7697466467958272,0.7703206562266965,0.7708955223880597,0.7714712471994025,0.7720478325859492,0.7726252804786836,0.7737827715355805,0.7743628185907047,0.7749437359339835,0.7755255255255256,0.7761081893313299,0.7766917293233083,0.7772761474793077,0.7778614457831325,0.7784476262245666,0.7790346907993967,0.779622641509434,0.7802114803625377,0.780801209372638,0.7813918305597579,0.7819833459500378,0.7825757575757576,0.7831690674753601,0.783763277693475,0.7843583902809416,0.7849544072948328,0.785551330798479,0.7861491628614916,0.7867479055597868,0.7873475609756098,0.7879481311975591,0.7885496183206107,0.7891520244461421,0.7897553516819572,0.7903596021423106,0.7909647779479326,0.7915708812260537,0.7921779141104295,0.7927858787413661,0.793394777265745,0.7940046118370484,0.7946153846153846,0.7952270977675134,0.7958397534668721,0.7964533538936006,0.7970679012345679,0.7976833976833977,0.7982998454404946,0.7989172467130704,0.8001549186676995,0.8007751937984496,0.8013964313421257,0.8020186335403726,0.8026418026418026,0.8032659409020217,0.8038910505836576,0.8045171339563862,0.8051441932969603,0.8057722308892356,0.8064012490241999,0.80703125,0.8076622361219703,0.8082942097026604,0.8089271730618638,0.8095611285266457,0.8101960784313725,0.8108320251177394,0.8114689709347996,0.8121069182389937,0.8127458693941778,0.8133858267716535,0.814026792750197,0.8146687697160884,0.8153117600631413,0.815955766192733,0.8166007905138339,0.817246835443038,0.8178939034045922,0.8185419968304279,0.8191911181601903,0.8198412698412698,0.8204924543288324,0.8211446740858506,0.8217979315831344,0.822452229299363,0.8223107569721115,0.8229665071770335,0.8236233040702314,0.8242811501597445,0.8249400479616307,0.8256,0.8262610088070457,0.8269230769230769,0.8275862068965517,0.8282504012841091,0.8289156626506025,0.8287781350482315,0.829444891391794,0.8301127214170693,0.830781627719581,0.8314516129032258,0.8321226795803067,0.8319870759289176,0.8318512530315278,0.8325242718446602,0.8331983805668016,0.8338735818476499,0.8345498783454988,0.8352272727272727,0.8359057676685622,0.8365853658536585,0.8379478827361564,0.8386308068459658,0.8393148450244698,0.84,0.8398692810457516,0.8405560098119379,0.8412438625204582,0.8419328419328419,0.8426229508196721,0.8433141919606235,0.8440065681444991,0.8438783894823336,0.8445723684210527,0.8452674897119341,0.8459637561779242,0.8466611706512778,0.8473597359735974,0.8480594549958712,0.8487603305785124,0.8494623655913979,0.8501655629139073,0.8500414250207126,0.8507462686567164,0.8506224066390041,0.8513289036544851,0.8512053200332502,0.8519134775374376,0.8517901748542881,0.8516666666666667,0.8523769808173478,0.8522537562604341,0.8529657477025898,0.8536789297658863,0.8543933054393306,0.8542713567839196,0.8549874266554903,0.8557046979865772,0.8564231738035264,0.8563025210084033,0.8570227081581161,0.8577441077441077,0.8584667228306655,0.8591905564924115,0.859915611814346,0.8597972972972973,0.8605240912933221,0.8604060913705583,0.8602878916172735,0.8610169491525423,0.8608990670059372,0.8607809847198642,0.8615123194562447,0.8622448979591837,0.8621276595744681,0.8620102214650767,0.8627450980392157,0.863481228668942,0.8633646456020495,0.8641025641025641,0.864841745081266,0.865582191780822,0.8654670094258783,0.8653516295025729,0.8660944206008584,0.865979381443299,0.8667239896818573,0.8666092943201377,0.8673557278208441,0.868103448275862,0.8679896462467644,0.8687392055267703,0.8694900605012964,0.8693771626297578,0.8701298701298701,0.8708838821490468,0.8716392020815265,0.8723958333333334,0.8731537793223284,0.8730434782608696,0.8738033072236727,0.8745644599303136,0.8753269398430689,0.87521815008726,0.8759825327510917,0.8767482517482518,0.8775153105861767,0.8782837127845884,0.8790534618755478,0.8789473684210526,0.8788410886742757,0.8796133567662566,0.8795074758135444,0.8802816901408451,0.8810572687224669,0.8809523809523809,0.880847308031774,0.8807420494699647,0.8815207780725022,0.8814159292035398,0.8813108945969885,0.8812056737588653,0.8819875776397516,0.8827708703374778,0.8835555555555555,0.8843416370106761,0.8842386464826358,0.8841354723707665,0.8849241748438894,0.8857142857142857,0.8865058087578195,0.8872987477638641,0.8871978513876455,0.8870967741935484,0.8869955156950673,0.8868940754039497,0.8876909254267745,0.8884892086330936,0.8892889288928892,0.8900900900900901,0.8899909828674482,0.8898916967509025,0.8897922312556459,0.8896925858951176,0.8895927601809954,0.8894927536231884,0.8893925657298277,0.8892921960072595,0.8900999091734787,0.89,0.8898999090081893,0.8897996357012751,0.8906107566089334,0.8914233576642335,0.8922374429223744,0.8930530164533821,0.8929551692589204,0.8928571428571429,0.8927589367552704,0.8926605504587156,0.8934802571166207,0.8933823529411765,0.8932842686292548,0.8931860036832413,0.8930875576036866,0.8939114391143912,0.8947368421052632,0.8946395563770795,0.8945420906567992,0.8953703703703704,0.8952734012974977,0.8961038961038961,0.8969359331476323,0.8977695167286245,0.8976744186046511,0.8985102420856611,0.8984156570363467,0.8992537313432836,0.8991596638655462,0.9,0.8999064546304958,0.899812734082397,0.9006560449859419,0.9015009380863039,0.9014084507042254,0.9022556390977443,0.9021636876763875,0.9030131826741996,0.9029217719132894,0.9037735849056604,0.9036827195467422,0.9035916824196597,0.9044465468306528,0.9043560606060606,0.9042654028436019,0.905123339658444,0.905982905982906,0.905893536121673,0.9058039961941009,0.9066666666666666,0.9065776930409915,0.9064885496183206,0.9073543457497613,0.9072657743785851,0.907177033492823,0.9080459770114943,0.9089165867689357,0.9097888675623801,0.9106628242074928,0.9105769230769231,0.9104908565928778,0.9113680154142582,0.9122468659594986,0.9121621621621622,0.9120772946859903,0.9129593810444874,0.9128751210067764,0.9137596899224806,0.9146459747817652,0.9145631067961165,0.9154518950437318,0.9163424124513618,0.9162609542356378,0.9161793372319688,0.9170731707317074,0.91796875,0.9178885630498533,0.9187866927592955,0.9187071498530852,0.9196078431372549,0.9195289499509323,0.9194499017681729,0.9193706981317601,0.9192913385826772,0.9192118226600985,0.9191321499013807,0.9190523198420533,0.9189723320158103,0.9198813056379822,0.9207920792079208,0.9217046580773043,0.9216269841269841,0.9215491559086395,0.9224652087475149,0.9223880597014925,0.9223107569721115,0.9232303090727817,0.9231536926147704,0.9240759240759241,0.924,0.923923923923924,0.9238476953907816,0.9237713139418254,0.9246987951807228,0.9246231155778895,0.9255533199195171,0.9254783484390735,0.9254032258064516,0.9253279515640767,0.9262626262626262,0.9261880687563195,0.9271255060728745,0.92806484295846,0.9279918864097363,0.9279187817258884,0.9278455284552846,0.9277721261444557,0.9287169042769857,0.928644240570846,0.9295918367346939,0.9295199182839632,0.9304703476482618,0.9303991811668373,0.930327868852459,0.9302564102564103,0.9301848049281314,0.9301130524152107,0.9310699588477366,0.9309989701338826,0.9309278350515464,0.9318885448916409,0.9318181818181818,0.9317476732161324,0.9316770186335404,0.9316062176165804,0.9315352697095436,0.9325025960539979,0.9334719334719335,0.9334027055150884,0.9333333333333333,0.9332638164754953,0.9331941544885177,0.9331243469174504,0.9330543933054394,0.9340314136125655,0.9339622641509434,0.9338929695697796,0.9348739495798319,0.935856992639327,0.9357894736842105,0.9357218124341412,0.9367088607594937,0.9376979936642027,0.9376321353065539,0.9375661375661376,0.9375,0.9384941675503712,0.9384288747346072,0.9383634431455898,0.9393617021276596,0.939297124600639,0.9392324093816631,0.9391675560298826,0.9391025641025641,0.9401069518716577,0.9400428265524625,0.939978563772776,0.9399141630901288,0.9398496240601504,0.9397849462365592,0.9397201291711518,0.9396551724137931,0.9395900755124056,0.9395248380129589,0.9394594594594594,0.9404761904761905,0.9404117009750813,0.940347071583514,0.9402823018458197,0.9402173913043478,0.940152339499456,0.9400871459694989,0.9400218102508179,0.9399563318777293,0.9398907103825137,0.9409190371991247,0.940854326396495,0.9407894736842105,0.9407244785949506,0.9406593406593406,0.9405940594059405,0.9405286343612335,0.9404630650496141,0.9415011037527594,0.9414364640883978,0.9424778761061947,0.9424141749723145,0.9423503325942351,0.9422863485016648,0.9422222222222222,0.9421579532814238,0.9420935412026726,0.9420289855072463,0.9419642857142857,0.9418994413407821,0.941834451901566,0.9417693169092946,0.9417040358744395,0.9427609427609428,0.9426966292134832,0.9426321709786277,0.9425675675675675,0.943630214205186,0.9435665914221218,0.943502824858757,0.9434389140271493,0.9433748584371461,0.9444444444444444,0.9443813847900113,0.9443181818181818,0.944254835039818,0.9441913439635535,0.9441277080957811,0.9440639269406392,0.944,0.9439359267734554,0.9438717067583047,0.9438073394495413,0.9437428243398392,0.9436781609195403,0.9436133486766398,0.9447004608294931,0.9446366782006921,0.9445727482678984,0.9445086705202312,0.9444444444444444,0.944380069524913,0.9443155452436195,0.9442508710801394,0.9441860465116279,0.9441210710128056,0.9440559440559441,0.9439906651108518,0.9439252336448598,0.9438596491228071,0.9437939110070258,0.943728018757327,0.9436619718309859,0.9435957696827262,0.9435294117647058,0.9433962264150944,0.9433293978748524,0.9432624113475178,0.9431952662721893,0.943127962085308,0.9430604982206405,0.9441805225653207,0.9441141498216409,0.944047619047619,0.9439809296781884,0.9439140811455847,0.9438470728793309,0.9449760765550239,0.9449101796407186,0.9448441247002398,0.9447779111644657,0.9447115384615384,0.9446450060168472,0.944578313253012,0.9445114595898673,0.9444444444444444,0.9443772672309553,0.9443099273607748,0.9454545454545454,0.9453883495145631,0.9465370595382746,0.9464720194647201,0.9464068209500609,0.9463414634146341,0.9462759462759462,0.9462102689486552,0.9473684210526315,0.9473039215686274,0.947239263803681,0.9471744471744472,0.947109471094711,0.9470443349753694,0.9469790382244143,0.9481481481481482,0.9480840543881335,0.948019801980198,0.9479553903345725,0.9478908188585607,0.9490683229813665,0.9490049751243781,0.9489414694894147,0.9488778054862843,0.9488139825218477,0.94875,0.9486858573216521,0.9485570890840652,0.9484924623115578,0.949685534591195,0.9496221662468514,0.9495586380832283,0.9494949494949495,0.9506953223767383,0.950632911392405,0.9505703422053232,0.950507614213198,0.951715374841169,0.9516539440203562,0.9515923566878981,0.951530612244898,0.9514687100893997,0.9514066496163683,0.9513444302176697,0.9525641025641025,0.9525032092426188,0.9537275064267352,0.9536679536679536,0.9536082474226805,0.9535483870967741,0.9534883720930233,0.9534282018111255,0.9533678756476683,0.9546044098573282,0.9545454545454546,0.9544863459037711,0.9544270833333334,0.954367666232073,0.9543080939947781,0.954248366013072,0.9541884816753927,0.9541284403669725,0.9553805774278216,0.9553219448094612,0.9552631578947368,0.9565217391304348,0.9564643799472295,0.9564068692206077,0.9563492063492064,0.9576158940397351,0.9588859416445623,0.9588313413014609,0.9601063829787234,0.9600532623169108,0.96,0.9599465954606141,0.9598930481283422,0.9598393574297188,0.9597855227882037,0.959731543624161,0.9596774193548387,0.9596231493943472,0.9595687331536388,0.9595141700404858,0.9594594594594594,0.959404600811908,0.959349593495935,0.9592944369063772,0.9592391304347826,0.9591836734693877,0.9591280653950953,0.9590723055934516,0.9590163934426229,0.9589603283173734,0.958904109589041,0.9588477366255144,0.9587912087912088,0.9601100412654745,0.9600550964187328,0.96,0.9599447513812155,0.9598893499308437,0.9598337950138505,0.9597780859916782,0.9597222222222223,0.9596662030598053,0.9596100278551533,0.9595536959553695,0.9594972067039106,0.9594405594405594,0.9593837535014006,0.9593267882187938,0.9592696629213483,0.9592123769338959,0.9591549295774648,0.9590973201692524,0.9590395480225988,0.958981612446959,0.9603399433427762,0.9602836879432625,0.9602272727272727,0.9601706970128022,0.9601139601139601,0.9600570613409415,0.96,0.9599427753934192,0.9598853868194842,0.9612625538020086,0.9612068965517241,0.9611510791366906,0.9610951008645533,0.961038961038961,0.9624277456647399,0.9623733719247467,0.9623188405797102,0.9622641509433962,0.9622093023255814,0.9621542940320232,0.9620991253644315,0.962043795620438,0.9619883040935673,0.9619326500732065,0.9618768328445748,0.9618208516886931,0.961764705882353,0.9617083946980854,0.9616519174041298,0.9615952732644018,0.9630177514792899,0.9629629629629629,0.9629080118694362,0.9643387815750372,0.9642857142857143,0.9642324888226528,0.9641791044776119,0.9641255605381166,0.9640718562874252,0.9640179910044977,0.963963963963964,0.9639097744360903,0.9653614457831325,0.9653092006033183,0.9652567975830816,0.9652042360060514,0.9651515151515152,0.9650986342943855,0.9650455927051672,0.9649923896499238,0.9649390243902439,0.9648854961832061,0.9648318042813455,0.9647779479326187,0.9647239263803681,0.9646697388632872,0.9646153846153847,0.9645608628659477,0.9660493827160493,0.9659969088098919,0.9659442724458205,0.9658914728682171,0.9658385093167702,0.9657853810264385,0.9657320872274143,0.9656786271450858,0.965625,0.9655712050078247,0.9655172413793104,0.9654631083202512,0.9654088050314465,0.9653543307086614,0.9652996845425867,0.966824644549763,0.9667721518987342,0.9667194928684627,0.9666666666666667,0.9666136724960255,0.9665605095541401,0.9665071770334929,0.9664536741214057,0.9664,0.9663461538461539,0.9662921348314607,0.9662379421221865,0.966183574879227,0.9661290322580646,0.9660743134087237,0.9660194174757282,0.965964343598055,0.9659090909090909,0.9658536585365853,0.9657980456026058,0.965742251223491,0.9656862745098039,0.9656301145662848,0.9655737704918033,0.9655172413793104,0.9654605263157895,0.9654036243822076,0.9653465346534653,0.9652892561983472,0.9652317880794702,0.9651741293532339,0.9651162790697675,0.9650582362728786,0.965,0.9649415692821369,0.9648829431438127,0.964824120603015,0.964765100671141,0.9647058823529412,0.9646464646464646,0.9645868465430016,0.964527027027027,0.9661590524534687,0.9661016949152542,0.966044142614601,0.9659863945578231,0.9659284497444633,0.9658703071672355,0.9658119658119658,0.9657534246575342,0.967409948542024,0.9673539518900344,0.9690189328743546,0.9689655172413794,0.9689119170984456,0.9688581314878892,0.9688041594454073,0.96875,0.9686956521739131,0.9686411149825784,0.9685863874345549,0.9685314685314685,0.968476357267951,0.968421052631579,0.968365553602812,0.9683098591549296,0.9682539682539683,0.9681978798586572,0.968141592920354,0.9680851063829787,0.9680284191829485,0.9679715302491103,0.9679144385026738,0.9678571428571429,0.9677996422182469,0.967741935483871,0.9676840215439856,0.9676258992805755,0.9675675675675676,0.9675090252707581,0.9674502712477396,0.967391304347826,0.9673321234119783,0.9672727272727273,0.9672131147540983,0.9671532846715328,0.9670932358318098,0.967032967032967,0.9669724770642202,0.9669117647058824,0.9668508287292817,0.966789667896679,0.966728280961183,0.9666666666666667,0.9666048237476809,0.966542750929368,0.9664804469273743,0.9664179104477612,0.9663551401869159,0.9662921348314607,0.9662288930581614,0.9661654135338346,0.9661016949152542,0.9660377358490566,0.9659735349716446,0.9659090909090909,0.9658444022770398,0.9657794676806084,0.9657142857142857,0.9656488549618321,0.9674952198852772,0.9674329501915708,0.9673704414587332,0.9673076923076923,0.9672447013487476,0.9671814671814671,0.9671179883945842,0.9670542635658915,0.9669902912621359,0.9669260700389105,0.9668615984405458,0.966796875,0.9667318982387475,0.9666666666666667,0.9666011787819253,0.9665354330708661,0.9664694280078896,0.9664031620553359,0.9663366336633663,0.9662698412698413,0.9662027833001988,0.9661354581673307,0.9660678642714571,0.966,0.9659318637274549,0.9658634538152611,0.96579476861167,0.9657258064516129,0.9656565656565657,0.9655870445344129,0.9655172413793104,0.9654471544715447,0.9674134419551935,0.9673469387755103,0.967280163599182,0.9672131147540983,0.9671457905544147,0.9670781893004116,0.9670103092783505,0.9669421487603306,0.9668737060041408,0.966804979253112,0.9667359667359667,0.9666666666666667,0.9665970772442589,0.9665271966527197,0.9664570230607966,0.9663865546218487,0.9663157894736842,0.9662447257383966,0.9661733615221987,0.9661016949152542,0.9660297239915074,0.9659574468085106,0.9658848614072495,0.9658119658119658,0.9657387580299786,0.9678111587982833,0.967741935483871,0.9676724137931034,0.9676025917926566,0.9675324675324676,0.9674620390455532,0.967391304347826,0.9673202614379085,0.9672489082969432,0.9671772428884027,0.9671052631578947,0.967032967032967,0.9691629955947136,0.9690949227373068,0.9690265486725663,0.9689578713968958,0.9688888888888889,0.9688195991091314,0.96875,0.9686800894854586,0.968609865470852,0.9685393258426966,0.9684684684684685,0.9683972911963883,0.9683257918552036,0.9682539682539683,0.9681818181818181,0.9681093394077449,0.9680365296803652,0.9679633867276888,0.9701834862385321,0.9701149425287356,0.9700460829493087,0.9699769053117783,0.9699074074074074,0.9698375870069605,0.9697674418604652,0.9696969696969697,0.969626168224299,0.9695550351288056,0.9694835680751174,0.9694117647058823,0.9693396226415094,0.9692671394799054,0.9691943127962085,0.9691211401425178,0.969047619047619,0.9689737470167065,0.9688249400479616,0.9711538461538461,0.9710843373493976,0.9710144927536232,0.9709443099273608,0.9733009708737864,0.9732360097323601,0.973170731707317,0.9731051344743277,0.9730392156862745,0.972972972972973,0.9729064039408867,0.9728395061728395,0.9727722772277227,0.9727047146401985,0.972636815920398,0.972568578553616,0.9725,0.974937343358396,0.9748743718592965,0.9748110831234257,0.9747474747474747,0.9746835443037974,0.9771573604060914,0.9770992366412213,0.9770408163265306,0.9769820971867008,0.9769230769230769,0.9768637532133676,0.9768041237113402,0.9767441860465116,0.9766839378238342,0.9766233766233766,0.9765625,0.9765013054830287,0.9764397905759162,0.9763779527559056,0.9763157894736842,0.9762532981530343,0.9761904761904762,0.9761273209549072,0.976063829787234,0.976,0.9759358288770054,0.9758713136729222,0.9758064516129032,0.9757412398921833,0.9756756756756757,0.975609756097561,0.9755434782608695,0.9754768392370572,0.9754098360655737,0.9753424657534246,0.9752747252747253,0.9752066115702479,0.9751381215469613,0.9750692520775623,0.975,0.9749303621169917,0.9748603351955307,0.9747899159663865,0.9747191011235955,0.9746478873239437,0.9745762711864406,0.9745042492917847,0.9744318181818182,0.9743589743589743,0.9742857142857143,0.9742120343839542,0.9741379310344828,0.9740634005763689,0.9739884393063584,0.9739130434782609,0.9738372093023255,0.9737609329446064,0.9736842105263158,0.9736070381231672,0.9735294117647059,0.9734513274336283,0.9733727810650887,0.973293768545994,0.9732142857142857,0.9731343283582089,0.9730538922155688,0.972972972972973,0.9728915662650602,0.972809667673716,0.9727272727272728,0.9726443768996961,0.9725609756097561,0.9724770642201835,0.9723926380368099,0.9723076923076923,0.9722222222222222,0.9721362229102167,0.9720496894409938,0.9719626168224299,0.975,0.9749216300940439,0.9748427672955975,0.9747634069400631,0.9746835443037974,0.9746031746031746,0.9745222929936306,0.9744408945686901,0.9743589743589743,0.9742765273311897,0.9741935483870968,0.9741100323624595,0.974025974025974,0.9739413680781759,0.9738562091503268,0.9737704918032787,0.9736842105263158,0.9735973597359736,0.9735099337748344,0.973421926910299,0.9733333333333334,0.9732441471571907,0.9731543624161074,0.9730639730639731,0.972972972972973,0.9728813559322034,0.9727891156462585,0.9726962457337884,0.9726027397260274,0.9725085910652921,0.9724137931034482,0.972318339100346,0.9722222222222222,0.9721254355400697,0.972027972027972,0.9719298245614035,0.971830985915493,0.9717314487632509,0.9716312056737588,0.9715302491103203,0.9714285714285714,0.9713261648745519,0.9712230215827338,0.9711191335740073,0.9746376811594203,0.9781818181818182,0.9781021897810219,0.978021978021978,0.9779411764705882,0.977859778597786,0.9777777777777777,0.9776951672862454,0.9776119402985075,0.9775280898876404,0.9774436090225563,0.9773584905660377,0.9772727272727273,0.9771863117870723,0.9770992366412213,0.9770114942528736,0.9769230769230769,0.9768339768339769,0.9767441860465116,0.9766536964980544,0.9765625,0.9764705882352941,0.9763779527559056,0.9762845849802372,0.9761904761904762,0.9760956175298805,0.976,0.9759036144578314,0.9758064516129032,0.9757085020242915,0.975609756097561,0.9755102040816327,0.9753086419753086,0.9752066115702479,0.975103734439834,0.975,0.9748953974895398,0.9747899159663865,0.9746835443037974,0.9745762711864406,0.9744680851063829,0.9743589743589743,0.9742489270386266,0.9741379310344828,0.974025974025974,0.9739130434782609,0.9737991266375546,0.9736842105263158,0.973568281938326,0.9734513274336283,0.9733333333333334,0.9732142857142857,0.9730941704035875,0.972972972972973,0.9728506787330317,0.9727272727272728,0.9726027397260274,0.9724770642201835,0.9723502304147466,0.9722222222222222,0.9720930232558139,0.9719626168224299,0.971830985915493,0.9716981132075472,0.976303317535545,0.9761904761904762,0.9760765550239234,0.9759615384615384,0.9758454106280193,0.9757281553398058,0.975609756097561,0.9754901960784313,0.9753694581280788,0.9752475247524752,0.9751243781094527,0.975,0.9748743718592965,0.9797979797979798,0.9796954314720813,0.9795918367346939,0.9794871794871794,0.979381443298969,0.9792746113989638,0.9791666666666666,0.9790575916230366,0.9789473684210527,0.9788359788359788,0.9787234042553191,0.9786096256684492,0.978494623655914,0.9783783783783784,0.9782608695652174,0.9781420765027322,0.978021978021978,0.9779005524861878,0.9777777777777777,0.9776536312849162,0.9775280898876404,0.9774011299435028,0.9772727272727273,0.9771428571428571,0.9770114942528736,0.9826589595375722,0.9825581395348837,0.9824561403508771,0.9821428571428571,0.9820359281437125,0.9819277108433735,0.9878787878787879,0.9878048780487805,0.9877300613496932,0.9876543209876543,0.9875776397515528,0.9875,0.9874213836477987,0.9873417721518988,0.9872611464968153,0.9871794871794872,0.9870967741935484,0.987012987012987,0.9869281045751634,0.9868421052631579,0.9867549668874173,0.9866666666666667,0.9865771812080537,0.9864864864864865,0.9863945578231292,0.9863013698630136,0.9862068965517241,0.9861111111111112,0.986013986013986,0.9859154929577465,0.9858156028368794,0.9857142857142858,0.9856115107913669,0.9855072463768116,0.9854014598540146,0.9852941176470589,0.9851851851851852,0.9850746268656716,0.9849624060150376,0.9848484848484849,0.9847328244274809,0.9846153846153847,0.9844961240310077,0.984375,0.984251968503937,0.9841269841269841,0.983739837398374,0.9831932773109243,0.9830508474576272,0.9829059829059829,0.9827586206896551,0.9826086956521739,0.9824561403508771,0.9823008849557522,0.9821428571428571,0.9819819819819819,0.9818181818181818,0.9814814814814815,0.9813084112149533,0.9811320754716981,0.9809523809523809,0.9807692307692307,0.9805825242718447,0.9803921568627451,0.9801980198019802,0.98,0.9797979797979798,0.9795918367346939,0.979381443298969,0.9791666666666666,0.9789473684210527,0.9787234042553191,0.978494623655914,0.9782608695652174,0.978021978021978,0.9777777777777777,0.9775280898876404,0.9772727272727273,0.9770114942528736,0.9883720930232558,0.9882352941176471,0.9880952380952381,0.9879518072289156,0.9878048780487805,0.9876543209876543,0.9875,0.9873417721518988,0.9871794871794872,0.987012987012987,0.9868421052631579,0.9866666666666667,0.9864864864864865,0.9863013698630136,0.9861111111111112,0.9859154929577465,0.9857142857142858,0.9855072463768116,0.9852941176470589,0.9850746268656716,0.9848484848484849,0.9846153846153847,0.984375,0.9841269841269841,0.9838709677419355,0.9836065573770492,0.9833333333333333,0.9830508474576272,0.9827586206896551,0.9824561403508771,0.9821428571428571,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Recall\"},\"constrain\":\"domain\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Precision\"},\"scaleanchor\":\"x\",\"scaleratio\":1},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Precision-Recall Curve (AUC=0.9163)\"},\"height\":600,\"width\":800,\"shapes\":[{\"line\":{\"dash\":\"dash\"},\"type\":\"line\",\"x0\":0,\"x1\":1,\"y0\":1,\"y1\":0}],\"showlegend\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('dcbe661a-1ea2-4a0b-9e6b-9277d872d085');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"}],"source":["target_score = lgb_clf.predict_proba(features_valid)[:, 1]\n","\n","fpr, tpr, thresholds = roc_curve(target_valid, target_score)\n","\n","fig = px.area(\n","    x=fpr, y=tpr,\n","    title=f'ROC Curve (AUC={auc(fpr, tpr):.4f})',\n","    labels=dict(x='False Positive Rate', y='True Positive Rate'),\n","    width=800, height=600\n",")\n","fig.add_shape(\n","    type='line', line=dict(dash='dash'),\n","    x0=0, x1=1, y0=0, y1=1\n",")\n","\n","fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n","fig.update_xaxes(constrain='domain')\n","fig.update_layout(showlegend=False)\n","fig.show()\n","\n","precision, recall, thresholds = precision_recall_curve(target_valid, target_score)\n","\n","fig = px.area(\n","    x=recall, y=precision,\n","    title=f'Precision-Recall Curve (AUC={auc(fpr, tpr):.4f})',\n","    labels=dict(x='Recall', y='Precision'),\n","    width=800, height=600\n",")\n","fig.add_shape(\n","    type='line', line=dict(dash='dash'),\n","    x0=0, x1=1, y0=1, y1=0\n",")\n","fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n","fig.update_xaxes(constrain='domain')\n","fig.update_layout(showlegend=False)\n","fig.show()"]},{"cell_type":"markdown","metadata":{},"source":["--------"]},{"cell_type":"markdown","metadata":{},"source":["# XGBoost"]},{"cell_type":"code","execution_count":653,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T16:54:34.856327Z","iopub.status.busy":"2023-11-30T16:54:34.855760Z","iopub.status.idle":"2023-11-30T17:05:01.539192Z","shell.execute_reply":"2023-11-30T17:05:01.538397Z","shell.execute_reply.started":"2023-11-30T16:54:34.856295Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Runtime:\n","CPU times: user 1.64 s, sys: 975 ms, total: 2.61 s\n","Wall time: 2min 21s\n"]}],"source":["%%time\n","\n","xgb_model = xgb.XGBClassifier(random_state=random_state) # fix encoding if issues arise\n","\n","xgb_params = {\n","#'min_child_weight': [1, 5, 10],\n","#'gamma': [0.5, 1, 1.5, 2, 5],\n","#'subsample': [0.6, 0.8, 1.0],\n","#'colsample_bytree': [0.6, 0.8, 1.0],\n","'booster': ['dart', 'gblinear', 'gbtree'],\n","#'max_leaves': [0,6,12,16,25,35],\n","'learning_rate': [0.01, 0.05, 0.08, 0.1, 0.15, 0.2],\n","#'max_depth': [1,,6,8,12,15,18,20],\n","'eval_metric': ['auc'],\n","}\n","\n","xgb_clf = RandomizedSearchCV(xgb_model, xgb_params, scoring='roc_auc', n_jobs=-1, cv=cv)\n","xgb_clf.fit(features_train, target_train)\n","# create a variable for the best model\n","best_xgb = xgb_clf.best_estimator_\n","xgb_pred = best_xgb.predict(features_valid)\n","print('Runtime:')"]},{"cell_type":"code","execution_count":678,"metadata":{},"outputs":[{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAA9gAAAHkCAYAAADFDYeOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAACz1ElEQVR4nOzdd1zV5fvH8dcBDlO2Cg5A3OJOQbPcW3NkNsw00/pWapn9sjStbDmyZdrSLLMsS3PkVpw5wZ3iVgRUXIDsdc75/UGeIkccBXG8n4/H7/HL+7OuD/IVrnPd930ZLBaLBRERERERERG5IXbFHYCIiIiIiIjInUAJtoiIiIiIiEghUIItIiIiIiIiUgiUYIuIiIiIiIgUAiXYIiIiIiIiIoVACbaIiIiIiIhIIVCCLSIiIiIiIlIIlGCLiIiIiIiIFAIl2CIiIiIiIiKFQAm2iIgUm4sXLzJu3DhatWpF3bp16dixI9OnT8dsNhfo+q1bt1KtWjUA4uLiqFatGnFxcQBUq1aNrVu3FlqsFy5cYOnSpdY/F/b9/23Hjh08++yzNGrUiNDQUJ566il27txpPT537lxatWpVqM/cvHkzR48eva5rz549S8OGDfn444/zjVssFvr27csLL7yQb3zlypX06dOHsLAw6taty0MPPcRvv/2W75xWrVpRrVo16/81bNiQF198kQsXLlwzFrPZzPfff0/Xrl2pW7cuLVu25L333iMpKcl6Tp8+fZg0adJ1vWtB/Pv7cdeuXbRr147atWsze/bsIv/+ERGR4qEEW0REikViYiIPP/wwe/fu5f3332fRokW88MILfP3117z//vs2369MmTJs2LCBMmXKFEG08OGHH7Ju3Trrnzds2ED9+vWL5FnLly/nySefpHr16syYMYNZs2ZRtWpV+vbty/bt24vkmQD9+vXj/Pnz13Vt6dKlefXVV5k2bRoHDhywjn///fccOnSI0aNHW8e++OILhg4dyr333svPP//MokWL6NmzJ2PHjuXbb7/Nd9/XX3+dDRs2sH79en744QcuXrzIa6+9ds1YhgwZwvfff89zzz3HokWLGDduHDt27ODpp58mKyvrut7PVv/+fpwyZQqBgYEsXbqUjh07Fun3j4iIFB+H4g5ARETuTh999BGOjo5MmzYNJycnAAICAnB2dmbgwIE88cQTBAcHF/h+9vb2lCpVqqjCxWKx5PtzUT0rNTWVN998k+eff56BAwdax0eMGMGpU6eYMGECs2bNKpJn36iHH36YhQsX8vrrrzN79myio6P5+OOPGTduHL6+vgAcPHiQyZMn8+GHH9KpUyfrtb169cLV1ZX333+fvn374uCQ9yuKu7u79Wvt5+fH0KFDefTRR0lJScHd3f2yGH7//XfWrFnDkiVLCAwMBPK+r6ZMmUKbNm1YsGABjzzySFF/KS77fkxJSSE0NJTy5csDUKJEiSKPQUREbj5VsEVE5KbLzs5m8eLF9O7d25pcX9KyZUumT59OuXLlADhy5AgDBgygfv361K5dm8cff/yK05j/PSUXIDIyknbt2lG3bl2GDBnCxYsXgbyp5a1ateKtt96iQYMGTJkyhezsbMaOHUvTpk2pWbMmrVq14pdffgFg0qRJzJs3j3nz5lmnZf9zim9WVhYTJkygefPm1KtXj+eee47Tp0/ni2vFihW0adOG2rVr8+yzz+abrvxPq1evJjU1lb59+1527LXXXuO9996z/tlisTBp0iQaNWpEw4YNGT9+fL6v8dXeB/KmX0+YMIH777+f7t2707JlSwD69u173VOnDQYD7733HkePHuWHH35g1KhRtGzZMl8iPW/ePCpVqpRv7JKOHTvy+++/W5PrK3FxccFgMFz1+Lx582jbtq01ub6kZMmSfP/997Rr1+6ya/7ra7V582a6detG7dq1ad26db4POJYsWUL79u2pXbs2nTp1Ijw8HMj//dinTx8iIiL4/PPPrUsa/vn9k52dzXvvvUejRo1o1KgRr7zyivX749J9Pv/8c0JDQ3nnnXeu+u4iIlL8lGCLiMhNFxMTQ3p6OrVr177smMFgoHHjxjg6OmI2m3nuuecoV64cCxYsYNasWZhMJiZMmFCg58ycOZORI0cyc+ZMjh8/ztixY63HTp48SXZ2NnPnzuWBBx5gypQprF27lkmTJrFs2TK6d+/Ou+++y/nz5+nfvz8dO3akY8eOzJkz57LnvPXWW6xcuZLx48cza9YscnNzGThwYL615F999RUff/wxP/74I3/++SfffffdFWM+cOAAFStWvGKFs3z58lSuXNn651OnTnH8+HFmzZrFO++8w3fffcf69esBrvk+lyxcuJBp06Yxbtw46/rnSZMm0b9//wJ9fa8kKCiIwYMHM2HCBE6cOMFbb72V7/iuXbu45557rnito6Mj/v7+V713Wloa33zzDS1atLhi9Rryvn5X+r4CqFu3Ll5eXpeNX+trZTKZeOmll+jQoQNLly5lyJAhvP322xw5coQLFy7w6quv8uyzz7Js2TIeeughXn755cs+PJk0aRL169enf//+bNiw4bLnf/zxx+zdu5epU6cyY8YMUlNTGTJkSL5zduzYwW+//XbFD15EROTWoSniIiJy0yUnJwNcNUm6JDMzk8cee4zHH38cV1dXAB588EG++eabAj1n8ODBNG/eHIBRo0bx1FNPMWrUKOvxp59+mqCgIACqV69O48aNqVevHgDPPfccn3/+OdHR0TRs2BBnZ2cAfHx88j3j4sWLLFiwgKlTp9K4cWMgb712ixYt2Lhxo3Wa+4svvkidOnUA6NKlC3/++ecVY05JSSnw9GGj0ch7772Hq6srwcHBTJkyhQMHDtCsWbNrvk/JkiUB6Nq1q7Wieomnpydubm4Fev7VNG/enA8//JBKlSpd9vVKTEy8LMlt06ZNvo3Lpk6dSsOGDYG8Dy/effddLBYLmZmZGI1GZsyYcdVnX23q+LVc62vl4OBAUlISJUuWpHz58pQvX57SpUtTqlQpTp48SU5ODv7+/pQrV47+/ftTrVo1nJycSE1Ntd7fy8sLo9GIq6vrZUsLMjIy+PHHH/ntt9+sfxcffPABjRo14uDBg9a/iyeffPKyqryIiNx6lGCLiMhNdynBujRl+2pcXV3p1asX8+fPZ+/evRw7doyoqChrgvhf/lnJDAkJITc3l5iYGOvYpfWwkJfkbdy4kXHjxlmfA2Ayma75jOjoaMxmM3Xr1s33fsHBwRw9etSaYF9K5CFv/W1OTs4V7+fl5WX9AOK/+Pr6Wj94gLwPLLKzswv8Ppem4RdE586dOXXqFABly5Zl8eLFVzzPZDIxatQo7rnnHrZv385vv/3GQw89ZD3u6el52ftNnz7dGle7du3yxfjiiy9ap3UnJyezcOFC+vfvz6+//kqVKlUue76Xl9d/fl/927W+Vl5eXvTq1YtRo0bxxRdf0LJlSx566CE8PT3x8PCgRYsWPPXUUwQHB9O6dWsefvhhXFxcCvzs2NhYcnJyeOyxx/KNm81moqOjqVmzJmDb35WIiBQfTREXEZGbLjAwEHd3d/bt23fF488//zybNm0iLS2Nnj17smjRIipWrMiLL77Iq6++WuDn2NvbW//70iZlRqPROvbP9d+ffPIJw4YNw8HBge7du+dbg3st/15DfonJZMo3Rfyfz72WmjVrEh0dna8Cesm2bdsYPHgwGRkZQP73u+TSexbkfa4W+5VMmTKF+fPnM3/+fKZMmXLV86ZNm8bRo0f59NNPeeKJJxg/fjznzp2zHq9Tp06+dmOQ90FHUFBQvg8hLvH19bUeq127Nq+//jqlS5dm7ty5V3x+zZo1r/p99fHHH/P9999fNv5fX6vRo0ezaNEiHnnkEXbv3s0jjzzCunXrMBgMfP3118yePZv27duzZs0aHnzwQfbv33/Vr8+/Xfow4aeffrJ+fefPn8+KFSu47777rOfZ8nclIiLFRwm2iIjcdA4ODnTq1ImZM2daK66XrF69mtWrV1O6dGkiIiI4e/YsM2bM4Omnn6ZJkyacOnXqsh29r+bQoUPW/96zZw9GozFf1fqfZs2axRtvvMErr7xCp06drEnspWddbWOtgIAAHBwc2LVrl3UsMTGREydO2LQL+iVNmzbF3d2dH3/88bJj33//PfHx8QWqkP7X+9iqXLly1kT3atXUI0eOMGnSJF577TX8/Px46aWXKFGiRL6NuXr27Mnhw4dZtWrVZdefOXOmwPFcbWZB165dCQ8PJzY29rJ7z5w584obqF3ra3Xu3DnefvttgoKCeP755/ntt99o3Lgxq1ev5ujRo4wfP546deowdOhQFi9eTJkyZfjjjz8K/B4BAQHY29uTlJRk/fqWKFGCsWPH/me/bxERufUowRYRkWLxwgsvkJqayoABA4iIiCAmJobZs2czfPhw+vbtS+XKlfHy8iI9PZ3w8HDi4uKYPXv2FZPyq/nkk0/YvHkzu3bt4r333uOxxx67anLq5eXFmjVriI2NZdu2bdZK+aVnubi4cPLkycuSQDc3Nx5++GHeffddtm7dyoEDBxg2bBj+/v75KpAF5ebmxuuvv86kSZP49NNPOXr0KPv37+eNN95g7dq1+daQX8t/vc+VuLq6cvjwYVJSUmyO22Qy8dprr3HPPfdY22C5urry1ltvsWLFCpYvXw7krXf+v//7P15++WW++OILDh06xIkTJ5g5cyY9evSwrme+JCUlhXPnznHu3Dni4uKYNGkSJ06coEOHDleMo1OnToSFhfHkk0+ydOlSYmNjWbduHQMGDKBSpUr07NnTpq+Vp6cnK1euZMyYMcTExBAZGcmBAwcICQnBw8ODn3/+mS+++ILY2FjWrl3LyZMnCQkJKfDXrUSJEjz88MOMHj2arVu3cuTIEV599VVOnDhx1Q+DRETk1qU12CIiUixKlSrFzz//zKRJk6xtiQIDA3nxxRfp1asXAPXr12fQoEG8/fbbZGVlUa1aNd58801GjhxZoGrnU089xciRI0lMTKRjx4688sorVz13zJgxjB49ms6dO+Pn58fDDz+Mvb09+/fvp1mzZnTr1o1BgwbRtWtXtmzZku/a1157jfHjx/Piiy+SnZ1NkyZNmD59Oo6Ojtf1tenatSseHh5MnTqVmTNnYjAYqF27NjNnzrRulPZf/ut9rqRPnz588MEHxMTE8Prrr9sU89SpUzl69CgLFy7MN968eXMeeOAB3n33XRo3boynpyf9+/enevXqfPfdd8yYMYP09HSCgoJ4/PHH6du3b75NysaMGcOYMWOAvGnSlStX5tNPP73qTuQGg4EvvviCKVOm8Omnn3L69GlKlixJmzZtGDRo0BWnWv/X1+qLL75gzJgxdO3aFTc3N3r27MnDDz+MnZ0dkyZN4sMPP+Srr77C19eXl19+mfvvvz9fu7j/Mnz4cOv3T05ODqGhoUyZMuWKSwBEROTWZrBc71wxEREREREREbHSFHERERERERGRQqAEW0RERERERKQQKMEWERERERERKQRKsEVEREREREQKgRJsERERERERkUKgBFtERERERESkENzVfbDNZjOZmZkYDIbiDkVERERERERuQRaLBWdnZ+zs/rs+fVdXsDMzM8nMzCzuMEREREREROQWZUveeFdXsA0GAy4uLri4uBR3KCIiIiIiInKbu6sr2CIiIiIiIiKFRQm2iIiIiIiISCFQgi0iIiIiIiJSCO7qNdj/xWQykZOTU9xhyB3GaDRib29f3GGIiIiIiEghU4J9FampqcTFxWGxWIo7FLnDGAwGypcvT4kSJYo7FBERERERKURKsK/AZDIRFxeHq6srpUqVUp9sKTQWi4Vz584RFxdHlSpVVMkWEREREbmDKMG+gpycHCwWC6VKlVILLyl0pUqVIjo6mpycHCXYIiIiIiJ3EG1ydg2qXEtR0PeViIiIiMidSQn2bSAuLo5atWrRrVs3unfvTpcuXejVqxeHDh2y6T7r1q2jZcuWvPjiizbH0KdPH+t/V6tWzebrCyIuLo5WrVoBMHHiRFatWpVv7HqNGDGCkydPXlccIiIiIiIiBaUp4reJ0qVLs2DBAuufZ86cyauvvsr8+fMLfI9ly5bx7LPP8thjj9n8/IiICJuvuRFDhgwB8pLdG7V161YGDRp0w/cRERERERG5FiXYBZSeng6Ai4uLdYpvdnY2ubm52Nvb4+TkdNm5zs7O2NnlTRLIyckhJycHOzs7nJ2dbziexo0bM2HCBABiYmIYPXo0iYmJODo68tprr3HPPfcwfPhwEhMTiYmJoWfPnqxatYrNmzdjsVi47777rnjN6dOnGTFiBOfPn8fR0ZHRo0czb948AHr06MHcuXOBvM262rZty1dffUXlypXJzs6mTZs2LFq0CA8PD2ucBw4c4M033yQjIwM3Nzc++OADypYty+jRozl06BAXLlygQoUKTJ48Od/7DR8+nLCwMMLCwsjKyuKll17i2LFjBAQEMGbMGDw9PWnVqhW1a9fmwIEDfP/99/z8889s2rSJ5ORkPD09mTx5Mr/99htnz57lf//7Hz/88AOnT59mzJgxZGRk4O7uzltvvUWlSpWIiopi5MiRAFSvXv2G/35EREREROTuc8tMEf/jjz+YPn36Nc9JT09n7ty5jB8/nvHjx7N48eKb1qe6SpUqVKlShYSEBOvYl19+SZUqVRg1alS+c+vUqUOVKlXyTUuePn06VapU4ZVXXrnhWMxmM/Pnz6dBgwYAvPbaawwdOpR58+YxYcIEXnnlFXJzcwFwd3dn6dKlDBgwgFatWvHiiy/Sq1evq17z9ttv07JlSxYtWsTw4cP57LPPeOuttwCsyTXkrSPu0aOHtYK+evVqQkND8yXXAMOGDeN///sfCxcu5LHHHuObb75h586d2NnZ8euvvxIeHk52djbr16+/6vteuHCBJ554gt9//52goCA+//xz67H777+f5cuXk5WVxeHDh5k1axbLly8nODiYRYsW8fzzz1O6dGmmTJmCh4cHr7/+Oh988AHz5s1jyJAhDBs2zPo1fPnll5k3bx7ly5e/4b8jERERERG5+9wSFezIyEjWrFlDYGDgNc+bPXs22dnZ9O3bl8zMTBYsWEBOTg7du3e/OYEWo7Nnz9KtWzcgr3JepUoV3nvvPdLS0vjzzz/zJfm5ubmcPn0agPr16192r2tds3XrVmtl/FIF+Wp69OjB448/bk1M+/Xrl+94YmIi8fHxtGnTBoDu3btb/668vLyYOXMmx44dIzo62lr1v5KgoCAaNmwIQNeuXRk+fLj12KX3CwoK4vXXX2fOnDkcP36cnTt3EhAQkO8+x48fJyYmJt908YSEBC5cuMCZM2do2rSp9b1+++23q8YjIiIiIiJyJcWaYKekpLBo0SKOHz+Or6/vNc+NjY0lOjqagQMHUqpUKQC6dOnCjz/+SKtWrS6rnBa2w4cPA+Rr2/X888/zzDPPXNZqac+ePQD5poL369eP3r17W6eM2+rfa7AvSUlJwdHRMd+xM2fOWL9GV2ozZjabr3qNg4NDvl2uDx8+TJUqVa4Yk7+/PxUrVmTFihUcO3aMxo0b5zv+73vl5OQQFxfHsWPH+PTTT+nXrx89evQgMTERi8Vy1Xf/99fMweHvb9tLX+O9e/cydOhQnnrqKdq3b4+dnd1l9zSbzQQEBFjf22KxcObMmcvO/ef9RURERERECqpYp4ifOnUKe3t7nn/+ecqVK3fNc2NiYihRooQ1cQSoUKECBoOBmJiYog4VV1dXXF1d8yWMjo6OuLq65lt//c9z/5kYGo1GXF1dC2X99T+5u7tToUIFa9K4bds2evToYZ0ibus1YWFhLF68GICdO3fy8ssvA2Bvb3/Fe/bs2ZMxY8bQtWvXy9pPubu7U7ZsWTZs2ADA8uXLGT9+PJs3b6Zz58489NBDlCxZksjISEwm01XjjY6OZu/evQDMmTOHJk2aXHZOZGQkjRs35vHHH6dy5cps3LjRek97e3tMJhMVK1bk4sWLREZGArBw4UKee+45vL29KVeuHOHh4QDW9xcREREREbFFsZbqqlWrVuCWT5c2rvone3t7XFxcSE5OLorwbhsTJkxg9OjRfPPNN9jb2zNx4kQcHR2v65o33niDUaNG8dNPP+Ho6Mj48eMBaNu2LV27dmXOnDn57tOqVStGjBjBgw8+eM3nTJgwAQ8PD8aOHUtaWhqvvPIKy5Ytw9HRkfr1619zt/DAwEC+/vproqOjqVKlCkOHDr3snE6dOjF48GC6dOmC0WikevXqxMbGAtC6dWv+97//MWXKFCZOnMiYMWPIzMzE1dWVDz/80BrniBEjmDx5MvXq1bvm105ERERERG5ccnJykc9EvtkMlmvNzb2J5s+fT1JS0mXreC/5/fffuXDhAk899VS+8U8++YQGDRrQrFkzm5+ZkZEBXD6NOjMzk+PHjxMcHFzoFec7icViYfPmzXzzzTd8++23xR3ObUPfXyIiIiJyN9u/fz/Dhg3DYDCwcOHC4g7nP10tb7yS22axqYODwxWnEefm5mI0GoshIhkzZgyrVq3i66+/Lu5QRERERETkNlGyZEn27dsH5C0F/q/Nrm8nt0ybrv/i6elJSkpKvjGTyURGRsYdN63gdjFy5EhWr1591U3QRERERETk7hYTE8Nrr72WrxNQqVKl+PLLL4mMjLyjkmu4jRLsoKAgkpOT8/Whjo6OBrisHZOIiIiIiIgUvwsXLvDjjz8ya9Yszp8/bx3v0KEDJUuWLMbIisYtO0XcbDaTnp6Ok5MTRqORcuXKERAQwJw5c+jcuTPZ2dksWrSIunXrqoItIiIiIiJSzNLT05k9ezaOjo706tULgPr16zN48GBatmz5n62Z7wS3bIKdnJzMxIkT6datG/Xq1cNgMPDoo4+yZMkSvv/+e4xGIyEhIbRv3764QxUREREREbnrLV26lNdffx1/f38eeugha2ejESNGFHNkN88ts4t4cdAu4lIc9P0lIiIiIrc7i8XC9u3bMRgMNGjQAIDs7GweffRRHnjgAXr37n3H/K57R+4ifis7m5hOclr2VY97uDlS2tv1JkYkIiIiIiJSdL7//ntGjhxJWFgY8+bNA8DR0dH633crJdg36GxiOs+NW0VOrvmq5xgd7PhqeOsbSrLj4uLo0KEDlSpVAvLWqKelpdG9e3defPHF674vwNatW5k8eTI//PDDDd1n1apV7N27lyFDhtzQfSZNmgTACy+8wIEDBxgzZgxJSUmYTCbq1avHyJEjcXUtmg8s4uLi6Nu3L6tXr77i8fnz5zNz5kyys7Mxm8107dqVZ555hjlz5rBw4UK+//77fOePHz8eZ2fnG/6aiIiIiIgUp4SEBLKzs/H39wfyNikbO3YsFStWJDs72zod/G6nBPsGJadlXzO5BsjJNZOcln3DVezSpUuzYMEC65/PnDlD+/bt6dy5szXxLk6tW7emdevWhXrPoUOHMmbMGOrXr4/ZbObtt9/m008/5fXXXy/U5xTEL7/8wqxZs/j6668pXbo0qampPPvsszg4OPDII48wbtw4zpw5g5+fH5DXRm7RokX8/PPPNz1WEREREZHC8tNPP/HGG2/QvXt3PvroIwD8/f3ZuXNnkRW+bldKsAvAYrGQlW264rHsq4xf6bzMrNzLxp0c7TEYDNcV17lz57BYLLi5uTFq1CgOHTrEhQsXqFChApMnT+bChQsMHDiQmjVrsm/fPpydnfnoo48ICAhgw4YNjB07FicnJ4KDg633PH78OG+++SZJSUm4uroycuRI6tSpw/Dhw3F2dmbXrl0kJSUxdOhQwsPD2b9/Py1btmTkyJHMnTuXiIgIBg8ezKBBg6z3PHHiBE8++SRDhw5l2rRpLFy4ELPZTGhoKCNGjMDBwYFvvvmGX3/9FW9vbzw8PKhTpw4A58+fJy0tDQA7OzsGDx7MyZMngbxP0d58801OnToFwODBg2nVqhVnzpzh9ddfJyUlhbNnz9KxY0dee+015s6dy7x580hKSuL++++nb9++jBgxgvPnz+Po6Mjo0aPx8fEhKyuL//u//+PQoUM4ODjw2WefERAQwJdffsn48eMpXbo0ACVKlGDMmDGcPXsWNzc32rdvz6JFixgwYAAAGzZsoHLlypQvX/66/n5FRERERIqD2WwmJycHJycnAKpUqUJmZiZHjhzBbDZjZ5fX7VnJ9eWUYP8Hi8XCa5M3sD864b9PvobXPt9wxfEaFXwYP/j+AiXZZ8+epVu3bmRnZ5OQkECtWrWYPHkysbGx2NnZ8euvv2KxWOjbty/r16+nZs2aHDp0iPfff5/atWvz3nvvMXPmTF5++WVee+01vvvuO6pWrcrIkSOtzxg2bBgDBgygY8eO7Nq1iyFDhrB8+XIgr2I+f/585s2bx7vvvsvy5ctxcnKiWbNmvPDCC9Z7lC9f3lppX7duHR9++CHPPPMMGzZsYNeuXcyZMwd7e3vefPNNZs2aRd26dZk9ezZz587F3t6eRx55xJpgjxgxgsGDB1OqVCkaN25Mq1ataNmyJQDvv/8+Xbt2pV27diQkJPDoo49St25dFi1aRIcOHXj44YdJTU2lefPmPPPMMwCcOnWKZcuWYTQaee6552jZsiVPPvkkERERfPbZZ4wePZoLFy7wxBNPUL9+fcaOHctPP/3EM888w+nTp6lbt26+v5OgoCCCgoIA6NmzJ6NHj7Ym2PPnz+fhhx/+728OEREREZFbxJIlSxg3bhyPPfYYAwcOBKBhw4YsWbKEOnXqXHdx8G6hBPs2cmmKuNlsZvz48ezfv5/GjRtjNBrx8vJi5syZHDt2jOjoaNLT0wHw9fWldu3aANSoUYNt27Zx8OBBSpcuTdWqVQF48MEHmThxImlpaZw4cYKOHTsCUK9ePTw9PTl27BgALVq0AKBs2bJUqVLF2sfOy8uL5OTky+I9cuQIb7/9Nt9++y0lSpRg48aN7Nmzh4ceegiArKws7O3tycrKokWLFpQoUQLIW89hNudNu+/Rowft2rVj8+bNbNq0iREjRtC5c2feeOMNNmzYwOHDh/n8888ByM3N5ejRowwYMIAtW7Ywbdo0Dh8+THZ2tnXnv1q1amE0GoG8tecTJkwAICwsjLCwMOLi4ihdujT169cHoGrVqmzbts36Kd2luK6kfv365OTkcPjwYfz9/dm+fTvjx4+34W9YRERERKR4paSkcPToUX777Teef/55DAYDBoPhskKTXJkS7P9gMBgYP/j+q04RP3by4lWr0/80ftD9VCznedn49UwRt7OzY9iwYXTv3p0pU6ZQvXp1Pv30U/r160ePHj1ITEzkUve1S9M6Lr2LxWKx/v9LHBzyvg2u1LHNYrGQm5s3tf1SYvrPa64mKSmJQYMGMXr0aCpUqADkrUnu168fTz31FJD3P16DwWCtvF9iNBrJysoiOjqaJUuWMHDgQNq2bUvbtm158skn6d69O2+88QZms5kZM2bg5eUF5FX4fXx8GDduHCdOnKBr1660adOGTZs2We//z631HRwc8n3tDx8+jIuLS753u/S18vLyIiAggD///JNGjRpZj+/du5fffvuNt956C8irYi9cuJBy5crRvn17bfYgIiIiIresHTt28PXXX/PQQw/Rrl07ALp160ZGRgY9e/ZUtfo62BV3ALcDg8GAs5PDFf/P0dG+QPdwdLS/4vXX+03r4ODAq6++ytSpU1m7di2dO3fmoYceomTJkkRGRmIyXX1teLVq1bhw4QL79u0DYPHixUDemuKAgACWLl0KwK5duzh79qy10l1QOTk5vPDCCzzyyCM0a9bMOt64cWMWLFhAWloaJpOJoUOH8ttvv3HvvfeyevVqkpOTyc7OJjw8HAAfHx9mzJjBli1brPc4cuQI1apVs97vp59+AiA6OpoHHniAixcvsnHjRp555hk6duzI6dOnOXPmzBUrz2FhYdZ337lzJy+//PI13+vpp59m3LhxnD17FoCLFy8yduxYAgICrOd069aN1atXs3jxYnr27GnT101ERERE5GZavnw5ixYtYsqUKdYxZ2dn+vXrZ51dKrZRBfs21qxZM+rXr09SUhK7du1i2bJlODo6Ur9+feLi4q56ndFo5OOPP2b48OEYjUZq1KhhPTZhwgRGjx7NF198gdFoZNKkSTZXYZctW8aOHTvIyMhg4cKFWCwW6tatyzvvvMPBgwd55JFHMJlMhIWF0bt3bxwcHHjqqafo2bMnnp6elClTBgAPDw++/vprJkyYwMiRIzEajQQHB/PJJ58AMGrUKN566y26dOmCxWLh/fffx9fXl2effZZXX30VDw8PfHx8qF27NrGxsZfF+cYbbzBq1Ch++uknHB0d/3M692OPPYbJZGLAgAEYDAbMZjMPPvgg/fv3t57j6+tLcHAwZ86csX4QICIiIiJS3BISEvjxxx/p2LEjVapUAeDJJ5/k/Pnz1j2E5MYZLFeaF3yXuLQu95/ThgEyMzM5fvw4wcHBODs7X/MeN6sPttw5bPn+EhEREREpDM899xwLFy7kiSee0D5BNrpa3nglqmDfoNLernw1vDXJadlXPcfDzVHJtYiIiIiI3BRms5kFS1ZRsUoIbm5uALTv1pvo+FSq1WnCkbgk5ShFRBVsbqyCLWIrfX+JiIiISFHq9/RgzpVogZ298arnaJZtwdlSwdYmZyIiIiIiIrexkydP5tvUt0Gj+66ZXAPk5JqvOQtXro8S7Gu4i4v7UoT0fSUiIiIihWXYsGE0btyY1atXW8dat2pdjBHd3bQG+wqMRiMGg4Fz585RqlQp9X+TQmOxWDh37hwGgyFfX3ERERERkYIwmUzY2//dKtjDwwOz2UxERARt2rQBwNHJti5AUniUYF+Bvb095cuXJy4ujujo6OIOR+4wBoOB8uXL5/uHUURERETkWiwWC5MnT2b69On88ssvVK5cGYD//e9/9OzZM1/r3XOJ6cUV5l1PCfZVlChRgipVqpCTk1Pcocgdxmg0KrkWEREREZsYDAZ27NhBfHw8s2bNYtSoUQD4+fnh5+dHemYOG3efYmVEDPujE4o52ruXEuxrsLe3VyIkIiIiIiI3ldlsZs2aNfz444989tlnuLu7A/Diiy/ywAMP0KVLFyCvqr3v2AVWRsSwcc8psrJNABgA7fpTPJRgi4iIiIiI3GLefvttjh49yq+//sqAAQMAqF+/PvXr1+dcYgar1x1kVWQspy+kWa8pV8qN1qGBVCznyeipW4or9LuaEmwREREREZFiFBcXx7x58xg0aBB2dnbY2dnxwgsvsH//ftq1awdAdo6JLXtPEx4Rw67D57jUmMbFyZ7765ajTVggNSr4YDAYOJuYjtHBjpxc81WfaXSww8NNm6EVNoPlLu4ZZEvDcBERERERkcKWlZXFPffcQ1JSEjNnzqRFixbWYxaLhSNxSYRHxLBu50nSMv7eH6pWJV/ahAZyX52yODtdXjc9m5h+zT7XHm6OlPZ2LdR3uVPZkjeqgi0iIiIiInKTZGdnExkZyX333QeAk5MTPXv25MCBA9a11hdTs1izPY7wiBOciE+xXlvSy4XWDQNoHRpImZJu13xOaW9XJdDFQBVsVMEWEREREZGil5KSQosWLThz5gx//PEHwcHBQF5vawsGtu8/Q3hkDJFRZzCZ89I0o4Md99YuQ5vQQOpUKYW9naE4X+GupAq2iIiIiIjILSAhIQEfHx8A3N3dCQkJwWKxEBMTQ3BwMDHxyYRHxrJmeyxJKVnW66oEeNEmLJBm9cpRwlVrpW8XqmCjCraIiIiIiBSuCxcuMGjQIPbs2UNkZCRubnlTus+cOYOjSwm27DvHqogYDsYkWq/xLOFIywYBtAkNJKiMR3GFLv+iCraIiIiIiMhNZrFYMBjypnB7e3sTGxtLSkoKW7dupUWLlvx55DzhkXFs2nOK7L92+LazMxBaw4/WoYGEhvjhYG9XnK8gN0gVbFTBFhERERGR65eQkMDkyZPZuXMnc+fOtSbZEREROLr5si82h9XbYjibmGG9JsDPnbZhgbRoUB5vd+fiCl0KQBVsERERERGRm8Te3p4ffviB9PR0tmzZQv0GoWz+8zTh23PYc2Sv9Tw3Zwea1S9Pm7BAqgR4WRNxuXOogo0q2CIiIiIiUjDZ2dksXLiQI0eO8Nprr1nHp0//Hns3f5Ispdmw+xTpmbkAGAxQt3IpWocFcm/tMjgZ7YsrdLlOtuSNSrBRgi0iIiIiIgVz8OBBWrVqhZ2dHRs3bqSEV2nWbIslPDKGuLOp1vP8fFxpHRpI64YBlPZRP+rbmRLsAlKCLSIiIiIi17J//36io6Pp2LGjdezFIS/h7l8TO+/q7DmaiPmvntWORnvuq1OGtmFB1Kzoi516Vt8RtAZbRERERETkBm3dupUePXrg5eVFixYtiE/MJjwyhgue7Tl+PhvOJwBQPcibNmGBNK1XDldnYzFHLcVJFWxUwRYREREREUhLS+PUqVNUqVIFAJPJRItW7Qmq3QrPwFBizqRbz/V2d6JVwwBahwYS4OdeXCHLTaAp4gWkBFtERERERAA2btzI008/TUBAAEuWLmP34XOER8SwZe9pck15KZODvYGwmv60CQ3knmqlsVfP6ruCpoiLiIiIiIhcg8ViISMjA1fXvA3IQkJCsBg9sPg2oP+7y0lMybaeW6GMB23DAml+T3k8SzgVV8hyG1AFG1WwRURERETuJpGRkbzxxhsEBwfz8aeT2Lj7JOGRsew7dsF6TgkXIy3uKU/rsEAqlfNUz+q7mCrYIiIiIiIiV+Hi4sKx+HTS3X3o89YysnJMANgZoF610rQNC6RRTX+MDupZLbZRBRtVsEVERERE7lRHjhzhyy+/JCgoiMf7PsPqv3pWnz6fZj2nTEk32oYF0qphAL6eyg0kP1WwRUREREREgD/3RrFs4yHKnC/DqpgV/NWyGmdHe5rWK0fr0EBCgn00BVwKhSrYqIItIiIiInInSE1N5ddff6V8+fJUrBFGeGQM63bEkZqRYz2nZkVf2oQGcl/dsrg4qd4o/00VbBERERERuet8/c33/LBgM+VDWmFYnmEdL+npTKvQQFqHBlC2ZIlijFDudEqwRURERETktmOxWIiIiMDTy5tkkwfhETFEnAwg4J7yABgd7GhcqwxtQgOpW7UU9naaAi5FTwm2iIiIiIjcdt4eO5HFGw5TrnpzTIa/e1NXLu9Jm7AgmtcvRwlXx2KMUO5GSrBFREREROSWd/78eXJMBnYfSyE8MoaDF4LxrxGMCfBwc6RlgwDahAVSoYxHcYcqdzEl2CIiIiIicssymy289/E0Vm49gU/QPZgtdgDY2RmoV9mHDk0q0rCGP0YHu2KOVEQJtoiIiIiI3GLMZjNnEtJYu/0k4dtiOZtQCq/AUpgtEOBXgjahgbRsEIC3h3NxhyqSjxJsERERERG5JWTlmPhk6jzW7jiJ0bOCddzVyYHq5R15rNM9VA9Sz2q5dSnBFhERERGRYmOxWDgUk0h4ZCzrd8aRnmm0Jtd1KpekbVggjWuXwdlRqYvc+vRdKiIiIiIiN11icibfz9vE2p2nMNm7W8d9PZwo7XyRgU+0oUI532KMUMR2SrBFREREROSmyDWZiYw6Q3hEDNsOnMFstoC9OwaLieYNg2gTGkjtSiWxU89quU0pwRYRERERkSIVfTqZhesOsmZ7LDlme+t4QElHci5EMahfR+rVDinGCEUKhxJsEREREREpdKnp2azbeZLwyBiOxCb9NWqPo52JB5pVo01YIAF+7kDHYoxSpHApwRYRERERkUJhMlvYffgc4VtPsOnPU5jMeeP2dgbKeZk4sWclTz/VjY4dahZvoCJFRAm2iIiIiIjckNPn01gVGcOqyBjOX8y0jvu4QY82tWhxT3ncXY3Y2T1YjFGKFD0l2CIiIiIiYrPMrFw27jnFyogY9h27YB13czHiwVkiV83k0UH96NasUjFGKXJzGSwWi6W4gyguGRkZALi4uBRzJCIiIiIitz6LxcL+6ATCI2LYsPskGVmmv8bNVAsoQfcWITSq5U9mRhoODg64uroWc8QiN86WvFEVbBERERERuaYLFzNYvS2WVZExnDyXZh0v4+tG6qkdbFo+gy6vvEDT+m0BcDR6FFeoIsVKFWxUwRYRERER+becXBNb98UTHhHDzoNnMf+VNVhM2TS7J4DO91chJNiHo0ePYjabqVq1avEGLFJEiqyCnZmZycKFC/njjz/Yt28fCQkJGAwGSpUqRUhICM2aNaNDhw5KWEVEREREblNH45IIj4xh3Y44UtJzrOMhwT7sWvcrURGL6V7rdWpWbAxA5cqViytUkVtOgSrY2dnZTJkyhRkzZlChQgWaNGlC5cqV8fLywmw2k5iYyMGDB9mxYwfHjx/n8ccf57nnnsPJyelmvMN1UwVbRERERAQupmaxbmcc4RExHD+VbB23t2TyYOtatA0LomypEqxatYrU1FQ6deqE0WgsxohFbp5Cr2A/9thjtGrViiVLllCyZMlrnnvy5El+/fVXHn30UebPn3/Ncy0WC2vXrmXnzp1kZmYSFBREp06d8Pb2vuL5aWlpLF++nKNHj2KxWKhYsSLt27fH3d29IK8hIiIiIiJ/MZnM7Dx0jpURJ4jYF0+uKa/u5mBvR2iNUsydPo7TR7fxfPtplC2V17e6devWxRmyyC2vQBXspKQkvLy8bLpxQa5Zu3YtkZGRdOvWDQ8PD8LDw0lMTGTgwIHY29tfdv706dMxm8106tQJi8XCkiVLMJvNPPPMMzbFdokq2CIiIiJyt4k7m0J4RAxrtseSkJxlHfdyyeXRDvVpfk953F0dmTx5MikpKfTr148yZcoUY8QixavQK9i2JtcFucZkMrF582batGlj3RChZ8+efPTRR0RFRVG7du1852dmZnLixAkee+wx/P39Abj//vuZNWsWGRkZSpJFRERERK4iPTOHP3adYlVkDPujE6zj7q6ONK5Zks/HvEjqhRje6LsGd1dHAAYPHlxc4YrctoqtTVd8fDzZ2dlUrFjROubs7EyZMmU4ceLEZQm2g4MDjo6O7N69mwoVKgCwZ88efH19cXZ2vpmhi4iIiIjc8sxmC/uOXSA8MoaNe06RlZ3Xs9rOAJXLOPNQ29qEhvhjdLDjz1W1yMioRG5ubjFHLXJ7K1CC/V9rqf+pe/fuBTovOTlv8wQPj/w98tzd3a3H/snBwYHu3buzaNEixo0bh8FgwN3dnX79+mEwGAocn4iIiIjInexsYjqrt8USHhHDmYR063i5UiUIrebB5DEvsf/iOd56ZhtGBzsAvvjiC21aJlIICpRgL1y4kE2bNuHh4YGbm9tVzzMYDAVOsHNy8rb8d3DIH4KDg4N1jvs/WSwW4uPjCQgIoEmTJpjNZlavXs2sWbPo37//Lb9juYiIiIhIUcnKMbHlz9OER8Sw+8g5Lu2y5OLkQOOapeh0X2WqBeVtJPzjZ47YWzw4duwY9erVA1ByLVJICpRgT5s2jXfffZc1a9Ywd+7c61qTfdmD/0qsc3Nz8/0POjc3F0dHx8vO37dvHxEREbz00kvWZLpXr158+umn7Ny5k8aNG99wTCIiIiIitwuLxcLh2CTCI2JYvzOOtMy/p3fXqVySesGuzJo2nrnr43ip13rrrM/p06dTtmxZJdUiRaDAa7BHjRrF4cOHGTduHOPGjbvhB3t6egKQkpKCj4+PdTwlJQU/P7/Lzo+JicHX1zdfpdrFxYWSJUty4cKFG45HREREROR2kJiSydrtcYRHxhATn2IdL+XtQuuGgbQODcDf1420tDTeHLqb9PR09u3bZ93jKCgoqLhCF7njFTjBNhgMTJgwgaioqEJ5sJ+fH05OTkRHR1sT7MzMTE6fPk1YWNhl53t4eLB3715yc3Ot1e/s7GwSExMv2xBNREREROROkmsys23/GcIjYti2/wwmc94ccEcHO+6tXZYGVUqwZvFPbPx9Pr07fAGAm5sbkydPpkaNGpQtW7Y4wxe5a9i0i7ifn98Vq8vX9WAHB0JDQwkPD8fNzQ0vLy9WrlyJp6cnNWrUwGw2k56ejpOTE0ajkbp167Jp0ybmzJlDy5YtsVgsrFmzBgcHB+vaERERERGRO8mJ+GTCI2JYuz2OpNS/e1ZXDfSiTVgQTeuVo4SLkWPHjvHtt9OwWCwMGzaM4OBgAFq3bl1coYvclQwWy6UtEG4+s9nMqlWr2LVrF7m5uQQFBdGpUye8vLxISkpi4sSJdOvWzZpAnzt3jvDwcGJjYzEYDAQFBdGuXbvrXhNuS8NwEREREZGbITUjhz92xrEyIobDsUnWca8STrRsGEDTOn7s2LKKlJQUnn76aevxTz75hHvuuYdmzZqpy45IIbIlbyzWBLu4KcEWERERkVuB2Wxhz5FzrIyIYcufp8nONQNgb2cgNMSPNqGBNKjhh4O9HWvWrOGJJ57A3d2dbdu2UaJEiWKOXuTOZkveaNMUcRERERERKTzxF9IIj4xh9bZYziX+3ao2yN+dNmGBtLgngLgTh7l48RgO9mUAaN68OU2bNqVp06aqVIvcYlTBRhVsEREREbl5MrNy2fTnKcIjYvnz6HnruJuLkWb1y9E2LJDK5b0wGAwsWLCAgQMHUrlyZdasWYOdnV0xRi5yd1IFW0RERETkFmKxWDgQnUh4ZAx/7DpJRlZez2qDAepWKUXbsEAa1ypDVmY6Fy9exGDwBqBVq1Z4eXlRq1Yt0tLScHd3L87XEJH/YHMFu0aNGmzYsAFfX9984+fPn6dp06bs37+/UAMsSqpgi4iIiEhRunAxgzXb4wiPiOHkuVTruL+vK21CA2nZMIDS3q4ALFq0iP/7v//jvvvu49tvv7Wem56ejqur602PXUTyFGkFe8yYMVf85Mzd3Z0xY8bYejsRERERkTtKTq6ZiKh4wiNi2HHgDH+1rMbJ0Z776pSlTVggNYN9MRggK+vv1lvVq1cnNTWVEydOkJmZibOzM4CSa5HbiNZgowq2iIiIiNy446cusvKvntUp6dnW8RoVfGgTFsj9dcvi6mwEYO3atbz33nu0aNGCUaNGWc/dvXs3derU0eZlIreQIq1gm0wmfv31V5o3b07ZsmWZOHEiK1asICQkhJEjR153T2oRERERkdtNclo263bEER4Zw7GTF63jPh7OtGoYQOvQAMqXvnz2Z3Z2Nvv37ycxMZHhw4fj4JD3a3ndunVvWuwiUvhsrmC/9957LF++nKlTpxIXF8dLL73Eiy++yPr16/Hz8+Ojjz4qqlgLnSrYIiIiImIrk9nCzoNnCY+MYeveeHJNeT2rHewNNKpZhjZhgdSvWgp7+7wdv6Oiovj666+5//77efjhhwEwm83MmDGDbt264e3tXWzvIiL/zZa80eYEu0mTJnzxxRfUq1eP//u//yMtLY2vvvqKw4cP89hjj7F9+/bri7oYKMEWERERkYI6eS6VVX/1rL5wMdM6XrGsJ23CAml+T3k83Bwvu+6rr77i3XffpXr16oSHh2v6t8htpkiniGdkZODr60tubi7r16/nlVdeAfI+hbs0tUVERERE5E6QnpnDxt2nWBkRw/7oBOu4u6sjLRqUp01oIBXLeVrHk5OTmTVrFqGhodSvXx+AXr16sX//fvr166fkWuQOZ3MFe8CAAbi5uVGiRAl+//131q1bx7lz53j33XcpWbIkEydOLKpYC50q2CIiIiLybxaLhX3HLrAyIoZNe06RmW0CwM4A91T3o01oIGE1/TA62F927YgRI5gxYwadOnVi6tSpNzt0ESkCRVrBfu+993jnnXfYt28fY8eOxdfXlxkzZuDr68tbb71le7QiIiIiIreAc4kZrN4Ww6rIWE5fSLOOlyvlRuvQQFo1DMDX8+9fsC0WC5s2baJy5cr4+fkB0K9fP7Zu3UqrVq1uevwiUvzUpgtVsEVERETuVtk5JrbsPU14RAy7Dp/j0m/GLk723F+3HG3DgqhewfuKU7uHDRvGTz/9xAsvvMDw4cOt4xaLRVPBRe4gRVrBTk1N5auvvqJHjx5UqFCB4cOHW9t0TZgwgXLlytkesYiIiIjITWKxWDgSl0R4RAzrdp4kLSPHeqxWJV/ahgXSpHZZnJ3y/6p89uxZPD09cXJyAqBVq1bMmzfvsvsruRa5e9lcwR42bBgHDhzgs88+Y8+ePbz11luMGTOGZcuWkZmZyZQpU4oq1kKnCraIiIjI3eNiahZrtscRHnGCE/Ep1vGSXi60Dg2gdcNAypR0u+K177//PlOnTuWDDz7gkUceAcBkMpGcnKw2WyJ3uCKtYK9bt44ZM2YQHBzMhAkTaNmyJZ06dSIkJIQHH3zQ9mhFRERERIqIyWRm+4GzrIw4QWTUGUzmvNqS0cGOe2uXoU1oIHWqlMLezvCv60zY2/+9iZmnpyc5OTlERkZaE2x7e3sl1yKSj80JtsViwWg0kpmZyebNm60bm128eBFXV9dCD1BERERE5GxiOslp2Vc97uHmSGnvv38XjYlPJjwyljXbY0lKybKOVwnwok1YIM3qlaOE6+U9qwGmT5/OV199xeeff06DBg0A6N27N/fdd5+19ZaIyJXYnGA3btyYN954A1dXV+zs7GjTpg2bN2/m3Xff1W6JIiIiIlLoziam89y4VeTkmq96jtHBjk9eak5UdAKrImI4GJNoPeZZwpGWDQJoExpIUBmP/3zenj17iI2NZebMmdYE29vbW9VqEflPNq/BTklJYeLEiZw6dYq+ffvSuHFjpk+fzpkzZxgyZAjOzs5FFWuh0xpsERERkVvfkbgkhn6y7j/Pc7A3kGvK+9XWzs5AaA0/2oQF0rCGHw72dle8ZsOGDXz33XeMHTuW0qVLA3Dw4EG2b9/Ogw8+qN8TRcSmvFFtulCCLSIiInIrK2iCDRDg507bsEBaNCiPt/t/F366devGtm3bGDp0KK+88sqNhioid6Ai3eQsIyODX375hSNHjmAymazj2dnZREVFsXTpUltvKSIiIiJyw4b2qk/LBgFXbZN15swZZs2axfPPP4+jY97664EDB7J+/Xpt1isihcLmBHvUqFFs2rSJJk2asGzZMjp27MiJEyf4888/GTx4cFHEKCIiIiLynwL9Pa6aXJvNZrp160ZsbCwBAQH06NEDgPbt29O+ffubGaaI3MFsTrDXr1/PxIkTadKkCYcPH6Zfv37UqlWLcePGcfjw4aKIUURERETuUtk5JsIjTth8nclkYtOmTTRt2hQAOzs7evXqxZo1ayhVqlRhhykiAsCVd3u4hqysLCpUqABAlSpV2Lt3LwCPPvoo27ZtK9TgREREROTuZLFY+GPXSZ7/YDWLN0bbdG1OTg4tWrTgscceY9euXdbxwYMHM3/+fGvSLSJS2GxOsCtVqsSmTZuAvAR7+/btQN7u4llZWde6VERERETkPx2KSeS1yRv44IdtnE1Ix7PElftVX43RaKR+/fp4e3sTFxdnHbe3ty/sUEVE8rF5ivjgwYMZMmSIdR1L586dee655zh48KA+DRQRERGR63Y+KYMZS6JYsz0vKXZytOehllW4v15Zhny09pp9sM2mHExZaYAXAG+++Sbjx49XtxgRuamuq01XbGwsZrOZoKAgDhw4wIIFC/D29qZPnz631T9iatMlIiIiUvwys3KZt/YIc9YcITsnr0tNq4YB9O1UA1/PvN/Tziamk5yWnXeBxQKXNjOzWHjppZfYu2c7H49/x7p5mYhIYVEf7AJSgi0iIiJSfMxmC2t3xDFjSRQXLmYCUKOCD093q0XVQO/Lzk9NTeWLL75g1apVLFq0CKPRCMCuXbtwd3enUqVKNzV+Ebk7FHqC3apVq6u2PPi3VatWFei8W4ESbBEREZHiEXX8AlMX7OVIbBIApX1ceeqBEO6rU/aqv3dmZWURFhbG+fPnmTJlCp07d76JEYvI3cqWvLFAa7BfeOGFG4tIRERERAQ4k5DO9EX72LD7FAAuTg483LoK3ZpVwtH49yZkubm5LF++nK1bt/LOO+8A4OTkxMiRI3F1dVXvahG5JV3XFPGDBw+SlZVFnTp1APj2229p0qQJ1atXL/QAi5Iq2CIiIiI3R3pmDrNXHWbB+qPk5JqxM0DbRkH07lAdb3fny84/ffo0jRs3tibatWrVKoaoRURsyxttbtO1ZMkSHn74YXbs2GEd27NnD48++ijh4eG23k5ERERE7mAms4XlW07w7LhVzFl9mJxcM3WrlOTTl1sw+OF61uT62LFjLFiwwHpdmTJl6NOnD0OGDMHPz6+4whcRsYnNFewOHTrw7LPP8uCDD+Ybnzt3LtOmTWPx4sWFGmBRUgVbREREpOjsPnyOab/v5fipZADKlnSjf5eahNX0z7fO+sCBA7Rp0wYnJyciIyPx8fEprpBFRC5T6Guw/yk+Pp769etfNt6gQQNGjx5t6+1ERERE5A5z6lwq3y7cx9Z98QC4uRjp1a4anZoEY3SwIyMjg+joaGrUqAFAtWrVqFOnDqVKlSI5OVkJtojctmxOsENCQvjxxx8ZNWpUvvFff/31tluDLSIiIiKFJzU9m1krD7F44zFyTRbs7Ax0urcCvdpXx8PNEchbWvj444/j5ubGxo0bcXBwwGAwMHfuXJydL1+LLSJyO7E5wR4+fDgDBgxg3bp11k8dDx48SFJSElOmTCn0AEVERETk1mYymVm2OZqZyw+Skp4NQMMafvTvUpMAP3fS09OBvAS7SpUq1utiY2MJDg4GUHItIneE69pFPCEhgcWLF3P8+HEcHBwICgqia9euuLu7F0WMRUZrsEVERERuzPYDZ5j2+15iz6QCEODnztNda3FP9dLs27ePkSNH4uTkxC+//GK95tChQ1SsWBEHB5trPSIiN50teeN1Jdh3CiXYIiIiItcnJj6ZaQv3sePAWQDcXR15omN12jcKwt4+r1HNyZMnuffee7Gzs2Pz5s2UKVOmOEMWEbkuSrALSAm2iIiIiG0upmbx84qDLN0cjdlswcHewAP3V+T+Gm7MmP4NLi4u+fbqWbBgAY0bN1arLRG5bSnBLiAl2CIiIiIFk5NrZvHGY8xacZC0zFwAGtfy56kuNSlbsgQbN27kkUcewcXFhW3btuHl5VW8AYuIFJIibdMlIiIiIncPi8XC1n3xfLtwH6fPpwFQoYw7Fd3PUtEnnrIlGwHQpEkT+vfvT7t27fD09CzOkEVEis11V7APHz5MdHQ09913HxcuXKB8+fIYDIbCjq9IqYItIiIicnXHT13kmwV72XPkPABe7k706ViDM4c3MPy1VwkKCuKPP/7A3t6+mCMVESk6RVrBvnjxIkOGDCEiIgKA5cuX8/777xMbG8uUKVMoV66crbcUERERkVtIYnImPy47wMqIE1gs4GAH99fy4vlHm+DqbCS9dilm/vgDDz74ILm5uUqwRUT+YnMFe9iwYaSmpjJ+/HiaN2/O77//jpubG8OGDcPR0ZEvv/yyqGItdKpgi4iIiPwtO8fEgvVHmb3qEBlZJgDKeWSyfOZ7NAmtw8yZM4s5QhGRm69IK9h//PEHP/zwAx4eHtYxHx8fRowYwWOPPWbr7URERESkmFksFjbsPsX0xVGcTUgHoGqgF093rY2rXQorZ6RTsmRJcnNz1btaROQarutfyKysrMvGEhIS9A+uiIiIyG3mUEwi3yzYy/7oBAByMpKo7JXIhBeGYGdnAHzYsWOHNi4TESkAO1sveOCBB3j//fc5fPgwBoOB9PR0tmzZwhtvvEGnTp2KIkYRERERKWTnkzL4+Kft/N/E9eyPTsDJ0Z77qjuzd9FbxEWt5Z971yq5FhEpGJvXYGdnZ/Pxxx8zc+ZMcnJyMBgM2Nvb07NnT4YPH46zs3NRxVrotAZbRERE7jaZWbnMXXuE2eEHyTXnjbVqGEDfTjXw8XAmMjKS0NDQ2647jIhIUbElb7zuNl2ZmZnExsZiMpkICAjAzc3tem5TrJRgi4iIyN3CbLawdkccM5ZEceFiJgCp547gnLyLpfN/KOboRERuXUW6yVn79u3p3LkznTp1okqVKrZHJyIiIiI31e8rt/L9koNk2+VN9S7t48rjbSpxdPdZHnvs82KOTkTkzmFzBfuXX35hxYoVbN26leDgYDp27Ejnzp0JCgoqqhiLjCrYIiIicic7k5DO9EX72LD7VN6AOYcnu9Sla9OKOBrVu1pEpCBuyhTxixcvsmrVKlasWMGWLVuoWLEinTt3ZsCAAddzu2KhBFtERETuNElJScyYOQuDTz3W7DpHTq4ZgwFKmE4yuNe9NAmrX9whiojcVm5Kgn3JkSNHWLp0Kd999x0Wi4WdO3feyO1uKiXYIiIicicxmS30fn40SfaVMLrkTQevW6UkA7rWIrisdgIXEbkeRZ5gR0VFsXz5clauXMnJkydp2rQpnTp1omXLlrdVsqoEW0RERG5nFouFP/74g4YNG3L4ZBrTft/L8VPJAHi4wIuPhRFW0187gouI3IAi3eSsVatWnD17lsaNG/PMM8/Qtm1bSpQoYXuUIiIiInJD+vXrxx9bdtP28VGcSjYC4OZi5LG2Vel8X0WMDnbFHKGIyN3F5gT7f//7H+3bt8fb27so4hERERGRqzhz5gylS5fGYDCQmp6NV5UOhPh05VSyA3Z2BjrdW4Fe7avj4eZY3KGKiNyVCpRgR0ZGUr9+fRwcHKhUqRJHjhy56rmhoaGFFpyIiIiI5Bk2bBi//vorM2f+xEXKMHP5QVLSXTHYQcMafvTvUpMAP/fiDlNE5K5WoAS7T58+bNy4EV9fX/r06XPV8wwGA/v37y+04ERERETuVhaLJd/aaQcHB1xLVuWz30+SYToPQICfO093rcU91UsXV5giIvIPN7yL+O1Mm5yJiIjIrcZisfDll1/yww8/MGfOHMqVK0dMfDKfz95OVHTeBmburo480bE67RsFYW+vddYiIkWpSDc5a926Nb/99hteXl75xs+cOUP37t3ZvHmzrbcUERERkb8YDAbWrl1LTEwM03+YhW/VtizdHI3ZbMHB3sAD91fk0bbVKOFiLO5QRUTkXwqUYC9btox169YBcPLkSd555x2cnJzynXPy5Ens7e0LP0IRERGRO5TFYmH9+vXMmjWLjz/+2FodeXHIS9Ro8gh7zrmQvvE4AI1r+fNUl5qULanuLSIit6oCJdhhYWHWBBvyfhj8W5UqVXjllVdserjFYmHt2rXs3LmTzMxMgoKC6NSp01V3KDeZTKxZs4Y9e/aQmZlJ2bJl6dChA/7+/jY9V0RERORWYDKZGDZsGCdPnqRZs2Y89thjbN0Xz4z16Zw+bwRyqVjWkwHdalKncqniDldERP6DzWuwJ0+ezIABAwpl3fLatWuJjIykW7dueHh4EB4eTmJiIgMHDrxiNfz333/n0KFDdO/eHS8vL1avXk1sbCyDBg3C2dnZ5udrDbaIiIjcTKdOnWLJkiUMGDDAuoHZ999/z9GjR2nf9XGWRF5gz5G8Dcy83J3o07EGrUMDsbczXOu2IiJShGzJGwuUYP+zTVdkZOQ1zy1omy6TycQHH3xAmzZtrNdkZmby0Ucf0bVrV2rXrp3v/MTERD777DN69epF1apVred//fXXdO3aleDg4AI995+UYIuIiMjNkpGRQb169UhNTWXevHmEhYUBkJicyY/LDrAy4gQWCxgd7OjevBI9W1XB1VnrrEVEiluhb3JWFG264uPjyc7OpmLFitYxZ2dnypQpw4kTJy5LsI8ePYqzszNVqlTJd/6QIUMK9DwRERGRmyk3N5ddu3bRsGFDIO8Xs65du3L8+HHs7e3JzjGxYP1RZq86REaWCYCm9crxZOcQ/HxcizN0ERG5TgVKsA8cOHDF/74Rycl5bSY8PDzyjbu7u1uP/dOFCxfw9vZm//79bNiwgeTkZMqUKUO7du0oVUprkkREROTWkZiYSLt27Th79ixbtmyhTJkyAIwZMwYHBwc27DrF8+NXcTYxrypSNdCLp7vWpkawT3GGLSIiN8jmNl2QV00uXbo07u7u/PHHH6xevZqQkBAefvjhAt8jJycnLwCH/CE4ODhYS/D/lJWVRUJCAuvXr6dt27Y4Ozvzxx9/8N133zFo0CDc3Nyu51VERERECkVycrK1cODt7U1gYCDZ2dkcOXLEmmAfP53KNwv2sj86AQBfT2ee7BxC8/rlsdM6axGR256drRf88ssvdO3alf379xMVFcXzzz9PbGwsEydOZOLEiQW+z6XEOjc3N994bm4ujo6OlwdqZ0dWVhYPPfQQlSpVoly5cjz00EMA7Nq1y9bXEBERESkUZ8+epU+fPjRv3pysrCzr+MSJE9m6dStNmzblfFIGH/20nf+buJ790Qk4OdrzePvqfDW8NS0bBCi5FhG5Q9icYH/zzTeMHz+esLAwfvvtN2rUqME333zDJ598wuzZswt8H09PTwBSUlLyjaekpODu7n7Z+R4eHtjZ2eWbDm40GvH29iYpKcnW1xAREREpFN7e3kRFRXHu3DkiIiKs4+XLlweDAz8tP8Cz41axdnscAK0aBvD18Nb0alcNZ8frmkwoIiK3KJv/VT9z5gwNGjQAYM2aNTz66KMA+Pv7k5aWVuD7+Pn54eTkRHR0ND4+eeuNMjMzOX36tHVXzX+qUKECa9as4dSpU5QtWxbIm2aemJhIrVq1bH0NEREREZslJCTw9ddfExUVxQ8//ADkfeD/6aefEhAQQIUKFQAwmy2s3RHHjCVRXLiYCUBIsA9Pd6tFlQDv4gpfRESKmM0JdsWKFVm4cCE+Pj6cOnWKNm3akJOTw7fffkv16tUL/mAHB0JDQwkPD8fNzQ0vLy9WrlyJp6cnNWrUwGw2k56ejpOTE0ajkcDAQCpWrMi8efN44IEHcHV1Ze3atdjZ2VG3bl1bX0NERETEZiaTiSlTppCdnc3OnTupX78+AE2bNrWeE3X8AlMX7OVIbBIApX1c6f9ATZrUKWPtfS0iInemAvXB/qfNmzfz0ksvcfHiRR5//HHefPNN3nnnHVasWMFXX31lUzXZbDazatUqdu3aRW5uLkFBQXTq1AkvLy+SkpKYOHEi3bp1o169ekDeRmfh4eFERUWRk5NDQEAAHTp0uO5dxNUHW0RERK4mJyeHJUuWEBMTwwsvvGAd/+qrr6hQoQJt27bF3t7eOn4mIZ3pi/axYfcpAFycHHikTVW6Nq2Io9H+svuLiMjtwZa80eYEG/IS45SUFOs66vPnz+Pp6YnRaLT1VsVKCbaIiIhcze7du+nUqRNGo5GIiAhKly59xfPSM3OYveowC9YfJSfXjJ0B2jYKoneH6ni7O9/kqEVEpLDZkjde184a58+fZ+bMmRw9ehSTyURwcDCPPPKIdd2RiIiIyO3m8OHDxMbG0qpVKwDq1q1Lx44dCQkJuWKHE5PZQnhEDD8u209SSt7u4XWrlGRA11oEl/W8qbGLiMitweYK9rZt23jmmWeoVq0a9erVw2QysXv3bg4ePMi3335r3QDtdqAKtoiIiACsX7+eXr164efnx5YtW66YUP/T7sPnmPb7Xo6fSgagbEk3+nepSVhNf62zFhG5wxTpFPGePXty77338n//93/5xj/88EO2bdvGrFmzbLldsVKCLSIicnfKyMjgzJkz1tl32dnZNGnShLp16zJu3Lir7u9y6lwq3y7cx9Z98QC4uRjp1a4anZoEY3SwufupiIjcBoo0wa5bty4LFiy4bDp4dHQ03bp1Y/fu3bbcrlgpwRYREbn7rF+/nueff54qVaowf/5863h6ejqurq5XvCY1PZtZKw+xeOMxck0W7OwMdLq3Ar3aV8fD7drVbhERub0V6RrscuXKsWfPnssS7N27d1OyZElbbyciIiJS5DIzM3F2zttwrFq1aqSlpXH27FkSExPx9s7rS32l5NpkMrNsczQzlx8kJT0bgIY1/OjfpSYBfu437wVEROS2YHOC/fTTT/PWW29x7Ngx6tSpA+Ql1z/88AMvv/xyoQcoIiIicr0iIyN5++23qVq1Kh9//DEAfn5+LFy4kJCQkHxttv5t+4EzTPt9L7FnUgEI8HPn6a61uKf6lXcTFxERua42XXPnzuXHH3/k6NGjODk5ERwcTL9+/ejYsWNRxFhkNEVcRETkzrZt2za6deuGu7s7O3fuLNDP/Jj4ZKYt3MeOA2cBcHd15ImO1WnfKAh7e62zFhG52xR5H+w7hRJsERGRO8fRo0eZMmUKVatWZcCAAQBYLBZ++OEHOnbseNWNyy65mJrFzysOsnRzNGazBQd7Aw/cX5FH21ajhIvxZryCiIjcggo9wTaZTHz99desXLkSo9FImzZteOqppzAab+8fNkqwRURE7hy//PILL7/8MmXKlGHLli04OBRsJVxOrpnFG48xa8VB0jJzAWhcy5+nutSkbMkSRRmyiIjcBgp9k7PPP/+c6dOn06VLFxwcHPjmm2+IiYnhvffeu7FIRURERK5Deno6c+bMITg4mKZNmwLQrVs3Nm3aRK9eva65tvoSi8XClr3xfLdoH6fPpwFQsawnA7rVpE7la1e7RURErqRAFezWrVvzxhtv0KJFCwAiIiJ45pln2L59e4E/Hb4VqYItIiJye5owYQKffvop9957L3PmzLH5+mMnLzLt973sOXIeAC93J/p0rEHr0EDs7QyFHa6IiNzGCr2CHR8fT0hIiPXPDRs2JDc3l/Pnz+Pv73+dYYqIiIj8N4vFwvbt2ylVqhRBQUEA9O7dm0WLFtGhQwfMZjN2dgXbfCwxOZMflu4nPDIGiwWMDnZ0b16Jnq2q4Op8ey99ExGR4legBNtkMuWbamVnZ4ejoyM5OTlFFpiIiIgIwNixY/n888/p3bs3H3zwAQBly5Zl7dq1GAwFqzZn55hYsP4os1cdIiPLBEDTeuV4snMIfj6X978WERG5Hrfv/G4RERG5IyUkJODk5ISbmxuQt1Rt6tSply1LK0hybbFY2LDrFNMX7+NsYt4Uv6qBXjzdtTY1gn0KP3gREbmrFTjBnjZtGq6uf3/Cm5OTw4wZM/D09Mx33uDBgwsvOhEREbmrTJo0iU8//ZRhw4bx3HPPARAWFsb27dvx8bEtIT4Uk8g3C/ayPzoBgJKezjzZOYRm9ctjp3XWIiJSBAqUYIeGhvLnn3/mG6tfvz4HDhzIN1bQaVoiIiIiAGazGcC6htrX15fMzEwiIyOtCbbBYLApuT6flMH3S6JYuz0OACdHex5qWYUHW1TC2VGT90REpOgUaBfxO5V2ERcRESk+s2fPZtKkSbzxxhu0bdsWyPvZvHv3bho1amTzB/eZWbnMXXuE39YcITsnb511q4YB9O1UA19P/awXEZHrY0veWKAtN+fMmYMtebjJZGL27NkFPl9ERETuPgcOHODo0aPMnDnTOubi4kLjxo1tSq7NZgurt8Xy3PhV/LziINk5JkKCffj4pWYM7XWPkmsREblpCjRPKjY2lgceeIDu3bvTpk0bgoODr3jeiRMnWLx4MQsWLKBdu3aFGqiIiIjcvrZt28Y333zDK6+8QuXKlQHo378/5cqV45FHHrnu+0Ydv8DUBXs5EpsEQGkfV/o/UJMmdcpo6ZqIiNx0BZ4ifuzYMb755huWLFmCt7c3FStWxNvbG7PZTFJSEocOHSI5OZnOnTvz9NNPU6lSpaKO/YZpiriIiMjN8dRTT7FixQqefPJJxowZc8P3O5OQzvRF+9iw+xQALk4OPNKmKl2bVsTRaP8fV4uIiBScLXmjzWuwU1JSiIiIICoqioSEBAwGA76+voSEhNCoUaN8O43f6pRgi4iIFL6EhAR+/vln+vbti7u7OwCbN29mzpw5DBgwgJCQkOu+d3pmDrNXHWbB+qPk5JqxM0DbRkH07lAdb3fnwnoFERERqyJNsO8kSrBFREQKX4cOHfjzzz955513GDBgQKHc02S2EB4Rw4/L9pOUkgVA3SolGdC1FsFlPf/jahERketnS96oXhUiIiJy3cxmMxs3buS+++6zttp6/PHHmTlzJgEBAYXyjN2HzzHt970cP5UMQNmSbvTvUpOwmv5aZy0iIrcUVbBRBVtEROR6WCwWunTpws6dO5k5cyYtWrQA8rqJ2NnZ3XDye+pcKt8u3MfWffEAuLkY6dWuGp2aBGN0KFAjFBERkRumCraIiIgUiYSEBHx8fAAwGAw0aNCAI0eOcPr0aes59vY3tslYano2s1YeYvHGY+SaLNjZGeh0bwV6ta+Oh5vjDd1bRESkKBVKBTshIQFvb+/bbpqWKtgiIiIFk5ubywsvvMDSpUtZs2aNtWVnQkICjo6OlChR4oafYTKZWbY5mpnLD5KSng1Awxp+9O9SkwA/9xu+v4iIyPWwJW+0eX7VmTNnGDp0KPv37ycrK4snnniC++67j1atWnHgwAHboxUREZFb0j8/g3dwcCA1NZWcnBxWr15tHffx8SmU5Hr7gTO88NEavpr3Jynp2QT4ufP2M/fy1tONlVyLiMhtw+YK9vPPP096ejrjxo1j7dq1fPLJJ0ydOpXff/+dAwcOMHPmzKKKtdCpgi0iInK5rKwsvv76a+bNm8eiRYtwc3MDICoqCuCG2mz9W0x8MtMW7mPHgbMAuLs68kTH6rRvFIS9vdZZi4hI8SvSNdhbtmxh7ty5lClThvDwcFq3bk3dunXx8fHhgQcesD1aERERuaUYjUZ+/fVXjh8/zty5c+nTpw9QuIn1xdQsflp+gGVbTmA2W3CwN/DA/RV5tG01SrgYC+05IiIiN5PNCbaTkxNZWVlcvHiRrVu38tFHHwEQFxeHp6f6UIqIiNxOzGYzq1evZsWKFYwfPx6DwYCdnR0jRowgMzOTLl26FOrzcnLNLN54jFkrDpKWmQtA41r+PNWlJmVL3vhUcxERkeJkc4Ldpk0bXnrpJZydnfH09KRFixYsWbKEMWPG8OCDDxZFjCIiIlJEUlNTGThwIGlpaTzwwAM0a9YMgM6dOxfqcywWC1v2xvPdon2cPp8GQMWyngzoVpM6lUsV6rNERESKi80J9ujRo/nxxx85efIkjz76KE5OTmRnZ/Pcc8/Ru3fvoohRRERECsnJkyfZuHEjjzzyCAAeHh4MGDCArKwsKlWqVCTPPHbyItN+38ueI+cB8HJ3ok/HGrQODcTe7vbqQCIiInItN9Sm6+LFi7i7u2MwGG67Fl2gTc5EROTucvr0aRo3bozZbGbjxo0EBgYW6fMSkzP5Yel+wiNjsFjA6GBH9+aV6NmqCq7OWmctIiK3hyLd5MxisfDVV18xffp0UlJSWL58ORMnTsTV1ZVRo0bh6Ohoe8QiIiJS6LKzszl06BC1atUCoEyZMtx3332YTCbS0tKK7rk5JhasP8rsVYfIyDIB0KxeOZ7sHEJpH9cie66IiEhxs7mCPXnyZBYvXsyrr77K0KFDWbhwITExMbz55pu0bNmSUaNGFVWshU4VbBERuVMdO3aMnj17kpWVxbZt26w/6zIzM3F2di6SZ1osFjbsOsX0xfs4m5j3M7ZqoBdPd61NjWCfInmmiIhIUbMlb7S5weS8efN45513aNmypXVa+H333cf48eNZunSprbcTERGRQpKenm7976CgIJycnHBycuLo0aPW8aJKrg/FJPLa5A188OM2ziZmUNLTmf97/B4mvNBMybWIiNw1bJ4ifuHCBUqXLn3ZuIeHR74f7CIiInJzHDt2jNdff50LFy6wYsUKDAYD9vb2/PDDDwQGBhbp8q3zSRl8vySKtdvjAHBytOehllV4sEUlnB1t/jVDRETktmbzT77GjRszbdo03nnnHetYamoqH3/8MY0aNSrU4EREROS/eXt7s23bNrKysjh48CDVq1cHoHLlykX2zMysXOauPcJva46QnZO3zrpVwwD6dqqBr6eWXomIyN3J5jXY8fHxDB48mNOnT5OYmEilSpU4deoUZcuW5csvv6R8+fJFFWuh0xpsERG53Zw5c4YpU6aQkpLCBx98YB1fsmQJderUueGfw2cT00lOy77qcXcXI/uOJzBjSRQXLmYCEBLsw9PdalElwPuGni0iInIrsiVvvO42XZs3b+bYsWPk5uYSHBzM/fffj52dzUu6i5USbBERud1ERUXRtm1b7O3t2bx5M+XKlSu0e59NTOe5cavIyTVf9RwDcOkXh9I+rvR/oCZN6pS5Ldt1ioiIFESRtul644036Ny5M40bN+bee++1PToREREpkOzsbBYtWkRmZiaPP/44ACEhIQwaNIjQ0FDKlClTqM9LTsu+ZnINecm1k9Gex9pVo2vTijga7Qs1BhERkduZzQl2eno6gwYNwsXFhfbt29OpUycaNGhQFLGJiIjc1cLDw3nhhRfw8fHhwQcftH5y/vrrrxdrXCOfCqN+tcs3PBUREbnb2Zxgf/TRR2RnZ7NhwwZWrlzJwIEDcXFxoWPHjnTq1InatWsXRZwiIiJ3vAMHDpCamkrDhg0BaNeuHQ0aNKB169aYzdeuLN9M7m5Ftyu5iIjI7ey612Bfkp2dzfTp0/nqq6/IyMhg//79hRVbkdMabBERuVXMmTOHIUOGULt2bZYuXXpT1zSnZuSwff8ZVkXGsPPQuf88/5Ohzalc3qvoAxMREbkFFOkabACTycTWrVtZsWIF4eHhmM1munTpQufOna/ndiIiInedtLQ0UlJS8Pf3B6Bly5a4uroSGBhIeno6bm5uRfr8+AtpbN0XT8S+ePYdu4DJfEOft4uIiAjXkWAPHz6cNWvWYLFYaN26NWPHjqVJkybY22uTExERkYJYsGABw4cPp3Xr1kyePBkAX19ftm3bhqenZ5E802y2cCgmkYioeLbuiycmPiXf8QA/d6oGerEqMrZIni8iInI3sDnBzs7O5v3336dZs2Y4OmoNloiIyH+xWCzk5uZiNBoBqFixIsnJyURFRZGdnW39eVrYyXVmVi67Dp8jYl88kVFnSErNsh6zszNQM9iXsJr+hNX0o2zJEhyJS1KCLSIicgNsTrA//vjjoohDRETkjrR27VrGjx9Pu3btGDp0KAC1a9dm3rx5NGzYEDs7u0J93oWLGURGnWHrvnj2HD5H9j/abrk6O9Cguh9hNf1pWL00JVzzf1Du4eaI0cHumq26jA52eGiTMxERkSsq0CZnNWrUYMOGDfj6+lK9evVrbryiTc5ERET+tmDBAgYOHEhAQACbNm0q9ITaYrEQfTrZup76cGxSvuOlfVxpVNOfRiH+hFT0xehw7eefTUwnOS37qsc93Bwp7e1aGKGLiIjcFmzJGwuUYEdERHDPPffg4OBARETENc8NCwsrYJjFTwm2iIgUpoMHDzJ16lRatmxp3fgzJyeHadOm8cgjj+Dj41Moz8nJNbP36Hki9sWzNSqec4kZ+Y5XC/T+a+q3P0H+7jd1R3IREZE7TaHvIv7PpHnevHmMHDmSEiVK5Dvn4sWLvPHGG7dVgi0iIlKYFi9ezM8//8yBAwesCbbRaOS555674XunpGezbX/e1O8dB86SkZVrPeZotKdelVKE1fQnNMQPHw/nG36eiIiI2K5ACfbOnTs5ceIEAPPnz6dmzZqXJdjHjh1jw4YNhR+hiIjILSgtLY1ff/2VRo0aERISAkCfPn04fPgw/fv3x2Kx3HDl+NS5VLbuy9v1e390AuZ/tNLycnciLMSfRjX9qVOlJM6O19V5U0RERApRgaaIHzhwgEGDBmGxWDh16hT+/v751pAZDAZcXV3p1asXjz/+eJEGXJg0RVxERK7Xyy+/zC+//ELPnj2ZOHFiodzTZLZwIDqByL9aacWdTc13vEIZD8Jq5iXVlct7YWenqd8iIiJFrdCniFevXp1Vq1YBeZ/OT548ucj6dIqIiNxqLBYLkZGRVK5c2bqOuk+fPkRGRt7w0qiMrFx2HjzL1n3xbNt/Jt8GY/Z2BmpXKkloTT/CQvzx93W7oWeJiIhI0SpQBftOpQq2iIgUxNChQ/n111959dVXGTJkiHXcbDZf167g55MyiPirSr3n8HlyTX+3xXJzMdKwuh+NavpzT/XSuLkYC+UdRERE5PoUegW7IG26Lq01u53adImIiFzJhQsX8PT0xMEh78fk/fffz++//05mZma+8wqaXFssFo6evEjEvngiouI5Gncx3/Eyvm7Wqd81gn1wsC/cVl4iIiJyc9jcpmvr1q3X3LTldtpFXBVsERH5t/fee49vv/2Wzz77jAceeACA7OxsUlNTbWqzlZ1jYs+R80RExRO5L57zF/9Ozg0GqB7kk9dKK8SPAD+10hIREblVFWmbrkaNGgF/T4s7e/Ys27dvp1q1alSsWPF64hURESk2/97t28nJiaysLP744w9rgu3o6Fig5Ppiapa1ldbOg2fJzDb9fV9He+6pVpqwED8a1vDHy92p8F9GREREipXNa7C3b9/OSy+9xIQJE6hYsSI9evQgKyuLjIwMJkyYQMeOHYsq1kKnCraIyN3t+++/Z8qUKUydOtXaauvcuXNER0fTsGHD/6wqWywW4s6mEvFXK62DJxL4RyctfDycrVO/61QuiaPRvihfR0RERIpAoVew/2nMmDF06tSJunXrMm3aNJycnFi9ejWLFy/ms88+u60SbBERubtt3ryZ6OhofvjhB8aOHQtAqVKlKFWq1FWvMZnMREUn5K2n3hfPqfNp+Y5XLOtpTaorlffU1G8REZG7iM0J9uHDh5k0aRIuLi6sXr2adu3a4ejoSFhYGKNHj7bpXhaLhbVr17Jz504yMzMJCgqiU6dOeHt7/+e1e/bsYd68eQwZMgQvLy9bX0NERO4iFouFiIgIpk+fzpgxY6w/ZwYOHMi9997Lww8/fM3r0zNz2HGplVbUGVIzcqzHHOwN1KlcirCa/oSG+FHa27VI30VERERuXTYn2CVLluTIkSOkp6cTFRXF8OHDAdi0aRNlypSx6V7r1q1j27ZtdOvWDQ8PD8LDw/nxxx8ZOHAg9vZXn0aXlJTEkiVLbA1dRETuYqNGjSIqKopatWoxaNAgAOrUqUOdOnWueP7ZhHRrK629R8+Ta/p77re7q5HQEH/CavpTv2opXJ3VSktERESuI8Hu168fgwYNws7Ojtq1axMWFsZXX33F5MmTrdPrCsJkMrF582batGlD1apVAejZsycfffQRUVFR1K5d+4rXWSwW5s2bR9myZTl+/Lit4YuIyF3g/PnzzJkzh2eeeQZ7e3sMBgODBg1i06ZNtGvX7orXmM0WjsQlWddTR59Ozne8XKkS1qnf1YO8sVcrLREREfkXmxPsvn370rBhQ06dOkXTpk0BaNy4MS1atKB69eoFvk98fDzZ2dn5dh53dnamTJkynDhx4qoJ9h9//IHJZKJ58+ZKsEVE5DImk4n27dsTHx9PhQoV6NChAwDdu3ene/fu+c7NyjGx+/A5IvbFExkVT0JylvWYnQFqBPsSFuJPWE0/ypd2v5mvISIiIrchmxNsgJCQEBITE/nll18wm80EBwdTs2ZNm+6RnJxXGfDw8Mg37u7ubj32bydPnmTTpk0888wzpKSkXE/oIiJyhzGZTOzYsYPQ0FAA7O3t6dmzJxs2bMDNze2y8xNTMtkW9VcrrUPnyM75u5WWi5M991TzI6ymPw1r+OHh5njT3kNERERufzYn2PHx8QwcOJDjx48THByMyWTixIkTlC1blu+++w4/P78C3ScnJ2+DGAeH/CE4ODhYt0H/p+zsbObOnUubNm3w9fVVgi0iImRmZtK2bVuOHTvG6tWrqVatGgCvvPIKw4cPx2AwYLFYiDmTYp36fSgmkX82qCzp5UKjmv6EhfhTu7IvRge10hIREZHrY3OC/fbbb+Pr68t3332Hp6cnAImJiQwbNoz333+fzz77rGAP/iuxzs3NxWj8e3OY3NxcHB0vrxgsXboUX19fGjZsaGvIIiJyB0lOTrbOfnJ2dqZ69eokJCRw9OhRa4JtsLNnz5Hzea20ouKJv5Ce7x6VA7wIC8lbTx1c1kOttERERKRQ2Jxgb9myhV9++cWaXAN4e3vzyiuv0Lt37wLf59L1KSkp+Pj4WMdTUlKuWAXftWsX9vb2jBkzBsjb7Azgiy++oGnTptb14CIicmdKTk7m5ZdfZuPGjWzZssX6c+Sdd97B09MTs8HI+p1xbN0Xz/b9Z0jLzLVea3Swo26VvFZaYSF++Hq6FNdriIiIyB3M5gTb09OTixcvXjaenJycrxL9X/z8/HByciI6OtqaYGdmZnL69GnCwsIuO/+FF17I9+e4uDjmzZvH448/XuBp6SIicvtyd3fn2LFjJCcns27dOrp27Ur8hTQiD6ezdd8x9h27gMn899xvzxKOhNbIa6VVr2opXJyua9sRERERkQKz+beNzp07M2rUKEaPHm3d6Xv37t288847dOrUqeAPdnAgNDSU8PBw3Nzc8PLyYuXKlXh6elKjRg3MZjPp6ek4OTlhNBrzVbnh703SvLy8cHFRJUJE5E6SkpLCN998wx9//MGcOXOws7PDYDAwduxYkrOdOZ1iZNCE1cTE59+PI8DP3bqeumqQN/Z2mvotIiIiN4/NCfaQIUO4cOECAwYMwGKxYLFYcHBw4OGHH+bVV1+16V4tW7bEbDbz+++/k5ubS1BQEE888QT29vYkJSUxceJEunXrRr169WwNU0REbmN2dnZMmTKF5ORkVqxcjVe5mn+10kokKfUfrbTsDNQM9s2b+l3Tj7IlSxRj1CIiInK3M1gs/9xLteCSk5OJjo7G0dGRwMBAXF1dCzu2Indpt3JVwEVEio/JZGLVqlXs3LmT1157DYCE5EwmfjOPcxmunEm2IzvXbD3f1dmBBtX/aqVVvTQlXNVKS0RERIqOLXnjdS1IO3r0KL/99hvHjh3DYDBQvXp1evbsSbly5a7ndiIicheLi4ujf//+OHuUxb1CM46czuZwbBJw6YNbM6V9XGlU059GIf6EVPTF6GBXjBGLiIiIXJnNFezVq1fz4osvUr9+fWrVqoXJZGLv3r1ERUUxdepUQkNDiyrWQqcKtojIzRcTE8P+/ftp1bote4/mtdJatiGKXEP+f4urBXr/NfXbnyB/d7XSEhERkWJhS95oc4LdsWNHevTowTPPPJNv/Msvv2T58uXMnz/fltsVKyXYIiI319Ztu3hmyDv4BNajdIV7yMg2WY85Gu2p91crrdAQP3w8nIsxUhEREZE8RTpF/PTp07Ru3fqy8Q4dOvDVV1/ZejsREbmDZWVlsXPvUeJTHdm6L56o4wkENX4SgIxsE17uToSF+NOopj91qpTE2VGttEREROT2ZfNvMh07duSbb77h7bffztf3evbs2Ta16RIRkTuTyWzh4IkEfl+9m7WRxzC6lcp3PNCvBI1rl6VRTX8ql/fCTq20RERE5A5h8xTxl19+mRUrVuDl5UWtWrUwGo0cPHiQ2NhY6tati6Pj37u5zpgxo9ADLkyaIi4iUjgysnLZefAsm/88yY6D50lOy7Yes5hN1KjgRdN7gggL8cff160YIxURERGxTZFOEa9YsSLPPfdcvrFq1arZehsREbnNnU/KICIqnoh98ew6dBbT3520cHMx0rC6H2U9cujUsg5e7rdfK0cRERERW113H+w7gSrYIiIFZ7FYOHryIpH74tkaFc/RuIv5jmemnCU1PooJbw2mcb1gHOzVSktERERuf0XeB1tERO4OObkm9hw5z9Z98UTui+f8xcx/HLVQo4JvXiutED82rllCs2avUK5cuWKLV0RERKQ4qYKNKtgiIv90MTWLbfvPsPWvqd8ZWX+30nJytKe8N6z6/TtIjWHLxrW4uWlNtYiIiNy5Cr2CnZaWpl+gRETuUBaLhbizqUTsiyciKp4D0QmY//HRq4vRQiU/Bx7qEEqdyiVxsDfw6tm1PPDAC/qAUkREROQfClTBDgsLY8GCBZQpU4YRI0YwcuRISpQocTPiK1KqYIvI3cpkMrM/OoGt+/I2KTt1Pi3f8YplPQmr6U/8kS18PHYk1apVY9WqVRgMaqklIiIid5dCr2CbzWY2btzIvffey/z583niiSfw9va+4rlly5a1IVQREblZ0jNz2HHwLFv3xbN9/xlS0nOsxxzsDdSpXIry3mZqV/SkcYNaAFy8WIbfZ3/HQw89RE5OTr5WjCIiIiKSX4Eq2JMmTeLzzz+/rHJx6VKDwYDFYsFgMLB///6iibQIqIItIne6swnp1lZafx49T67p73/y3V0dCQ3xI6ymP/WrlmLG9Gm8++67dOrUialTp1rPu/Tvu4iIiMjdyJa8scCbnCUnJ5OSkkLr1q2ZPXs2Pj4+Vzzvdto9Vgm2iNxpzGYLR+KSrEn18VPJ+Y6XK1WCsJr+NKrpTzkfB8CCl5cXAIcOHaJt27Z07dqViRMnYmenNlsiIiIiRZJgX3Ly5EnKli1LZmYmJ06cwGw2ExgYeFuuyVaCLSK3orOJ6SSnZV/1uIebI6W9Xa1/zsoxsefwubxWWlHxJCRnWY/ZGaBGsC9hIf6E1fSjfGl3AL7//nvGjBlDv379GDFihPX8hISEq36AKiIiInI3KtI+2KVLl2bs2LH89NNP5Obm5t3EwYEuXbrw9ttva32eiMgNOJuYznPjVpGTa77qOUYHO8YPvp/oU8l5rbQOnyMr++9WWi5O9txTLW/qd8Mafni4OWKxWDCb/76nn58fqampRERE5JsCruRaRERE5PrZXMF+7733WLduHW+++Sb169fHbDazc+dO3nvvPdq0acNrr71WVLEWOlWwReRWcyQuiaGfrLP5upJeLjSq6U9YTX9qV/LF6GBvPbZkyRI++eQTnn76aR599FEATCYTmzZt4v7779f6ahEREZFrKNIK9qJFi5g4cSKNGjWyjjVv3hwnJydeeeWV2yrBFhG5nVUO8CIsJG89dXBZj6smysePHycqKoqZM2daE2x7e3uaNm16M8MVERERuePZnGBbLBZ8fX0vG/fx8SEtLe0KV4iISGEb/UxjGlT3u2x87969fPPNN/Tp04cGDRoA8Pjjj2MwGOjVq9fNDlNERETkrmLzFrGNGzfmww8/JDU11TqWnJzMxx9/nK+qLSIitjtzIb1A53mWcLri+Lfffsvs2bPztdny9vZm4MCBeHt7F0qMIiIiInJlNlewX3/9dfr27UvTpk0JDg4G8qYfBgQE8OWXXxZ6gCIid4PT59P4ecUB1m6PK/A1ycnJzJo1i27duuHnl1fNfvrpp8nKyuLpp58uqlBFRERE5CpsTrD9/PxYtGgR69ev59ixYzg5OREcHMx9992nnqkiIjY6l5jBL+EHWRkRg9ls056TPPvss6xfv56LFy8ybNgwAEJCQvj888+LIlQRERER+Q82J9gARqOR1q1b07p168KOR0TkrpCYnMns1YdZuimaXFNe+6wG1UvT/J7yfPzTjgLdo3fv3pw+fZrKlSsXZagiIiIiUkDXlWCLiMj1SU7LZu6awyzaeNzau7pWJV+e6FCDmhV9OZuYjtHB7j/7YHu4OdKpUyc6d+6sNlsiIiIitwib+2DfSdQHW0RulvTMHBasO8r89UdJz8wFoFqgN3061qBOlZL5kuSzienEnTqPh6eHdeznn3/ml1mz6NOnD089+TilvV1v+juIiIiI3I1syRuVYKMEW0SKTmZWLos2HmfumsOkpOcAEFzWgyc61iC0ht9l1WeLxcKrr77K7NmzmTdvHvXr1wcgJSUFk8mEl5fXzX4FERERkbuaLXnjdU8RP3fuHLm5ufw7Py9btuz13lJE5I6RnWNi2ZZoZq86TFJKFgDlS5egd4fqNKldFju7vxNri8ViTbQNBgNZWVnk5OSwatUqa4Lt7u5+819CRERERGxicwV7w4YNvPnmm5w+fTrf+KVfEPfv31+oARYlVbBFpLDlmsyER8Twy8qDnL+YCYC/ryu92lWn+T3lsf9HYm0ymZg2bRozZ87kt99+o2TJkgAcPXqU5ORka3ItIiIiIsWnSCvY7777LnXq1OHLL7+kRIkStkcnInIHMpktrNsRx88rDhB/IR2Akp7OPNq2Gm3CAnGwv7yNob29Pb///jtHjhzhp59+4sUXXwSgUqVKNzV2ERERESkcNlew69aty6JFiwgICCiqmG4aVbBF5EaZzRY2/3mamcv3E3smFQCvEk483LoKHe6tgKPRHsib5bNp0ybmzJnDBx98gNFoBGDNmjWcOnWKHj166N8iERERkVtQkVawGzZsyPbt2++IBFtE5HpZLBa27T/Dj8sOcOzkRQBKuBjp0bIyXe6viLNT/n9es7OzGTRoEOfOnaNFixZ069YNgJYtW9702EVERESkaNicYIeGhvL222+zdu1agoKCrFWYSwYPHlxowYmI3Ip2HzrHD8v2c/BEIgAuTg50b16Jbs0q4eaS92/imTNnCA8Pp3fv3gA4OTnx7LPPEhsbS506dYotdhEREREpOjZPEe/Tp8/Vb2YwMGPGjBsO6mbRFHERscX+4wn8uGw/e46cB8DRaE+X+4Pp0bIKHm6O1vNSUlK45557SE9PZ/ny5dSqVau4QhYRERGRG1SkU8R/+OEH2yMSEbmNHYlL4sel+9l+4CwADvZ2dLg3iEdaV8XbwxmTycTevXutibS7uzvt27cnNjaW7Ozs4gxdRERERG4imyvYAFFRUUybNo1jx45hMpkIDg6md+/ehIWFFUWMRUYVbBG5lhPxycxcdoDNf+a1JbSzM9A2LJBH2lSltLcrAOfOnaNLly6cO3eOyMhIfHx8AMjMzMTZ2bnYYhcRERGRwmFL3nh535j/sHLlSh555BEsFgs9evSgR48eGAwG+vfvT3h4uO3RiojcYk6dS+Wjmdt54cM1bP7zNAYDtGhQni9fa8Xgh+tRwunvc0uWLIm3tzcuLi4cOHDAOq7kWkREROTuY3MF+4EHHqBnz57069cv3/j06dOZN28eCxYsKMz4ipQq2CLyT2cT05m14iCrtsViNuf909ikThkeb1+dIH8PTp8+zYgRIzhw4AAbNmzAwSFvlc3x48fx9/fXvyUiIiIid6AiXYMdGxt7xbYyLVu25OOPP7b1diIixS4hOZPZ4YdYtuUEuSYzAA1r+NG7Q3Uql/eynufl5cX27dtJSEhg+/btNGrUCIDg4ODiCFtEREREbjE2J9iVKlVi/fr1l+0mvm7dOsqVK1dogYmIFLWLqVnMXXOERRuPk51jAqBO5ZI80aEGfp4wbdpUjh07xpdffgnkfWr58ccfExwcTOXKlYszdBERERG5Bdk8RXzNmjW88MILdOjQgbp16wKwa9culi9fzgcffECnTp2KJNCioCniInentIwc5q87yoL1R8nIygWgepA3T3SsQd0qpQA4efIk9957LyaTifDwcGrUqFGcIYuIiIhIMbElb7yuXcQ3b97MTz/9xNGjR3FyciI4OJh+/fpRp04d26MtRkqwRe4uGVm5LNpwjLlrjpCakQNAxXKePN6uKueid3D69GmeeeYZ6/mffPIJVapUoUOHDtb11iIiIiJydynyBPtOoQRb5O6QnWNi6eZo5qw6TFJqFgABfu707lCde2uVISJiKw899BDOzs5s27YNb2/vYo5YRERERG4Vhb7J2YgRIxg5ciQlSpRgxIgR1zx37NixBbmliEiRy8k1Ex5xgl/CD3HhYiYAZXzdaFPfmzLuGdxXpywAjRo1omnTptSvX784wxURERGR25zmPIrIHcdktrB2eyw/rzjImYR0AEp6ufBY22oYUg7T/6luBAQEsGHDBuzt7TEYDMyaNauYoxYRERGR212BEux/VqV79OhBvXr1MBqN+c7Jzs5m/fr1hRudiIgNzGYLG/ec4qflB4g7mwqAZwlHOoT68WiHuhgd7MnIKI2XlxdVq1YlKSkJX1/fYo5aRERERO4UNq/BrlGjBhs3bsTHxyffeFRUFI899hh79uwp1ACLktZgi9wZLBYLkVFn+HHZfo6fSgbA3dVI3UADMyePpFbN6vz000/W8y9evIinp2dxhSsiIiIit5FCX4P9008/8c4772AwGLBYLNx3331XPK9JkyY2hCkicmMsFgu7Dp3jx2X7ORSTBICrkwPdW1SmW7OKnD97msnvnOPoUSMpKSm4u7sDKLkWERERkSJR4Ap2ZGQkZrOZJ598kkmTJuX7BdVgMODi4kLVqlVxdHQssmALmyrYIrevfccu8MPS/ew7dgEAo72B3PO7qVnWxNj3RlvPi4yMpH79+mqzJSIiIiLXpUjbdJ08eRKj0UhaWhrBwcEALFmyhNDQUEqVKnUd4RYfJdgit5/DsYn8uPQAOw6eBcDoYEfHJhUo73KBp5/qjZeXFzt27MDJyamYIxURERGRO4EteaOdrTePiYmhQ4cOLFy40Do2Y8YMOnXqxPbt2229nYhIgUSfTub977by8qfr/0quzVQulcPXw9vwTLfadGjbnLfeeotVq1YpuRYRERGRYmFzBbt79+506tSJ//3vf/nGv/76a1asWMFvv/1WqAEWJVWwRW59J8+l8tPyA/yx6yQWC9gZoLxnFkt+fJ9ypdxZv349dnY2f1YoIiIiIlIghb7J2T9FR0fToUOHy8Y7duzIF198YevtRESu6ExCOr+sPMiqbbGYzXmfA95Xtyy921fHp4QdppOr6d27NwaDoZgjFRERERHJY3OCXbHi/7d333FRXev+xz9DR5EqAioCNsRu1GiMxi4KarCkWKPmnGhyEzW53pRjfiknxzTPTU6OKaaZxBJ7SaKiASsxRtFILFgQRRE7RUA6M78/vMyRgGUUGYXv+/XyFV17zd7PmlkSn3nWXrshkZGRTJw4sVT7xo0badCgQYUFJiLVU+qlXJZEH+HnHScoKr6SWF9K2Uc957O8PPZjc7/Zs2dbK0QRERERkXJZnGBPnTqVZ555hm3bttGiRQsADh8+zK5du5g1a1aFBygi1cOl7HyWbUxg9S/HzIl12ybe9GzjyvQX3qXHuHGYTCZVrEVERETkrmXxPdgACQkJLF++nOPHj2NnZ0dAQAAjRozA39//TsR4x+gebBHry84tZOXmo/y4NZG8gmIAatpmM/2pUFo1rg2A0WjUfdYiIiIiYhV39DFd11NYWIi9vX1Fne6OU4ItYj25+UUsjYpn7fZkLucVAVDHzYYdaz5hUK/7eOedt60coYiIiIjIHU6wL168yOeff87Ro0cpLr5SbTKZTBQWFpKYmEhsbOwthGwdSrBFKl9+YTGRvx5n7uq9FBptAWjgW4vR/Ztxf3MfLl68iI+Pj5WjFBERERG54o4+B/tvf/sbMTExtGrVit9//502bdrg6enJ3r17ee655yyPVkSqhYLCYtb8coyn3o7i6x8PUGi0JS/rPG45v/Pv/+7JA63qYmtrq+RaRERERO5ZFm9yFhsby5w5c2jXrh3btm2jR48etG/fni+++IKtW7cyduzYOxGniNyjiouNzPx8FTHxl7FxdAXA28OZId0CcDN40q3bX7RxmYiIiIhUCRYn2CaTyVxhaty4MfHx8bRv354BAwbw9ddfW3yuzZs3s2fPHvLy8ggICCAsLAwPD49y+58/f57o6GhOnTqFwWAgMDCQfv364ebmZukwROQOMxpN/PJHCt+vP0TKBVtsHF2xMebx1LCO9OscgL2dLRBs7TBFRERERCqMxUvEmzdvzg8//ABASEgI27ZtA+DUqVMWX3zLli3s2rWLgQMHMmHCBEwmE/Pnzzff2321nJwc5s2bh729PePGjWPUqFFcvnyZ+fPnU1RUZPG1ReTOiIuL48nJf+eZ96KYOX83KRcuU9PJlpDamXw5vS/hXRv+X3ItIiIiIlK1WFzB/u///m8mTZqEs7MzDz/8MF999RWDBg3i9OnTDB48+KbPU1xczPbt2+nTpw9NmzYFYPjw4fzv//4v8fHxtGrVqlT/Q4cOUVBQQEREhHmn8iFDhvCvf/2L5ORkgoKCLB2KiFQgk8nEnsMXePPr3zE6tIGLudR0smNIj8YM6taQGk73zhMGRERERERuhcUJdkhICJs2bSIvLw8PDw+WL19OdHQ07u7uDBgw4KbPc/bsWQoKCmjYsKG5zcnJCT8/P06cOFEmwW7YsCGPP/54qceAldy3WbKrm4hUroyMDJYsWUL7ruEs3XScA8dSwcELg6mI7m1q89QjD1CrhoO1wxQRERERqRQWJ9gDBw7k448/pnnz5gD4+PgwatQoiy+cmZkJgKura6n2WrVqmY9dzd3dHXd391Jtv/zyC3Z2dgQEBFh8fRG5PSaTieGjn6bQrQ0/Hd4FgL2dDWFdghjeqwnutRytHKGIiIiISOWyOMG2sbGhsLDwti9ccg47u9Ih2NnZ3VRFeseOHcTGxtK/f39q1qx52/GIyPWZTCZiY2Pp2LEjSWcyWbDuEM7Bj+MM2Bgg9IFAHuvTFC83PVdeRERERKonixPsHj16MH78eHr27Em9evVwcCi9/PPZZ5+9uQv/X2JdVFRUatl3UVFRmXNezWQysWnTJmJiYujWrRudOnWydAgiYiGj0cigQYM4mHiGRya9Q3xyHnAlse7Z3p/H+wXj66UvukRERESkerM4wT58+DAtWrTg/PnznD9/vtQxS55lW/JoraysLDw9Pc3tWVlZ5seA/VlxcTE//PAD+/btIzQ0lM6dO1savojcpMzMTPMtHOfTc/EIeZjmwd7m5Lpb23qMDA2mfp1a1gxTREREROSuYXGCPW/evAq5sI+PD46OjiQlJZkT7Ly8PM6cOcP9999f7mtWrlzJwYMHGTZsGC1btqyQOESktIKCAl544QUiIyP5ce0Gtuy7xM87TlBs8sFggE4tfBnVvxlBdfX8eRERERGRq91Ugj1q1Cg+++yzUhuS5eXl4eTkdOsXtrOjY8eOREdHU7NmTdzd3YmKisLNzY2QkBCMRiM5OTk4Ojpib29PXFwcBw4coG/fvgQGBpKdnW0+V0kfEbl9Dg4OnDmfgVezcP72ZRxG05WVKe2aejN6QAhNG3hYOUIRERERkbvTTSXYu3fvLrOxWZcuXfjhhx/w9/e/5Yv37NkTo9HIjz/+SFFREQEBAYwePRpbW1syMjL46KOPePjhh2nbti379u0DICoqiqioqFLnKekjIpbJzc3lm2++YfXq1axYsYIiow0rNh+FoEfxKTJhNEGLhl6M7t+Mlo1qWztcEREREZG7msFkMplu1KlZs2Zs27YNLy8vc1u7du348ccfbyvBtraS3cqdnbXrsVRPhYWFPPDAA5y7kMa4qTNJuOjE5bwiAJr4uzN6QAjtmnpbtL+CiIiIiEhVYkneaPE92CJybzKZTGzdupVNmzbx+uuvYzAYKDYZGDj2b+xPsSHulAEoItDPlVH9m9Gpha8SaxERERERCyjBFqkm0tLSGDduHAUFBfQfEM7FQi+WRB8hPcsWgHreNRkZ2oyubephY6PEWkRERETEUjedYEdGRuLi4mL+s9FoJCoqqtQjtgAiIiIqLDgRuXVnzpwhNjaWwYMHA+Dl5cXo0WNIK/Lis8iLpGWdBqCOZw1G9A2mZ/v62NraWDNkEREREZF72k3dg92rV6+bO5nBwIYNG247qMqie7Clqjp58iTdunXDYDCwY8cOanvXISYuhe/XH+LMxcsAeLo68VjfpvS9PwB7OyXWIiIiIiLlqfB7sDdu3Hh7EYnIHVVUVMTx48dp0qQJAA0aNKBdu3bY2NoSsyeZTfsOcPJsFgBuLg4M79WUAV0CcbS3tWbYIiIiIiJVyk1VsKsqVbClKkhISGDkyJEUFxfz22+/4eDggMlk4tc/klm26RhHT10CoKazPUN7NGZQt4Y4O2r7BRERERGRm6FdxEWquPz8fBwdHQEICAiguLiYoqIiEhMTKbL3Zl7kQQ4mpQHg7GjL4G6NiOjRGBdne2uGLSIiIiJSpamCjSrYcu9ITEzkjTfeICsri1WrVpnb4+PjKbLzZMnGRP5IuAiAg50NYQ8GMbxXE9xcHK0UsYiIiIjIvU0VbJEqqlatWsTExFBUVMSxY8do2LAhx1IusWx7JrHxCQDY2RoI7RzII72b4OWmL49ERERERCqLKtiogi13p/Pnz/P1119TUFDA66+/bm5fvnw57du3x9bZiwXrD7HtjyuP27KxMdC7gz+P9Q3Gx7OGtcIWEREREalSLMkblWCjBFvuTrt372bw4ME4ODgQGxtL7dq1ATibepnv1x9iy++nMJrAYIBubesxMrQZ9bxdbnBWERERERGxhJaIi9xjCgsLWbt2LUajkSFDhgDQvn17xo0bR7du3fDw8OBCei6Low8TvfMkxcYr34t1bunLqP4hBPq5WjN8ERERERFBFWxAFWyxvpUrV/Lss8/i5+fH9u3bsbf/z27f6Vl5LNuQwNpfkygqNgJwX7M6jO7fjCb+HtYKWURERESkWlAFW+Qud/ToUXJzc2nVqhUAYWFhhISEMGDAAAoLC7G3tycrp4DlGxNYve04+QXFALRo6MWYASG0aOhlzfBFRERERKQcqmCjCrZUrsWLF/PCCy/QuXNnli9fbm43mUwYDAZy8gr5YUsiq7YmkpNXBEDTBu6MGRBCmybeGAwGa4UuIiIiIlLtqIItchfJzc0lJycHL68rVeeHHnoIR0dH3N3dycvLw8nJCYD8gmLWbDvO8k0JZOUUAhBU15XR/UPo2NxHibWIiIiIyF1OFWxUwZY7Z9WqVUyfPp3w8HDef/99c3taWhqenp4AFBYVs277CZZsOEJGVj4A9bxdGNW/GQ+2rouNjRJrERERERFrUQVbxIqKi4uxtbUFoG7dumRkZLBr165S7Z6enhQVG9kQe5JFUUe4mHHlL62PZw1GhgbTvV19bG1trDYGERERERGxnCrYqIItFWPLli3885//JDw8nEmTJgFX7quOiYnhwQcfNCfXxUYTW/ecYuH6w5xJvQyAl5sTj/UNpk/HBtjbKbEWEREREblbqIItYgWnT5/m999/JyMjg4kTJ2IwGDAYDDz00EMAGI0mtu8/w4J1h0g+lwWAu4sjw3s3YcADgTjY21ozfBERERERuU1KsEVuwdGjR/nqq68IDQ2lZ8+eAERERHD+/HlGjhxZakMyk8nEroPnmL/uEMdSLgHg4mzP0J6NGdi1Ic6O+msoIiIiIlIV6F/2Irdg0aJFzJs3j+PHj5sTbGdnZ6ZMmVKq3x8JF5gfeZBDJ9Kv9HG05eGHGvNw90a4ONtXetwiIiIiInLnKMEWuYHc3FyWLVtGly5daNSoEQDjx48nKSmJJ598stzXHDyexvx1B9l79CIADva2DHwwiKE9G+Pm4lhpsYuIiIiISOXRJmdokzO5vmeffZaVK1cyduxY3nnnnev2PXoqgwXrDrHr4DkA7GwN9O8cyCN9muLp6lQZ4YqIiIiISAXSJmcit2H37t00bdqUWrVqATBy5Eh+//13WrRocc3XnDibyffrD/Hr3jMA2NgY6NOxAY/1aUodzxqVEreIiIiIiFiXKtiogi3/MXnyZJYvX86bb77JX/7yF+DKJmVGo9H8mK2rnb6YzcL1h9my5xQmExgM0L1dfUaEBlO3tktlhy8iIiIiIhVMFWyRm5Seno6bmxs2NleePd2xY0d++ukn0tLSzH0MBkOZ5Pp8eg6Lo44QHXsSo/HKd1RdWvsxMrQZAb6ulTcAERERERG5a6iCjSrY1dVbb73Ft99+y5dffkmvXr2AK3MiOzsbb2/vcl+TlpnH0ugjrPvtBEXFRgA6hPgwKrQZjf3dKyt0ERERERGpJKpgi5TDZDKVej51cXExeXl5REdHmxNsZ2fncv/iZF4uYPnGBFZvO05BYTEArRrVZvSAZjQP8qqcAYiIiIiIyF1NFWxUwa7qTCYT8+bNY86cOcyZM4eGDRsCkJKSQnJyMp06dSqVeF/tcm4hq7Yk8sPWRHLziwAIDvBgzIAQ2jQpv8otIiIiIiJVhyrYIlcxGAxER0eTkJDA3LlzeeONNwCoV68e9erVK/c1eflF/PTLMVZsOkp2biEADeu6MXpAMzqE+FwzIRcRERERkepLFWxUwa5qdu3axbx583j77bepWbMmALGxsezdu5fHHnsMF5dr7+5dUFhM5PYklm1IICM7HwB/HxdG9Q/hgZZ+2NgosRYRERERqU4syRuVYKMEuyoxGo10796dY8eOMWPGDMaNG3dTryssMhIde5LFUYdJvZQHgK9XDUaGNuOhdvWxVWItIiIiIlItaYm4VBtpaWn8+OOPPPHEExgMBmxsbJg0aRK7d++mc+fON3x9sdHElt+T+X79Yc6l5QBQ282Jx/sF07tjA+xsbe70EEREREREpIpQBRtVsO9VhYWFdOjQgYsXL7Jw4UIeeuihm36t0Whi297TfL/+EKfOZwPgXsuRR3o3oX/nQBzsbW9wBhERERERqQ5UwZYqyWg0sn//flq3bg2Avb09gwcPZufOndjY3Fyl2WQyERt/jvnrDnL8dCYAtWrYM6xnE8IfDMLJUX8lRERERETk1qiCjSrY94KcnBwGDBjAsWPH2LZtGw0aNAAgLy8PR0fHG+7qbTKZ+CPhAvMjD3H4ZDoAzo52DOneiMEPNaKms/0dH4OIiIiIiNx7VMGWKiEnJ4caNWoAUKNGDerVq8e5c+c4ePCgOcF2cnK64XkOHEtl/rqD7E9MBcDB3pZBXYMY2rMJrjUd7twARERERESkWlEFG1Ww7zbp6em88sorbN++nd9++838+Zw8eRJPT8/rPmbragnJ6cxfd4jfD50HwM7WhgFdAnmkVxM8XG+cmIuIiIiIiKiCLfc0V1dX9u7dy8WLF9myZQv9+/cHMFetb+TEmUwWrD/E9n1nALC1MdDn/gY81icYbw99mSIiIiIiIneGKtiogm1NWVlZfPvtt+zcuZO5c+ea76XeunUrtWvXpnnz5jd9rtMXslmw/hAxcSmYTGAwQI/76jOiXzP8ate8U0MQEREREZEqzJK8UQk2SrCtKSMjgw4dOpCbm8vSpUvp0qWLxec4l5bD4qjDbNiVjNF4ZTo/2KYuI/sF08DXtaJDFhERERGRakRLxOWuZDQa2bRpE/Hx8Tz33HMAuLu7M23aNGrXrk379u0tOl/qpVyWRB/h5x0nKCq+klh3bO7DqNBmNKrvXtHhi4iIiIiIXJcq2KiCXVmOHDlCz549sbGxYfv27dSvX/+WznMpO59lGxNYu+04BUVGANo0qc3o/iE0C/SsyJBFRERERKSaUwVb7gopKSkkJCTQo0cPAJo2bUpYWBj169fH0dHR4vNl5xayavNRfoxJJDe/GICQQE9GD2hG68beFRm6iIiIiIiIxVTBRhXsO2H37t0MGTIENzc3du7ceVvvcW5+ET/FHGPF5qNczi0EoFF9N0b3D6F9szrmjdFEREREREQqmirYUukKCgo4d+4c/v7+ALRp0wY/Pz8CAgJITU29peXg+YXFRP6axLKNR7iUXQBAA99ajAptxgOt/JRYi4iIiIjIXUUVbFTBvl2xsbFMmjQJb29vIiMjzYnvpUuXcHNzs/h8hUVGonaeYHHUEdIy8wDwq12TkaHN6Na2HrY2SqxFRERERKRyqIItd1xhYSH29vYANGrUiIyMDIxGI+fOncPX1xfA4uS6uNjIpt2nWBh1mPNpOQB4ezjzeN9genXwx87WpmIHISIiIiIiUoFUwUYVbEvs37+fGTNm4OnpySeffGJu3717N61atcLBwcHicxqNJn75I4Xv1x8i5cJlADxqOfJon6aEdg7A3s62wuIXERERERGxhCrYckdt3boVR0dHMjIycHd3B7D4GdYAJpOJHQfOsmDdIZLOZAJQq4YDw3s1JuzBIJwcND1FREREROTeoQo2qmBfS0pKCt988w3e3t5MnDjR3P7NN9/Qp08f84ZmljKZTOw5coH5kQdJSM4AoIaTHUN6NGZwt4bUcLKviPBFRERERERumyV5oxJslGBfyw8//MAzzzxD7dq12bFjB05OTrd9zv2JF5m/7hAHjqUC4Ohgy+BuDRnSozG1ali+vFxERERERORO0hJxsVhBQQGrV6/Gy8uL7t27AxAWFkZERARDhgy5pXurr3bkZDrzIw+y58gFAOztbAjrEsTwXk1wr+V42/GLiIiIiIhYmyrYqIIN8Mknn/D222/Ttm1bVq9eXWHPmD5++hIL1h1ix4GzANjaGOjXKYBH+zSltrvedxERERERubupgi03dOjQIRwdHQkKCgLgscceY/78+fTt25fi4mLs7G5vapw6n8X36w8TE5cCgI0BerT3Z0S/YHy9at52/CIiIiIiIncbVbCpfhXsWbNm8e677zJs2DD+/e9/m9uNRiM2Ntd/1vT59BwyLxdc83h+QTFRO0+waVcyxv+bWd3a1mNEv2D8fWpVSPwiIiIiIiKVRRVsKeXy5cuYTCZcXFwA6Nq1KzY2NhiNRkwmk3k5+M0k15Pe3UBhkfGmrtuphS+j+jcjqK7b7Q1ARERERETkHqAEu4r79ttvee+995g0aRJTpkwBoF27dsTGxuLr62vRuTIvF9xUct20gTsTh7SmaQOPW4pZRERERETkXnT9kqXcc0wmE1ev+nd1dSUzM5OYmJhS/SxNri3x9LA2Sq5FRERERKTaUYJdhaxbt47w8HDWrFljbhs4cCBz585lyZIlVoxMRERERESk6rPqEnGTycTmzZvZs2cPeXl5BAQEEBYWhodH+dXPnJwc1q1bR0JCAgAtW7akX79+2NvbV2bYd619+/bxxx9/8N133zFw4EAAHBwc6N27t5UjExERERERqfqsWsHesmULu3btYuDAgUyYMAGTycT8+fMpLi4ut//SpUtJTU1l7NixPProoyQkJJSq1lYnBw8eZNq0aRw4cMDcNnbsWF588UVmz55txchERERERESqJ6sl2MXFxWzfvp0ePXrQtGlTfH19GT58OJmZmcTHx5fpn5ycTFJSEhEREfj5+REUFMSgQYP4448/yMzMtMIIrOujjz5i4cKFfP311+Y2Hx8fpkyZgpeXlxUjExERERERqZ6slmCfPXuWgoICGjZsaG5zcnLCz8+PEydOlOl/8uRJXFxc8Pb2NrcFBgZiMBg4efJkpcRsLZcvX+abb74hPT3d3PaXv/yF8PBwRowYYcXIREREREREpITV7sEuqTq7urqWaq9Vq1a5FenMzEzc3Eo/T9nW1hZnZ+cqX8F+4okn2L59Ozk5OfzXf/0XAB06dKBDhw6VGodrTQfs7Wyu+6guezsbXGs6VGJUIiIiIiIidwerJdiFhYVXArArHYKdnR25ubnl9re1tS3TbmdnR1FR0Z0J8i7xyCOPcO7cOfz8/KwaRx2PGsx+uTeZlwuu2ce1pgN1PGpUYlQiIiIiIiJ3B6sl2CWJdVFRUaldwIuKinBwKFsBtbOzK3fzsz+/vioaNmwYjzzyCDY21n+qWh2PGkqgRUREREREymG1jK1kuXdWVlap9qysLGrVqlVu/z/3LS4uJjc3t8wy86rGzs7urkiuRURERERE5NqslrX5+Pjg6OhIUlKSuS0vL48zZ84QEBBQpn9AQACZmZmkpaWZ20pe6+/vf6fDFREREREREbkuqy4R79ixI9HR0dSsWRN3d3eioqJwc3MjJCQEo9FITk4Ojo6O2NvbU69ePfz9/Vm2bBnh4eEUFBSwevVq2rRpU+Ur2CIiIiIiInL3M5hMJpO1Lm40GtmwYQNxcXEUFRUREBBAWFgY7u7uZGRk8NFHH/Hwww/Ttm1b4MrjqtauXUtCQgL29vY0b96c0NDQMhul3aySzdScnZ0rakgiIiIiIiJShViSN1o1wbY2JdgiIiIiIiJyPZbkjdo5S0RERERERKQCKMEWERERERERqQBKsEVEREREREQqgBJsERERERERkQqgBFtERERERESkAijBFhEREREREakASrBFREREREREKoASbBEREREREZEKoARbREREREREpAIowRYRERERERGpAHbWDsCaTCYTeXl51g5DRERERERE7lK5ubk4OTndVF+DyWQy3eF47lpGo5G8vDwMBoO1QxEREREREZG7kMlkwsnJCRubGy8Ar9YJtoiIiIiIiEhF0T3YIiIiIiIiIhVACbaIiIiIiIhIBVCCLSIiIiIiIlIBlGCLiIiIiIiIVAAl2CIiIiIiIiIVQAm2iIiIiIiISAVQgi0iIiIiIiJSAZRgi4iIiIiIiFQAJdgiIiIiIiIiFUAJtoiIiIiIiEgFUIItIiIiIiIiUgHsrB1AdWcymdi8eTN79uwhLy+PgIAAwsLC8PDwKLd/Tk4O69atIyEhAYCWLVvSr18/7O3tKzNsqeIsnZfnz58nOjqaU6dOYTAYCAwMpF+/fri5uVVy5FJVWTonr7Z3715WrlzJlClTcHd3v/PBSrVh6bwsLi5m06ZN7N27l7y8POrWrUv//v3x9fWt5MilqrJ0Tl6+fJn169eTmJiIyWSiYcOGhIaGUqtWrUqOXKqLmJgYEhMTGTdu3DX73Ov5jirYVrZlyxZ27drFwIEDmTBhAiaTifnz51NcXFxu/6VLl5KamsrYsWN59NFHSUhIYM2aNZUctVR1lszLnJwc5s2bh729PePGjWPUqFFcvnyZ+fPnU1RUZIXopSqy9GdliYyMDNauXVtJUUp1Y+m8XLNmDXFxcQwePJinnnqKGjVqsGDBAvLy8io5cqmqbuXflRkZGYwZM4YxY8Zw6dIlFi1aVMlRS3URGxvLpk2bbtjvXs93lGBbUXFxMdu3b6dHjx40bdoUX19fhg8fTmZmJvHx8WX6Jycnk5SUREREBH5+fgQFBTFo0CD++OMPMjMzrTACqYosnZeHDh2ioKCAiIgI6tSpQ926dRkyZAgXL14kOTnZCiOQqsbSOVnCZDKxcuVK6tatW4nRSnVh6bxMT09nz549DB48mMaNG1O7dm0GDx6MnZ0dZ86cscIIpKqxdE7m5eVx4sQJHnzwQXx9ffHz86Nr166cPn2a3NxcK4xAqqqsrCwWLlxIVFQUXl5e1+1bFfIdJdhWdPbsWQoKCmjYsKG5zcnJCT8/P06cOFGm/8mTJ3FxccHb29vcFhgYiMFg4OTJk5USs1R9ls7Lhg0b8vjjj5datmMwGAD0P2ipEJbOyRIxMTEUFxfTtWvXyghTqhlL52ViYiJOTk40adKkVP8pU6YQFBRUKTFL1WbpnLSzs8PBwYE//viD/Px88vPz2bt3L15eXjg5OVVm6FLFnT59GltbW55++mnq1at33b5VId/RPdhWVPItjKura6n2WrVqlfsNTWZmZpl7Wm1tbXF2dr5nvtGRu5+l89Ld3b3Mfa2//PILdnZ2BAQE3LE4pfqwdE4CpKSk8Ouvv/LXv/6VrKysOx6jVD+WzsvU1FQ8PDw4ePAgv/zyC5mZmfj5+dGvX79S/5AUuVWWzkk7OzsiIiJYvXo17777LgaDgVq1ajFu3DjzF+UiFSE4OJjg4OCb6lsV8h1VsK2osLAQuPID7mp2dnbl3rtaWFiIra1tmfZr9Re5FZbOyz/bsWMHsbGx9OnTh5o1a96RGKV6sXROFhQUsGLFCvr06XPDpWgit8rSeZmfn09aWhpbt26ld+/ejBgxAltbW7755hsuX75cKTFL1WbpnDSZTJw9exZ/f3/Gjx/P2LFjcXNzY9GiReTn51dKzCJ/VhXyHSXYVlTyA/DPk6WoqAgHB4dy+5e3SUVRUdE9s6ue3P0snZclTCYTGzduZN26dXTr1o1OnTrd0Til+rB0TkZGRuLl5UWHDh0qJT6pniydlzY2NuTn5zNs2DAaNWpEvXr1GDZsGABxcXF3PF6p+iydkwcOHGDnzp0MGTKEBg0aEBgYyIgRI8jIyGDPnj2VErPIn1WFfEdLxK2oZPlDVlYWnp6e5vasrCx8fHzK7X/48OFSbcXFxeTm5pZZDiRyqyydl3BlHv7www/s27eP0NBQOnfuXCmxSvVg6ZyMi4vD1taWt99+G7jy5Q/Ap59+Srdu3ejWrVslRC1VnaXz0tXVFRsbm1LLwe3t7fHw8CAjI+OOxytVn6Vz8uTJk3h5eeHo6Ghuc3Z2pnbt2qSmpt75gEXKURXyHVWwrcjHxwdHR0eSkpLMbXl5eZw5c6bce1cDAgLIzMwkLS3N3FbyWn9//zsdrlQTls5LgJUrV3LgwAGGDRum5FoqnKVz8rnnnuOZZ55h0qRJTJo0iUGDBgEwcuRIVbWlwlg6LwMDAzEajZw+fdrcVlhYSHp6eqlkSORWWTonXV1dSUtLK1XxLigoID09XbfXiNVUhXxHFWwrsrOzo2PHjkRHR1OzZk3c3d2JiorCzc2NkJAQjEYjOTk5ODo6Ym9vT7169fD392fZsmWEh4dTUFDA6tWradOmzT3zjY7c/Sydl3FxcRw4cIC+ffsSGBhIdna2+VwlfURuh6Vz8s/JSsmmKO7u7jg7O1tjCFIFWTovGzRoQMOGDVm5ciUDBw6kRo0abN68GRsbG9q0aWPt4UgVYOmcbNOmDb/++ivLli2jZ8+emEwmNm3ahJ2dHW3btrX2cKSaqIr5jsFUsnZOrMJoNLJhwwbi4uIoKioiICCAsLAw3N3dycjI4KOPPuLhhx82/6C7fPkya9euJSEhAXt7e5o3b05oaGiZDS1Ebocl83LevHkcO3as3PNcPXdFboelPyuvlpSUxHfffceUKVPK7HgvcjssnZf5+flER0cTHx9PYWEh/v7+9O/fX7uIS4WxdE5euHCB6OhokpOTMRgMBAQE0K9fP/2slDtm1apVZGRkMG7cOIAqme8owRYRERERERGpALoHW0RERERERKQCKMEWERERERERqQBKsEVEREREREQqgBJsERERERERkQqgBFtERERERESkAijBFhEREREREakASrBFREREREREKoASbBEREREREZEKoARbRKSaCQ4OJjg4mNOnT5c5tnDhQoKDg5k1a5YVIrvzevXqxYoVKwAYM2bMTY0zOzubVatW3fI1Z82axZgxY2759ZV5reDgYHbs2FHusR07dhAcHAzAqVOnCA4O5tSpU2Vel5qaSmRk5C3HkJqaytChQyksLDRf8+pf7dq148knnyQuLu6Wr1Hiz+9XZGQkqamp5R6rDFfPT2vbtWsXvXv3LtX24YcfsmTJEitFJCJyb1CCLSJSDdnb27Nx48Yy7dHR0RgMBitEVPlmzZrFhAkTbtjv22+/Zfny5ZUQ0d2tXbt2/PLLL+Ue++WXX2jXrh0A//znP9myZcstX2fmzJmMGjUKe3v7Uucv+bVixQpq1arFU089RVZW1i1fB2DChAnmL1lSUlKYOnUqubm5ZY5VN4cPH2bKlCmYTKZS7U8++SSff/456enpVopMROTupwRbRKQa6tChQ5kEOzs7mz179tC8eXMrRVW53N3dqVmz5g37/TnJqK4cHBzw9vYu95i3tzcODg7A7b1fp06dYsOGDQwaNKjM+Ut+BQUFMX36dC5dunTNavvNqlmzJu7u7kDZuK8+Vp0sWrSIxx9/HC8vrzLHXF1d6dq1K99//70VIhMRuTcowRYRqYZ69+7Nzp07yc7ONrdt3ryZDh06lEk6Fy1aRK9evWjXrh1jxozh8OHD5mPnzp1j8uTJdOzYkZYtWzJkyBB2794N/GcZ8c8//0yfPn1o1aoVEydOJCMjo9yYZs2axfPPP88rr7xCmzZtCA0NZcOGDebjvXr1YubMmXTt2pWIiAhMJhNHjhxhzJgxtG7dmtDQUBYsWFAm9h49enDffffx6aefljr25yXi33zzjXmcTz75JMnJyaxYsYKPP/6YnTt3mpdHFxQU8I9//INOnTrRqVMnpk2bVmpMR48eZcSIEbRp04axY8det9p3K2NOTEzkySef5L777qNbt258/PHHGI1G82sKCwuZPn06bdq0oU+fPqxdu9Z8LDs7m1deeYUHHniAli1b0r9/f6Kjo0vFFBsbS79+/WjTpg1Tpkzh0qVLQOkl4n9WskR81qxZrFy5kpUrV9KrVy8+++yzMsnynDlzGDlyZLnnWbx4MV27djUn69dia2sLYK5ynz17lilTpnD//ffTqVMn/vGPf1BQUGB+P1599VU6depEu3btmDRpEufOnTO//yXLwEuWQ/fu3ZsVK1aYjxmNRrp161ZqFYPJZOKhhx7ihx9+AK4spx46dCitW7dm0KBBrF+//pqxFxUV8cEHH9C1a1fat2/P5MmTy50jN/qs1q5dS2hoKK1atSIsLKzUsblz59KzZ09atWrF0KFD2bVrl/lYr169rluZ37p1K++99x7jxo0r93ivXr1YvHhxqTknIiL/oQRbRKQaatq0KT4+PmzdutXcFhUVRZ8+fUr127hxIx9//DH/7//9P1auXEn79u0ZO3asOemaNm0axcXFLFq0iFWrVuHj48Mbb7xR6hyzZ8/mgw8+YP78+ezbt49vvvnmmnFFRUVhMplYsWIFw4YNY/LkyRw9etR8/KeffuLrr7/m3XffJT8/n7/+9a+0b9+eH3/8kZdeeolPP/3UfL90TEwMM2bMYOrUqSxevJh9+/aRkpJS7nUXLVrExx9/zLRp01i5ciU1a9ZkypQphIWFMWHChFLLoz/44AP279/Pl19+ydy5c8nOzmbKlCnAleT7qaeewt/fnxUrVhAaGsrixYuv+1lYMub09HRGjhxJnTp1WLp0Ka+//jrz589n7ty55v579uwBYMWKFYwYMYJp06Zx4sQJAGbMmMHx48eZM2cOq1evpkOHDkyfPt2cjAIsWLCA6dOns2DBAo4fP84777xz3fivNmHCBAYMGMCAAQNYtmwZ4eHhHDlyhOPHj5v7REZGEh4eXu7rY2Ji6NKly3WvkZ6ezvvvv4+Hhwft2rWjoKCAJ554gtzcXObNm8e//vUvNm/ezPvvv28eT2xsLHPmzGHZsmVcvnyZt99+u8x5ly5dav5vWFiYud3Gxob+/fsTFRVlbouLiyMjI4PevXtz4cIFJk6cyNChQ/npp5/4y1/+wssvv1wqqb3aRx99xMqVK3n77bdZvHgxqampvP7662X6Xe+zSk1N5cUXX2TixImsW7eOYcOG8cILL5CRkUF8fDzvv/8+r7/+OpGRkXTo0IGpU6eaE+Jly5Zd99aITz/9lH79+l3zeOfOnbl48SJHjhy5Zh8RkerMztoBiIiIdfTu3ZuNGzcSFhZGQUEB27Zt47XXXuOnn34y9/nqq6+YOHEiPXv2BGDq1Kls3bqVH3/8kdGjR9OnTx9CQ0Px9fUFYNSoUTz11FOlrjN58mRat24NwKBBg9i3b981Y3Jzc+Pvf/87Dg4ONGrUiK1bt7J8+XJeeuklAAYPHmyuoi5duhQvLy+mTp0KQGBgICkpKcydO5eIiAiWLl3KoEGDiIiIAODtt9+me/fu5V538eLFjBs3zpxYvfbaa3z99dcA1KhRA3t7e7y9vcnNzWX+/PksX77cHMf7779Pp06dOHz4MGfOnCEjI4M33niDGjVq0KhRI3bu3ElaWlqFjHnu3Lk4Ozvz1ltvYWdnR6NGjbhw4QKffPKJueJYp04d3njjDezt7WnUqBGbN29m6dKlTJs2jY4dOzJ+/HiaNm0KXEmIly5dSmpqKn5+fgA8++yz5vfp1VdfZfz48bz66qvXjP9qNWvWxMnJCQBPT088PT1p3bo169at4+mnnyYlJYX4+Hhmz55d5rVFRUUcPnyYRo0alTlWcn+30WgkLy+PgIAAPvzwQ1xdXdmwYQPnzp1jyZIluLm5mT+/p59+mueff55Tp07h6OhIvXr1cHd359133y13FYWnp6f5vyVjKBEeHs6YMWPIzs7GxcWF9evX0717d1xcXPjqq6/o0qULo0ePBiAgIICDBw/y3Xff0aFDh1LnMZlMLFmyhJdeeomHHnoIgDfffLPcTeGu91mlp6dTWFiIr68v9erVY8KECQQHB+Po6EhKSgoGg4G6detSv359pk6dSs+ePTEajdjY2JjHeascHR3x9/cnPj6eZs2a3da5RESqIiXYIiLVVO/evZk8eTJFRUVs376dpk2blrnvMjExkZkzZ/LBBx+Y2/Lz80lKSsJgMDBixAjWrl3L77//zvHjx9m/f3+ZpaMBAQHm37u4uFBYWHjNmFq2bFlqeXDLli1JTEw0/7levXrm3x87doxDhw6Zky+A4uJi8/LhxMREHn/8cfMxDw8P/P39y73u8ePHadGihfnPtWvXNie4V0tOTqawsLDUeeFK4peUlERycjKBgYHUqFHDfKxVq1bX3fTLkjEnJibSokUL7Oz+87/vdu3aceHCBTIzMwEICQkptUFYixYtzOeLiIggOjqaJUuWcOzYMQ4cOABced+ujrdE8+bNKSoq4uTJk9eM/0bCw8NZuXIlTz/9NJGRkdx///3l3t976dIljEYjHh4eZY6VrEqwsbHBxcWlVJ/ExEQCAwPNyTXAfffdZ477scceY82aNXTt2pX777+fPn36MHToUIvG0LZtW7y9vdmyZQvh4eH8/PPP/M///A9wZR5u2rSp1DwsLCwkKCiozHnS09PJyMgoNdcaN27Mc889V6bv9T6rkJAQevTowfjx4wkKCqJ379488sgjODs707VrV5o2bcqgQYNo3ry5+djVc+Z2ubu7m3dbFxGR0pRgi4hUU+3btwdg9+7dREdH07dv3zJ9iouL+dvf/sYDDzxQqt3FxQWj0ciECRPIzMwkLCyMXr16UVhYyLPPPluq79XJ3o38OQkoLi7GxuY/dzM5Ojqaf19UVMQDDzzAa6+9ds3z/XnjqmvFcrPJR0ki+v3335dKogG8vLxYtGjRTV/zWte+3piv/n2Jki80SmK7+rUlx0tiePHFF9mzZw8PP/wwI0aMwNvbm8cee6xU/5IvKOA/758ln+GfhYWF8d5773HixAnWr1/Po48+Wm6/kt3ry7u39+ovaf6svPek5L0oSUY3btzI5s2b2bx5Mx988AGrV68uc7/+zYxj/fr1BAQEkJ6eTo8ePYAr83DQoEFMmjSpVP/y5pQlSe71PiuDwcDnn3/O3r172bBhA1FRUXz//fd8//33hISEsHTpUnbu3MmmTZtYsWIFCxcuZMWKFfj4+Fg05mspqYaLiEhZ+ukoIlJN2dnZ0b17dzZu3MimTZvK3H8NEBQUxNmzZwkICDD/mj17NnFxcRw9epTY2Fi+/fZbJk2aRI8ePTh//jxw6ztJHz58uFSCtX///mturBUUFMTx48epX7++Oba4uDjmzZsHQJMmTUotR8/Ozjbfi/xnAQEBHDp0yPzn9PR0OnfuzKlTp0o9tszf3x9bW1syMjLM13RxceGdd94hNTWVJk2akJSUVOrxUQcPHqzQMR84cKDUKoA9e/bg6elp3vE6ISGh1Gv27t1Lw4YNyc7OZvXq1Xz44YdMnjyZvn37mu+lv/rzuvre2r1792Jvb0/9+vWvO4ar/fkxb3Xq1OH+++9n+fLlHDp06Jr397q7u2Nra2vxI6CCgoJISkoqtew7Li4OOzs7GjRowKpVq9i0aRMDBgzgvffe46uvvmL37t1lKrA3ejxdeHg427ZtY/369fTq1QtnZ2fz9U+cOFHq78iGDRtK3WpRwtXVFQ8Pj1Jz7eDBgzz00EPk5eWZ2270WSUmJvLee+/RunVrnn/+edasWYOfnx8xMTHs2bOHzz//nM6dO/PKK6+wbt068vPzzZsPVoT09HRq165dYecTEalKlGCLiFRjvXv3Nt/LXN7y6fHjx/Pdd9+xatUqTp48ycyZM4mMjKRRo0a4urpiY2PDmjVrSElJYd26debdia/eNMsSycnJzJw5k2PHjvHZZ59x4MABhg8fXm7fwYMHk5eXx2uvvUZiYiJbtmxhxowZ5uXHo0ePJjIykiVLlpCYmMhrr71WKom52pgxY/juu++Ijo7m+PHjvP7669SvX5/69evj7OzM+fPnOXXqFC4uLjzyyCO88cYb7Nixg6NHj/Liiy9y4sQJ6tevT5cuXfDz82P69OkkJiayYsWKUrt43+6YBw0aREFBgXnM0dHRzJo1ixEjRpgTxNOnT/PWW2+RmJjIJ598Qnx8PCNGjMDBwQFnZ2d+/vlnTp06RUxMDH//+9+B0p/Xhx9+yPbt24mLi+Mf//gHjz/+uDmZvBnOzs6kpKSYd+oGGDhwIN9++y0PPvhgqaXcV7OxsaFZs2aldqm/GQ8++CD+/v68+OKLHD58mN9++4233nqLgQMH4urqSlZWFjNmzGD79u0kJyfz008/4evrW2YpeskYDx06xOXLl8tcJyQkhDp16jB//nwGDBhgbh85ciT79+/nww8/JCkpiZ9++okPPviAunXrlhvvmDFj+Oijj/jtt99ISEhgxowZtG3bttR93zf6rFxdXVm4cCGffvopycnJbN68mZSUFJo3b46TkxOffPIJS5cu5dSpU6xZs4acnBzzlzZpaWnlju9mZWdnk5KSUmqZu4iI/IcSbBGRaqxr164UFRWVW72GK8tin3/+ef79738zcOBAtm/fzmeffUZgYCC+vr688cYbfPnllwwcOJAvvviCV199FTs7O+Lj428pnjZt2pCWlkZERASRkZF88cUX17xv2sXFhS+//JKkpCQiIiJ49dVXGTVqFBMnTgSuPOv7nXfe4fPPP2f48OF4enoSEhJS7rkefvhhJkyYwJtvvsnQoUPJz8/n3//+NwB9+/bFaDQSHh5OamoqL7/8Mg888ACTJ0/m0Ucfxc7Oji+++AJbW1vs7e35/PPPuXTpEkOGDGHhwoWMGjWqQsf81VdfcfLkSSIiInjrrbd44oknSi3L7969OxkZGQwZMoTVq1fz2Wef4ePjg4ODAzNnzmT9+vWEh4fz7rvv8vTTT+Pt7V2qyj5+/HimT5/O+PHjadeuHdOmTbtu/OW9l8ePH2fw4MHmyni/fv0oLi4utTt3ebp168bvv/9u0fVsbW3Nj2B79NFHeeGFF+jdu7c5IR01ahQRERH8z//8D2FhYcTHx/PZZ5+VWgoPVzY3Gzx4MFOnTjXvKP5nYWFh2Nramjcogyv3yM+ePZuYmBgGDhzIv/71L15++WUGDx5c7jmeeuop+vXrx9SpUxkxYgS+vr689dZbpfrc6LPy9vZm1qxZ5uN///vfeeGFF+jatSshISHMmDGDr776igEDBjB79mxmzpxp3jxu+PDhzJkzx6L3+Gp79uzB19eXxo0b3/I5RESqMoPpVtfxiYiIVKBZs2axc+dO8xLv6qC6jLnkS5Bt27aVec761U6ePMnQoUOJiYmxqGouleeVV17B39+fZ555xtqhiIjclVTBFhERkTsiOzubdevW8eabbxIeHn7d5BqgQYMGdO/evdz7l8X60tPT2bZtGyNGjLB2KCIidy0l2CIiInLHvPrqq1y6dInnn3/+pvq/9NJLLFiw4Jbv45c7Z86cOTz99NPlPkpNRESu0BJxERERERERkQqgCraIiIiIiIhIBVCCLSIiIiIiIlIBlGCLiIiIiIiIVAAl2CIiIiIiIiIVQAm2iIiIiIiISAVQgi0iIiIiIiJSAZRgi4iIiIiIiFQAJdgiIiIiIiIiFUAJtoiIiIiIiEgF+P8ShgfkcoW7TAAAAABJRU5ErkJggg==","text/plain":["<Figure size 1000x500 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["sns.set(style=\"white\", color_codes=True)\n","plt.rcParams['axes.linewidth'] = 0.1\n","\n","fig, ax = plt.subplots(figsize = (10,5))\n","disp = CalibrationDisplay.from_estimator(xgb_clf, features_valid, target_valid, ax=ax)\n","plt.title('Calibration Chart - XGB Classifier', fontsize=10)\n","ax.set_xlabel('Mean predicted probability (Positive class: 1)', fontsize=10)\n","ax.set_ylabel('Fraction of positives (Positive class: 1)',fontsize=10)\n","\n","ax.tick_params(color='gray', labelcolor='gray')\n","for spine in ax.spines.values():\n","    spine.set_edgecolor('gray')\n","\n","\n","fig.tight_layout()\n","plt.legend(fontsize=8)\n","plt.show()"]},{"cell_type":"code","execution_count":655,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T17:05:01.545140Z","iopub.status.busy":"2023-11-30T17:05:01.543025Z","iopub.status.idle":"2023-11-30T17:05:07.446876Z","shell.execute_reply":"2023-11-30T17:05:07.446006Z","shell.execute_reply.started":"2023-11-30T17:05:01.545108Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Cross Validation Scores: [0.92986224 0.91388249 0.92603687 0.87318548 0.93358295 0.90967742\n"," 0.90014401 0.89451325 0.90941401 0.90311489 0.88544262 0.88245968\n"," 0.92200461 0.8890841  0.93078917 0.91131912 0.93355415 0.89343318\n"," 0.9351884  0.9088939  0.89475041 0.92108295 0.9141129  0.91382488\n"," 0.89634217 0.93257488 0.92623848 0.90460829 0.91146556 0.88060564\n"," 0.91150442 0.89634217 0.90573157 0.93508065 0.92088134 0.92635369\n"," 0.90869816 0.90216014 0.88869626 0.90242141 0.92808661 0.92684332\n"," 0.88461982 0.88338134 0.91131912 0.8750576  0.91926843 0.92413594\n"," 0.8925393  0.91525081]\n"]}],"source":["xgb_scores = cross_val_score(xgb_model, features_train, target_train, cv=cv, scoring='roc_auc')\n","print('Cross Validation Scores: {}'.format(xgb_scores))"]},{"cell_type":"code","execution_count":656,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T17:05:07.453675Z","iopub.status.busy":"2023-11-30T17:05:07.451234Z","iopub.status.idle":"2023-11-30T17:05:07.470522Z","shell.execute_reply":"2023-11-30T17:05:07.469855Z","shell.execute_reply.started":"2023-11-30T17:05:07.453628Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Best hyperparameters: {'learning_rate': 0.2, 'eval_metric': 'auc', 'booster': 'gbtree'}\n","\n","Best score: 0.910742213150237\n","\n","Average Cross Validation Score: 0.908791215308284\n","\n","ROC AUC Score - Validation Dataset: 0.9211217004622846\n"]}],"source":["# summary\n","print('Best hyperparameters:',  xgb_clf.best_params_)\n","print()\n","print('Best score:',  xgb_clf.best_score_)\n","print()\n","print('Average Cross Validation Score: {}'.format(xgb_scores.mean()))\n","print()\n","print('ROC AUC Score - Validation Dataset:',  roc_auc_score(target_valid, xgb_clf.predict_proba(features_valid)[:, 1]))"]},{"cell_type":"markdown","metadata":{},"source":["# ROC AUC Curve - XGBoost"]},{"cell_type":"code","execution_count":657,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T17:05:07.476704Z","iopub.status.busy":"2023-11-30T17:05:07.474433Z","iopub.status.idle":"2023-11-30T17:05:07.619121Z","shell.execute_reply":"2023-11-30T17:05:07.618202Z","shell.execute_reply.started":"2023-11-30T17:05:07.476645Z"},"trusted":true},"outputs":[{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"fillpattern":{"shape":""},"hovertemplate":"False Positive Rate=%{x}<br>True Positive Rate=%{y}<extra></extra>","legendgroup":"","line":{"color":"#636efa"},"marker":{"symbol":"circle"},"mode":"lines","name":"","orientation":"v","showlegend":false,"stackgroup":"1","type":"scatter","x":[0,0,0,0.00267379679144385,0.00267379679144385,0.00267379679144385,0.00267379679144385,0.0053475935828877,0.0053475935828877,0.008021390374331552,0.008021390374331552,0.013368983957219251,0.013368983957219251,0.013368983957219251,0.013368983957219251,0.016042780748663103,0.016042780748663103,0.016042780748663103,0.016042780748663103,0.01871657754010695,0.01871657754010695,0.01871657754010695,0.01871657754010695,0.0213903743315508,0.0213903743315508,0.02406417112299465,0.02406417112299465,0.02406417112299465,0.02406417112299465,0.02406417112299465,0.02406417112299465,0.026737967914438502,0.026737967914438502,0.029411764705882353,0.029411764705882353,0.03208556149732621,0.03208556149732621,0.034759358288770054,0.034759358288770054,0.0374331550802139,0.0374331550802139,0.040106951871657755,0.040106951871657755,0.0427807486631016,0.0427807486631016,0.045454545454545456,0.045454545454545456,0.0481283422459893,0.0481283422459893,0.05080213903743316,0.05080213903743316,0.053475935828877004,0.053475935828877004,0.05614973262032086,0.05614973262032086,0.058823529411764705,0.058823529411764705,0.06149732620320856,0.06149732620320856,0.06417112299465241,0.06417112299465241,0.06684491978609626,0.06684491978609626,0.06951871657754011,0.06951871657754011,0.07219251336898395,0.07219251336898395,0.0748663101604278,0.0748663101604278,0.07754010695187166,0.07754010695187166,0.08021390374331551,0.08021390374331551,0.08288770053475936,0.08288770053475936,0.0855614973262032,0.0855614973262032,0.08823529411764706,0.08823529411764706,0.09090909090909091,0.09090909090909091,0.0962566844919786,0.0962566844919786,0.09893048128342247,0.09893048128342247,0.10160427807486631,0.10160427807486631,0.10695187165775401,0.10695187165775401,0.10962566844919786,0.10962566844919786,0.11229946524064172,0.11229946524064172,0.11497326203208556,0.11497326203208556,0.11764705882352941,0.11764705882352941,0.12032085561497326,0.12032085561497326,0.12566844919786097,0.12566844919786097,0.12834224598930483,0.12834224598930483,0.13101604278074866,0.13101604278074866,0.13368983957219252,0.13368983957219252,0.13636363636363635,0.13636363636363635,0.13903743315508021,0.13903743315508021,0.14171122994652408,0.14171122994652408,0.1443850267379679,0.1443850267379679,0.14705882352941177,0.14705882352941177,0.1497326203208556,0.1497326203208556,0.15240641711229946,0.15240641711229946,0.15508021390374332,0.15508021390374332,0.15775401069518716,0.15775401069518716,0.16042780748663102,0.16042780748663102,0.16310160427807488,0.16310160427807488,0.1657754010695187,0.1657754010695187,0.1711229946524064,0.1711229946524064,0.17379679144385027,0.17379679144385027,0.18449197860962566,0.18449197860962566,0.18983957219251338,0.18983957219251338,0.1925133689839572,0.1925133689839572,0.19786096256684493,0.19786096256684493,0.20053475935828877,0.20053475935828877,0.20320855614973263,0.20320855614973263,0.20588235294117646,0.20588235294117646,0.21122994652406418,0.21122994652406418,0.21390374331550802,0.21390374331550802,0.21657754010695188,0.21657754010695188,0.2192513368983957,0.2192513368983957,0.22192513368983957,0.22192513368983957,0.22459893048128343,0.22459893048128343,0.22727272727272727,0.22727272727272727,0.22994652406417113,0.22994652406417113,0.23796791443850268,0.23796791443850268,0.24064171122994651,0.24064171122994651,0.24331550802139038,0.24331550802139038,0.24598930481283424,0.24598930481283424,0.24866310160427807,0.24866310160427807,0.2540106951871658,0.2540106951871658,0.2620320855614973,0.2620320855614973,0.2647058823529412,0.2647058823529412,0.27540106951871657,0.27540106951871657,0.27807486631016043,0.27807486631016043,0.2807486631016043,0.2807486631016043,0.28342245989304815,0.28342245989304815,0.28609625668449196,0.28609625668449196,0.29411764705882354,0.29411764705882354,0.30213903743315507,0.30213903743315507,0.3155080213903743,0.3155080213903743,0.32085561497326204,0.32085561497326204,0.3235294117647059,0.3235294117647059,0.339572192513369,0.339572192513369,0.3422459893048128,0.3422459893048128,0.34759358288770054,0.34759358288770054,0.3502673796791444,0.3502673796791444,0.36363636363636365,0.36363636363636365,0.3663101604278075,0.3663101604278075,0.37967914438502676,0.37967914438502676,0.3850267379679144,0.3850267379679144,0.3877005347593583,0.3877005347593583,0.39037433155080214,0.39037433155080214,0.393048128342246,0.393048128342246,0.39572192513368987,0.39572192513368987,0.40106951871657753,0.40106951871657753,0.40641711229946526,0.40641711229946526,0.42780748663101603,0.42780748663101603,0.4304812834224599,0.4304812834224599,0.44385026737967914,0.44385026737967914,0.45454545454545453,0.45454545454545453,0.4893048128342246,0.4893048128342246,0.5026737967914439,0.5026737967914439,0.5080213903743316,0.5080213903743316,0.5294117647058824,0.5347593582887701,0.5588235294117647,0.5588235294117647,1],"xaxis":"x","y":[0,0.000968054211035818,0.015488867376573089,0.015488867376573089,0.027105517909002903,0.02904162633107454,0.031945788964181994,0.031945788964181994,0.044530493707647625,0.044530493707647625,0.05517909002904162,0.05517909002904162,0.08615682478218781,0.08809293320425944,0.14133591481122942,0.14133591481122942,0.2042594385285576,0.20619554695062922,0.22749273959341723,0.22749273959341723,0.27783155856727976,0.2797676669893514,0.2971926427879961,0.2971926427879961,0.3388189738625363,0.3388189738625363,0.38528557599225555,0.3872216844143272,0.38818973862536305,0.39012584704743464,0.3978702807357212,0.3978702807357212,0.42400774443368827,0.42400774443368827,0.4453049370764763,0.4453049370764763,0.462729912875121,0.462729912875121,0.46950629235237173,0.46950629235237173,0.48596321393998065,0.48596321393998065,0.5014520813165537,0.5014520813165537,0.5091965150048403,0.5091965150048403,0.5450145208131656,0.5450145208131656,0.547918683446273,0.547918683446273,0.5682478218780251,0.5682478218780251,0.5750242013552759,0.5750242013552759,0.5808325266214908,0.5808325266214908,0.643756050338819,0.643756050338819,0.6563407550822846,0.6563407550822846,0.665053242981607,0.665053242981607,0.6766698935140368,0.6766698935140368,0.6795740561471443,0.6795740561471443,0.68054211035818,0.68054211035818,0.6844143272023233,0.6844143272023233,0.6892545982575025,0.6892545982575025,0.6931268151016456,0.6931268151016456,0.6940948693126815,0.6940948693126815,0.7057115198451114,0.7057115198451114,0.707647628267183,0.707647628267183,0.7144240077444337,0.7144240077444337,0.7192642787996127,0.7192642787996127,0.7337850919651501,0.7337850919651501,0.739593417231365,0.739593417231365,0.7473378509196515,0.7473378509196515,0.7512100677637947,0.7512100677637947,0.755082284607938,0.755082284607938,0.7608906098741529,0.7608906098741529,0.7783155856727977,0.7783155856727977,0.7889641819941917,0.7889641819941917,0.7947725072604066,0.7947725072604066,0.7996127783155856,0.7996127783155856,0.8073572120038722,0.8073572120038722,0.8092933204259438,0.8092933204259438,0.814133591481123,0.814133591481123,0.8151016456921588,0.8151016456921588,0.8160696999031946,0.8160696999031946,0.8354307841239109,0.8354307841239109,0.8363988383349468,0.8363988383349468,0.8383349467570184,0.8383349467570184,0.8402710551790901,0.8402710551790901,0.8412391093901258,0.8412391093901258,0.8480154888673765,0.8480154888673765,0.856727976766699,0.856727976766699,0.8586640851887706,0.8586640851887706,0.8664085188770572,0.8664085188770572,0.8673765730880929,0.8673765730880929,0.8731848983543078,0.8731848983543078,0.8789932236205228,0.8789932236205228,0.8818973862536302,0.8818973862536302,0.8838334946757018,0.8838334946757018,0.8848015488867377,0.8848015488867377,0.8857696030977735,0.8857696030977735,0.8867376573088093,0.8867376573088093,0.8906098741529526,0.8906098741529526,0.8925459825750242,0.8925459825750242,0.8944820909970959,0.8944820909970959,0.8973862536302033,0.8973862536302033,0.8983543078412392,0.8983543078412392,0.8993223620522749,0.8993223620522749,0.9070667957405615,0.9070667957405615,0.9119070667957405,0.9119070667957405,0.914811229428848,0.914811229428848,0.9177153920619555,0.9177153920619555,0.9186834462729913,0.9186834462729913,0.9244917715392061,0.9244917715392061,0.925459825750242,0.925459825750242,0.9370764762826719,0.9370764762826719,0.9380445304937076,0.9380445304937076,0.9419167473378509,0.9419167473378509,0.9438528557599225,0.9438528557599225,0.9448209099709584,0.9448209099709584,0.9515972894482091,0.9515972894482091,0.9535333978702807,0.9535333978702807,0.957405614714424,0.957405614714424,0.9593417231364957,0.9593417231364957,0.9622458857696031,0.9622458857696031,0.9641819941916747,0.9641819941916747,0.9690222652468539,0.9690222652468539,0.9699903194578896,0.9699903194578896,0.9709583736689255,0.9709583736689255,0.9719264278799613,0.9719264278799613,0.972894482090997,0.972894482090997,0.9738625363020329,0.9738625363020329,0.9748305905130688,0.9748305905130688,0.9757986447241046,0.9757986447241046,0.9767666989351403,0.9767666989351403,0.9777347531461762,0.9777347531461762,0.978702807357212,0.978702807357212,0.9806389157792836,0.9806389157792836,0.9835430784123911,0.9835430784123911,0.9854791868344628,0.9854791868344628,0.989351403678606,0.989351403678606,0.9903194578896418,0.9903194578896418,0.9912875121006777,0.9912875121006777,0.9932236205227493,0.9932236205227493,0.9941916747337851,0.9941916747337851,0.995159728944821,0.995159728944821,0.9961277831558567,0.9961277831558567,0.9970958373668926,0.9970958373668926,0.9980638915779284,0.9980638915779284,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,1,1],"yaxis":"y"}],"layout":{"height":600,"legend":{"tracegroupgap":0},"shapes":[{"line":{"dash":"dash"},"type":"line","x0":0,"x1":1,"y0":0,"y1":1}],"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"title":{"text":"ROC Curve (AUC=0.9211)"},"width":800,"xaxis":{"anchor":"y","constrain":"domain","domain":[0,1],"title":{"text":"False Positive Rate"}},"yaxis":{"anchor":"x","domain":[0,1],"scaleanchor":"x","scaleratio":1,"title":{"text":"True Positive Rate"}}}},"text/html":["<div>                            <div id=\"fb72e7bf-bd59-4283-855c-84b4638c13a8\" class=\"plotly-graph-div\" style=\"height:600px; width:800px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"fb72e7bf-bd59-4283-855c-84b4638c13a8\")) {                    Plotly.newPlot(                        \"fb72e7bf-bd59-4283-855c-84b4638c13a8\",                        [{\"fillpattern\":{\"shape\":\"\"},\"hovertemplate\":\"False Positive Rate=%{x}\\u003cbr\\u003eTrue Positive Rate=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"stackgroup\":\"1\",\"x\":[0.0,0.0,0.0,0.00267379679144385,0.00267379679144385,0.00267379679144385,0.00267379679144385,0.0053475935828877,0.0053475935828877,0.008021390374331552,0.008021390374331552,0.013368983957219251,0.013368983957219251,0.013368983957219251,0.013368983957219251,0.016042780748663103,0.016042780748663103,0.016042780748663103,0.016042780748663103,0.01871657754010695,0.01871657754010695,0.01871657754010695,0.01871657754010695,0.0213903743315508,0.0213903743315508,0.02406417112299465,0.02406417112299465,0.02406417112299465,0.02406417112299465,0.02406417112299465,0.02406417112299465,0.026737967914438502,0.026737967914438502,0.029411764705882353,0.029411764705882353,0.03208556149732621,0.03208556149732621,0.034759358288770054,0.034759358288770054,0.0374331550802139,0.0374331550802139,0.040106951871657755,0.040106951871657755,0.0427807486631016,0.0427807486631016,0.045454545454545456,0.045454545454545456,0.0481283422459893,0.0481283422459893,0.05080213903743316,0.05080213903743316,0.053475935828877004,0.053475935828877004,0.05614973262032086,0.05614973262032086,0.058823529411764705,0.058823529411764705,0.06149732620320856,0.06149732620320856,0.06417112299465241,0.06417112299465241,0.06684491978609626,0.06684491978609626,0.06951871657754011,0.06951871657754011,0.07219251336898395,0.07219251336898395,0.0748663101604278,0.0748663101604278,0.07754010695187166,0.07754010695187166,0.08021390374331551,0.08021390374331551,0.08288770053475936,0.08288770053475936,0.0855614973262032,0.0855614973262032,0.08823529411764706,0.08823529411764706,0.09090909090909091,0.09090909090909091,0.0962566844919786,0.0962566844919786,0.09893048128342247,0.09893048128342247,0.10160427807486631,0.10160427807486631,0.10695187165775401,0.10695187165775401,0.10962566844919786,0.10962566844919786,0.11229946524064172,0.11229946524064172,0.11497326203208556,0.11497326203208556,0.11764705882352941,0.11764705882352941,0.12032085561497326,0.12032085561497326,0.12566844919786097,0.12566844919786097,0.12834224598930483,0.12834224598930483,0.13101604278074866,0.13101604278074866,0.13368983957219252,0.13368983957219252,0.13636363636363635,0.13636363636363635,0.13903743315508021,0.13903743315508021,0.14171122994652408,0.14171122994652408,0.1443850267379679,0.1443850267379679,0.14705882352941177,0.14705882352941177,0.1497326203208556,0.1497326203208556,0.15240641711229946,0.15240641711229946,0.15508021390374332,0.15508021390374332,0.15775401069518716,0.15775401069518716,0.16042780748663102,0.16042780748663102,0.16310160427807488,0.16310160427807488,0.1657754010695187,0.1657754010695187,0.1711229946524064,0.1711229946524064,0.17379679144385027,0.17379679144385027,0.18449197860962566,0.18449197860962566,0.18983957219251338,0.18983957219251338,0.1925133689839572,0.1925133689839572,0.19786096256684493,0.19786096256684493,0.20053475935828877,0.20053475935828877,0.20320855614973263,0.20320855614973263,0.20588235294117646,0.20588235294117646,0.21122994652406418,0.21122994652406418,0.21390374331550802,0.21390374331550802,0.21657754010695188,0.21657754010695188,0.2192513368983957,0.2192513368983957,0.22192513368983957,0.22192513368983957,0.22459893048128343,0.22459893048128343,0.22727272727272727,0.22727272727272727,0.22994652406417113,0.22994652406417113,0.23796791443850268,0.23796791443850268,0.24064171122994651,0.24064171122994651,0.24331550802139038,0.24331550802139038,0.24598930481283424,0.24598930481283424,0.24866310160427807,0.24866310160427807,0.2540106951871658,0.2540106951871658,0.2620320855614973,0.2620320855614973,0.2647058823529412,0.2647058823529412,0.27540106951871657,0.27540106951871657,0.27807486631016043,0.27807486631016043,0.2807486631016043,0.2807486631016043,0.28342245989304815,0.28342245989304815,0.28609625668449196,0.28609625668449196,0.29411764705882354,0.29411764705882354,0.30213903743315507,0.30213903743315507,0.3155080213903743,0.3155080213903743,0.32085561497326204,0.32085561497326204,0.3235294117647059,0.3235294117647059,0.339572192513369,0.339572192513369,0.3422459893048128,0.3422459893048128,0.34759358288770054,0.34759358288770054,0.3502673796791444,0.3502673796791444,0.36363636363636365,0.36363636363636365,0.3663101604278075,0.3663101604278075,0.37967914438502676,0.37967914438502676,0.3850267379679144,0.3850267379679144,0.3877005347593583,0.3877005347593583,0.39037433155080214,0.39037433155080214,0.393048128342246,0.393048128342246,0.39572192513368987,0.39572192513368987,0.40106951871657753,0.40106951871657753,0.40641711229946526,0.40641711229946526,0.42780748663101603,0.42780748663101603,0.4304812834224599,0.4304812834224599,0.44385026737967914,0.44385026737967914,0.45454545454545453,0.45454545454545453,0.4893048128342246,0.4893048128342246,0.5026737967914439,0.5026737967914439,0.5080213903743316,0.5080213903743316,0.5294117647058824,0.5347593582887701,0.5588235294117647,0.5588235294117647,1.0],\"xaxis\":\"x\",\"y\":[0.0,0.000968054211035818,0.015488867376573089,0.015488867376573089,0.027105517909002903,0.02904162633107454,0.031945788964181994,0.031945788964181994,0.044530493707647625,0.044530493707647625,0.05517909002904162,0.05517909002904162,0.08615682478218781,0.08809293320425944,0.14133591481122942,0.14133591481122942,0.2042594385285576,0.20619554695062922,0.22749273959341723,0.22749273959341723,0.27783155856727976,0.2797676669893514,0.2971926427879961,0.2971926427879961,0.3388189738625363,0.3388189738625363,0.38528557599225555,0.3872216844143272,0.38818973862536305,0.39012584704743464,0.3978702807357212,0.3978702807357212,0.42400774443368827,0.42400774443368827,0.4453049370764763,0.4453049370764763,0.462729912875121,0.462729912875121,0.46950629235237173,0.46950629235237173,0.48596321393998065,0.48596321393998065,0.5014520813165537,0.5014520813165537,0.5091965150048403,0.5091965150048403,0.5450145208131656,0.5450145208131656,0.547918683446273,0.547918683446273,0.5682478218780251,0.5682478218780251,0.5750242013552759,0.5750242013552759,0.5808325266214908,0.5808325266214908,0.643756050338819,0.643756050338819,0.6563407550822846,0.6563407550822846,0.665053242981607,0.665053242981607,0.6766698935140368,0.6766698935140368,0.6795740561471443,0.6795740561471443,0.68054211035818,0.68054211035818,0.6844143272023233,0.6844143272023233,0.6892545982575025,0.6892545982575025,0.6931268151016456,0.6931268151016456,0.6940948693126815,0.6940948693126815,0.7057115198451114,0.7057115198451114,0.707647628267183,0.707647628267183,0.7144240077444337,0.7144240077444337,0.7192642787996127,0.7192642787996127,0.7337850919651501,0.7337850919651501,0.739593417231365,0.739593417231365,0.7473378509196515,0.7473378509196515,0.7512100677637947,0.7512100677637947,0.755082284607938,0.755082284607938,0.7608906098741529,0.7608906098741529,0.7783155856727977,0.7783155856727977,0.7889641819941917,0.7889641819941917,0.7947725072604066,0.7947725072604066,0.7996127783155856,0.7996127783155856,0.8073572120038722,0.8073572120038722,0.8092933204259438,0.8092933204259438,0.814133591481123,0.814133591481123,0.8151016456921588,0.8151016456921588,0.8160696999031946,0.8160696999031946,0.8354307841239109,0.8354307841239109,0.8363988383349468,0.8363988383349468,0.8383349467570184,0.8383349467570184,0.8402710551790901,0.8402710551790901,0.8412391093901258,0.8412391093901258,0.8480154888673765,0.8480154888673765,0.856727976766699,0.856727976766699,0.8586640851887706,0.8586640851887706,0.8664085188770572,0.8664085188770572,0.8673765730880929,0.8673765730880929,0.8731848983543078,0.8731848983543078,0.8789932236205228,0.8789932236205228,0.8818973862536302,0.8818973862536302,0.8838334946757018,0.8838334946757018,0.8848015488867377,0.8848015488867377,0.8857696030977735,0.8857696030977735,0.8867376573088093,0.8867376573088093,0.8906098741529526,0.8906098741529526,0.8925459825750242,0.8925459825750242,0.8944820909970959,0.8944820909970959,0.8973862536302033,0.8973862536302033,0.8983543078412392,0.8983543078412392,0.8993223620522749,0.8993223620522749,0.9070667957405615,0.9070667957405615,0.9119070667957405,0.9119070667957405,0.914811229428848,0.914811229428848,0.9177153920619555,0.9177153920619555,0.9186834462729913,0.9186834462729913,0.9244917715392061,0.9244917715392061,0.925459825750242,0.925459825750242,0.9370764762826719,0.9370764762826719,0.9380445304937076,0.9380445304937076,0.9419167473378509,0.9419167473378509,0.9438528557599225,0.9438528557599225,0.9448209099709584,0.9448209099709584,0.9515972894482091,0.9515972894482091,0.9535333978702807,0.9535333978702807,0.957405614714424,0.957405614714424,0.9593417231364957,0.9593417231364957,0.9622458857696031,0.9622458857696031,0.9641819941916747,0.9641819941916747,0.9690222652468539,0.9690222652468539,0.9699903194578896,0.9699903194578896,0.9709583736689255,0.9709583736689255,0.9719264278799613,0.9719264278799613,0.972894482090997,0.972894482090997,0.9738625363020329,0.9738625363020329,0.9748305905130688,0.9748305905130688,0.9757986447241046,0.9757986447241046,0.9767666989351403,0.9767666989351403,0.9777347531461762,0.9777347531461762,0.978702807357212,0.978702807357212,0.9806389157792836,0.9806389157792836,0.9835430784123911,0.9835430784123911,0.9854791868344628,0.9854791868344628,0.989351403678606,0.989351403678606,0.9903194578896418,0.9903194578896418,0.9912875121006777,0.9912875121006777,0.9932236205227493,0.9932236205227493,0.9941916747337851,0.9941916747337851,0.995159728944821,0.995159728944821,0.9961277831558567,0.9961277831558567,0.9970958373668926,0.9970958373668926,0.9980638915779284,0.9980638915779284,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,1.0,1.0],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"False Positive Rate\"},\"constrain\":\"domain\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"True Positive Rate\"},\"scaleanchor\":\"x\",\"scaleratio\":1},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"ROC Curve (AUC=0.9211)\"},\"height\":600,\"width\":800,\"shapes\":[{\"line\":{\"dash\":\"dash\"},\"type\":\"line\",\"x0\":0,\"x1\":1,\"y0\":0,\"y1\":1}],\"showlegend\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('fb72e7bf-bd59-4283-855c-84b4638c13a8');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"fillpattern":{"shape":""},"hovertemplate":"Recall=%{x}<br>Precision=%{y}<extra></extra>","legendgroup":"","line":{"color":"#636efa"},"marker":{"symbol":"circle"},"mode":"lines","name":"","orientation":"v","showlegend":false,"stackgroup":"1","type":"scatter","x":[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9932236205227493,0.9932236205227493,0.9922555663117134,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.989351403678606,0.989351403678606,0.989351403678606,0.9883833494675702,0.9874152952565344,0.9864472410454985,0.9854791868344628,0.9854791868344628,0.9845111326234269,0.9835430784123911,0.9835430784123911,0.9825750242013552,0.9816069699903195,0.9806389157792836,0.9806389157792836,0.9796708615682478,0.978702807357212,0.978702807357212,0.9777347531461762,0.9777347531461762,0.9777347531461762,0.9767666989351403,0.9767666989351403,0.9767666989351403,0.9767666989351403,0.9767666989351403,0.9767666989351403,0.9757986447241046,0.9757986447241046,0.9748305905130688,0.9748305905130688,0.9748305905130688,0.9748305905130688,0.9748305905130688,0.9748305905130688,0.9738625363020329,0.9738625363020329,0.972894482090997,0.972894482090997,0.972894482090997,0.9719264278799613,0.9719264278799613,0.9709583736689255,0.9709583736689255,0.9709583736689255,0.9709583736689255,0.9709583736689255,0.9709583736689255,0.9709583736689255,0.9699903194578896,0.9699903194578896,0.9690222652468539,0.9690222652468539,0.9690222652468539,0.968054211035818,0.9670861568247822,0.9661181026137464,0.9651500484027106,0.9641819941916747,0.9641819941916747,0.9641819941916747,0.9641819941916747,0.9641819941916747,0.9641819941916747,0.9632139399806389,0.9622458857696031,0.9622458857696031,0.9622458857696031,0.9622458857696031,0.9612778315585673,0.9603097773475314,0.9593417231364957,0.9593417231364957,0.9593417231364957,0.9593417231364957,0.9583736689254598,0.957405614714424,0.957405614714424,0.9564375605033882,0.9554695062923524,0.9545014520813165,0.9535333978702807,0.9535333978702807,0.952565343659245,0.9515972894482091,0.9515972894482091,0.9506292352371732,0.9496611810261375,0.9486931268151017,0.9477250726040658,0.9467570183930301,0.9457889641819942,0.9448209099709584,0.9448209099709584,0.9438528557599225,0.9438528557599225,0.9438528557599225,0.9438528557599225,0.9438528557599225,0.9428848015488868,0.9419167473378509,0.9419167473378509,0.9409486931268151,0.9399806389157793,0.9390125847047435,0.9380445304937076,0.9380445304937076,0.9380445304937076,0.9380445304937076,0.9370764762826719,0.9370764762826719,0.9370764762826719,0.936108422071636,0.9351403678606002,0.9341723136495643,0.9332042594385286,0.9322362052274927,0.9312681510164569,0.9303000968054211,0.9293320425943853,0.9283639883833494,0.9273959341723137,0.9264278799612778,0.925459825750242,0.925459825750242,0.9244917715392061,0.9244917715392061,0.9235237173281704,0.9225556631171346,0.9215876089060987,0.920619554695063,0.9196515004840271,0.9186834462729913,0.9186834462729913,0.9177153920619555,0.9177153920619555,0.9167473378509197,0.9157792836398838,0.914811229428848,0.914811229428848,0.914811229428848,0.914811229428848,0.9138431752178122,0.9128751210067764,0.9119070667957405,0.9119070667957405,0.9109390125847048,0.9099709583736689,0.9090029041626331,0.9080348499515973,0.9070667957405615,0.9070667957405615,0.9060987415295256,0.9051306873184899,0.904162633107454,0.9031945788964182,0.9022265246853823,0.9012584704743466,0.9002904162633107,0.8993223620522749,0.8993223620522749,0.8983543078412392,0.8983543078412392,0.8973862536302033,0.8973862536302033,0.8964181994191674,0.8954501452081317,0.8944820909970959,0.8944820909970959,0.89351403678606,0.8925459825750242,0.8925459825750242,0.8915779283639884,0.8906098741529526,0.8906098741529526,0.8906098741529526,0.8896418199419167,0.888673765730881,0.8877057115198451,0.8867376573088093,0.8867376573088093,0.8857696030977735,0.8857696030977735,0.8848015488867377,0.8848015488867377,0.8838334946757018,0.8838334946757018,0.8838334946757018,0.882865440464666,0.8818973862536302,0.8818973862536302,0.8809293320425944,0.8799612778315585,0.8789932236205228,0.8789932236205228,0.8789932236205228,0.8780251694094869,0.8770571151984511,0.8760890609874153,0.8751210067763795,0.8741529525653436,0.8731848983543078,0.8731848983543078,0.8731848983543078,0.8731848983543078,0.8731848983543078,0.872216844143272,0.8712487899322362,0.8702807357212003,0.8693126815101646,0.8683446272991288,0.8673765730880929,0.8673765730880929,0.8664085188770572,0.8664085188770572,0.8664085188770572,0.8654404646660213,0.8644724104549855,0.8635043562439496,0.8625363020329139,0.861568247821878,0.8606001936108422,0.8596321393998064,0.8586640851887706,0.8586640851887706,0.8576960309777347,0.856727976766699,0.856727976766699,0.8557599225556631,0.8547918683446273,0.8538238141335914,0.8528557599225557,0.8518877057115198,0.850919651500484,0.8499515972894482,0.8489835430784124,0.8480154888673765,0.8480154888673765,0.8470474346563408,0.846079380445305,0.8451113262342691,0.8441432720232332,0.8431752178121975,0.8422071636011617,0.8412391093901258,0.8412391093901258,0.8402710551790901,0.8402710551790901,0.8393030009680542,0.8383349467570184,0.8383349467570184,0.8373668925459826,0.8363988383349468,0.8363988383349468,0.8354307841239109,0.8354307841239109,0.8344627299128751,0.8334946757018393,0.8325266214908035,0.8315585672797676,0.8305905130687319,0.829622458857696,0.8286544046466602,0.8276863504356244,0.8267182962245886,0.8257502420135527,0.8247821878025169,0.8238141335914811,0.8228460793804453,0.8218780251694094,0.8209099709583737,0.8199419167473379,0.818973862536302,0.8180058083252663,0.8170377541142304,0.8160696999031946,0.8160696999031946,0.8151016456921588,0.8151016456921588,0.814133591481123,0.814133591481123,0.8131655372700871,0.8121974830590513,0.8112294288480155,0.8102613746369797,0.8092933204259438,0.8092933204259438,0.8083252662149081,0.8073572120038722,0.8073572120038722,0.8063891577928364,0.8054211035818006,0.8044530493707648,0.8034849951597289,0.8025169409486931,0.8015488867376573,0.8005808325266215,0.7996127783155856,0.7996127783155856,0.7986447241045499,0.797676669893514,0.7967086156824782,0.7957405614714425,0.7947725072604066,0.7947725072604066,0.7938044530493708,0.7928363988383349,0.7918683446272992,0.7909002904162633,0.7899322362052275,0.7889641819941917,0.7889641819941917,0.7889641819941917,0.7879961277831559,0.78702807357212,0.7860600193610843,0.7850919651500484,0.7841239109390126,0.7831558567279767,0.782187802516941,0.7812197483059051,0.7802516940948693,0.7792836398838335,0.7783155856727977,0.7783155856727977,0.7773475314617618,0.7763794772507261,0.7754114230396902,0.7744433688286544,0.7734753146176185,0.7725072604065828,0.771539206195547,0.7705711519845111,0.7696030977734754,0.7686350435624395,0.7676669893514037,0.7666989351403679,0.7657308809293321,0.7647628267182962,0.7637947725072604,0.7628267182962246,0.7618586640851888,0.7608906098741529,0.7608906098741529,0.7599225556631172,0.7589545014520813,0.7579864472410455,0.7570183930300097,0.7560503388189739,0.755082284607938,0.755082284607938,0.7541142303969022,0.7531461761858664,0.7521781219748306,0.7512100677637947,0.7512100677637947,0.750242013552759,0.7492739593417231,0.7483059051306873,0.7473378509196515,0.7473378509196515,0.7463697967086157,0.7454017424975798,0.744433688286544,0.7434656340755083,0.7424975798644724,0.7415295256534365,0.7405614714424008,0.739593417231365,0.739593417231365,0.739593417231365,0.7386253630203291,0.7376573088092934,0.7366892545982575,0.7357212003872217,0.7347531461761858,0.7337850919651501,0.7337850919651501,0.7328170377541142,0.7318489835430784,0.7308809293320426,0.7299128751210068,0.7289448209099709,0.7279767666989352,0.7270087124878993,0.7260406582768635,0.7250726040658277,0.7241045498547919,0.723136495643756,0.7221684414327202,0.7212003872216844,0.7202323330106486,0.7192642787996127,0.7192642787996127,0.718296224588577,0.7173281703775412,0.7163601161665053,0.7153920619554696,0.7144240077444337,0.7144240077444337,0.7144240077444337,0.7134559535333979,0.712487899322362,0.7115198451113263,0.7105517909002904,0.7095837366892546,0.7086156824782188,0.707647628267183,0.707647628267183,0.7066795740561471,0.7057115198451114,0.7057115198451114,0.7047434656340755,0.7037754114230397,0.7028073572120038,0.7018393030009681,0.7008712487899322,0.6999031945788964,0.6989351403678606,0.6979670861568248,0.6969990319457889,0.6960309777347532,0.6950629235237173,0.6940948693126815,0.6940948693126815,0.6931268151016456,0.6931268151016456,0.6921587608906099,0.691190706679574,0.6902226524685382,0.6892545982575025,0.6892545982575025,0.6882865440464666,0.6873184898354308,0.686350435624395,0.6853823814133592,0.6844143272023233,0.6844143272023233,0.6834462729912875,0.6824782187802517,0.6815101645692159,0.68054211035818,0.68054211035818,0.6795740561471443,0.6795740561471443,0.6786060019361084,0.6776379477250726,0.6766698935140368,0.6766698935140368,0.675701839303001,0.6747337850919651,0.6737657308809293,0.6727976766698935,0.6718296224588577,0.6708615682478218,0.6698935140367861,0.6689254598257502,0.6679574056147144,0.6669893514036787,0.6660212971926428,0.665053242981607,0.665053242981607,0.6640851887705711,0.6631171345595354,0.6621490803484995,0.6611810261374637,0.6602129719264279,0.6592449177153921,0.6582768635043562,0.6573088092933205,0.6563407550822846,0.6563407550822846,0.6553727008712488,0.6544046466602129,0.6534365924491772,0.6524685382381413,0.6515004840271055,0.6505324298160697,0.6495643756050339,0.648596321393998,0.6476282671829623,0.6466602129719264,0.6456921587608906,0.6447241045498547,0.643756050338819,0.643756050338819,0.6427879961277831,0.6418199419167473,0.6408518877057116,0.6398838334946757,0.6389157792836399,0.6379477250726041,0.6369796708615683,0.6360116166505324,0.6350435624394967,0.6340755082284608,0.633107454017425,0.6321393998063891,0.6311713455953534,0.6302032913843175,0.6292352371732817,0.6282671829622459,0.6272991287512101,0.6263310745401742,0.6253630203291385,0.6243949661181026,0.6234269119070668,0.6224588576960309,0.6214908034849952,0.6205227492739593,0.6195546950629235,0.6185866408518877,0.6176185866408519,0.616650532429816,0.6156824782187803,0.6147144240077445,0.6137463697967086,0.6127783155856728,0.611810261374637,0.6108422071636012,0.6098741529525653,0.6089060987415296,0.6079380445304937,0.6069699903194579,0.6060019361084221,0.6050338818973863,0.6040658276863504,0.6030977734753146,0.6021297192642788,0.601161665053243,0.6001936108422071,0.5992255566311714,0.5982575024201355,0.5972894482090997,0.5963213939980639,0.5953533397870281,0.5943852855759922,0.5934172313649564,0.5924491771539206,0.5914811229428848,0.590513068731849,0.5895450145208132,0.5885769603097774,0.5876089060987415,0.5866408518877058,0.5856727976766699,0.5847047434656341,0.5837366892545982,0.5827686350435625,0.5818005808325266,0.5808325266214908,0.5808325266214908,0.579864472410455,0.5788964181994192,0.5779283639883833,0.5769603097773476,0.5759922555663117,0.5750242013552759,0.5750242013552759,0.57405614714424,0.5730880929332043,0.5721200387221684,0.5711519845111326,0.5701839303000968,0.569215876089061,0.5682478218780251,0.5682478218780251,0.5672797676669894,0.5663117134559535,0.5653436592449177,0.5643756050338818,0.5634075508228461,0.5624394966118103,0.5614714424007744,0.5605033881897387,0.5595353339787028,0.558567279767667,0.5575992255566312,0.5566311713455954,0.5556631171345595,0.5546950629235237,0.5537270087124879,0.5527589545014521,0.5517909002904162,0.5508228460793805,0.5498547918683446,0.5488867376573088,0.547918683446273,0.547918683446273,0.5469506292352372,0.5459825750242013,0.5450145208131656,0.5450145208131656,0.5440464666021297,0.5430784123910939,0.542110358180058,0.5411423039690223,0.5401742497579864,0.5392061955469506,0.5382381413359149,0.537270087124879,0.5363020329138432,0.5353339787028074,0.5343659244917716,0.5333978702807357,0.5324298160696999,0.5314617618586641,0.5304937076476283,0.5295256534365924,0.5285575992255567,0.5275895450145208,0.526621490803485,0.5256534365924492,0.5246853823814134,0.5237173281703775,0.5227492739593417,0.5217812197483059,0.5208131655372701,0.5198451113262342,0.5188770571151985,0.5179090029041626,0.5169409486931268,0.515972894482091,0.5150048402710552,0.5140367860600193,0.5130687318489835,0.5121006776379478,0.5111326234269119,0.510164569215876,0.5091965150048403,0.5091965150048403,0.5082284607938045,0.5072604065827686,0.5062923523717329,0.505324298160697,0.5043562439496612,0.5033881897386253,0.5024201355275896,0.5014520813165537,0.5014520813165537,0.5004840271055179,0.4995159728944821,0.4985479186834463,0.4975798644724105,0.49661181026137463,0.49564375605033884,0.494675701839303,0.4937076476282672,0.4927395934172314,0.49177153920619554,0.49080348499515974,0.4898354307841239,0.4888673765730881,0.4878993223620523,0.48693126815101645,0.48596321393998065,0.48596321393998065,0.4849951597289448,0.484027105517909,0.4830590513068732,0.48209099709583736,0.48112294288480156,0.4801548886737657,0.4791868344627299,0.4782187802516941,0.47725072604065827,0.4762826718296225,0.4753146176185866,0.4743465634075508,0.47337850919651503,0.4724104549854792,0.4714424007744434,0.47047434656340753,0.46950629235237173,0.46950629235237173,0.46853823814133594,0.4675701839303001,0.4666021297192643,0.46563407550822844,0.46466602129719264,0.46369796708615685,0.462729912875121,0.462729912875121,0.4617618586640852,0.46079380445304935,0.45982575024201355,0.45885769603097776,0.4578896418199419,0.4569215876089061,0.45595353339787026,0.45498547918683446,0.45401742497579867,0.4530493707647628,0.452081316553727,0.45111326234269117,0.45014520813165537,0.4491771539206196,0.4482090997095837,0.44724104549854793,0.4462729912875121,0.4453049370764763,0.4453049370764763,0.4443368828654405,0.44336882865440463,0.44240077444336884,0.441432720232333,0.4404646660212972,0.4394966118102614,0.43852855759922554,0.43756050338818975,0.4365924491771539,0.4356243949661181,0.4346563407550823,0.43368828654404645,0.43272023233301066,0.4317521781219748,0.430784123910939,0.4298160696999032,0.42884801548886736,0.42787996127783157,0.4269119070667957,0.4259438528557599,0.4249757986447241,0.42400774443368827,0.42400774443368827,0.4230396902226525,0.4220716360116166,0.42110358180058083,0.42013552758954503,0.4191674733785092,0.4181994191674734,0.41723136495643753,0.41626331074540174,0.41529525653436594,0.4143272023233301,0.4133591481122943,0.41239109390125844,0.41142303969022265,0.41045498547918685,0.409486931268151,0.4085188770571152,0.4075508228460794,0.40658276863504356,0.40561471442400776,0.4046466602129719,0.4036786060019361,0.4027105517909003,0.40174249757986447,0.40077444336882867,0.3998063891577928,0.398838334946757,0.3978702807357212,0.3978702807357212,0.3969022265246854,0.3959341723136496,0.39496611810261373,0.39399806389157793,0.39303000968054214,0.3920619554695063,0.3910939012584705,0.39012584704743464,0.38818973862536305,0.3872216844143272,0.38528557599225555,0.38431752178121975,0.38334946757018395,0.3823814133591481,0.3814133591481123,0.38044530493707646,0.37947725072604066,0.37850919651500486,0.377541142303969,0.3765730880929332,0.37560503388189737,0.37463697967086157,0.3736689254598258,0.3727008712487899,0.3717328170377541,0.3707647628267183,0.3697967086156825,0.3688286544046467,0.36786060019361083,0.36689254598257504,0.3659244917715392,0.3649564375605034,0.3639883833494676,0.36302032913843174,0.36205227492739595,0.3610842207163601,0.3601161665053243,0.3591481122942885,0.35818005808325265,0.35721200387221685,0.356243949661181,0.3552758954501452,0.3543078412391094,0.35333978702807356,0.35237173281703776,0.3514036786060019,0.3504356243949661,0.3494675701839303,0.34849951597289447,0.3475314617618587,0.3465634075508228,0.345595353339787,0.34462729912875123,0.3436592449177154,0.3426911907066796,0.34172313649564373,0.34075508228460794,0.33978702807357214,0.3388189738625363,0.3388189738625363,0.3378509196515005,0.33688286544046464,0.33591481122942884,0.33494675701839305,0.3339787028073572,0.3330106485963214,0.33204259438528555,0.33107454017424975,0.33010648596321396,0.3291384317521781,0.3281703775411423,0.32720232333010646,0.32623426911907066,0.32526621490803487,0.324298160696999,0.3233301064859632,0.32236205227492737,0.3213939980638916,0.3204259438528558,0.3194578896418199,0.31848983543078413,0.31752178121974833,0.3165537270087125,0.3155856727976767,0.31461761858664083,0.31364956437560504,0.31268151016456924,0.3117134559535334,0.3107454017424976,0.30977734753146174,0.30880929332042595,0.30784123910939015,0.3068731848983543,0.3059051306873185,0.30493707647628265,0.30396902226524686,0.30300096805421106,0.3020329138431752,0.3010648596321394,0.30009680542110356,0.29912875121006777,0.29816069699903197,0.2971926427879961,0.2971926427879961,0.2962245885769603,0.2952565343659245,0.2942884801548887,0.2933204259438529,0.29235237173281703,0.29138431752178123,0.2904162633107454,0.2894482090997096,0.2884801548886738,0.28751210067763794,0.28654404646660214,0.2855759922555663,0.2846079380445305,0.2836398838334947,0.28267182962245885,0.28170377541142305,0.2807357212003872,0.2797676669893514,0.27783155856727976,0.27686350435624396,0.2758954501452081,0.2749273959341723,0.2739593417231365,0.27299128751210067,0.27202323330106487,0.271055179090029,0.2700871248789932,0.2691190706679574,0.2681510164569216,0.2671829622458858,0.26621490803484993,0.26524685382381413,0.26427879961277834,0.2633107454017425,0.2623426911907067,0.26137463697967084,0.26040658276863504,0.25943852855759925,0.2584704743465634,0.2575024201355276,0.25653436592449175,0.25556631171345595,0.25459825750242016,0.2536302032913843,0.2526621490803485,0.25169409486931266,0.25072604065827686,0.24975798644724104,0.24878993223620524,0.24782187802516942,0.2468538238141336,0.24588576960309777,0.24491771539206195,0.24394966118102615,0.24298160696999033,0.2420135527589545,0.24104549854791868,0.24007744433688286,0.23910939012584706,0.23814133591481124,0.2371732817037754,0.2362052274927396,0.23523717328170377,0.23426911907066797,0.23330106485963215,0.23233301064859632,0.2313649564375605,0.23039690222652467,0.22942884801548888,0.22846079380445306,0.22749273959341723,0.22749273959341723,0.2265246853823814,0.22555663117134558,0.2245885769603098,0.22362052274927396,0.22265246853823814,0.22168441432720232,0.2207163601161665,0.2197483059051307,0.21878025169409487,0.21781219748305905,0.21684414327202323,0.2158760890609874,0.2149080348499516,0.21393998063891578,0.21297192642787996,0.21200387221684414,0.2110358180058083,0.21006776379477252,0.2090997095837367,0.20813165537270087,0.20716360116166505,0.20619554695062922,0.2042594385285576,0.20329138431752178,0.20232333010648595,0.20135527589545016,0.20038722168441434,0.1994191674733785,0.1984511132623427,0.19748305905130686,0.19651500484027107,0.19554695062923524,0.19457889641819942,0.1936108422071636,0.19264278799612777,0.19167473378509198,0.19070667957405615,0.18973862536302033,0.1887705711519845,0.18780251694094868,0.1868344627299129,0.18586640851887706,0.18489835430784124,0.18393030009680542,0.1829622458857696,0.1819941916747338,0.18102613746369797,0.18005808325266215,0.17909002904162633,0.1781219748305905,0.1771539206195547,0.17618586640851888,0.17521781219748306,0.17424975798644723,0.1732817037754114,0.17231364956437561,0.1713455953533398,0.17037754114230397,0.16940948693126814,0.16844143272023232,0.16747337850919652,0.1665053242981607,0.16553727008712488,0.16456921587608905,0.16360116166505323,0.16263310745401743,0.1616650532429816,0.1606969990319458,0.15972894482090996,0.15876089060987417,0.15779283639883834,0.15682478218780252,0.1558567279767667,0.15488867376573087,0.15392061955469508,0.15295256534365925,0.15198451113262343,0.1510164569215876,0.15004840271055178,0.14908034849951599,0.14811229428848016,0.14714424007744434,0.14617618586640851,0.1452081316553727,0.1442400774443369,0.14327202323330107,0.14230396902226525,0.14133591481122942,0.14133591481122942,0.1403678606001936,0.1393998063891578,0.13843175217812198,0.13746369796708616,0.13649564375605033,0.1355275895450145,0.1345595353339787,0.1335914811229429,0.13262342691190707,0.13165537270087124,0.13068731848983542,0.12971926427879962,0.1287512100677638,0.12778315585672798,0.12681510164569215,0.12584704743465633,0.12487899322362052,0.12391093901258471,0.12294288480154889,0.12197483059051308,0.12100677637947725,0.12003872216844143,0.11907066795740562,0.1181026137463698,0.11713455953533398,0.11616650532429816,0.11519845111326234,0.11423039690222653,0.1132623426911907,0.1122942884801549,0.11132623426911907,0.11035818005808325,0.10939012584704744,0.10842207163601161,0.1074540174249758,0.10648596321393998,0.10551790900290416,0.10454985479186835,0.10358180058083252,0.10261374636979671,0.10164569215876089,0.10067763794772508,0.09970958373668926,0.09874152952565343,0.09777347531461762,0.0968054211035818,0.09583736689254599,0.09486931268151017,0.09390125847047434,0.09293320425943853,0.09196515004840271,0.0909970958373669,0.09002904162633107,0.08906098741529525,0.08809293320425944,0.08615682478218781,0.08518877057115198,0.08422071636011616,0.08325266214908035,0.08228460793804453,0.08131655372700872,0.0803484995159729,0.07938044530493708,0.07841239109390126,0.07744433688286544,0.07647628267182963,0.0755082284607938,0.07454017424975799,0.07357212003872217,0.07260406582768635,0.07163601161665054,0.07066795740561471,0.0696999031945789,0.06873184898354308,0.06776379477250725,0.06679574056147145,0.06582768635043562,0.06485963213939981,0.06389157792836399,0.06292352371732816,0.061955469506292354,0.06098741529525654,0.060019361084220714,0.0590513068731849,0.05808325266214908,0.057115198451113264,0.05614714424007745,0.05517909002904162,0.05517909002904162,0.05517909002904162,0.05421103581800581,0.05324298160696999,0.05227492739593417,0.051306873184898356,0.05033881897386254,0.049370764762826716,0.0484027105517909,0.04743465634075508,0.046466602129719266,0.04549854791868345,0.044530493707647625,0.044530493707647625,0.04356243949661181,0.04259438528557599,0.041626331074540175,0.04065827686350436,0.03969022265246854,0.03872216844143272,0.0377541142303969,0.036786060019361085,0.03581800580832527,0.03484995159728945,0.03388189738625363,0.03291384317521781,0.031945788964181994,0.031945788964181994,0.030977734753146177,0.030009680542110357,0.02904162633107454,0.027105517909002903,0.026137463697967087,0.02516940948693127,0.02420135527589545,0.023233301064859633,0.022265246853823813,0.021297192642787996,0.02032913843175218,0.01936108422071636,0.018393030009680542,0.017424975798644726,0.016456921587608905,0.015488867376573089,0.015488867376573089,0.01452081316553727,0.013552758954501452,0.012584704743465635,0.011616650532429816,0.010648596321393998,0.00968054211035818,0.008712487899322363,0.007744433688286544,0.006776379477250726,0.005808325266214908,0.00484027105517909,0.003872216844143272,0.002904162633107454,0.001936108422071636,0.000968054211035818,0],"xaxis":"x","y":[0.7341862117981521,0.7347083926031295,0.7352313167259786,0.7357549857549858,0.7362794012829651,0.7368045649072753,0.7373304782298359,0.7378571428571429,0.7383845604002859,0.7389127324749643,0.7394416607015032,0.7399713467048711,0.7405017921146954,0.7410329985652798,0.741564967695621,0.7420977011494253,0.7426312005751258,0.7431654676258993,0.7437005039596832,0.7442363112391931,0.7447728911319395,0.7453102453102453,0.7458483754512636,0.7463872832369942,0.7469269703543022,0.7474674384949349,0.7480086893555394,0.7485507246376811,0.7490935460478607,0.7496371552975326,0.7501815541031227,0.7507267441860465,0.7512727272727273,0.7518195050946143,0.752367079388201,0.7529154518950437,0.7534646243617797,0.754014598540146,0.7545653761869978,0.7551169590643275,0.7556693489392831,0.7562225475841874,0.7567765567765568,0.7573313782991202,0.7578870139398386,0.7584434654919237,0.7590007347538574,0.7595588235294117,0.7601177336276674,0.7606774668630338,0.7612380250552689,0.7617994100294986,0.7623616236162362,0.7629246676514032,0.7634885439763488,0.7640532544378699,0.764618800888231,0.7651851851851852,0.765752409191994,0.766320474777448,0.7668893838158871,0.7674591381872214,0.7680297397769517,0.7686011904761905,0.7691734921816828,0.7697466467958272,0.7703206562266965,0.7708955223880597,0.7714712471994025,0.7720478325859492,0.7726252804786836,0.7732035928143712,0.7737827715355805,0.7743628185907047,0.7749437359339835,0.7755255255255256,0.7761081893313299,0.7766917293233083,0.7772761474793077,0.7778614457831325,0.7784476262245666,0.7790346907993967,0.779622641509434,0.7802114803625377,0.780801209372638,0.7813918305597579,0.7819833459500378,0.7825757575757576,0.7831690674753601,0.783763277693475,0.7843583902809416,0.7849544072948328,0.785551330798479,0.7861491628614916,0.7867479055597868,0.7873475609756098,0.7879481311975591,0.7885496183206107,0.7891520244461421,0.7897553516819572,0.7903596021423106,0.7909647779479326,0.7915708812260537,0.7921779141104295,0.7927858787413661,0.793394777265745,0.7940046118370484,0.7946153846153846,0.7952270977675134,0.7958397534668721,0.7964533538936006,0.7970679012345679,0.7976833976833977,0.7982998454404946,0.7989172467130704,0.7995356037151703,0.8001549186676995,0.8007751937984496,0.8013964313421257,0.8020186335403726,0.8026418026418026,0.8032659409020217,0.8038910505836576,0.8045171339563862,0.8051441932969603,0.8057722308892356,0.8064012490241999,0.80703125,0.8076622361219703,0.8082942097026604,0.8089271730618638,0.8095611285266457,0.8101960784313725,0.8108320251177394,0.8114689709347996,0.8121069182389937,0.8127458693941778,0.8133858267716535,0.814026792750197,0.8146687697160884,0.8153117600631413,0.815955766192733,0.8166007905138339,0.817246835443038,0.8178939034045922,0.8185419968304279,0.8191911181601903,0.8198412698412698,0.8204924543288324,0.8211446740858506,0.8217979315831344,0.822452229299363,0.8231075697211155,0.8237639553429027,0.8244213886671987,0.8250798722044729,0.8257394084732215,0.8264,0.8270616493194556,0.8277243589743589,0.8283881315156375,0.8290529695024077,0.8297188755020081,0.8303858520900321,0.831053901850362,0.8317230273752013,0.8315874294923449,0.832258064516129,0.8329297820823245,0.8336025848142165,0.8342764753435732,0.8349514563106796,0.8356275303643724,0.8363047001620746,0.8369829683698297,0.8376623376623377,0.8390243902439024,0.8397070789259561,0.8403908794788274,0.8410757946210269,0.8417618270799347,0.8424489795918367,0.8431372549019608,0.8438266557645135,0.8445171849427169,0.8443898443898444,0.8450819672131148,0.8457752255947498,0.8456486042692939,0.8463434675431388,0.8470394736842105,0.8477366255144033,0.8484349258649094,0.8491343775762572,0.849009900990099,0.8497109826589595,0.8504132231404958,0.8511166253101737,0.8518211920529801,0.8525269262634632,0.8532338308457711,0.8539419087136929,0.8546511627906976,0.8553615960099751,0.8560732113144759,0.8567860116569526,0.8575,0.8582151793160967,0.8580968280467446,0.858813700918964,0.8595317725752508,0.8602510460251046,0.8609715242881072,0.8608549874266554,0.8615771812080537,0.8623005877413937,0.8630252100840337,0.8637510513036165,0.8644781144781145,0.8643639427127211,0.8650927487352446,0.8649789029535865,0.8648648648648649,0.8655959425190194,0.8663282571912013,0.8670618120237087,0.8677966101694915,0.8685326547921968,0.8692699490662139,0.8700084961767205,0.8707482993197279,0.8706382978723404,0.8713798977853492,0.8721227621483376,0.8720136518771331,0.8727583262169086,0.8735042735042735,0.8733960650128315,0.8732876712328768,0.8731790916880892,0.8730703259005146,0.8738197424892704,0.8737113402061856,0.8736027515047291,0.8743545611015491,0.8742463393626184,0.8741379310344828,0.8740293356341674,0.8747841105354058,0.874675885911841,0.8745674740484429,0.8753246753246753,0.8752166377816292,0.8759757155247181,0.8767361111111112,0.8766290182450044,0.8773913043478261,0.8781549173194082,0.8789198606271778,0.8796861377506539,0.8804537521815009,0.880349344978166,0.8811188811188811,0.8810148731408574,0.8817863397548161,0.8825591586327782,0.8833333333333333,0.884108867427568,0.8848857644991213,0.8847845206684257,0.8855633802816901,0.8854625550660793,0.8862433862433863,0.8870255957634599,0.8869257950530035,0.887709991158267,0.8876106194690265,0.8883968113374667,0.8891843971631206,0.8899733806566105,0.8907637655417406,0.8915555555555555,0.8923487544483986,0.8922528940338379,0.893048128342246,0.8929527207850134,0.89375,0.8945487042001787,0.8944543828264758,0.8943598925693823,0.8942652329749103,0.8941704035874439,0.8940754039497307,0.894878706199461,0.89568345323741,0.8964896489648965,0.8972972972972973,0.8981064021641119,0.898014440433213,0.8979223125564589,0.8987341772151899,0.8995475113122172,0.9003623188405797,0.900271985494107,0.9001814882032668,0.9000908265213442,0.9009090909090909,0.9017288444040037,0.9025500910746812,0.902461257976299,0.9023722627737226,0.9031963470319635,0.903107861060329,0.9030192131747484,0.9029304029304029,0.9028414298808433,0.9036697247706422,0.9035812672176309,0.9034926470588235,0.9043238270469182,0.9042357274401474,0.904147465437788,0.9040590405904059,0.9039704524469068,0.9038817005545287,0.9037927844588344,0.9037037037037037,0.9045412418906394,0.9044526901669759,0.9052924791086351,0.9061338289962825,0.9069767441860465,0.9078212290502793,0.907735321528425,0.9076492537313433,0.9084967320261438,0.908411214953271,0.9083255378858747,0.9082397003745318,0.9081537019681349,0.9090056285178236,0.9098591549295775,0.9107142857142857,0.9106302916274694,0.911487758945386,0.9123468426013195,0.9122641509433962,0.9121813031161473,0.9120982986767486,0.9120151371807,0.9119318181818182,0.9118483412322275,0.9117647058823529,0.9116809116809117,0.9115969581749049,0.9115128449096099,0.9114285714285715,0.9113441372735939,0.9122137404580153,0.9121298949379179,0.9130019120458891,0.9129186602870814,0.9128352490421456,0.912751677852349,0.9126679462571977,0.9125840537944284,0.9125,0.9133782483156881,0.9132947976878613,0.914175506268081,0.9140926640926641,0.9140096618357488,0.913926499032882,0.914811229428848,0.9156976744186046,0.9165858389912707,0.916504854368932,0.9164237123420796,0.9163424124513618,0.9172346640701071,0.9171539961013645,0.9170731707317074,0.9169921875,0.916911045943304,0.9168297455968689,0.9177277179236043,0.9176470588235294,0.9175662414131501,0.9174852652259332,0.9174041297935103,0.9173228346456693,0.9172413793103448,0.9171597633136095,0.9170779861796644,0.9179841897233202,0.9179030662710188,0.9188118811881189,0.9187314172447968,0.9196428571428571,0.9195630585898709,0.9194831013916501,0.9194029850746268,0.9203187250996016,0.9202392821535393,0.9201596806387226,0.9210789210789211,0.921,0.9209209209209209,0.9218436873747495,0.9227683049147443,0.9226907630522089,0.9226130653266331,0.9225352112676056,0.9224572004028198,0.9233870967741935,0.9233097880928355,0.9242424242424242,0.9241658240647118,0.9251012145748988,0.9250253292806484,0.9259634888438134,0.9269035532994924,0.926829268292683,0.9267548321464903,0.9276985743380856,0.9276248725790011,0.9275510204081633,0.9274770173646578,0.9284253578732107,0.9293756397134084,0.9293032786885246,0.9292307692307692,0.9291581108829569,0.9290853031860226,0.9290123456790124,0.9289392378990731,0.9298969072164949,0.9308565531475749,0.9318181818181818,0.9327817993795243,0.932712215320911,0.9326424870466321,0.9325726141078838,0.9325025960539979,0.9324324324324325,0.9323621227887617,0.9333333333333333,0.9332638164754953,0.9342379958246346,0.93521421107628,0.9351464435146444,0.9350785340314136,0.9350104821802935,0.9349422875131165,0.9348739495798319,0.9348054679284963,0.9347368421052632,0.934668071654373,0.9356540084388185,0.9355860612460402,0.9355179704016914,0.9365079365079365,0.9364406779661016,0.936373276776246,0.9363057324840764,0.9362380446333688,0.9361702127659575,0.9361022364217252,0.9360341151385928,0.935965848452508,0.9358974358974359,0.9368983957219251,0.936830835117773,0.9367631296891747,0.9366952789699571,0.9366272824919442,0.9365591397849462,0.9364908503767492,0.9364224137931034,0.9374325782092773,0.937365010799136,0.9383783783783783,0.9383116883116883,0.9382448537378115,0.9392624728850325,0.9391965255157437,0.9391304347826087,0.940152339499456,0.9400871459694989,0.9411123227917121,0.9410480349344978,0.940983606557377,0.9409190371991247,0.940854326396495,0.9407894736842105,0.9407244785949506,0.9406593406593406,0.9405940594059405,0.9405286343612335,0.9404630650496141,0.9403973509933775,0.9403314917127071,0.9402654867256637,0.9401993355481728,0.9401330376940134,0.9400665926748057,0.94,0.9399332591768632,0.9398663697104677,0.939799331103679,0.9408482142857143,0.9407821229050279,0.941834451901566,0.9417693169092946,0.9428251121076233,0.9427609427609428,0.9426966292134832,0.9426321709786277,0.9425675675675675,0.9425028184892897,0.9435665914221218,0.943502824858757,0.9434389140271493,0.9445073612684032,0.9444444444444444,0.9443813847900113,0.9443181818181818,0.944254835039818,0.9441913439635535,0.9441277080957811,0.9440639269406392,0.944,0.9450800915331807,0.9450171821305842,0.944954128440367,0.9448909299655568,0.9448275862068966,0.9447640966628308,0.945852534562212,0.9457900807381776,0.9457274826789839,0.945664739884393,0.9456018518518519,0.9455388180764774,0.9454756380510441,0.9465737514518002,0.9476744186046512,0.9476135040745053,0.9475524475524476,0.9474912485414235,0.947429906542056,0.9473684210526315,0.9473067915690867,0.9472450175849941,0.9471830985915493,0.9471210340775558,0.9470588235294117,0.9469964664310954,0.9481132075471698,0.948051948051948,0.9479905437352246,0.9479289940828403,0.9478672985781991,0.9478054567022538,0.9477434679334917,0.9476813317479191,0.9476190476190476,0.9475566150178785,0.9474940334128878,0.9474313022700119,0.9473684210526315,0.9473053892215569,0.947242206235012,0.9471788715486195,0.9471153846153846,0.9470517448856799,0.946987951807229,0.9481302774427021,0.9480676328502415,0.9480048367593712,0.9479418886198547,0.9478787878787879,0.9478155339805825,0.9477521263669502,0.948905109489051,0.9488428745432399,0.948780487804878,0.9487179487179487,0.9486552567237164,0.9498164014687882,0.9497549019607843,0.9496932515337423,0.9496314496314496,0.949569495694957,0.9507389162561576,0.9506781750924784,0.9506172839506173,0.9505562422744128,0.9504950495049505,0.9504337050805453,0.9503722084367245,0.9503105590062112,0.9502487562189055,0.9514321295143213,0.9526184538653366,0.9525593008739076,0.9525,0.9524405506883604,0.9523809523809523,0.9523212045169385,0.9522613065326633,0.9534591194968554,0.9534005037783375,0.9533417402269861,0.9532828282828283,0.9532237673830595,0.9531645569620253,0.9531051964512041,0.9530456852791879,0.9529860228716646,0.9529262086513995,0.9528662420382166,0.9528061224489796,0.9527458492975734,0.9526854219948849,0.9526248399487837,0.9525641025641025,0.9537869062901155,0.9537275064267352,0.9536679536679536,0.9536082474226805,0.9535483870967741,0.9534883720930233,0.9547218628719275,0.9559585492227979,0.9559014267185474,0.9558441558441558,0.9557867360208062,0.9557291666666666,0.9556714471968709,0.9556135770234987,0.9555555555555556,0.9568062827225131,0.9567496723460026,0.9566929133858267,0.9579500657030223,0.9578947368421052,0.9578392621870883,0.9577836411609498,0.9577278731836195,0.9576719576719577,0.9576158940397351,0.9575596816976127,0.9575033200531209,0.9574468085106383,0.9573901464713716,0.9573333333333334,0.9572763684913218,0.9585561497326203,0.9585006693440429,0.9597855227882037,0.959731543624161,0.9596774193548387,0.9596231493943472,0.9595687331536388,0.9608636977058029,0.9608108108108108,0.9607577807848444,0.9607046070460704,0.9606512890094979,0.9605978260869565,0.9619047619047619,0.9618528610354223,0.9618008185538881,0.9617486338797814,0.9616963064295485,0.963013698630137,0.9629629629629629,0.9642857142857143,0.9642365887207703,0.9641873278236914,0.9641379310344828,0.9654696132596685,0.9654218533886584,0.9653739612188366,0.9653259361997226,0.9652777777777778,0.9652294853963839,0.9651810584958217,0.9651324965132496,0.9650837988826816,0.965034965034965,0.9649859943977591,0.9649368863955119,0.9648876404494382,0.9662447257383966,0.9661971830985916,0.9661495063469676,0.9661016949152542,0.9660537482319661,0.9660056657223796,0.9659574468085106,0.9659090909090909,0.9658605974395448,0.9658119658119658,0.9671897289586305,0.9671428571428572,0.9670958512160229,0.9670487106017192,0.9670014347202296,0.9669540229885057,0.9669064748201439,0.9668587896253602,0.9668109668109668,0.9667630057803468,0.9667149059334298,0.9666666666666667,0.9666182873730044,0.9665697674418605,0.9679767103347889,0.967930029154519,0.9678832116788321,0.9678362573099415,0.9677891654465594,0.967741935483871,0.9676945668135095,0.9676470588235294,0.96759941089838,0.967551622418879,0.9675036927621861,0.9674556213017751,0.9674074074074074,0.9673590504451038,0.9673105497771174,0.9672619047619048,0.9672131147540983,0.9671641791044776,0.9671150971599403,0.9670658682634731,0.967016491754123,0.9669669669669669,0.9669172932330827,0.9668674698795181,0.9668174962292609,0.9667673716012085,0.9667170953101362,0.9666666666666667,0.9666160849772383,0.9665653495440729,0.9665144596651446,0.9664634146341463,0.966412213740458,0.9663608562691132,0.9663093415007658,0.9662576687116564,0.9662058371735791,0.9661538461538461,0.9661016949152542,0.9660493827160493,0.9659969088098919,0.9659442724458205,0.9658914728682171,0.9658385093167702,0.9657853810264385,0.9657320872274143,0.9656786271450858,0.965625,0.9655712050078247,0.9655172413793104,0.9654631083202512,0.9654088050314465,0.9653543307086614,0.9652996845425867,0.9652448657187994,0.9651898734177216,0.96513470681458,0.9650793650793651,0.9650238473767886,0.964968152866242,0.9649122807017544,0.9648562300319489,0.9648,0.9647435897435898,0.9646869983948636,0.9646302250803859,0.966183574879227,0.9661290322580646,0.9660743134087237,0.9660194174757282,0.965964343598055,0.9659090909090909,0.9658536585365853,0.9674267100977199,0.967373572593801,0.9673202614379085,0.967266775777414,0.9672131147540983,0.9671592775041051,0.9671052631578947,0.9670510708401977,0.9686468646864687,0.968595041322314,0.9685430463576159,0.9684908789386402,0.96843853820598,0.9683860232945092,0.9683333333333334,0.9682804674457429,0.9682274247491639,0.9681742043551089,0.9681208053691275,0.9680672268907563,0.968013468013468,0.9679595278246206,0.9679054054054054,0.9678510998307953,0.9677966101694915,0.967741935483871,0.967687074829932,0.9676320272572402,0.9675767918088737,0.9675213675213675,0.9691780821917808,0.9691252144082333,0.9690721649484536,0.9690189328743546,0.9706896551724138,0.9706390328151986,0.9705882352941176,0.9705372616984402,0.9704861111111112,0.9704347826086956,0.9703832752613241,0.9703315881326352,0.9702797202797203,0.9702276707530648,0.9701754385964912,0.9701230228471002,0.9700704225352113,0.9700176366843033,0.9699646643109541,0.9699115044247788,0.9698581560283688,0.9698046181172292,0.9697508896797153,0.9696969696969697,0.9696428571428571,0.9695885509838998,0.9695340501792115,0.9694793536804309,0.9694244604316546,0.9693693693693693,0.9693140794223827,0.969258589511754,0.9692028985507246,0.969147005444646,0.9690909090909091,0.9690346083788707,0.968978102189781,0.9689213893967094,0.9688644688644689,0.9688073394495413,0.96875,0.9686924493554327,0.9704797047970479,0.9704251386321626,0.9703703703703703,0.9703153988868275,0.9702602230483272,0.9702048417132216,0.9701492537313433,0.9700934579439252,0.9700374531835206,0.9718574108818011,0.9718045112781954,0.9717514124293786,0.9716981132075472,0.9716446124763705,0.9715909090909091,0.9715370018975332,0.9714828897338403,0.9714285714285714,0.9713740458015268,0.97131931166348,0.9712643678160919,0.9712092130518234,0.9711538461538461,0.9710982658959537,0.971042471042471,0.9709864603481625,0.9728682170542635,0.9728155339805825,0.9727626459143969,0.9727095516569201,0.97265625,0.9726027397260274,0.9725490196078431,0.9724950884086444,0.9724409448818898,0.9723865877712031,0.9723320158102767,0.9722772277227723,0.9722222222222222,0.9721669980119284,0.9721115537848606,0.9720558882235529,0.972,0.9719438877755511,0.9738955823293173,0.9738430583501007,0.9737903225806451,0.9737373737373738,0.9736842105263158,0.973630831643002,0.9735772357723578,0.9735234215885947,0.9755102040816327,0.9754601226993865,0.9754098360655737,0.9753593429158111,0.9753086419753086,0.9752577319587629,0.9752066115702479,0.9751552795031055,0.975103734439834,0.975051975051975,0.975,0.9749478079331941,0.9748953974895398,0.9748427672955975,0.9747899159663865,0.9747368421052631,0.9746835443037974,0.9746300211416491,0.9745762711864406,0.9766454352441614,0.9765957446808511,0.976545842217484,0.9764957264957265,0.9764453961456103,0.9763948497854077,0.9763440860215054,0.9762931034482759,0.9762419006479481,0.9761904761904762,0.9761388286334056,0.9760869565217392,0.9760348583877996,0.9759825327510917,0.975929978118162,0.9758771929824561,0.9758241758241758,0.9757709251101322,0.9757174392935982,0.9756637168141593,0.975609756097561,0.9755555555555555,0.9755011135857461,0.9776785714285714,0.9776286353467561,0.9775784753363229,0.9775280898876404,0.9774774774774775,0.9774266365688488,0.9773755656108597,0.9773242630385488,0.9772727272727273,0.9772209567198178,0.9771689497716894,0.977116704805492,0.9770642201834863,0.9770114942528736,0.9769585253456221,0.976905311778291,0.9768518518518519,0.9767981438515081,0.9767441860465116,0.9766899766899767,0.9766355140186916,0.9765807962529274,0.9765258215962441,0.9764705882352941,0.9764150943396226,0.9763593380614657,0.976303317535545,0.9762470308788599,0.9785714285714285,0.9785202863961814,0.9784688995215312,0.9784172661870504,0.9783653846153846,0.9783132530120482,0.9782608695652174,0.9782082324455206,0.9781553398058253,0.9780487804878049,0.9779951100244498,0.9778869778869779,0.9778325123152709,0.9777777777777777,0.9777227722772277,0.9776674937965261,0.9776119402985075,0.9775561097256857,0.9775,0.9774436090225563,0.9773869346733668,0.9773299748110831,0.9772727272727273,0.9772151898734177,0.9771573604060914,0.9770992366412213,0.9770408163265306,0.9769820971867008,0.9769230769230769,0.9768637532133676,0.9768041237113402,0.9767441860465116,0.9766839378238342,0.9766233766233766,0.9765625,0.9765013054830287,0.9764397905759162,0.9763779527559056,0.9763157894736842,0.9762532981530343,0.9761904761904762,0.9761273209549072,0.976063829787234,0.976,0.9759358288770054,0.9758713136729222,0.9758064516129032,0.9757412398921833,0.9756756756756757,0.975609756097561,0.9755434782608695,0.9754768392370572,0.9754098360655737,0.9753424657534246,0.9752747252747253,0.9752066115702479,0.9751381215469613,0.9750692520775623,0.975,0.9749303621169917,0.9776536312849162,0.9775910364145658,0.9775280898876404,0.9774647887323944,0.9774011299435028,0.9773371104815864,0.9772727272727273,0.9772079772079773,0.9771428571428571,0.9770773638968482,0.9770114942528736,0.9769452449567724,0.976878612716763,0.9768115942028985,0.9767441860465116,0.9766763848396501,0.9766081871345029,0.9765395894428153,0.9764705882352941,0.976401179941003,0.9763313609467456,0.9762611275964391,0.9761904761904762,0.9761194029850746,0.9760479041916168,0.975975975975976,0.9759036144578314,0.9758308157099698,0.9757575757575757,0.9756838905775076,0.975609756097561,0.9755351681957186,0.9754601226993865,0.9753846153846154,0.9753086419753086,0.9752321981424149,0.9751552795031055,0.9750778816199377,0.975,0.9749216300940439,0.9748427672955975,0.9747634069400631,0.9746835443037974,0.9746031746031746,0.9777070063694268,0.9776357827476039,0.9775641025641025,0.977491961414791,0.9774193548387097,0.9773462783171522,0.9772727272727273,0.9771986970684039,0.9771241830065359,0.9770491803278688,0.9769736842105263,0.976897689768977,0.9768211920529801,0.9767441860465116,0.9766666666666667,0.9765886287625418,0.9765100671140939,0.9764309764309764,0.9763513513513513,0.9761904761904762,0.9761092150170648,0.976027397260274,0.9759450171821306,0.9758620689655172,0.9757785467128027,0.9756944444444444,0.975609756097561,0.9755244755244755,0.9754385964912281,0.9753521126760564,0.9752650176678446,0.975177304964539,0.9750889679715302,0.975,0.974910394265233,0.9748201438848921,0.9747292418772563,0.9746376811594203,0.9745454545454545,0.9744525547445255,0.9743589743589743,0.9742647058823529,0.974169741697417,0.9740740740740741,0.9739776951672863,0.9738805970149254,0.9737827715355806,0.9736842105263158,0.9735849056603774,0.9734848484848485,0.973384030418251,0.9732824427480916,0.9731800766283525,0.9730769230769231,0.972972972972973,0.9728682170542635,0.9727626459143969,0.97265625,0.9725490196078431,0.9724409448818898,0.9723320158102767,0.9722222222222222,0.9721115537848606,0.972,0.9718875502008032,0.9717741935483871,0.97165991902834,0.9715447154471545,0.9714285714285714,0.9713114754098361,0.9711934156378601,0.9710743801652892,0.975103734439834,0.975,0.9748953974895398,0.9747899159663865,0.9746835443037974,0.9745762711864406,0.9744680851063829,0.9743589743589743,0.9742489270386266,0.9741379310344828,0.974025974025974,0.9739130434782609,0.9737991266375546,0.9736842105263158,0.973568281938326,0.9734513274336283,0.9733333333333334,0.9732142857142857,0.9730941704035875,0.972972972972973,0.9728506787330317,0.9727272727272728,0.9726027397260274,0.9723502304147466,0.9722222222222222,0.9720930232558139,0.9719626168224299,0.971830985915493,0.9716981132075472,0.9715639810426541,0.9714285714285714,0.9712918660287081,0.9711538461538461,0.9710144927536232,0.970873786407767,0.9707317073170731,0.9705882352941176,0.9704433497536946,0.9702970297029703,0.9701492537313433,0.97,0.9698492462311558,0.9696969696969697,0.9695431472081218,0.9693877551020408,0.9692307692307692,0.9690721649484536,0.9689119170984456,0.96875,0.9685863874345549,0.968421052631579,0.9682539682539683,0.9680851063829787,0.9679144385026738,0.967741935483871,0.9675675675675676,0.967391304347826,0.9672131147540983,0.967032967032967,0.9668508287292817,0.9666666666666667,0.9664804469273743,0.9662921348314607,0.9661016949152542,0.9659090909090909,0.9657142857142857,0.9655172413793104,0.9653179190751445,0.9651162790697675,0.9649122807017544,0.9647058823529412,0.9644970414201184,0.9642857142857143,0.9640718562874252,0.963855421686747,0.9636363636363636,0.9634146341463414,0.9631901840490797,0.9629629629629629,0.9627329192546584,0.9625,0.9622641509433962,0.9620253164556962,0.9617834394904459,0.9615384615384616,0.9612903225806452,0.961038961038961,0.9607843137254902,0.9605263157894737,0.9668874172185431,0.9666666666666667,0.9664429530201343,0.9662162162162162,0.9659863945578231,0.9657534246575342,0.9655172413793104,0.9652777777777778,0.965034965034965,0.9647887323943662,0.9645390070921985,0.9642857142857143,0.9640287769784173,0.9637681159420289,0.9635036496350365,0.9632352941176471,0.9629629629629629,0.9626865671641791,0.9624060150375939,0.9621212121212122,0.9618320610687023,0.9615384615384616,0.9612403100775194,0.9609375,0.9606299212598425,0.9603174603174603,0.96,0.9596774193548387,0.959349593495935,0.9590163934426229,0.9586776859504132,0.9583333333333334,0.957983193277311,0.9576271186440678,0.9572649572649573,0.9568965517241379,0.9565217391304348,0.956140350877193,0.9557522123893806,0.9553571428571429,0.954954954954955,0.9545454545454546,0.9541284403669725,0.9537037037037037,0.9532710280373832,0.9528301886792453,0.9523809523809523,0.9519230769230769,0.9514563106796117,0.9509803921568627,0.9504950495049505,0.95,0.9494949494949495,0.9489795918367347,0.9484536082474226,0.9479166666666666,0.9468085106382979,0.946236559139785,0.9456521739130435,0.945054945054945,0.9444444444444444,0.9438202247191011,0.9431818181818182,0.9425287356321839,0.9418604651162791,0.9411764705882353,0.9404761904761905,0.9397590361445783,0.9390243902439024,0.9382716049382716,0.9375,0.9367088607594937,0.9358974358974359,0.935064935064935,0.9342105263157895,0.9333333333333333,0.9324324324324325,0.9315068493150684,0.9305555555555556,0.9295774647887324,0.9285714285714286,0.927536231884058,0.9264705882352942,0.9253731343283582,0.9242424242424242,0.9230769230769231,0.921875,0.9206349206349206,0.9193548387096774,0.9344262295081968,0.95,0.9491525423728814,0.9482758620689655,0.9473684210526315,0.9464285714285714,0.9454545454545454,0.9444444444444444,0.9433962264150944,0.9423076923076923,0.9411764705882353,0.94,0.9387755102040817,0.9583333333333334,0.9574468085106383,0.9565217391304348,0.9555555555555556,0.9545454545454546,0.9534883720930233,0.9523809523809523,0.9512195121951219,0.95,0.9487179487179487,0.9473684210526315,0.9459459459459459,0.9444444444444444,0.9428571428571428,0.9705882352941176,0.9696969696969697,0.96875,0.967741935483871,0.9655172413793104,0.9642857142857143,0.9629629629629629,0.9615384615384616,0.96,0.9583333333333334,0.9565217391304348,0.9545454545454546,0.9523809523809523,0.95,0.9473684210526315,0.9444444444444444,0.9411764705882353,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],"yaxis":"y"}],"layout":{"height":600,"legend":{"tracegroupgap":0},"shapes":[{"line":{"dash":"dash"},"type":"line","x0":0,"x1":1,"y0":1,"y1":0}],"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"title":{"text":"Precision-Recall Curve (AUC=0.9211)"},"width":800,"xaxis":{"anchor":"y","constrain":"domain","domain":[0,1],"title":{"text":"Recall"}},"yaxis":{"anchor":"x","domain":[0,1],"scaleanchor":"x","scaleratio":1,"title":{"text":"Precision"}}}},"text/html":["<div>                            <div id=\"521f95d9-7fbf-4114-955a-c2295e3db401\" class=\"plotly-graph-div\" style=\"height:600px; width:800px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"521f95d9-7fbf-4114-955a-c2295e3db401\")) {                    Plotly.newPlot(                        \"521f95d9-7fbf-4114-955a-c2295e3db401\",                        [{\"fillpattern\":{\"shape\":\"\"},\"hovertemplate\":\"Recall=%{x}\\u003cbr\\u003ePrecision=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"stackgroup\":\"1\",\"x\":[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9990319457889641,0.9980638915779284,0.9980638915779284,0.9980638915779284,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9970958373668926,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.9961277831558567,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.995159728944821,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9941916747337851,0.9932236205227493,0.9932236205227493,0.9922555663117134,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9912875121006777,0.9903194578896418,0.9903194578896418,0.9903194578896418,0.989351403678606,0.989351403678606,0.989351403678606,0.9883833494675702,0.9874152952565344,0.9864472410454985,0.9854791868344628,0.9854791868344628,0.9845111326234269,0.9835430784123911,0.9835430784123911,0.9825750242013552,0.9816069699903195,0.9806389157792836,0.9806389157792836,0.9796708615682478,0.978702807357212,0.978702807357212,0.9777347531461762,0.9777347531461762,0.9777347531461762,0.9767666989351403,0.9767666989351403,0.9767666989351403,0.9767666989351403,0.9767666989351403,0.9767666989351403,0.9757986447241046,0.9757986447241046,0.9748305905130688,0.9748305905130688,0.9748305905130688,0.9748305905130688,0.9748305905130688,0.9748305905130688,0.9738625363020329,0.9738625363020329,0.972894482090997,0.972894482090997,0.972894482090997,0.9719264278799613,0.9719264278799613,0.9709583736689255,0.9709583736689255,0.9709583736689255,0.9709583736689255,0.9709583736689255,0.9709583736689255,0.9709583736689255,0.9699903194578896,0.9699903194578896,0.9690222652468539,0.9690222652468539,0.9690222652468539,0.968054211035818,0.9670861568247822,0.9661181026137464,0.9651500484027106,0.9641819941916747,0.9641819941916747,0.9641819941916747,0.9641819941916747,0.9641819941916747,0.9641819941916747,0.9632139399806389,0.9622458857696031,0.9622458857696031,0.9622458857696031,0.9622458857696031,0.9612778315585673,0.9603097773475314,0.9593417231364957,0.9593417231364957,0.9593417231364957,0.9593417231364957,0.9583736689254598,0.957405614714424,0.957405614714424,0.9564375605033882,0.9554695062923524,0.9545014520813165,0.9535333978702807,0.9535333978702807,0.952565343659245,0.9515972894482091,0.9515972894482091,0.9506292352371732,0.9496611810261375,0.9486931268151017,0.9477250726040658,0.9467570183930301,0.9457889641819942,0.9448209099709584,0.9448209099709584,0.9438528557599225,0.9438528557599225,0.9438528557599225,0.9438528557599225,0.9438528557599225,0.9428848015488868,0.9419167473378509,0.9419167473378509,0.9409486931268151,0.9399806389157793,0.9390125847047435,0.9380445304937076,0.9380445304937076,0.9380445304937076,0.9380445304937076,0.9370764762826719,0.9370764762826719,0.9370764762826719,0.936108422071636,0.9351403678606002,0.9341723136495643,0.9332042594385286,0.9322362052274927,0.9312681510164569,0.9303000968054211,0.9293320425943853,0.9283639883833494,0.9273959341723137,0.9264278799612778,0.925459825750242,0.925459825750242,0.9244917715392061,0.9244917715392061,0.9235237173281704,0.9225556631171346,0.9215876089060987,0.920619554695063,0.9196515004840271,0.9186834462729913,0.9186834462729913,0.9177153920619555,0.9177153920619555,0.9167473378509197,0.9157792836398838,0.914811229428848,0.914811229428848,0.914811229428848,0.914811229428848,0.9138431752178122,0.9128751210067764,0.9119070667957405,0.9119070667957405,0.9109390125847048,0.9099709583736689,0.9090029041626331,0.9080348499515973,0.9070667957405615,0.9070667957405615,0.9060987415295256,0.9051306873184899,0.904162633107454,0.9031945788964182,0.9022265246853823,0.9012584704743466,0.9002904162633107,0.8993223620522749,0.8993223620522749,0.8983543078412392,0.8983543078412392,0.8973862536302033,0.8973862536302033,0.8964181994191674,0.8954501452081317,0.8944820909970959,0.8944820909970959,0.89351403678606,0.8925459825750242,0.8925459825750242,0.8915779283639884,0.8906098741529526,0.8906098741529526,0.8906098741529526,0.8896418199419167,0.888673765730881,0.8877057115198451,0.8867376573088093,0.8867376573088093,0.8857696030977735,0.8857696030977735,0.8848015488867377,0.8848015488867377,0.8838334946757018,0.8838334946757018,0.8838334946757018,0.882865440464666,0.8818973862536302,0.8818973862536302,0.8809293320425944,0.8799612778315585,0.8789932236205228,0.8789932236205228,0.8789932236205228,0.8780251694094869,0.8770571151984511,0.8760890609874153,0.8751210067763795,0.8741529525653436,0.8731848983543078,0.8731848983543078,0.8731848983543078,0.8731848983543078,0.8731848983543078,0.872216844143272,0.8712487899322362,0.8702807357212003,0.8693126815101646,0.8683446272991288,0.8673765730880929,0.8673765730880929,0.8664085188770572,0.8664085188770572,0.8664085188770572,0.8654404646660213,0.8644724104549855,0.8635043562439496,0.8625363020329139,0.861568247821878,0.8606001936108422,0.8596321393998064,0.8586640851887706,0.8586640851887706,0.8576960309777347,0.856727976766699,0.856727976766699,0.8557599225556631,0.8547918683446273,0.8538238141335914,0.8528557599225557,0.8518877057115198,0.850919651500484,0.8499515972894482,0.8489835430784124,0.8480154888673765,0.8480154888673765,0.8470474346563408,0.846079380445305,0.8451113262342691,0.8441432720232332,0.8431752178121975,0.8422071636011617,0.8412391093901258,0.8412391093901258,0.8402710551790901,0.8402710551790901,0.8393030009680542,0.8383349467570184,0.8383349467570184,0.8373668925459826,0.8363988383349468,0.8363988383349468,0.8354307841239109,0.8354307841239109,0.8344627299128751,0.8334946757018393,0.8325266214908035,0.8315585672797676,0.8305905130687319,0.829622458857696,0.8286544046466602,0.8276863504356244,0.8267182962245886,0.8257502420135527,0.8247821878025169,0.8238141335914811,0.8228460793804453,0.8218780251694094,0.8209099709583737,0.8199419167473379,0.818973862536302,0.8180058083252663,0.8170377541142304,0.8160696999031946,0.8160696999031946,0.8151016456921588,0.8151016456921588,0.814133591481123,0.814133591481123,0.8131655372700871,0.8121974830590513,0.8112294288480155,0.8102613746369797,0.8092933204259438,0.8092933204259438,0.8083252662149081,0.8073572120038722,0.8073572120038722,0.8063891577928364,0.8054211035818006,0.8044530493707648,0.8034849951597289,0.8025169409486931,0.8015488867376573,0.8005808325266215,0.7996127783155856,0.7996127783155856,0.7986447241045499,0.797676669893514,0.7967086156824782,0.7957405614714425,0.7947725072604066,0.7947725072604066,0.7938044530493708,0.7928363988383349,0.7918683446272992,0.7909002904162633,0.7899322362052275,0.7889641819941917,0.7889641819941917,0.7889641819941917,0.7879961277831559,0.78702807357212,0.7860600193610843,0.7850919651500484,0.7841239109390126,0.7831558567279767,0.782187802516941,0.7812197483059051,0.7802516940948693,0.7792836398838335,0.7783155856727977,0.7783155856727977,0.7773475314617618,0.7763794772507261,0.7754114230396902,0.7744433688286544,0.7734753146176185,0.7725072604065828,0.771539206195547,0.7705711519845111,0.7696030977734754,0.7686350435624395,0.7676669893514037,0.7666989351403679,0.7657308809293321,0.7647628267182962,0.7637947725072604,0.7628267182962246,0.7618586640851888,0.7608906098741529,0.7608906098741529,0.7599225556631172,0.7589545014520813,0.7579864472410455,0.7570183930300097,0.7560503388189739,0.755082284607938,0.755082284607938,0.7541142303969022,0.7531461761858664,0.7521781219748306,0.7512100677637947,0.7512100677637947,0.750242013552759,0.7492739593417231,0.7483059051306873,0.7473378509196515,0.7473378509196515,0.7463697967086157,0.7454017424975798,0.744433688286544,0.7434656340755083,0.7424975798644724,0.7415295256534365,0.7405614714424008,0.739593417231365,0.739593417231365,0.739593417231365,0.7386253630203291,0.7376573088092934,0.7366892545982575,0.7357212003872217,0.7347531461761858,0.7337850919651501,0.7337850919651501,0.7328170377541142,0.7318489835430784,0.7308809293320426,0.7299128751210068,0.7289448209099709,0.7279767666989352,0.7270087124878993,0.7260406582768635,0.7250726040658277,0.7241045498547919,0.723136495643756,0.7221684414327202,0.7212003872216844,0.7202323330106486,0.7192642787996127,0.7192642787996127,0.718296224588577,0.7173281703775412,0.7163601161665053,0.7153920619554696,0.7144240077444337,0.7144240077444337,0.7144240077444337,0.7134559535333979,0.712487899322362,0.7115198451113263,0.7105517909002904,0.7095837366892546,0.7086156824782188,0.707647628267183,0.707647628267183,0.7066795740561471,0.7057115198451114,0.7057115198451114,0.7047434656340755,0.7037754114230397,0.7028073572120038,0.7018393030009681,0.7008712487899322,0.6999031945788964,0.6989351403678606,0.6979670861568248,0.6969990319457889,0.6960309777347532,0.6950629235237173,0.6940948693126815,0.6940948693126815,0.6931268151016456,0.6931268151016456,0.6921587608906099,0.691190706679574,0.6902226524685382,0.6892545982575025,0.6892545982575025,0.6882865440464666,0.6873184898354308,0.686350435624395,0.6853823814133592,0.6844143272023233,0.6844143272023233,0.6834462729912875,0.6824782187802517,0.6815101645692159,0.68054211035818,0.68054211035818,0.6795740561471443,0.6795740561471443,0.6786060019361084,0.6776379477250726,0.6766698935140368,0.6766698935140368,0.675701839303001,0.6747337850919651,0.6737657308809293,0.6727976766698935,0.6718296224588577,0.6708615682478218,0.6698935140367861,0.6689254598257502,0.6679574056147144,0.6669893514036787,0.6660212971926428,0.665053242981607,0.665053242981607,0.6640851887705711,0.6631171345595354,0.6621490803484995,0.6611810261374637,0.6602129719264279,0.6592449177153921,0.6582768635043562,0.6573088092933205,0.6563407550822846,0.6563407550822846,0.6553727008712488,0.6544046466602129,0.6534365924491772,0.6524685382381413,0.6515004840271055,0.6505324298160697,0.6495643756050339,0.648596321393998,0.6476282671829623,0.6466602129719264,0.6456921587608906,0.6447241045498547,0.643756050338819,0.643756050338819,0.6427879961277831,0.6418199419167473,0.6408518877057116,0.6398838334946757,0.6389157792836399,0.6379477250726041,0.6369796708615683,0.6360116166505324,0.6350435624394967,0.6340755082284608,0.633107454017425,0.6321393998063891,0.6311713455953534,0.6302032913843175,0.6292352371732817,0.6282671829622459,0.6272991287512101,0.6263310745401742,0.6253630203291385,0.6243949661181026,0.6234269119070668,0.6224588576960309,0.6214908034849952,0.6205227492739593,0.6195546950629235,0.6185866408518877,0.6176185866408519,0.616650532429816,0.6156824782187803,0.6147144240077445,0.6137463697967086,0.6127783155856728,0.611810261374637,0.6108422071636012,0.6098741529525653,0.6089060987415296,0.6079380445304937,0.6069699903194579,0.6060019361084221,0.6050338818973863,0.6040658276863504,0.6030977734753146,0.6021297192642788,0.601161665053243,0.6001936108422071,0.5992255566311714,0.5982575024201355,0.5972894482090997,0.5963213939980639,0.5953533397870281,0.5943852855759922,0.5934172313649564,0.5924491771539206,0.5914811229428848,0.590513068731849,0.5895450145208132,0.5885769603097774,0.5876089060987415,0.5866408518877058,0.5856727976766699,0.5847047434656341,0.5837366892545982,0.5827686350435625,0.5818005808325266,0.5808325266214908,0.5808325266214908,0.579864472410455,0.5788964181994192,0.5779283639883833,0.5769603097773476,0.5759922555663117,0.5750242013552759,0.5750242013552759,0.57405614714424,0.5730880929332043,0.5721200387221684,0.5711519845111326,0.5701839303000968,0.569215876089061,0.5682478218780251,0.5682478218780251,0.5672797676669894,0.5663117134559535,0.5653436592449177,0.5643756050338818,0.5634075508228461,0.5624394966118103,0.5614714424007744,0.5605033881897387,0.5595353339787028,0.558567279767667,0.5575992255566312,0.5566311713455954,0.5556631171345595,0.5546950629235237,0.5537270087124879,0.5527589545014521,0.5517909002904162,0.5508228460793805,0.5498547918683446,0.5488867376573088,0.547918683446273,0.547918683446273,0.5469506292352372,0.5459825750242013,0.5450145208131656,0.5450145208131656,0.5440464666021297,0.5430784123910939,0.542110358180058,0.5411423039690223,0.5401742497579864,0.5392061955469506,0.5382381413359149,0.537270087124879,0.5363020329138432,0.5353339787028074,0.5343659244917716,0.5333978702807357,0.5324298160696999,0.5314617618586641,0.5304937076476283,0.5295256534365924,0.5285575992255567,0.5275895450145208,0.526621490803485,0.5256534365924492,0.5246853823814134,0.5237173281703775,0.5227492739593417,0.5217812197483059,0.5208131655372701,0.5198451113262342,0.5188770571151985,0.5179090029041626,0.5169409486931268,0.515972894482091,0.5150048402710552,0.5140367860600193,0.5130687318489835,0.5121006776379478,0.5111326234269119,0.510164569215876,0.5091965150048403,0.5091965150048403,0.5082284607938045,0.5072604065827686,0.5062923523717329,0.505324298160697,0.5043562439496612,0.5033881897386253,0.5024201355275896,0.5014520813165537,0.5014520813165537,0.5004840271055179,0.4995159728944821,0.4985479186834463,0.4975798644724105,0.49661181026137463,0.49564375605033884,0.494675701839303,0.4937076476282672,0.4927395934172314,0.49177153920619554,0.49080348499515974,0.4898354307841239,0.4888673765730881,0.4878993223620523,0.48693126815101645,0.48596321393998065,0.48596321393998065,0.4849951597289448,0.484027105517909,0.4830590513068732,0.48209099709583736,0.48112294288480156,0.4801548886737657,0.4791868344627299,0.4782187802516941,0.47725072604065827,0.4762826718296225,0.4753146176185866,0.4743465634075508,0.47337850919651503,0.4724104549854792,0.4714424007744434,0.47047434656340753,0.46950629235237173,0.46950629235237173,0.46853823814133594,0.4675701839303001,0.4666021297192643,0.46563407550822844,0.46466602129719264,0.46369796708615685,0.462729912875121,0.462729912875121,0.4617618586640852,0.46079380445304935,0.45982575024201355,0.45885769603097776,0.4578896418199419,0.4569215876089061,0.45595353339787026,0.45498547918683446,0.45401742497579867,0.4530493707647628,0.452081316553727,0.45111326234269117,0.45014520813165537,0.4491771539206196,0.4482090997095837,0.44724104549854793,0.4462729912875121,0.4453049370764763,0.4453049370764763,0.4443368828654405,0.44336882865440463,0.44240077444336884,0.441432720232333,0.4404646660212972,0.4394966118102614,0.43852855759922554,0.43756050338818975,0.4365924491771539,0.4356243949661181,0.4346563407550823,0.43368828654404645,0.43272023233301066,0.4317521781219748,0.430784123910939,0.4298160696999032,0.42884801548886736,0.42787996127783157,0.4269119070667957,0.4259438528557599,0.4249757986447241,0.42400774443368827,0.42400774443368827,0.4230396902226525,0.4220716360116166,0.42110358180058083,0.42013552758954503,0.4191674733785092,0.4181994191674734,0.41723136495643753,0.41626331074540174,0.41529525653436594,0.4143272023233301,0.4133591481122943,0.41239109390125844,0.41142303969022265,0.41045498547918685,0.409486931268151,0.4085188770571152,0.4075508228460794,0.40658276863504356,0.40561471442400776,0.4046466602129719,0.4036786060019361,0.4027105517909003,0.40174249757986447,0.40077444336882867,0.3998063891577928,0.398838334946757,0.3978702807357212,0.3978702807357212,0.3969022265246854,0.3959341723136496,0.39496611810261373,0.39399806389157793,0.39303000968054214,0.3920619554695063,0.3910939012584705,0.39012584704743464,0.38818973862536305,0.3872216844143272,0.38528557599225555,0.38431752178121975,0.38334946757018395,0.3823814133591481,0.3814133591481123,0.38044530493707646,0.37947725072604066,0.37850919651500486,0.377541142303969,0.3765730880929332,0.37560503388189737,0.37463697967086157,0.3736689254598258,0.3727008712487899,0.3717328170377541,0.3707647628267183,0.3697967086156825,0.3688286544046467,0.36786060019361083,0.36689254598257504,0.3659244917715392,0.3649564375605034,0.3639883833494676,0.36302032913843174,0.36205227492739595,0.3610842207163601,0.3601161665053243,0.3591481122942885,0.35818005808325265,0.35721200387221685,0.356243949661181,0.3552758954501452,0.3543078412391094,0.35333978702807356,0.35237173281703776,0.3514036786060019,0.3504356243949661,0.3494675701839303,0.34849951597289447,0.3475314617618587,0.3465634075508228,0.345595353339787,0.34462729912875123,0.3436592449177154,0.3426911907066796,0.34172313649564373,0.34075508228460794,0.33978702807357214,0.3388189738625363,0.3388189738625363,0.3378509196515005,0.33688286544046464,0.33591481122942884,0.33494675701839305,0.3339787028073572,0.3330106485963214,0.33204259438528555,0.33107454017424975,0.33010648596321396,0.3291384317521781,0.3281703775411423,0.32720232333010646,0.32623426911907066,0.32526621490803487,0.324298160696999,0.3233301064859632,0.32236205227492737,0.3213939980638916,0.3204259438528558,0.3194578896418199,0.31848983543078413,0.31752178121974833,0.3165537270087125,0.3155856727976767,0.31461761858664083,0.31364956437560504,0.31268151016456924,0.3117134559535334,0.3107454017424976,0.30977734753146174,0.30880929332042595,0.30784123910939015,0.3068731848983543,0.3059051306873185,0.30493707647628265,0.30396902226524686,0.30300096805421106,0.3020329138431752,0.3010648596321394,0.30009680542110356,0.29912875121006777,0.29816069699903197,0.2971926427879961,0.2971926427879961,0.2962245885769603,0.2952565343659245,0.2942884801548887,0.2933204259438529,0.29235237173281703,0.29138431752178123,0.2904162633107454,0.2894482090997096,0.2884801548886738,0.28751210067763794,0.28654404646660214,0.2855759922555663,0.2846079380445305,0.2836398838334947,0.28267182962245885,0.28170377541142305,0.2807357212003872,0.2797676669893514,0.27783155856727976,0.27686350435624396,0.2758954501452081,0.2749273959341723,0.2739593417231365,0.27299128751210067,0.27202323330106487,0.271055179090029,0.2700871248789932,0.2691190706679574,0.2681510164569216,0.2671829622458858,0.26621490803484993,0.26524685382381413,0.26427879961277834,0.2633107454017425,0.2623426911907067,0.26137463697967084,0.26040658276863504,0.25943852855759925,0.2584704743465634,0.2575024201355276,0.25653436592449175,0.25556631171345595,0.25459825750242016,0.2536302032913843,0.2526621490803485,0.25169409486931266,0.25072604065827686,0.24975798644724104,0.24878993223620524,0.24782187802516942,0.2468538238141336,0.24588576960309777,0.24491771539206195,0.24394966118102615,0.24298160696999033,0.2420135527589545,0.24104549854791868,0.24007744433688286,0.23910939012584706,0.23814133591481124,0.2371732817037754,0.2362052274927396,0.23523717328170377,0.23426911907066797,0.23330106485963215,0.23233301064859632,0.2313649564375605,0.23039690222652467,0.22942884801548888,0.22846079380445306,0.22749273959341723,0.22749273959341723,0.2265246853823814,0.22555663117134558,0.2245885769603098,0.22362052274927396,0.22265246853823814,0.22168441432720232,0.2207163601161665,0.2197483059051307,0.21878025169409487,0.21781219748305905,0.21684414327202323,0.2158760890609874,0.2149080348499516,0.21393998063891578,0.21297192642787996,0.21200387221684414,0.2110358180058083,0.21006776379477252,0.2090997095837367,0.20813165537270087,0.20716360116166505,0.20619554695062922,0.2042594385285576,0.20329138431752178,0.20232333010648595,0.20135527589545016,0.20038722168441434,0.1994191674733785,0.1984511132623427,0.19748305905130686,0.19651500484027107,0.19554695062923524,0.19457889641819942,0.1936108422071636,0.19264278799612777,0.19167473378509198,0.19070667957405615,0.18973862536302033,0.1887705711519845,0.18780251694094868,0.1868344627299129,0.18586640851887706,0.18489835430784124,0.18393030009680542,0.1829622458857696,0.1819941916747338,0.18102613746369797,0.18005808325266215,0.17909002904162633,0.1781219748305905,0.1771539206195547,0.17618586640851888,0.17521781219748306,0.17424975798644723,0.1732817037754114,0.17231364956437561,0.1713455953533398,0.17037754114230397,0.16940948693126814,0.16844143272023232,0.16747337850919652,0.1665053242981607,0.16553727008712488,0.16456921587608905,0.16360116166505323,0.16263310745401743,0.1616650532429816,0.1606969990319458,0.15972894482090996,0.15876089060987417,0.15779283639883834,0.15682478218780252,0.1558567279767667,0.15488867376573087,0.15392061955469508,0.15295256534365925,0.15198451113262343,0.1510164569215876,0.15004840271055178,0.14908034849951599,0.14811229428848016,0.14714424007744434,0.14617618586640851,0.1452081316553727,0.1442400774443369,0.14327202323330107,0.14230396902226525,0.14133591481122942,0.14133591481122942,0.1403678606001936,0.1393998063891578,0.13843175217812198,0.13746369796708616,0.13649564375605033,0.1355275895450145,0.1345595353339787,0.1335914811229429,0.13262342691190707,0.13165537270087124,0.13068731848983542,0.12971926427879962,0.1287512100677638,0.12778315585672798,0.12681510164569215,0.12584704743465633,0.12487899322362052,0.12391093901258471,0.12294288480154889,0.12197483059051308,0.12100677637947725,0.12003872216844143,0.11907066795740562,0.1181026137463698,0.11713455953533398,0.11616650532429816,0.11519845111326234,0.11423039690222653,0.1132623426911907,0.1122942884801549,0.11132623426911907,0.11035818005808325,0.10939012584704744,0.10842207163601161,0.1074540174249758,0.10648596321393998,0.10551790900290416,0.10454985479186835,0.10358180058083252,0.10261374636979671,0.10164569215876089,0.10067763794772508,0.09970958373668926,0.09874152952565343,0.09777347531461762,0.0968054211035818,0.09583736689254599,0.09486931268151017,0.09390125847047434,0.09293320425943853,0.09196515004840271,0.0909970958373669,0.09002904162633107,0.08906098741529525,0.08809293320425944,0.08615682478218781,0.08518877057115198,0.08422071636011616,0.08325266214908035,0.08228460793804453,0.08131655372700872,0.0803484995159729,0.07938044530493708,0.07841239109390126,0.07744433688286544,0.07647628267182963,0.0755082284607938,0.07454017424975799,0.07357212003872217,0.07260406582768635,0.07163601161665054,0.07066795740561471,0.0696999031945789,0.06873184898354308,0.06776379477250725,0.06679574056147145,0.06582768635043562,0.06485963213939981,0.06389157792836399,0.06292352371732816,0.061955469506292354,0.06098741529525654,0.060019361084220714,0.0590513068731849,0.05808325266214908,0.057115198451113264,0.05614714424007745,0.05517909002904162,0.05517909002904162,0.05517909002904162,0.05421103581800581,0.05324298160696999,0.05227492739593417,0.051306873184898356,0.05033881897386254,0.049370764762826716,0.0484027105517909,0.04743465634075508,0.046466602129719266,0.04549854791868345,0.044530493707647625,0.044530493707647625,0.04356243949661181,0.04259438528557599,0.041626331074540175,0.04065827686350436,0.03969022265246854,0.03872216844143272,0.0377541142303969,0.036786060019361085,0.03581800580832527,0.03484995159728945,0.03388189738625363,0.03291384317521781,0.031945788964181994,0.031945788964181994,0.030977734753146177,0.030009680542110357,0.02904162633107454,0.027105517909002903,0.026137463697967087,0.02516940948693127,0.02420135527589545,0.023233301064859633,0.022265246853823813,0.021297192642787996,0.02032913843175218,0.01936108422071636,0.018393030009680542,0.017424975798644726,0.016456921587608905,0.015488867376573089,0.015488867376573089,0.01452081316553727,0.013552758954501452,0.012584704743465635,0.011616650532429816,0.010648596321393998,0.00968054211035818,0.008712487899322363,0.007744433688286544,0.006776379477250726,0.005808325266214908,0.00484027105517909,0.003872216844143272,0.002904162633107454,0.001936108422071636,0.000968054211035818,0.0],\"xaxis\":\"x\",\"y\":[0.7341862117981521,0.7347083926031295,0.7352313167259786,0.7357549857549858,0.7362794012829651,0.7368045649072753,0.7373304782298359,0.7378571428571429,0.7383845604002859,0.7389127324749643,0.7394416607015032,0.7399713467048711,0.7405017921146954,0.7410329985652798,0.741564967695621,0.7420977011494253,0.7426312005751258,0.7431654676258993,0.7437005039596832,0.7442363112391931,0.7447728911319395,0.7453102453102453,0.7458483754512636,0.7463872832369942,0.7469269703543022,0.7474674384949349,0.7480086893555394,0.7485507246376811,0.7490935460478607,0.7496371552975326,0.7501815541031227,0.7507267441860465,0.7512727272727273,0.7518195050946143,0.752367079388201,0.7529154518950437,0.7534646243617797,0.754014598540146,0.7545653761869978,0.7551169590643275,0.7556693489392831,0.7562225475841874,0.7567765567765568,0.7573313782991202,0.7578870139398386,0.7584434654919237,0.7590007347538574,0.7595588235294117,0.7601177336276674,0.7606774668630338,0.7612380250552689,0.7617994100294986,0.7623616236162362,0.7629246676514032,0.7634885439763488,0.7640532544378699,0.764618800888231,0.7651851851851852,0.765752409191994,0.766320474777448,0.7668893838158871,0.7674591381872214,0.7680297397769517,0.7686011904761905,0.7691734921816828,0.7697466467958272,0.7703206562266965,0.7708955223880597,0.7714712471994025,0.7720478325859492,0.7726252804786836,0.7732035928143712,0.7737827715355805,0.7743628185907047,0.7749437359339835,0.7755255255255256,0.7761081893313299,0.7766917293233083,0.7772761474793077,0.7778614457831325,0.7784476262245666,0.7790346907993967,0.779622641509434,0.7802114803625377,0.780801209372638,0.7813918305597579,0.7819833459500378,0.7825757575757576,0.7831690674753601,0.783763277693475,0.7843583902809416,0.7849544072948328,0.785551330798479,0.7861491628614916,0.7867479055597868,0.7873475609756098,0.7879481311975591,0.7885496183206107,0.7891520244461421,0.7897553516819572,0.7903596021423106,0.7909647779479326,0.7915708812260537,0.7921779141104295,0.7927858787413661,0.793394777265745,0.7940046118370484,0.7946153846153846,0.7952270977675134,0.7958397534668721,0.7964533538936006,0.7970679012345679,0.7976833976833977,0.7982998454404946,0.7989172467130704,0.7995356037151703,0.8001549186676995,0.8007751937984496,0.8013964313421257,0.8020186335403726,0.8026418026418026,0.8032659409020217,0.8038910505836576,0.8045171339563862,0.8051441932969603,0.8057722308892356,0.8064012490241999,0.80703125,0.8076622361219703,0.8082942097026604,0.8089271730618638,0.8095611285266457,0.8101960784313725,0.8108320251177394,0.8114689709347996,0.8121069182389937,0.8127458693941778,0.8133858267716535,0.814026792750197,0.8146687697160884,0.8153117600631413,0.815955766192733,0.8166007905138339,0.817246835443038,0.8178939034045922,0.8185419968304279,0.8191911181601903,0.8198412698412698,0.8204924543288324,0.8211446740858506,0.8217979315831344,0.822452229299363,0.8231075697211155,0.8237639553429027,0.8244213886671987,0.8250798722044729,0.8257394084732215,0.8264,0.8270616493194556,0.8277243589743589,0.8283881315156375,0.8290529695024077,0.8297188755020081,0.8303858520900321,0.831053901850362,0.8317230273752013,0.8315874294923449,0.832258064516129,0.8329297820823245,0.8336025848142165,0.8342764753435732,0.8349514563106796,0.8356275303643724,0.8363047001620746,0.8369829683698297,0.8376623376623377,0.8390243902439024,0.8397070789259561,0.8403908794788274,0.8410757946210269,0.8417618270799347,0.8424489795918367,0.8431372549019608,0.8438266557645135,0.8445171849427169,0.8443898443898444,0.8450819672131148,0.8457752255947498,0.8456486042692939,0.8463434675431388,0.8470394736842105,0.8477366255144033,0.8484349258649094,0.8491343775762572,0.849009900990099,0.8497109826589595,0.8504132231404958,0.8511166253101737,0.8518211920529801,0.8525269262634632,0.8532338308457711,0.8539419087136929,0.8546511627906976,0.8553615960099751,0.8560732113144759,0.8567860116569526,0.8575,0.8582151793160967,0.8580968280467446,0.858813700918964,0.8595317725752508,0.8602510460251046,0.8609715242881072,0.8608549874266554,0.8615771812080537,0.8623005877413937,0.8630252100840337,0.8637510513036165,0.8644781144781145,0.8643639427127211,0.8650927487352446,0.8649789029535865,0.8648648648648649,0.8655959425190194,0.8663282571912013,0.8670618120237087,0.8677966101694915,0.8685326547921968,0.8692699490662139,0.8700084961767205,0.8707482993197279,0.8706382978723404,0.8713798977853492,0.8721227621483376,0.8720136518771331,0.8727583262169086,0.8735042735042735,0.8733960650128315,0.8732876712328768,0.8731790916880892,0.8730703259005146,0.8738197424892704,0.8737113402061856,0.8736027515047291,0.8743545611015491,0.8742463393626184,0.8741379310344828,0.8740293356341674,0.8747841105354058,0.874675885911841,0.8745674740484429,0.8753246753246753,0.8752166377816292,0.8759757155247181,0.8767361111111112,0.8766290182450044,0.8773913043478261,0.8781549173194082,0.8789198606271778,0.8796861377506539,0.8804537521815009,0.880349344978166,0.8811188811188811,0.8810148731408574,0.8817863397548161,0.8825591586327782,0.8833333333333333,0.884108867427568,0.8848857644991213,0.8847845206684257,0.8855633802816901,0.8854625550660793,0.8862433862433863,0.8870255957634599,0.8869257950530035,0.887709991158267,0.8876106194690265,0.8883968113374667,0.8891843971631206,0.8899733806566105,0.8907637655417406,0.8915555555555555,0.8923487544483986,0.8922528940338379,0.893048128342246,0.8929527207850134,0.89375,0.8945487042001787,0.8944543828264758,0.8943598925693823,0.8942652329749103,0.8941704035874439,0.8940754039497307,0.894878706199461,0.89568345323741,0.8964896489648965,0.8972972972972973,0.8981064021641119,0.898014440433213,0.8979223125564589,0.8987341772151899,0.8995475113122172,0.9003623188405797,0.900271985494107,0.9001814882032668,0.9000908265213442,0.9009090909090909,0.9017288444040037,0.9025500910746812,0.902461257976299,0.9023722627737226,0.9031963470319635,0.903107861060329,0.9030192131747484,0.9029304029304029,0.9028414298808433,0.9036697247706422,0.9035812672176309,0.9034926470588235,0.9043238270469182,0.9042357274401474,0.904147465437788,0.9040590405904059,0.9039704524469068,0.9038817005545287,0.9037927844588344,0.9037037037037037,0.9045412418906394,0.9044526901669759,0.9052924791086351,0.9061338289962825,0.9069767441860465,0.9078212290502793,0.907735321528425,0.9076492537313433,0.9084967320261438,0.908411214953271,0.9083255378858747,0.9082397003745318,0.9081537019681349,0.9090056285178236,0.9098591549295775,0.9107142857142857,0.9106302916274694,0.911487758945386,0.9123468426013195,0.9122641509433962,0.9121813031161473,0.9120982986767486,0.9120151371807,0.9119318181818182,0.9118483412322275,0.9117647058823529,0.9116809116809117,0.9115969581749049,0.9115128449096099,0.9114285714285715,0.9113441372735939,0.9122137404580153,0.9121298949379179,0.9130019120458891,0.9129186602870814,0.9128352490421456,0.912751677852349,0.9126679462571977,0.9125840537944284,0.9125,0.9133782483156881,0.9132947976878613,0.914175506268081,0.9140926640926641,0.9140096618357488,0.913926499032882,0.914811229428848,0.9156976744186046,0.9165858389912707,0.916504854368932,0.9164237123420796,0.9163424124513618,0.9172346640701071,0.9171539961013645,0.9170731707317074,0.9169921875,0.916911045943304,0.9168297455968689,0.9177277179236043,0.9176470588235294,0.9175662414131501,0.9174852652259332,0.9174041297935103,0.9173228346456693,0.9172413793103448,0.9171597633136095,0.9170779861796644,0.9179841897233202,0.9179030662710188,0.9188118811881189,0.9187314172447968,0.9196428571428571,0.9195630585898709,0.9194831013916501,0.9194029850746268,0.9203187250996016,0.9202392821535393,0.9201596806387226,0.9210789210789211,0.921,0.9209209209209209,0.9218436873747495,0.9227683049147443,0.9226907630522089,0.9226130653266331,0.9225352112676056,0.9224572004028198,0.9233870967741935,0.9233097880928355,0.9242424242424242,0.9241658240647118,0.9251012145748988,0.9250253292806484,0.9259634888438134,0.9269035532994924,0.926829268292683,0.9267548321464903,0.9276985743380856,0.9276248725790011,0.9275510204081633,0.9274770173646578,0.9284253578732107,0.9293756397134084,0.9293032786885246,0.9292307692307692,0.9291581108829569,0.9290853031860226,0.9290123456790124,0.9289392378990731,0.9298969072164949,0.9308565531475749,0.9318181818181818,0.9327817993795243,0.932712215320911,0.9326424870466321,0.9325726141078838,0.9325025960539979,0.9324324324324325,0.9323621227887617,0.9333333333333333,0.9332638164754953,0.9342379958246346,0.93521421107628,0.9351464435146444,0.9350785340314136,0.9350104821802935,0.9349422875131165,0.9348739495798319,0.9348054679284963,0.9347368421052632,0.934668071654373,0.9356540084388185,0.9355860612460402,0.9355179704016914,0.9365079365079365,0.9364406779661016,0.936373276776246,0.9363057324840764,0.9362380446333688,0.9361702127659575,0.9361022364217252,0.9360341151385928,0.935965848452508,0.9358974358974359,0.9368983957219251,0.936830835117773,0.9367631296891747,0.9366952789699571,0.9366272824919442,0.9365591397849462,0.9364908503767492,0.9364224137931034,0.9374325782092773,0.937365010799136,0.9383783783783783,0.9383116883116883,0.9382448537378115,0.9392624728850325,0.9391965255157437,0.9391304347826087,0.940152339499456,0.9400871459694989,0.9411123227917121,0.9410480349344978,0.940983606557377,0.9409190371991247,0.940854326396495,0.9407894736842105,0.9407244785949506,0.9406593406593406,0.9405940594059405,0.9405286343612335,0.9404630650496141,0.9403973509933775,0.9403314917127071,0.9402654867256637,0.9401993355481728,0.9401330376940134,0.9400665926748057,0.94,0.9399332591768632,0.9398663697104677,0.939799331103679,0.9408482142857143,0.9407821229050279,0.941834451901566,0.9417693169092946,0.9428251121076233,0.9427609427609428,0.9426966292134832,0.9426321709786277,0.9425675675675675,0.9425028184892897,0.9435665914221218,0.943502824858757,0.9434389140271493,0.9445073612684032,0.9444444444444444,0.9443813847900113,0.9443181818181818,0.944254835039818,0.9441913439635535,0.9441277080957811,0.9440639269406392,0.944,0.9450800915331807,0.9450171821305842,0.944954128440367,0.9448909299655568,0.9448275862068966,0.9447640966628308,0.945852534562212,0.9457900807381776,0.9457274826789839,0.945664739884393,0.9456018518518519,0.9455388180764774,0.9454756380510441,0.9465737514518002,0.9476744186046512,0.9476135040745053,0.9475524475524476,0.9474912485414235,0.947429906542056,0.9473684210526315,0.9473067915690867,0.9472450175849941,0.9471830985915493,0.9471210340775558,0.9470588235294117,0.9469964664310954,0.9481132075471698,0.948051948051948,0.9479905437352246,0.9479289940828403,0.9478672985781991,0.9478054567022538,0.9477434679334917,0.9476813317479191,0.9476190476190476,0.9475566150178785,0.9474940334128878,0.9474313022700119,0.9473684210526315,0.9473053892215569,0.947242206235012,0.9471788715486195,0.9471153846153846,0.9470517448856799,0.946987951807229,0.9481302774427021,0.9480676328502415,0.9480048367593712,0.9479418886198547,0.9478787878787879,0.9478155339805825,0.9477521263669502,0.948905109489051,0.9488428745432399,0.948780487804878,0.9487179487179487,0.9486552567237164,0.9498164014687882,0.9497549019607843,0.9496932515337423,0.9496314496314496,0.949569495694957,0.9507389162561576,0.9506781750924784,0.9506172839506173,0.9505562422744128,0.9504950495049505,0.9504337050805453,0.9503722084367245,0.9503105590062112,0.9502487562189055,0.9514321295143213,0.9526184538653366,0.9525593008739076,0.9525,0.9524405506883604,0.9523809523809523,0.9523212045169385,0.9522613065326633,0.9534591194968554,0.9534005037783375,0.9533417402269861,0.9532828282828283,0.9532237673830595,0.9531645569620253,0.9531051964512041,0.9530456852791879,0.9529860228716646,0.9529262086513995,0.9528662420382166,0.9528061224489796,0.9527458492975734,0.9526854219948849,0.9526248399487837,0.9525641025641025,0.9537869062901155,0.9537275064267352,0.9536679536679536,0.9536082474226805,0.9535483870967741,0.9534883720930233,0.9547218628719275,0.9559585492227979,0.9559014267185474,0.9558441558441558,0.9557867360208062,0.9557291666666666,0.9556714471968709,0.9556135770234987,0.9555555555555556,0.9568062827225131,0.9567496723460026,0.9566929133858267,0.9579500657030223,0.9578947368421052,0.9578392621870883,0.9577836411609498,0.9577278731836195,0.9576719576719577,0.9576158940397351,0.9575596816976127,0.9575033200531209,0.9574468085106383,0.9573901464713716,0.9573333333333334,0.9572763684913218,0.9585561497326203,0.9585006693440429,0.9597855227882037,0.959731543624161,0.9596774193548387,0.9596231493943472,0.9595687331536388,0.9608636977058029,0.9608108108108108,0.9607577807848444,0.9607046070460704,0.9606512890094979,0.9605978260869565,0.9619047619047619,0.9618528610354223,0.9618008185538881,0.9617486338797814,0.9616963064295485,0.963013698630137,0.9629629629629629,0.9642857142857143,0.9642365887207703,0.9641873278236914,0.9641379310344828,0.9654696132596685,0.9654218533886584,0.9653739612188366,0.9653259361997226,0.9652777777777778,0.9652294853963839,0.9651810584958217,0.9651324965132496,0.9650837988826816,0.965034965034965,0.9649859943977591,0.9649368863955119,0.9648876404494382,0.9662447257383966,0.9661971830985916,0.9661495063469676,0.9661016949152542,0.9660537482319661,0.9660056657223796,0.9659574468085106,0.9659090909090909,0.9658605974395448,0.9658119658119658,0.9671897289586305,0.9671428571428572,0.9670958512160229,0.9670487106017192,0.9670014347202296,0.9669540229885057,0.9669064748201439,0.9668587896253602,0.9668109668109668,0.9667630057803468,0.9667149059334298,0.9666666666666667,0.9666182873730044,0.9665697674418605,0.9679767103347889,0.967930029154519,0.9678832116788321,0.9678362573099415,0.9677891654465594,0.967741935483871,0.9676945668135095,0.9676470588235294,0.96759941089838,0.967551622418879,0.9675036927621861,0.9674556213017751,0.9674074074074074,0.9673590504451038,0.9673105497771174,0.9672619047619048,0.9672131147540983,0.9671641791044776,0.9671150971599403,0.9670658682634731,0.967016491754123,0.9669669669669669,0.9669172932330827,0.9668674698795181,0.9668174962292609,0.9667673716012085,0.9667170953101362,0.9666666666666667,0.9666160849772383,0.9665653495440729,0.9665144596651446,0.9664634146341463,0.966412213740458,0.9663608562691132,0.9663093415007658,0.9662576687116564,0.9662058371735791,0.9661538461538461,0.9661016949152542,0.9660493827160493,0.9659969088098919,0.9659442724458205,0.9658914728682171,0.9658385093167702,0.9657853810264385,0.9657320872274143,0.9656786271450858,0.965625,0.9655712050078247,0.9655172413793104,0.9654631083202512,0.9654088050314465,0.9653543307086614,0.9652996845425867,0.9652448657187994,0.9651898734177216,0.96513470681458,0.9650793650793651,0.9650238473767886,0.964968152866242,0.9649122807017544,0.9648562300319489,0.9648,0.9647435897435898,0.9646869983948636,0.9646302250803859,0.966183574879227,0.9661290322580646,0.9660743134087237,0.9660194174757282,0.965964343598055,0.9659090909090909,0.9658536585365853,0.9674267100977199,0.967373572593801,0.9673202614379085,0.967266775777414,0.9672131147540983,0.9671592775041051,0.9671052631578947,0.9670510708401977,0.9686468646864687,0.968595041322314,0.9685430463576159,0.9684908789386402,0.96843853820598,0.9683860232945092,0.9683333333333334,0.9682804674457429,0.9682274247491639,0.9681742043551089,0.9681208053691275,0.9680672268907563,0.968013468013468,0.9679595278246206,0.9679054054054054,0.9678510998307953,0.9677966101694915,0.967741935483871,0.967687074829932,0.9676320272572402,0.9675767918088737,0.9675213675213675,0.9691780821917808,0.9691252144082333,0.9690721649484536,0.9690189328743546,0.9706896551724138,0.9706390328151986,0.9705882352941176,0.9705372616984402,0.9704861111111112,0.9704347826086956,0.9703832752613241,0.9703315881326352,0.9702797202797203,0.9702276707530648,0.9701754385964912,0.9701230228471002,0.9700704225352113,0.9700176366843033,0.9699646643109541,0.9699115044247788,0.9698581560283688,0.9698046181172292,0.9697508896797153,0.9696969696969697,0.9696428571428571,0.9695885509838998,0.9695340501792115,0.9694793536804309,0.9694244604316546,0.9693693693693693,0.9693140794223827,0.969258589511754,0.9692028985507246,0.969147005444646,0.9690909090909091,0.9690346083788707,0.968978102189781,0.9689213893967094,0.9688644688644689,0.9688073394495413,0.96875,0.9686924493554327,0.9704797047970479,0.9704251386321626,0.9703703703703703,0.9703153988868275,0.9702602230483272,0.9702048417132216,0.9701492537313433,0.9700934579439252,0.9700374531835206,0.9718574108818011,0.9718045112781954,0.9717514124293786,0.9716981132075472,0.9716446124763705,0.9715909090909091,0.9715370018975332,0.9714828897338403,0.9714285714285714,0.9713740458015268,0.97131931166348,0.9712643678160919,0.9712092130518234,0.9711538461538461,0.9710982658959537,0.971042471042471,0.9709864603481625,0.9728682170542635,0.9728155339805825,0.9727626459143969,0.9727095516569201,0.97265625,0.9726027397260274,0.9725490196078431,0.9724950884086444,0.9724409448818898,0.9723865877712031,0.9723320158102767,0.9722772277227723,0.9722222222222222,0.9721669980119284,0.9721115537848606,0.9720558882235529,0.972,0.9719438877755511,0.9738955823293173,0.9738430583501007,0.9737903225806451,0.9737373737373738,0.9736842105263158,0.973630831643002,0.9735772357723578,0.9735234215885947,0.9755102040816327,0.9754601226993865,0.9754098360655737,0.9753593429158111,0.9753086419753086,0.9752577319587629,0.9752066115702479,0.9751552795031055,0.975103734439834,0.975051975051975,0.975,0.9749478079331941,0.9748953974895398,0.9748427672955975,0.9747899159663865,0.9747368421052631,0.9746835443037974,0.9746300211416491,0.9745762711864406,0.9766454352441614,0.9765957446808511,0.976545842217484,0.9764957264957265,0.9764453961456103,0.9763948497854077,0.9763440860215054,0.9762931034482759,0.9762419006479481,0.9761904761904762,0.9761388286334056,0.9760869565217392,0.9760348583877996,0.9759825327510917,0.975929978118162,0.9758771929824561,0.9758241758241758,0.9757709251101322,0.9757174392935982,0.9756637168141593,0.975609756097561,0.9755555555555555,0.9755011135857461,0.9776785714285714,0.9776286353467561,0.9775784753363229,0.9775280898876404,0.9774774774774775,0.9774266365688488,0.9773755656108597,0.9773242630385488,0.9772727272727273,0.9772209567198178,0.9771689497716894,0.977116704805492,0.9770642201834863,0.9770114942528736,0.9769585253456221,0.976905311778291,0.9768518518518519,0.9767981438515081,0.9767441860465116,0.9766899766899767,0.9766355140186916,0.9765807962529274,0.9765258215962441,0.9764705882352941,0.9764150943396226,0.9763593380614657,0.976303317535545,0.9762470308788599,0.9785714285714285,0.9785202863961814,0.9784688995215312,0.9784172661870504,0.9783653846153846,0.9783132530120482,0.9782608695652174,0.9782082324455206,0.9781553398058253,0.9780487804878049,0.9779951100244498,0.9778869778869779,0.9778325123152709,0.9777777777777777,0.9777227722772277,0.9776674937965261,0.9776119402985075,0.9775561097256857,0.9775,0.9774436090225563,0.9773869346733668,0.9773299748110831,0.9772727272727273,0.9772151898734177,0.9771573604060914,0.9770992366412213,0.9770408163265306,0.9769820971867008,0.9769230769230769,0.9768637532133676,0.9768041237113402,0.9767441860465116,0.9766839378238342,0.9766233766233766,0.9765625,0.9765013054830287,0.9764397905759162,0.9763779527559056,0.9763157894736842,0.9762532981530343,0.9761904761904762,0.9761273209549072,0.976063829787234,0.976,0.9759358288770054,0.9758713136729222,0.9758064516129032,0.9757412398921833,0.9756756756756757,0.975609756097561,0.9755434782608695,0.9754768392370572,0.9754098360655737,0.9753424657534246,0.9752747252747253,0.9752066115702479,0.9751381215469613,0.9750692520775623,0.975,0.9749303621169917,0.9776536312849162,0.9775910364145658,0.9775280898876404,0.9774647887323944,0.9774011299435028,0.9773371104815864,0.9772727272727273,0.9772079772079773,0.9771428571428571,0.9770773638968482,0.9770114942528736,0.9769452449567724,0.976878612716763,0.9768115942028985,0.9767441860465116,0.9766763848396501,0.9766081871345029,0.9765395894428153,0.9764705882352941,0.976401179941003,0.9763313609467456,0.9762611275964391,0.9761904761904762,0.9761194029850746,0.9760479041916168,0.975975975975976,0.9759036144578314,0.9758308157099698,0.9757575757575757,0.9756838905775076,0.975609756097561,0.9755351681957186,0.9754601226993865,0.9753846153846154,0.9753086419753086,0.9752321981424149,0.9751552795031055,0.9750778816199377,0.975,0.9749216300940439,0.9748427672955975,0.9747634069400631,0.9746835443037974,0.9746031746031746,0.9777070063694268,0.9776357827476039,0.9775641025641025,0.977491961414791,0.9774193548387097,0.9773462783171522,0.9772727272727273,0.9771986970684039,0.9771241830065359,0.9770491803278688,0.9769736842105263,0.976897689768977,0.9768211920529801,0.9767441860465116,0.9766666666666667,0.9765886287625418,0.9765100671140939,0.9764309764309764,0.9763513513513513,0.9761904761904762,0.9761092150170648,0.976027397260274,0.9759450171821306,0.9758620689655172,0.9757785467128027,0.9756944444444444,0.975609756097561,0.9755244755244755,0.9754385964912281,0.9753521126760564,0.9752650176678446,0.975177304964539,0.9750889679715302,0.975,0.974910394265233,0.9748201438848921,0.9747292418772563,0.9746376811594203,0.9745454545454545,0.9744525547445255,0.9743589743589743,0.9742647058823529,0.974169741697417,0.9740740740740741,0.9739776951672863,0.9738805970149254,0.9737827715355806,0.9736842105263158,0.9735849056603774,0.9734848484848485,0.973384030418251,0.9732824427480916,0.9731800766283525,0.9730769230769231,0.972972972972973,0.9728682170542635,0.9727626459143969,0.97265625,0.9725490196078431,0.9724409448818898,0.9723320158102767,0.9722222222222222,0.9721115537848606,0.972,0.9718875502008032,0.9717741935483871,0.97165991902834,0.9715447154471545,0.9714285714285714,0.9713114754098361,0.9711934156378601,0.9710743801652892,0.975103734439834,0.975,0.9748953974895398,0.9747899159663865,0.9746835443037974,0.9745762711864406,0.9744680851063829,0.9743589743589743,0.9742489270386266,0.9741379310344828,0.974025974025974,0.9739130434782609,0.9737991266375546,0.9736842105263158,0.973568281938326,0.9734513274336283,0.9733333333333334,0.9732142857142857,0.9730941704035875,0.972972972972973,0.9728506787330317,0.9727272727272728,0.9726027397260274,0.9723502304147466,0.9722222222222222,0.9720930232558139,0.9719626168224299,0.971830985915493,0.9716981132075472,0.9715639810426541,0.9714285714285714,0.9712918660287081,0.9711538461538461,0.9710144927536232,0.970873786407767,0.9707317073170731,0.9705882352941176,0.9704433497536946,0.9702970297029703,0.9701492537313433,0.97,0.9698492462311558,0.9696969696969697,0.9695431472081218,0.9693877551020408,0.9692307692307692,0.9690721649484536,0.9689119170984456,0.96875,0.9685863874345549,0.968421052631579,0.9682539682539683,0.9680851063829787,0.9679144385026738,0.967741935483871,0.9675675675675676,0.967391304347826,0.9672131147540983,0.967032967032967,0.9668508287292817,0.9666666666666667,0.9664804469273743,0.9662921348314607,0.9661016949152542,0.9659090909090909,0.9657142857142857,0.9655172413793104,0.9653179190751445,0.9651162790697675,0.9649122807017544,0.9647058823529412,0.9644970414201184,0.9642857142857143,0.9640718562874252,0.963855421686747,0.9636363636363636,0.9634146341463414,0.9631901840490797,0.9629629629629629,0.9627329192546584,0.9625,0.9622641509433962,0.9620253164556962,0.9617834394904459,0.9615384615384616,0.9612903225806452,0.961038961038961,0.9607843137254902,0.9605263157894737,0.9668874172185431,0.9666666666666667,0.9664429530201343,0.9662162162162162,0.9659863945578231,0.9657534246575342,0.9655172413793104,0.9652777777777778,0.965034965034965,0.9647887323943662,0.9645390070921985,0.9642857142857143,0.9640287769784173,0.9637681159420289,0.9635036496350365,0.9632352941176471,0.9629629629629629,0.9626865671641791,0.9624060150375939,0.9621212121212122,0.9618320610687023,0.9615384615384616,0.9612403100775194,0.9609375,0.9606299212598425,0.9603174603174603,0.96,0.9596774193548387,0.959349593495935,0.9590163934426229,0.9586776859504132,0.9583333333333334,0.957983193277311,0.9576271186440678,0.9572649572649573,0.9568965517241379,0.9565217391304348,0.956140350877193,0.9557522123893806,0.9553571428571429,0.954954954954955,0.9545454545454546,0.9541284403669725,0.9537037037037037,0.9532710280373832,0.9528301886792453,0.9523809523809523,0.9519230769230769,0.9514563106796117,0.9509803921568627,0.9504950495049505,0.95,0.9494949494949495,0.9489795918367347,0.9484536082474226,0.9479166666666666,0.9468085106382979,0.946236559139785,0.9456521739130435,0.945054945054945,0.9444444444444444,0.9438202247191011,0.9431818181818182,0.9425287356321839,0.9418604651162791,0.9411764705882353,0.9404761904761905,0.9397590361445783,0.9390243902439024,0.9382716049382716,0.9375,0.9367088607594937,0.9358974358974359,0.935064935064935,0.9342105263157895,0.9333333333333333,0.9324324324324325,0.9315068493150684,0.9305555555555556,0.9295774647887324,0.9285714285714286,0.927536231884058,0.9264705882352942,0.9253731343283582,0.9242424242424242,0.9230769230769231,0.921875,0.9206349206349206,0.9193548387096774,0.9344262295081968,0.95,0.9491525423728814,0.9482758620689655,0.9473684210526315,0.9464285714285714,0.9454545454545454,0.9444444444444444,0.9433962264150944,0.9423076923076923,0.9411764705882353,0.94,0.9387755102040817,0.9583333333333334,0.9574468085106383,0.9565217391304348,0.9555555555555556,0.9545454545454546,0.9534883720930233,0.9523809523809523,0.9512195121951219,0.95,0.9487179487179487,0.9473684210526315,0.9459459459459459,0.9444444444444444,0.9428571428571428,0.9705882352941176,0.9696969696969697,0.96875,0.967741935483871,0.9655172413793104,0.9642857142857143,0.9629629629629629,0.9615384615384616,0.96,0.9583333333333334,0.9565217391304348,0.9545454545454546,0.9523809523809523,0.95,0.9473684210526315,0.9444444444444444,0.9411764705882353,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Recall\"},\"constrain\":\"domain\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Precision\"},\"scaleanchor\":\"x\",\"scaleratio\":1},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Precision-Recall Curve (AUC=0.9211)\"},\"height\":600,\"width\":800,\"shapes\":[{\"line\":{\"dash\":\"dash\"},\"type\":\"line\",\"x0\":0,\"x1\":1,\"y0\":1,\"y1\":0}],\"showlegend\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('521f95d9-7fbf-4114-955a-c2295e3db401');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"}],"source":["target_score = xgb_clf.predict_proba(features_valid)[:, 1]\n","\n","fpr, tpr, thresholds = roc_curve(target_valid, target_score)\n","\n","fig = px.area(\n","    x=fpr, y=tpr,\n","    title=f'ROC Curve (AUC={auc(fpr, tpr):.4f})',\n","    labels=dict(x='False Positive Rate', y='True Positive Rate'),\n","    width=800, height=600\n",")\n","fig.add_shape(\n","    type='line', line=dict(dash='dash'),\n","    x0=0, x1=1, y0=0, y1=1\n",")\n","\n","fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n","fig.update_xaxes(constrain='domain')\n","fig.update_layout(showlegend=False)\n","fig.show()\n","\n","precision, recall, thresholds = precision_recall_curve(target_valid, target_score)\n","\n","fig = px.area(\n","    x=recall, y=precision,\n","    title=f'Precision-Recall Curve (AUC={auc(fpr, tpr):.4f})',\n","    labels=dict(x='Recall', y='Precision'),\n","    width=800, height=600\n",")\n","fig.add_shape(\n","    type='line', line=dict(dash='dash'),\n","    x0=0, x1=1, y0=1, y1=0\n",")\n","fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n","fig.update_xaxes(constrain='domain')\n","fig.update_layout(showlegend=False)\n","fig.show()"]},{"cell_type":"markdown","metadata":{},"source":["--------"]},{"cell_type":"markdown","metadata":{},"source":["# Final Evaluation"]},{"cell_type":"markdown","metadata":{},"source":["`Model Selection - Average Score Comparison`\n","\n","`Note`\n","\n","- We've selected LightGBM as our optimal model based on score comparisons, it also performs much better compared to other models when it comes to scoring and speed. XGBClassifier is similar to our LightGBM model but takes considerably longer to compute."]},{"cell_type":"code","execution_count":658,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T17:05:07.620683Z","iopub.status.busy":"2023-11-30T17:05:07.620368Z","iopub.status.idle":"2023-11-30T17:05:07.627835Z","shell.execute_reply":"2023-11-30T17:05:07.626805Z","shell.execute_reply.started":"2023-11-30T17:05:07.620644Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Average Cross Validation Scores:\n","RandomForestClassifier: 0.8760777711552042\n","DecisionTreeClassifier: 0.7530509062867848\n","ExtraTreesClassifier: 0.8479972754101266\n","\n","LogisticRegression: 0.829162458233739\n","RidgeClassifier: 0.8259667628691291\n","\n","LightGBM: 0.9078685635877259\n","XGBoost: 0.908791215308284\n"]}],"source":["print('Average Cross Validation Scores:')\n","print('RandomForestClassifier: {}'.format(forest_scores.mean()))\n","print('DecisionTreeClassifier: {}'.format(tree_scores.mean()))\n","print('ExtraTreesClassifier: {}'.format(extra_trees_scores.mean()))\n","print()\n","print('LogisticRegression: {}'.format(log_scores.mean()))\n","print('RidgeClassifier: {}'.format(ridge_scores.mean()))\n","print()\n","print('LightGBM: {}'.format(lgb_scores.mean()))\n","print('XGBoost: {}'.format(xgb_scores.mean()))"]},{"cell_type":"markdown","metadata":{},"source":["`Model Selection - Feature Importances`"]},{"cell_type":"code","execution_count":659,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[LightGBM] [Info] Number of positive: 3097, number of negative: 1121\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001393 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 4218, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734234 -> initscore=1.016213\n","[LightGBM] [Info] Start training from score 1.016213\n"]},{"name":"stdout","output_type":"stream","text":["Feature Importance:\n"]},{"data":{"text/plain":["{'total_charges': 795,\n"," 'monthly_charges': 647,\n"," 'begin_month': 326,\n"," 'begin_year': 203,\n"," 'begin_dayofweek': 138,\n"," 'payment_method': 79,\n"," 'gender': 65,\n"," 'contract_type': 51,\n"," 'online_security': 44,\n"," 'tech_support': 40,\n"," 'senior_citizen': 38,\n"," 'online_backup': 38,\n"," 'partner': 36,\n"," 'paperless_billing': 32,\n"," 'multiple_lines': 31,\n"," 'dependents': 30,\n"," 'internet_service': 29,\n"," 'device_protection': 27,\n"," 'streaming_movies': 26,\n"," 'streaming_tv': 25}"]},"execution_count":659,"metadata":{},"output_type":"execute_result"}],"source":["boost = lgb_model.fit(features_train, target_train).booster_\n","# print('Feature names',boost.feature_name())\n","\n","print('Feature Importance:')\n","{k: v for k, v in sorted(zip(boost.feature_name(), lgb_clf.best_estimator_.feature_importances_), key= lambda x: x[1], reverse=True)}"]},{"cell_type":"code","execution_count":660,"metadata":{},"outputs":[],"source":["r = {k: v for k, v in sorted(zip(boost.feature_name(), lgb_clf.best_estimator_.feature_importances_), key= lambda x: x[1], reverse=True)}"]},{"cell_type":"code","execution_count":661,"metadata":{},"outputs":[{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"fill":"toself","r":[795,647,326,203,138,79,65,51,44,40],"theta":["total_charges","monthly_charges","begin_month","begin_year","begin_dayofweek","payment_method","gender","contract_type","online_security","tech_support"],"type":"scatterpolar"}],"layout":{"autosize":false,"polar":{"angularaxis":{"direction":"clockwise","period":6},"radialaxis":{"angle":-45}},"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"#E5ECF6","showlakes":true,"showland":true,"subunitcolor":"white"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"bgcolor":"#E5ECF6","radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"bgcolor":"#E5ECF6","caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","zerolinewidth":2}}},"title":{"text":"<b>Top 10 Most Important Features</b><br><sup>LightGBM</sup>"}}},"text/html":["<div>                            <div id=\"e42ff4db-87d6-46cc-90ab-1a71aeb73641\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"e42ff4db-87d6-46cc-90ab-1a71aeb73641\")) {                    Plotly.newPlot(                        \"e42ff4db-87d6-46cc-90ab-1a71aeb73641\",                        [{\"r\":[795,647,326,203,138,79,65,51,44,40],\"theta\":[\"total_charges\",\"monthly_charges\",\"begin_month\",\"begin_year\",\"begin_dayofweek\",\"payment_method\",\"gender\",\"contract_type\",\"online_security\",\"tech_support\"],\"type\":\"scatterpolar\",\"fill\":\"toself\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"polar\":{\"radialaxis\":{\"angle\":-45},\"angularaxis\":{\"direction\":\"clockwise\",\"period\":6}},\"title\":{\"text\":\"\\u003cb\\u003eTop 10 Most Important Features\\u003c\\u002fb\\u003e\\u003cbr\\u003e\\u003csup\\u003eLightGBM\\u003c\\u002fsup\\u003e\"},\"autosize\":false},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('e42ff4db-87d6-46cc-90ab-1a71aeb73641');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"}],"source":["fig = go.Figure(data=go.Scatterpolar(r = list(r.values())[:10],\n","               theta= list(r.keys())[:10]))\n","\n","fig.update_traces(fill='toself')\n","fig.update_layout(polar=dict(radialaxis_angle=-45, angularaxis= dict(direction='clockwise',period=6)))\n","\n","fig.update_layout(title_text='<b>Top 10 Most Important Features</b><br><sup>LightGBM</sup>',autosize=False)\n","\n","fig.show()"]},{"cell_type":"markdown","metadata":{},"source":["`Model Selection - Confusion Matrix`\n"]},{"cell_type":"code","execution_count":662,"metadata":{},"outputs":[{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"colorscale":[[0,"rgb(247,251,255)"],[0.125,"rgb(222,235,247)"],[0.25,"rgb(198,219,239)"],[0.375,"rgb(158,202,225)"],[0.5,"rgb(107,174,214)"],[0.625,"rgb(66,146,198)"],[0.75,"rgb(33,113,181)"],[0.875,"rgb(8,81,156)"],[1,"rgb(8,48,107)"]],"reversescale":false,"showscale":true,"type":"heatmap","x":["Class: 0","Class: 1"],"y":["Class: 0","Class: 1"],"z":[[253,121],[56,977]]}],"layout":{"annotations":[{"font":{"color":"#000000"},"showarrow":false,"text":"253","x":"Class: 0","xref":"x","y":"Class: 0","yref":"y"},{"font":{"color":"#000000"},"showarrow":false,"text":"121","x":"Class: 1","xref":"x","y":"Class: 0","yref":"y"},{"font":{"color":"#000000"},"showarrow":false,"text":"56","x":"Class: 0","xref":"x","y":"Class: 1","yref":"y"},{"font":{"color":"#FFFFFF"},"showarrow":false,"text":"977","x":"Class: 1","xref":"x","y":"Class: 1","yref":"y"},{"font":{"color":"black","size":14},"showarrow":false,"text":"Predicted value","x":0.5,"xref":"paper","y":-0.15,"yref":"paper"},{"font":{"color":"black","size":14},"showarrow":false,"text":"Real value","textangle":-90,"x":-0.15,"xref":"paper","y":0.5,"yref":"paper"}],"height":500,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"#E5ECF6","showlakes":true,"showland":true,"subunitcolor":"white"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"bgcolor":"#E5ECF6","radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"bgcolor":"#E5ECF6","caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","zerolinewidth":2}}},"title":{"text":"<b>Confusion matrix</b><br><sup>LightGBM</sup>"},"width":500,"xaxis":{"dtick":1,"gridcolor":"rgb(0, 0, 0)","side":"top","ticks":""},"yaxis":{"dtick":1,"ticks":"","ticksuffix":"  "}}},"text/html":["<div>                            <div id=\"7baf61de-020d-4e76-96bf-9dbb3fe4705e\" class=\"plotly-graph-div\" style=\"height:500px; width:500px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"7baf61de-020d-4e76-96bf-9dbb3fe4705e\")) {                    Plotly.newPlot(                        \"7baf61de-020d-4e76-96bf-9dbb3fe4705e\",                        [{\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"reversescale\":false,\"showscale\":true,\"x\":[\"Class: 0\",\"Class: 1\"],\"y\":[\"Class: 0\",\"Class: 1\"],\"z\":[[253,121],[56,977]],\"type\":\"heatmap\"}],                        {\"annotations\":[{\"font\":{\"color\":\"#000000\"},\"showarrow\":false,\"text\":\"253\",\"x\":\"Class: 0\",\"xref\":\"x\",\"y\":\"Class: 0\",\"yref\":\"y\"},{\"font\":{\"color\":\"#000000\"},\"showarrow\":false,\"text\":\"121\",\"x\":\"Class: 1\",\"xref\":\"x\",\"y\":\"Class: 0\",\"yref\":\"y\"},{\"font\":{\"color\":\"#000000\"},\"showarrow\":false,\"text\":\"56\",\"x\":\"Class: 0\",\"xref\":\"x\",\"y\":\"Class: 1\",\"yref\":\"y\"},{\"font\":{\"color\":\"#FFFFFF\"},\"showarrow\":false,\"text\":\"977\",\"x\":\"Class: 1\",\"xref\":\"x\",\"y\":\"Class: 1\",\"yref\":\"y\"},{\"font\":{\"color\":\"black\",\"size\":14},\"showarrow\":false,\"text\":\"Predicted value\",\"x\":0.5,\"xref\":\"paper\",\"y\":-0.15,\"yref\":\"paper\"},{\"font\":{\"color\":\"black\",\"size\":14},\"showarrow\":false,\"text\":\"Real value\",\"textangle\":-90,\"x\":-0.15,\"xref\":\"paper\",\"y\":0.5,\"yref\":\"paper\"}],\"xaxis\":{\"dtick\":1,\"gridcolor\":\"rgb(0, 0, 0)\",\"side\":\"top\",\"ticks\":\"\"},\"yaxis\":{\"dtick\":1,\"ticks\":\"\",\"ticksuffix\":\"  \"},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"\\u003cb\\u003eConfusion matrix\\u003c\\u002fb\\u003e\\u003cbr\\u003e\\u003csup\\u003eLightGBM\\u003c\\u002fsup\\u003e\"},\"height\":500,\"width\":500},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('7baf61de-020d-4e76-96bf-9dbb3fe4705e');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"}],"source":["import plotly.figure_factory as ff\n","\n","# heatmap\n","\n","cm = confusion_matrix(target_valid, lgb_pred)\n","\n","labels = ['Class: 0', 'Class: 1']\n","heatmap = go.Heatmap(z=cm, x=labels, y=labels, colorscale='Blues')\n","\n","# data labels\n","data_labels = [[y for y in x] for x in cm]\n","\n","# figure\n","fig = ff.create_annotated_heatmap(z=cm, x=labels, y=labels, annotation_text=data_labels, colorscale='Blues')\n","\n","# title\n","fig.update_layout(title_text='<b>Confusion matrix</b><br><sup>LightGBM</sup>'\n","                  #xaxis = dict(title='x'),\n","                  #yaxis = dict(title='x')\n","                 )\n","\n","# add custom xaxis title\n","fig.add_annotation(dict(font=dict(color=\"black\",size=14),\n","                        x=0.5,\n","                        y=-0.15,\n","                        showarrow=False,\n","                        text=\"Predicted value\",\n","                        xref=\"paper\",\n","                        yref=\"paper\"))\n","\n","# add custom yaxis title\n","fig.add_annotation(dict(font=dict(color=\"black\",size=14),\n","                        x=-0.15,\n","                        y=0.5,\n","                        showarrow=False,\n","                        text=\"Real value\",\n","                        textangle=-90,\n","                        xref=\"paper\",\n","                        yref=\"paper\"))\n","\n","# margin update\n","fig.update_layout(height=500, width=500)\n","\n","# colorbar\n","fig['data'][0]['showscale'] = True\n","\n","\n","fig.show()"]},{"cell_type":"markdown","metadata":{},"source":["`Model Selection - Final Evaluation`"]},{"cell_type":"markdown","metadata":{},"source":["`Note`\n","\n","After further review, given the ROC curve is calculated by taking each possible probability I've replaced my final ROC AUC Score with predictions using `.predict_proba()` which yields better results (91.56% vs 80.15% in the previously reviewed solution code)."]},{"cell_type":"code","execution_count":663,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T17:05:07.684311Z","iopub.status.busy":"2023-11-30T17:05:07.683993Z","iopub.status.idle":"2023-11-30T17:05:07.817022Z","shell.execute_reply":"2023-11-30T17:05:07.816316Z","shell.execute_reply.started":"2023-11-30T17:05:07.684279Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Final evaluation on test set:\n","\n","[LightGBM] [Info] Number of positive: 3097, number of negative: 1121\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001029 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 570\n","[LightGBM] [Info] Number of data points in the train set: 4218, number of used features: 20\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.734234 -> initscore=1.016213\n","[LightGBM] [Info] Start training from score 1.016213\n"]},{"name":"stdout","output_type":"stream","text":["ROC AUC Score: 91.56 %\n"]}],"source":["print('Final evaluation on test set:')\n","print()\n","# model\n","final_model = lgb.LGBMClassifier(random_state=random_state)\n","# train\n","final_model.fit(features_train, target_train)\n","# predict\n","final_predictions_test = final_model.predict(features_test)\n","final_predictions_test_proba = final_model.predict_proba(features_test)[:, 1]\n","# accuracy check\n","# final_model_accuracy = accuracy_score(target_test, final_predictions_test)\n","# final_model_f1 = f1_score(target_test, final_predictions_test)\n","final_model_roc_auc = roc_auc_score(target_test, final_predictions_test_proba)\n","#result\n","print('ROC AUC Score:',   round((final_model_roc_auc * 100), 2),'%') "]},{"cell_type":"markdown","metadata":{},"source":["# Part 3: Solution Report"]},{"cell_type":"markdown","metadata":{},"source":["`What steps of the plan were performed and what steps were skipped (explain why)?`\n","- We performed most of the steps from Part 1 minus the following:\n","    - Time series analyses - this was not needed afterall our general EDA/preprocessing was sufficient but could have been performed to paint a picture on the sign-up dates for each client.\n","\n","`What difficulties did you encounter and how did you manage to solve them?`\n","- Initially, we found some slight difficulties performing the ideal process of scaling and taking into account class imbalancing in models. We took more time to read documentation and found our effective solutions. This was as simple as moving the order of our code, fitting our scaler on just the training dataset and leveraging `RepeatedStratifiedKFold()` in our `RandomizedSearchGridCV()` for each model.\n","\n","- There were also some minor road bumps with some of the missing data which was not perceptible at first glance. We ran an iterative function to find said discrepancies and select our method of handling such (replacing, filling in or removing).\n","\n","`What were some of the key steps to solving the task?`\n","- Putting the project plan together and understanding the business goals first and foremost.\n","- Choosing this scoring metric before the analysis, so there are no distractions when making task decisions.\n","    - Not using an absolute measure (accuracy) but a relative-to-each-class measure (like ROC AUC).\n","- Getting a grasp on what type of data we are working with (especifially the data imbalance point) and how it will be consumed by our multiple model choices.\n","- Taking into account some of the decisions we make in EDA/Preprocessing and how they will later impact our results. Noting such decisions as we go and leaving the door open for futher flexibility in case of issues (like easily being able to amend our choices if we hit a roadblock or being able revert back to original).\n","- On the modeling side of things, having a benchmark model scenario to compare to (a dummy model) as well as deploying any type of gridsearch so we can find optimal model parameters and tune accordingly. \n","- Cross comparing model scores to find the ideal model but also taking into account some of the other values such as computing speed/burden. A compromise will have to be made at times (*e.g. not always selecting the highest scoring model*)\n","\n","\n","`What is your final model and what quality score does it have?`\n","- Our final model is the LightGBM model given there was a good balance of a high `cross_val_score` and computing speed. This originally yielded us an AUC ROC score of 80.15% based on using `.predict()` but after futher review, we've deployed `.predict_proba()` in the score calculation which yielded us a 91.56% score on a new, imbalanced test dataset. The recommendation to Interconnect is to use LightGBM to predict the customer churn rate given the scoring, its speed and the further flexibility the model deploys if modifications are needed as data changes or evolves.\n"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4018738,"sourceId":6991786,"sourceType":"datasetVersion"}],"dockerImageVersionId":30587,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":true,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false}},"nbformat":4,"nbformat_minor":4}
